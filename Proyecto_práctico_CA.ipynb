{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUehXgCyIRdq"
      },
      "source": [
        "# Actividad - Proyecto práctico\n",
        "\n",
        "\n",
        "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
        "*   Alumno 1: Camilo José Alape Herrera\n",
        "*   Alumno 2: Jonathan Catota\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwpYlnjWJhS9"
      },
      "source": [
        "---\n",
        "## **PARTE 1** - Instalación y requisitos previos\n",
        "\n",
        "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
        "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
        "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
        "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
        "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU2BPrK2JkP0"
      },
      "source": [
        "---\n",
        "### 1.1. Preparar enviroment (solo local)\n",
        "\n",
        "\n",
        "\n",
        "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
        "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
        "2. Instalar Anaconda\n",
        "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
        "\n",
        "\n",
        "```\n",
        "conda create --name miar_rl python=3.8\n",
        "conda activate miar_rl\n",
        "cd \"PATH_TO_FOLDER\"\n",
        "conda install git\n",
        "pip install jupyter\n",
        "```\n",
        "\n",
        "\n",
        "4. Abrir la notebook con *jupyter-notebook*.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "jupyter-notebook\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-kixNPiJqTc"
      },
      "source": [
        "---\n",
        "### 1.2. Localizar entorno de trabajo: Google colab o local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA2kZDPAUAKd",
        "outputId": "a799c229-39de-4fa2-a356-13e0332cbf46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jul 13 22:13:54 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dru79QPmOiN7",
        "outputId": "160bdad2-c1c9-4eb3-ba94-0ea8b6deb898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_YDFwZ-JscI"
      },
      "outputs": [],
      "source": [
        "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
        "mount='/content/gdrive'\n",
        "drive_root = mount + \"/My Drive/08_MIAR/actividades/proyecto practico\"\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dp_a1iBJ0tf"
      },
      "source": [
        "---\n",
        "### 1.3. Montar carpeta de datos local (solo Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6n7MIefJ21i",
        "outputId": "9041c3d7-1f89-4a65-a3ff-6ea840f8f31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We're running Colab\n",
            "Colab: mounting Google drive on  /content/gdrive\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "Colab: making sure  /content/gdrive/My Drive/08_MIAR/actividades/proyecto practico  exists.\n",
            "\n",
            "Colab: Changing directory to  /content/gdrive/My Drive/08_MIAR/actividades/proyecto practico\n",
            "/content/gdrive/My Drive/08_MIAR/actividades/proyecto practico\n",
            "Archivos en el directorio: \n",
            "['dqn_SpaceInvaders-v0_dueling_double.h5f.data-00000-of-00001', 'dqn_SpaceInvaders-v0_dueling_double.h5f.index', 'dqn_SpaceInvaders-v0_refined_weights_100000.h5f.data-00000-of-00001', 'dqn_SpaceInvaders-v0_refined_weights_100000.h5f.index', 'dqn_SpaceInvaders-v0_refined_log.json', 'boltzmann_weights.h5f.data-00000-of-00001', 'boltzmann_weights.h5f.index', 'boltzmann_log.json', 'double_weights.h5f.data-00000-of-00001', 'double_weights.h5f.index', 'double_log.json', 'dueling_weights.h5f.data-00000-of-00001', 'dueling_weights.h5f.index', 'dueling_log.json', 'combo_log.json', 'combo_weights_100000.h5f.data-00000-of-00001', 'combo_weights_100000.h5f.index', 'baseline_weights_100000.h5f.data-00000-of-00001', 'baseline_weights_100000.h5f.index', 'baseline_weights_200000.h5f.data-00000-of-00001', 'baseline_weights_200000.h5f.index', 'baseline_weights_300000.h5f.data-00000-of-00001', 'baseline_weights_300000.h5f.index', 'baseline_log.json', 'baseline_weights.h5f.index', 'baseline_weights.h5f.data-00000-of-00001', 'checkpoint']\n"
          ]
        }
      ],
      "source": [
        "# Switch to the directory on the Google Drive that you want to use\n",
        "import os\n",
        "if IN_COLAB:\n",
        "  print(\"We're running Colab\")\n",
        "\n",
        "  if IN_COLAB:\n",
        "    # Mount the Google Drive at mount\n",
        "    print(\"Colab: mounting Google drive on \", mount)\n",
        "\n",
        "    drive.mount(mount)\n",
        "\n",
        "    # Create drive_root if it doesn't exist\n",
        "    create_drive_root = True\n",
        "    if create_drive_root:\n",
        "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
        "      os.makedirs(drive_root, exist_ok=True)\n",
        "\n",
        "    # Change to the directory\n",
        "    print(\"\\nColab: Changing directory to \", drive_root)\n",
        "    %cd $drive_root\n",
        "# Verify we're in the correct working directory\n",
        "%pwd\n",
        "print(\"Archivos en el directorio: \")\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1ZSL5bpJ560"
      },
      "source": [
        "---\n",
        "### 1.4. Instalar librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UbVRjvHCJ8UF",
        "outputId": "cd295f5d-d806-4bee-b921-ec2adfe468f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.18.5\n",
            "  Using cached numpy-1.18.5.zip (5.4 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: gym==0.17.3 in /usr/local/lib/python3.11/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gym==0.17.3) (1.15.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from gym==0.17.3) (2.0.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.17.3) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.17.3) (1.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
            "Collecting git+https://github.com/Kojoley/atari-py.git\n",
            "  Cloning https://github.com/Kojoley/atari-py.git to /tmp/pip-req-build-igv925_7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Kojoley/atari-py.git /tmp/pip-req-build-igv925_7\n",
            "  Resolved https://github.com/Kojoley/atari-py.git to commit 86a1e05c0a95e9e6233c3a413521fdb34ca8a089\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from atari-py==1.2.2) (2.0.2)\n",
            "Building wheels for collected packages: atari-py\n",
            "  Building wheel for atari-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atari-py: filename=atari_py-1.2.2-cp311-cp311-linux_x86_64.whl size=4738555 sha256=41455e98a75654ecf3d9306d7687c8db1dba7d8025f3f9b53091cc4e8c468a3b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b4lopw8s/wheels/1a/58/b3/3baab9d1509939ecce2dfd9ca349c222b7ee6590f4bd6097a1\n",
            "Successfully built atari-py\n",
            "Installing collected packages: atari-py\n",
            "Successfully installed atari-py-1.2.2\n",
            "Collecting keras-rl2==1.0.5\n",
            "  Using cached keras_rl2-1.0.5-py3-none-any.whl.metadata (304 bytes)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from keras-rl2==1.0.5) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2==1.0.5) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (0.1.2)\n",
            "Using cached keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n",
            "Collecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.73.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.14.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.2,>=0.6.2 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.15.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2025.7.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.3.1)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.16 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.5.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "bigframes 2.8.0 requires cloudpickle>=2.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n",
            "bigframes 2.8.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.8 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "12def116c85842c680264b13b2ac7fb2",
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: atari_py==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from atari_py==1.2.2) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  %pip install numpy==1.18.5\n",
        "  %pip install gym==0.17.3\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install tensorflow==2.12\n",
        "  %pip install keras==2.12.0\n",
        "  %pip install atari_py==1.2.2\n",
        "else:\n",
        "  %pip install gym==0.17.3\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install pyglet==1.5.0\n",
        "  %pip install h5py==3.1.0\n",
        "  %pip install Pillow==9.5.0\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install Keras==2.2.4\n",
        "  %pip install tensorflow==2.5.3\n",
        "  %pip install torch==2.0.1\n",
        "  %pip install agents==1.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hzP_5ZuGb2X"
      },
      "source": [
        "---\n",
        "## **PARTE 2**. Enunciado\n",
        "\n",
        "Consideraciones a tener en cuenta:\n",
        "\n",
        "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
        "\n",
        "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
        "\n",
        "Este proyecto práctico consta de tres partes:\n",
        "\n",
        "1.   Implementar la red neuronal que se usará en la solución\n",
        "2.   Implementar las distintas piezas de la solución DQN\n",
        "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
        "\n",
        "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
        "\n",
        "IMPORTANTE:\n",
        "\n",
        "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
        "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
        "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
        "* Cada alumno deberá de subir la solución de forma individual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_b3mzw8IzJP"
      },
      "source": [
        "---\n",
        "## **PARTE 3**. Desarrollo y preguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duPmUNOVGb2a"
      },
      "source": [
        "#### Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3eRhgI-Gb2a"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4jgQjzoGb2a"
      },
      "source": [
        "#### Configuración base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwOE6I_KGb2a"
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "\n",
        "env_name = 'SpaceInvaders-v0'\n",
        "env = gym.make(env_name)\n",
        "\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqFI4jgmtdyf"
      },
      "outputs": [],
      "source": [
        "print(\"Numero de acciones disponibles:\" + str(nb_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h54a3rfhtjam"
      },
      "outputs": [],
      "source": [
        "print(\"Formato de las observaciones:\")\n",
        "env.observation_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jGEZUcpGb2a"
      },
      "outputs": [],
      "source": [
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3  # (height, width, channel)\n",
        "        img = Image.fromarray(observation)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        processed_batch = batch.astype('float32') / 255.\n",
        "        return processed_batch\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yitXTADGb2b"
      },
      "source": [
        "1. Implementación de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4GKrfWSGb2b",
        "outputId": "1f7f59f1-e368-4a62-c3db-ca1a47f500b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " permute (Permute)           (None, 84, 84, 4)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 20, 20, 32)        8224      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 9, 9, 64)          32832     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,687,206\n",
            "Trainable params: 1,687,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, Permute\n",
        "from keras import Input\n",
        "\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4  # Número de frames apilados\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Reordenar dimensiones para que Conv2D funcione: (C, H, W) -> (H, W, C)\n",
        "model.add(Permute((2, 3, 1), input_shape=(WINDOW_LENGTH,) + INPUT_SHAPE))  # (4, 84, 84) -> (84, 84, 4)\n",
        "\n",
        "# Arquitectura tipo DeepMind\n",
        "model.add(Conv2D(32, kernel_size=8, strides=4, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(nb_actions, activation='linear'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB9-_5HPGb2b"
      },
      "source": [
        "2. Implementación de la solución DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJrACIsVUQ2b",
        "outputId": "aeb4a8f3-036f-46c2-a79f-d3fa4195740f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 1000000 steps ...\n",
            "    420/1000000: episode: 1, duration: 1.660s, episode steps: 420, steps per second: 253, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1131/1000000: episode: 2, duration: 2.686s, episode steps: 711, steps per second: 265, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1941/1000000: episode: 3, duration: 3.202s, episode steps: 810, steps per second: 253, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2827/1000000: episode: 4, duration: 3.374s, episode steps: 886, steps per second: 263, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3345/1000000: episode: 5, duration: 1.990s, episode steps: 518, steps per second: 260, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3990/1000000: episode: 6, duration: 2.466s, episode steps: 645, steps per second: 262, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4451/1000000: episode: 7, duration: 1.774s, episode steps: 461, steps per second: 260, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5248/1000000: episode: 8, duration: 3.138s, episode steps: 797, steps per second: 254, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5733/1000000: episode: 9, duration: 1.848s, episode steps: 485, steps per second: 262, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6372/1000000: episode: 10, duration: 2.428s, episode steps: 639, steps per second: 263, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7096/1000000: episode: 11, duration: 2.751s, episode steps: 724, steps per second: 263, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7701/1000000: episode: 12, duration: 2.329s, episode steps: 605, steps per second: 260, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8349/1000000: episode: 13, duration: 2.520s, episode steps: 648, steps per second: 257, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9241/1000000: episode: 14, duration: 3.412s, episode steps: 892, steps per second: 261, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9696/1000000: episode: 15, duration: 1.735s, episode steps: 455, steps per second: 262, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10587/1000000: episode: 16, duration: 3.381s, episode steps: 891, steps per second: 264, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10988/1000000: episode: 17, duration: 1.593s, episode steps: 401, steps per second: 252, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11675/1000000: episode: 18, duration: 2.660s, episode steps: 687, steps per second: 258, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12436/1000000: episode: 19, duration: 2.875s, episode steps: 761, steps per second: 265, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13054/1000000: episode: 20, duration: 2.333s, episode steps: 618, steps per second: 265, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13784/1000000: episode: 21, duration: 2.818s, episode steps: 730, steps per second: 259, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14824/1000000: episode: 22, duration: 4.028s, episode steps: 1040, steps per second: 258, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15354/1000000: episode: 23, duration: 2.011s, episode steps: 530, steps per second: 264, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15847/1000000: episode: 24, duration: 1.887s, episode steps: 493, steps per second: 261, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16512/1000000: episode: 25, duration: 2.534s, episode steps: 665, steps per second: 262, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17747/1000000: episode: 26, duration: 4.767s, episode steps: 1235, steps per second: 259, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18271/1000000: episode: 27, duration: 2.063s, episode steps: 524, steps per second: 254, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18955/1000000: episode: 28, duration: 2.596s, episode steps: 684, steps per second: 264, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19537/1000000: episode: 29, duration: 2.200s, episode steps: 582, steps per second: 265, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20500/1000000: episode: 30, duration: 3.671s, episode steps: 963, steps per second: 262, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21403/1000000: episode: 31, duration: 3.515s, episode steps: 903, steps per second: 257, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22447/1000000: episode: 32, duration: 4.007s, episode steps: 1044, steps per second: 261, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23159/1000000: episode: 33, duration: 2.783s, episode steps: 712, steps per second: 256, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24002/1000000: episode: 34, duration: 3.285s, episode steps: 843, steps per second: 257, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24986/1000000: episode: 35, duration: 3.829s, episode steps: 984, steps per second: 257, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26115/1000000: episode: 36, duration: 4.308s, episode steps: 1129, steps per second: 262, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27313/1000000: episode: 37, duration: 4.524s, episode steps: 1198, steps per second: 265, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28110/1000000: episode: 38, duration: 3.002s, episode steps: 797, steps per second: 265, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28878/1000000: episode: 39, duration: 2.913s, episode steps: 768, steps per second: 264, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29495/1000000: episode: 40, duration: 2.327s, episode steps: 617, steps per second: 265, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30083/1000000: episode: 41, duration: 2.331s, episode steps: 588, steps per second: 252, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30740/1000000: episode: 42, duration: 2.526s, episode steps: 657, steps per second: 260, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31403/1000000: episode: 43, duration: 2.526s, episode steps: 663, steps per second: 262, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32244/1000000: episode: 44, duration: 3.160s, episode steps: 841, steps per second: 266, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33178/1000000: episode: 45, duration: 3.551s, episode steps: 934, steps per second: 263, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33620/1000000: episode: 46, duration: 1.717s, episode steps: 442, steps per second: 257, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34345/1000000: episode: 47, duration: 2.780s, episode steps: 725, steps per second: 261, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34846/1000000: episode: 48, duration: 1.912s, episode steps: 501, steps per second: 262, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35427/1000000: episode: 49, duration: 2.232s, episode steps: 581, steps per second: 260, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36463/1000000: episode: 50, duration: 3.940s, episode steps: 1036, steps per second: 263, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37172/1000000: episode: 51, duration: 2.735s, episode steps: 709, steps per second: 259, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38822/1000000: episode: 52, duration: 6.234s, episode steps: 1650, steps per second: 265, episode reward: 22.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39524/1000000: episode: 53, duration: 2.732s, episode steps: 702, steps per second: 257, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40034/1000000: episode: 54, duration: 1.987s, episode steps: 510, steps per second: 257, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40712/1000000: episode: 55, duration: 2.568s, episode steps: 678, steps per second: 264, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41632/1000000: episode: 56, duration: 3.492s, episode steps: 920, steps per second: 263, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42322/1000000: episode: 57, duration: 2.609s, episode steps: 690, steps per second: 265, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42956/1000000: episode: 58, duration: 2.383s, episode steps: 634, steps per second: 266, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43610/1000000: episode: 59, duration: 2.462s, episode steps: 654, steps per second: 266, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44475/1000000: episode: 60, duration: 3.234s, episode steps: 865, steps per second: 267, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45031/1000000: episode: 61, duration: 2.124s, episode steps: 556, steps per second: 262, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45442/1000000: episode: 62, duration: 1.565s, episode steps: 411, steps per second: 263, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45903/1000000: episode: 63, duration: 1.766s, episode steps: 461, steps per second: 261, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46640/1000000: episode: 64, duration: 2.940s, episode steps: 737, steps per second: 251, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47086/1000000: episode: 65, duration: 1.684s, episode steps: 446, steps per second: 265, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47696/1000000: episode: 66, duration: 2.312s, episode steps: 610, steps per second: 264, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48322/1000000: episode: 67, duration: 2.390s, episode steps: 626, steps per second: 262, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49084/1000000: episode: 68, duration: 2.906s, episode steps: 762, steps per second: 262, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49764/1000000: episode: 69, duration: 2.581s, episode steps: 680, steps per second: 263, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  50166/1000000: episode: 70, duration: 6.069s, episode steps: 402, steps per second:  66, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.008521, mae: 0.044553, mean_q: 0.079231, mean_eps: 0.954924\n",
            "  51219/1000000: episode: 71, duration: 30.253s, episode steps: 1053, steps per second:  35, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.006322, mae: 0.043830, mean_q: 0.064166, mean_eps: 0.954377\n",
            "  52002/1000000: episode: 72, duration: 22.728s, episode steps: 783, steps per second:  34, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007343, mae: 0.048120, mean_q: 0.066787, mean_eps: 0.953551\n",
            "  52754/1000000: episode: 73, duration: 21.555s, episode steps: 752, steps per second:  35, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.006277, mae: 0.045243, mean_q: 0.060474, mean_eps: 0.952860\n",
            "  53464/1000000: episode: 74, duration: 20.588s, episode steps: 710, steps per second:  34, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.006609, mae: 0.046120, mean_q: 0.060812, mean_eps: 0.952203\n",
            "  54162/1000000: episode: 75, duration: 20.271s, episode steps: 698, steps per second:  34, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.005409, mae: 0.043990, mean_q: 0.058797, mean_eps: 0.951569\n",
            "  54605/1000000: episode: 76, duration: 12.776s, episode steps: 443, steps per second:  35, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.005053, mae: 0.042637, mean_q: 0.056473, mean_eps: 0.951054\n",
            "  55106/1000000: episode: 77, duration: 14.355s, episode steps: 501, steps per second:  35, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.006536, mae: 0.046590, mean_q: 0.061371, mean_eps: 0.950630\n",
            "  55495/1000000: episode: 78, duration: 11.196s, episode steps: 389, steps per second:  35, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.007631, mae: 0.048034, mean_q: 0.059693, mean_eps: 0.950230\n",
            "  56708/1000000: episode: 79, duration: 35.126s, episode steps: 1213, steps per second:  35, episode reward: 29.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006369, mae: 0.046004, mean_q: 0.059482, mean_eps: 0.949510\n",
            "  57506/1000000: episode: 80, duration: 23.105s, episode steps: 798, steps per second:  35, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.007261, mae: 0.047988, mean_q: 0.063173, mean_eps: 0.948605\n",
            "  58279/1000000: episode: 81, duration: 22.321s, episode steps: 773, steps per second:  35, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.006691, mae: 0.047449, mean_q: 0.060852, mean_eps: 0.947897\n",
            "  58972/1000000: episode: 82, duration: 20.160s, episode steps: 693, steps per second:  34, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.006586, mae: 0.046415, mean_q: 0.059445, mean_eps: 0.947238\n",
            "  59361/1000000: episode: 83, duration: 11.309s, episode steps: 389, steps per second:  34, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.007713, mae: 0.048842, mean_q: 0.062570, mean_eps: 0.946751\n",
            "  60612/1000000: episode: 84, duration: 35.818s, episode steps: 1251, steps per second:  35, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.006579, mae: 0.053669, mean_q: 0.071209, mean_eps: 0.946013\n",
            "  61203/1000000: episode: 85, duration: 16.916s, episode steps: 591, steps per second:  35, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006678, mae: 0.063886, mean_q: 0.081247, mean_eps: 0.945185\n",
            "  61913/1000000: episode: 86, duration: 20.514s, episode steps: 710, steps per second:  35, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.006131, mae: 0.061733, mean_q: 0.077812, mean_eps: 0.944598\n",
            "  62553/1000000: episode: 87, duration: 18.524s, episode steps: 640, steps per second:  35, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006933, mae: 0.065489, mean_q: 0.081457, mean_eps: 0.943989\n",
            "  63067/1000000: episode: 88, duration: 14.791s, episode steps: 514, steps per second:  35, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.006168, mae: 0.061973, mean_q: 0.077972, mean_eps: 0.943471\n",
            "  63777/1000000: episode: 89, duration: 20.533s, episode steps: 710, steps per second:  35, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.007164, mae: 0.064907, mean_q: 0.081783, mean_eps: 0.942920\n",
            "  64424/1000000: episode: 90, duration: 18.624s, episode steps: 647, steps per second:  35, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.006983, mae: 0.064928, mean_q: 0.081308, mean_eps: 0.942310\n",
            "  65193/1000000: episode: 91, duration: 22.178s, episode steps: 769, steps per second:  35, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.007452, mae: 0.066076, mean_q: 0.084058, mean_eps: 0.941673\n",
            "  66781/1000000: episode: 92, duration: 45.587s, episode steps: 1588, steps per second:  35, episode reward: 20.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006752, mae: 0.064111, mean_q: 0.081865, mean_eps: 0.940611\n",
            "  67744/1000000: episode: 93, duration: 27.643s, episode steps: 963, steps per second:  35, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.006677, mae: 0.064562, mean_q: 0.082233, mean_eps: 0.939464\n",
            "  68499/1000000: episode: 94, duration: 21.991s, episode steps: 755, steps per second:  34, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.006807, mae: 0.063822, mean_q: 0.080562, mean_eps: 0.938692\n",
            "  68918/1000000: episode: 95, duration: 12.070s, episode steps: 419, steps per second:  35, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.006407, mae: 0.063151, mean_q: 0.079781, mean_eps: 0.938163\n",
            "  69711/1000000: episode: 96, duration: 22.819s, episode steps: 793, steps per second:  35, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.006676, mae: 0.063765, mean_q: 0.083590, mean_eps: 0.937617\n",
            "  70413/1000000: episode: 97, duration: 20.406s, episode steps: 702, steps per second:  34, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.006413, mae: 0.071084, mean_q: 0.090195, mean_eps: 0.936944\n",
            "  71319/1000000: episode: 98, duration: 26.321s, episode steps: 906, steps per second:  34, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.006410, mae: 0.079369, mean_q: 0.103564, mean_eps: 0.936221\n",
            "  72205/1000000: episode: 99, duration: 25.622s, episode steps: 886, steps per second:  35, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.006387, mae: 0.078890, mean_q: 0.100758, mean_eps: 0.935414\n",
            "  73012/1000000: episode: 100, duration: 23.353s, episode steps: 807, steps per second:  35, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.005981, mae: 0.078200, mean_q: 0.101189, mean_eps: 0.934653\n",
            "  73729/1000000: episode: 101, duration: 20.843s, episode steps: 717, steps per second:  34, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.005017, mae: 0.076856, mean_q: 0.097346, mean_eps: 0.933967\n",
            "  74552/1000000: episode: 102, duration: 24.105s, episode steps: 823, steps per second:  34, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.006139, mae: 0.079274, mean_q: 0.100939, mean_eps: 0.933274\n",
            "  75329/1000000: episode: 103, duration: 22.723s, episode steps: 777, steps per second:  34, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006861, mae: 0.080563, mean_q: 0.102657, mean_eps: 0.932554\n",
            "  75918/1000000: episode: 104, duration: 17.242s, episode steps: 589, steps per second:  34, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.006869, mae: 0.080737, mean_q: 0.103121, mean_eps: 0.931938\n",
            "  76551/1000000: episode: 105, duration: 18.429s, episode steps: 633, steps per second:  34, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.006993, mae: 0.081100, mean_q: 0.103042, mean_eps: 0.931389\n",
            "  77028/1000000: episode: 106, duration: 14.020s, episode steps: 477, steps per second:  34, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007048, mae: 0.082277, mean_q: 0.105757, mean_eps: 0.930891\n",
            "  77739/1000000: episode: 107, duration: 20.906s, episode steps: 711, steps per second:  34, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.007390, mae: 0.081586, mean_q: 0.102902, mean_eps: 0.930356\n",
            "  78722/1000000: episode: 108, duration: 28.890s, episode steps: 983, steps per second:  34, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.007482, mae: 0.082564, mean_q: 0.105873, mean_eps: 0.929593\n",
            "  79325/1000000: episode: 109, duration: 17.785s, episode steps: 603, steps per second:  34, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006536, mae: 0.080748, mean_q: 0.102918, mean_eps: 0.928878\n",
            "  79934/1000000: episode: 110, duration: 17.668s, episode steps: 609, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.006600, mae: 0.079762, mean_q: 0.101079, mean_eps: 0.928333\n",
            "  80643/1000000: episode: 111, duration: 20.661s, episode steps: 709, steps per second:  34, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.006679, mae: 0.094743, mean_q: 0.119902, mean_eps: 0.927741\n",
            "  81582/1000000: episode: 112, duration: 27.354s, episode steps: 939, steps per second:  34, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.005410, mae: 0.092731, mean_q: 0.119158, mean_eps: 0.926999\n",
            "  82409/1000000: episode: 113, duration: 24.109s, episode steps: 827, steps per second:  34, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.006878, mae: 0.098056, mean_q: 0.125209, mean_eps: 0.926204\n",
            "  83070/1000000: episode: 114, duration: 19.121s, episode steps: 661, steps per second:  35, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.006783, mae: 0.096622, mean_q: 0.121730, mean_eps: 0.925534\n",
            "  83529/1000000: episode: 115, duration: 13.347s, episode steps: 459, steps per second:  34, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.008898, mae: 0.101754, mean_q: 0.127890, mean_eps: 0.925030\n",
            "  84329/1000000: episode: 116, duration: 23.115s, episode steps: 800, steps per second:  35, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.004772, mae: 0.093117, mean_q: 0.117473, mean_eps: 0.924463\n",
            "  85200/1000000: episode: 117, duration: 25.113s, episode steps: 871, steps per second:  35, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.006499, mae: 0.097089, mean_q: 0.123220, mean_eps: 0.923712\n",
            "  86059/1000000: episode: 118, duration: 24.661s, episode steps: 859, steps per second:  35, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.006726, mae: 0.096885, mean_q: 0.123609, mean_eps: 0.922935\n",
            "  86706/1000000: episode: 119, duration: 18.656s, episode steps: 647, steps per second:  35, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007597, mae: 0.099140, mean_q: 0.125562, mean_eps: 0.922256\n",
            "  87356/1000000: episode: 120, duration: 18.818s, episode steps: 650, steps per second:  35, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.006302, mae: 0.096664, mean_q: 0.122076, mean_eps: 0.921673\n",
            "  88056/1000000: episode: 121, duration: 20.397s, episode steps: 700, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.005629, mae: 0.093998, mean_q: 0.119626, mean_eps: 0.921066\n",
            "  89012/1000000: episode: 122, duration: 27.679s, episode steps: 956, steps per second:  35, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.007039, mae: 0.098251, mean_q: 0.122159, mean_eps: 0.920321\n",
            "  89788/1000000: episode: 123, duration: 22.574s, episode steps: 776, steps per second:  34, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.006054, mae: 0.095573, mean_q: 0.120526, mean_eps: 0.919542\n",
            "  90820/1000000: episode: 124, duration: 29.860s, episode steps: 1032, steps per second:  35, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.005667, mae: 0.103810, mean_q: 0.131349, mean_eps: 0.918728\n",
            "  91834/1000000: episode: 125, duration: 29.424s, episode steps: 1014, steps per second:  34, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.006849, mae: 0.108460, mean_q: 0.139779, mean_eps: 0.917807\n",
            "  92420/1000000: episode: 126, duration: 16.951s, episode steps: 586, steps per second:  35, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.006092, mae: 0.107193, mean_q: 0.140120, mean_eps: 0.917087\n",
            "  93080/1000000: episode: 127, duration: 19.182s, episode steps: 660, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.008103, mae: 0.112605, mean_q: 0.141680, mean_eps: 0.916527\n",
            "  93647/1000000: episode: 128, duration: 16.334s, episode steps: 567, steps per second:  35, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.006123, mae: 0.107216, mean_q: 0.135189, mean_eps: 0.915974\n",
            "  94248/1000000: episode: 129, duration: 17.522s, episode steps: 601, steps per second:  34, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.005948, mae: 0.107919, mean_q: 0.138422, mean_eps: 0.915449\n",
            "  94958/1000000: episode: 130, duration: 20.549s, episode steps: 710, steps per second:  35, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.006483, mae: 0.108227, mean_q: 0.136876, mean_eps: 0.914858\n",
            "  95808/1000000: episode: 131, duration: 24.672s, episode steps: 850, steps per second:  34, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.006658, mae: 0.109217, mean_q: 0.137329, mean_eps: 0.914156\n",
            "  96416/1000000: episode: 132, duration: 17.830s, episode steps: 608, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.008223, mae: 0.112922, mean_q: 0.140554, mean_eps: 0.913501\n",
            "  97377/1000000: episode: 133, duration: 27.937s, episode steps: 961, steps per second:  34, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.005917, mae: 0.108359, mean_q: 0.137789, mean_eps: 0.912794\n",
            "  97928/1000000: episode: 134, duration: 16.008s, episode steps: 551, steps per second:  34, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.006500, mae: 0.108618, mean_q: 0.138825, mean_eps: 0.912113\n",
            "  98747/1000000: episode: 135, duration: 23.882s, episode steps: 819, steps per second:  34, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006550, mae: 0.108144, mean_q: 0.137658, mean_eps: 0.911498\n",
            "  99759/1000000: episode: 136, duration: 29.708s, episode steps: 1012, steps per second:  34, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.006015, mae: 0.107794, mean_q: 0.138383, mean_eps: 0.910673\n",
            " 100266/1000000: episode: 137, duration: 14.785s, episode steps: 507, steps per second:  34, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.005885, mae: 0.117306, mean_q: 0.150413, mean_eps: 0.909989\n",
            " 100783/1000000: episode: 138, duration: 14.909s, episode steps: 517, steps per second:  35, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.006826, mae: 0.129652, mean_q: 0.165864, mean_eps: 0.909528\n",
            " 101635/1000000: episode: 139, duration: 24.607s, episode steps: 852, steps per second:  35, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.006935, mae: 0.129615, mean_q: 0.163017, mean_eps: 0.908913\n",
            " 102078/1000000: episode: 140, duration: 12.791s, episode steps: 443, steps per second:  35, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.005802, mae: 0.128876, mean_q: 0.162847, mean_eps: 0.908330\n",
            " 102530/1000000: episode: 141, duration: 13.026s, episode steps: 452, steps per second:  35, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.006823, mae: 0.131215, mean_q: 0.164585, mean_eps: 0.907926\n",
            " 103190/1000000: episode: 142, duration: 19.086s, episode steps: 660, steps per second:  35, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.005873, mae: 0.126294, mean_q: 0.158475, mean_eps: 0.907426\n",
            " 103862/1000000: episode: 143, duration: 19.477s, episode steps: 672, steps per second:  35, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.007623, mae: 0.132224, mean_q: 0.166994, mean_eps: 0.906827\n",
            " 104294/1000000: episode: 144, duration: 12.486s, episode steps: 432, steps per second:  35, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.006685, mae: 0.131499, mean_q: 0.164032, mean_eps: 0.906330\n",
            " 104674/1000000: episode: 145, duration: 11.082s, episode steps: 380, steps per second:  34, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.008162, mae: 0.133977, mean_q: 0.165803, mean_eps: 0.905964\n",
            " 105248/1000000: episode: 146, duration: 16.658s, episode steps: 574, steps per second:  34, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.005647, mae: 0.126704, mean_q: 0.159023, mean_eps: 0.905536\n",
            " 105743/1000000: episode: 147, duration: 14.395s, episode steps: 495, steps per second:  34, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.005201, mae: 0.127477, mean_q: 0.162703, mean_eps: 0.905055\n",
            " 106390/1000000: episode: 148, duration: 18.757s, episode steps: 647, steps per second:  34, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.007517, mae: 0.133836, mean_q: 0.166470, mean_eps: 0.904541\n",
            " 107110/1000000: episode: 149, duration: 20.578s, episode steps: 720, steps per second:  35, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.005766, mae: 0.130392, mean_q: 0.164517, mean_eps: 0.903925\n",
            " 107926/1000000: episode: 150, duration: 23.549s, episode steps: 816, steps per second:  35, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.005913, mae: 0.128657, mean_q: 0.160785, mean_eps: 0.903234\n",
            " 108324/1000000: episode: 151, duration: 11.612s, episode steps: 398, steps per second:  34, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.005718, mae: 0.127793, mean_q: 0.158498, mean_eps: 0.902688\n",
            " 109037/1000000: episode: 152, duration: 20.821s, episode steps: 713, steps per second:  34, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006624, mae: 0.130686, mean_q: 0.162859, mean_eps: 0.902188\n",
            " 109451/1000000: episode: 153, duration: 11.913s, episode steps: 414, steps per second:  35, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.705 [0.000, 5.000],  loss: 0.005433, mae: 0.128197, mean_q: 0.161033, mean_eps: 0.901680\n",
            " 110215/1000000: episode: 154, duration: 22.140s, episode steps: 764, steps per second:  35, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.007705, mae: 0.140344, mean_q: 0.175505, mean_eps: 0.901151\n",
            " 110705/1000000: episode: 155, duration: 14.218s, episode steps: 490, steps per second:  34, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.007862, mae: 0.157947, mean_q: 0.195215, mean_eps: 0.900586\n",
            " 111352/1000000: episode: 156, duration: 18.754s, episode steps: 647, steps per second:  34, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.007584, mae: 0.163952, mean_q: 0.205252, mean_eps: 0.900075\n",
            " 112041/1000000: episode: 157, duration: 19.814s, episode steps: 689, steps per second:  35, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.005890, mae: 0.156042, mean_q: 0.194990, mean_eps: 0.899474\n",
            " 112478/1000000: episode: 158, duration: 12.492s, episode steps: 437, steps per second:  35, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.007193, mae: 0.157061, mean_q: 0.195271, mean_eps: 0.898966\n",
            " 113067/1000000: episode: 159, duration: 16.973s, episode steps: 589, steps per second:  35, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.006722, mae: 0.160357, mean_q: 0.199479, mean_eps: 0.898505\n",
            " 113779/1000000: episode: 160, duration: 20.343s, episode steps: 712, steps per second:  35, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.006379, mae: 0.159656, mean_q: 0.198142, mean_eps: 0.897920\n",
            " 114149/1000000: episode: 161, duration: 10.732s, episode steps: 370, steps per second:  34, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.008719, mae: 0.164828, mean_q: 0.207072, mean_eps: 0.897432\n",
            " 115231/1000000: episode: 162, duration: 31.050s, episode steps: 1082, steps per second:  35, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.006151, mae: 0.158059, mean_q: 0.195318, mean_eps: 0.896779\n",
            " 116025/1000000: episode: 163, duration: 22.887s, episode steps: 794, steps per second:  35, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.007070, mae: 0.161623, mean_q: 0.199765, mean_eps: 0.895935\n",
            " 116790/1000000: episode: 164, duration: 21.847s, episode steps: 765, steps per second:  35, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.007136, mae: 0.160823, mean_q: 0.200804, mean_eps: 0.895233\n",
            " 117403/1000000: episode: 165, duration: 17.595s, episode steps: 613, steps per second:  35, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.006544, mae: 0.157244, mean_q: 0.196884, mean_eps: 0.894614\n",
            " 118175/1000000: episode: 166, duration: 22.204s, episode steps: 772, steps per second:  35, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.006233, mae: 0.159090, mean_q: 0.200147, mean_eps: 0.893991\n",
            " 118846/1000000: episode: 167, duration: 19.350s, episode steps: 671, steps per second:  35, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.006339, mae: 0.159632, mean_q: 0.199472, mean_eps: 0.893341\n",
            " 119210/1000000: episode: 168, duration: 10.498s, episode steps: 364, steps per second:  35, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007436, mae: 0.164029, mean_q: 0.203970, mean_eps: 0.892875\n",
            " 120197/1000000: episode: 169, duration: 28.589s, episode steps: 987, steps per second:  35, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.007674, mae: 0.167042, mean_q: 0.207981, mean_eps: 0.892266\n",
            " 121051/1000000: episode: 170, duration: 24.666s, episode steps: 854, steps per second:  35, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.006455, mae: 0.190537, mean_q: 0.237801, mean_eps: 0.891438\n",
            " 122054/1000000: episode: 171, duration: 29.261s, episode steps: 1003, steps per second:  34, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006990, mae: 0.191140, mean_q: 0.236442, mean_eps: 0.890603\n",
            " 122845/1000000: episode: 172, duration: 22.960s, episode steps: 791, steps per second:  34, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.007713, mae: 0.193520, mean_q: 0.238954, mean_eps: 0.889795\n",
            " 124108/1000000: episode: 173, duration: 36.554s, episode steps: 1263, steps per second:  35, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007050, mae: 0.191283, mean_q: 0.238488, mean_eps: 0.888872\n",
            " 125046/1000000: episode: 174, duration: 27.146s, episode steps: 938, steps per second:  35, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.007079, mae: 0.191670, mean_q: 0.237839, mean_eps: 0.887882\n",
            " 125563/1000000: episode: 175, duration: 14.852s, episode steps: 517, steps per second:  35, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007894, mae: 0.195283, mean_q: 0.242850, mean_eps: 0.887226\n",
            " 126193/1000000: episode: 176, duration: 18.287s, episode steps: 630, steps per second:  34, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.007410, mae: 0.195976, mean_q: 0.243638, mean_eps: 0.886710\n",
            " 127167/1000000: episode: 177, duration: 27.955s, episode steps: 974, steps per second:  35, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.007365, mae: 0.194475, mean_q: 0.240036, mean_eps: 0.885988\n",
            " 127562/1000000: episode: 178, duration: 11.439s, episode steps: 395, steps per second:  35, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.007294, mae: 0.194595, mean_q: 0.240462, mean_eps: 0.885372\n",
            " 127959/1000000: episode: 179, duration: 11.416s, episode steps: 397, steps per second:  35, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: 0.007494, mae: 0.197247, mean_q: 0.244115, mean_eps: 0.885016\n",
            " 128545/1000000: episode: 180, duration: 17.079s, episode steps: 586, steps per second:  34, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.007118, mae: 0.193157, mean_q: 0.242161, mean_eps: 0.884573\n",
            " 129384/1000000: episode: 181, duration: 24.201s, episode steps: 839, steps per second:  35, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.006501, mae: 0.193518, mean_q: 0.239347, mean_eps: 0.883932\n",
            " 130035/1000000: episode: 182, duration: 18.764s, episode steps: 651, steps per second:  35, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006964, mae: 0.194991, mean_q: 0.242829, mean_eps: 0.883263\n",
            " 130443/1000000: episode: 183, duration: 11.723s, episode steps: 408, steps per second:  35, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.009535, mae: 0.218305, mean_q: 0.270983, mean_eps: 0.882786\n",
            " 130979/1000000: episode: 184, duration: 15.534s, episode steps: 536, steps per second:  35, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.007509, mae: 0.212499, mean_q: 0.264635, mean_eps: 0.882361\n",
            " 131875/1000000: episode: 185, duration: 26.486s, episode steps: 896, steps per second:  34, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.007476, mae: 0.213284, mean_q: 0.264687, mean_eps: 0.881717\n",
            " 132252/1000000: episode: 186, duration: 11.270s, episode steps: 377, steps per second:  33, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.007567, mae: 0.216327, mean_q: 0.268805, mean_eps: 0.881144\n",
            " 132731/1000000: episode: 187, duration: 14.532s, episode steps: 479, steps per second:  33, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.007152, mae: 0.219060, mean_q: 0.271951, mean_eps: 0.880759\n",
            " 133433/1000000: episode: 188, duration: 20.522s, episode steps: 702, steps per second:  34, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.007082, mae: 0.209919, mean_q: 0.260448, mean_eps: 0.880226\n",
            " 134176/1000000: episode: 189, duration: 21.779s, episode steps: 743, steps per second:  34, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.006911, mae: 0.214034, mean_q: 0.264769, mean_eps: 0.879576\n",
            " 135130/1000000: episode: 190, duration: 27.988s, episode steps: 954, steps per second:  34, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.007329, mae: 0.211614, mean_q: 0.263694, mean_eps: 0.878813\n",
            " 135770/1000000: episode: 191, duration: 18.701s, episode steps: 640, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.006135, mae: 0.207940, mean_q: 0.257300, mean_eps: 0.878095\n",
            " 136135/1000000: episode: 192, duration: 10.580s, episode steps: 365, steps per second:  34, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.006677, mae: 0.208704, mean_q: 0.258852, mean_eps: 0.877643\n",
            " 136560/1000000: episode: 193, duration: 12.462s, episode steps: 425, steps per second:  34, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.005869, mae: 0.208431, mean_q: 0.259247, mean_eps: 0.877289\n",
            " 136951/1000000: episode: 194, duration: 11.482s, episode steps: 391, steps per second:  34, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.007239, mae: 0.208921, mean_q: 0.259746, mean_eps: 0.876921\n",
            " 137537/1000000: episode: 195, duration: 17.100s, episode steps: 586, steps per second:  34, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.007007, mae: 0.215945, mean_q: 0.268044, mean_eps: 0.876480\n",
            " 138187/1000000: episode: 196, duration: 18.990s, episode steps: 650, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.006129, mae: 0.212990, mean_q: 0.264959, mean_eps: 0.875924\n",
            " 138710/1000000: episode: 197, duration: 15.174s, episode steps: 523, steps per second:  34, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.006942, mae: 0.215744, mean_q: 0.268605, mean_eps: 0.875397\n",
            " 139696/1000000: episode: 198, duration: 28.929s, episode steps: 986, steps per second:  34, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.006864, mae: 0.214203, mean_q: 0.265698, mean_eps: 0.874718\n",
            " 140590/1000000: episode: 199, duration: 26.286s, episode steps: 894, steps per second:  34, episode reward:  8.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.007276, mae: 0.219537, mean_q: 0.273365, mean_eps: 0.873872\n",
            " 141089/1000000: episode: 200, duration: 14.734s, episode steps: 499, steps per second:  34, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.007862, mae: 0.230688, mean_q: 0.286231, mean_eps: 0.873244\n",
            " 141719/1000000: episode: 201, duration: 18.207s, episode steps: 630, steps per second:  35, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.006911, mae: 0.227414, mean_q: 0.283482, mean_eps: 0.872736\n",
            " 142351/1000000: episode: 202, duration: 18.382s, episode steps: 632, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.242 [0.000, 5.000],  loss: 0.007890, mae: 0.226664, mean_q: 0.283303, mean_eps: 0.872169\n",
            " 143061/1000000: episode: 203, duration: 20.866s, episode steps: 710, steps per second:  34, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.007491, mae: 0.227731, mean_q: 0.281362, mean_eps: 0.871565\n",
            " 143877/1000000: episode: 204, duration: 24.082s, episode steps: 816, steps per second:  34, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.006777, mae: 0.222841, mean_q: 0.275693, mean_eps: 0.870877\n",
            " 144678/1000000: episode: 205, duration: 23.276s, episode steps: 801, steps per second:  34, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007616, mae: 0.230748, mean_q: 0.286902, mean_eps: 0.870150\n",
            " 145649/1000000: episode: 206, duration: 28.514s, episode steps: 971, steps per second:  34, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.008075, mae: 0.225798, mean_q: 0.282443, mean_eps: 0.869352\n",
            " 146384/1000000: episode: 207, duration: 21.604s, episode steps: 735, steps per second:  34, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.006804, mae: 0.225574, mean_q: 0.280597, mean_eps: 0.868586\n",
            " 147336/1000000: episode: 208, duration: 27.876s, episode steps: 952, steps per second:  34, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.007841, mae: 0.225465, mean_q: 0.280918, mean_eps: 0.867828\n",
            " 148360/1000000: episode: 209, duration: 30.002s, episode steps: 1024, steps per second:  34, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.007142, mae: 0.229588, mean_q: 0.284514, mean_eps: 0.866939\n",
            " 149235/1000000: episode: 210, duration: 25.697s, episode steps: 875, steps per second:  34, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.008050, mae: 0.228827, mean_q: 0.283880, mean_eps: 0.866084\n",
            " 150486/1000000: episode: 211, duration: 36.629s, episode steps: 1251, steps per second:  34, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007612, mae: 0.238433, mean_q: 0.297093, mean_eps: 0.865126\n",
            " 150967/1000000: episode: 212, duration: 14.031s, episode steps: 481, steps per second:  34, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.007683, mae: 0.248759, mean_q: 0.308489, mean_eps: 0.864347\n",
            " 151742/1000000: episode: 213, duration: 22.634s, episode steps: 775, steps per second:  34, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.007820, mae: 0.251176, mean_q: 0.311990, mean_eps: 0.863781\n",
            " 152376/1000000: episode: 214, duration: 18.663s, episode steps: 634, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.008167, mae: 0.251741, mean_q: 0.312573, mean_eps: 0.863148\n",
            " 153049/1000000: episode: 215, duration: 19.763s, episode steps: 673, steps per second:  34, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007457, mae: 0.252845, mean_q: 0.311072, mean_eps: 0.862559\n",
            " 153548/1000000: episode: 216, duration: 14.687s, episode steps: 499, steps per second:  34, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.006732, mae: 0.252038, mean_q: 0.312633, mean_eps: 0.862032\n",
            " 154143/1000000: episode: 217, duration: 17.432s, episode steps: 595, steps per second:  34, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.007161, mae: 0.250122, mean_q: 0.311777, mean_eps: 0.861540\n",
            " 154522/1000000: episode: 218, duration: 11.085s, episode steps: 379, steps per second:  34, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.245 [0.000, 5.000],  loss: 0.007379, mae: 0.254003, mean_q: 0.315941, mean_eps: 0.861101\n",
            " 155291/1000000: episode: 219, duration: 22.421s, episode steps: 769, steps per second:  34, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.008202, mae: 0.255050, mean_q: 0.316293, mean_eps: 0.860585\n",
            " 155830/1000000: episode: 220, duration: 15.833s, episode steps: 539, steps per second:  34, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.007915, mae: 0.253402, mean_q: 0.313156, mean_eps: 0.859996\n",
            " 156551/1000000: episode: 221, duration: 20.930s, episode steps: 721, steps per second:  34, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.007894, mae: 0.248398, mean_q: 0.309358, mean_eps: 0.859429\n",
            " 157306/1000000: episode: 222, duration: 22.187s, episode steps: 755, steps per second:  34, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.008720, mae: 0.252403, mean_q: 0.313016, mean_eps: 0.858765\n",
            " 158063/1000000: episode: 223, duration: 22.227s, episode steps: 757, steps per second:  34, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.008003, mae: 0.255925, mean_q: 0.316491, mean_eps: 0.858084\n",
            " 158684/1000000: episode: 224, duration: 18.215s, episode steps: 621, steps per second:  34, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.006170, mae: 0.246421, mean_q: 0.306774, mean_eps: 0.857465\n",
            " 159669/1000000: episode: 225, duration: 28.968s, episode steps: 985, steps per second:  34, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.007574, mae: 0.248709, mean_q: 0.307771, mean_eps: 0.856742\n",
            " 160632/1000000: episode: 226, duration: 28.310s, episode steps: 963, steps per second:  34, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.008554, mae: 0.276921, mean_q: 0.343589, mean_eps: 0.855865\n",
            " 161163/1000000: episode: 227, duration: 15.671s, episode steps: 531, steps per second:  34, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.007511, mae: 0.288050, mean_q: 0.357875, mean_eps: 0.855194\n",
            " 161806/1000000: episode: 228, duration: 18.920s, episode steps: 643, steps per second:  34, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.008324, mae: 0.287081, mean_q: 0.356252, mean_eps: 0.854664\n",
            " 162910/1000000: episode: 229, duration: 32.490s, episode steps: 1104, steps per second:  34, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007485, mae: 0.285225, mean_q: 0.354779, mean_eps: 0.853878\n",
            " 163793/1000000: episode: 230, duration: 25.977s, episode steps: 883, steps per second:  34, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006920, mae: 0.284048, mean_q: 0.351984, mean_eps: 0.852983\n",
            " 164749/1000000: episode: 231, duration: 28.075s, episode steps: 956, steps per second:  34, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.008228, mae: 0.285021, mean_q: 0.352285, mean_eps: 0.852155\n",
            " 165133/1000000: episode: 232, duration: 11.362s, episode steps: 384, steps per second:  34, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.008449, mae: 0.284156, mean_q: 0.353587, mean_eps: 0.851552\n",
            " 165650/1000000: episode: 233, duration: 15.265s, episode steps: 517, steps per second:  34, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.008983, mae: 0.289581, mean_q: 0.359896, mean_eps: 0.851147\n",
            " 166035/1000000: episode: 234, duration: 11.285s, episode steps: 385, steps per second:  34, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.008543, mae: 0.288129, mean_q: 0.357615, mean_eps: 0.850742\n",
            " 166560/1000000: episode: 235, duration: 15.566s, episode steps: 525, steps per second:  34, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.006347, mae: 0.283953, mean_q: 0.352706, mean_eps: 0.850334\n",
            " 167131/1000000: episode: 236, duration: 16.783s, episode steps: 571, steps per second:  34, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.008034, mae: 0.286484, mean_q: 0.354674, mean_eps: 0.849840\n",
            " 167978/1000000: episode: 237, duration: 24.961s, episode steps: 847, steps per second:  34, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.007419, mae: 0.282326, mean_q: 0.348820, mean_eps: 0.849201\n",
            " 168737/1000000: episode: 238, duration: 22.397s, episode steps: 759, steps per second:  34, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.007708, mae: 0.283219, mean_q: 0.350987, mean_eps: 0.848478\n",
            " 169449/1000000: episode: 239, duration: 20.978s, episode steps: 712, steps per second:  34, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.007040, mae: 0.283957, mean_q: 0.352443, mean_eps: 0.847815\n",
            " 170004/1000000: episode: 240, duration: 16.312s, episode steps: 555, steps per second:  34, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.007226, mae: 0.284897, mean_q: 0.353123, mean_eps: 0.847247\n",
            " 170590/1000000: episode: 241, duration: 17.205s, episode steps: 586, steps per second:  34, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.008122, mae: 0.312446, mean_q: 0.386396, mean_eps: 0.846734\n",
            " 171355/1000000: episode: 242, duration: 22.516s, episode steps: 765, steps per second:  34, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.008302, mae: 0.308073, mean_q: 0.381756, mean_eps: 0.846125\n",
            " 171921/1000000: episode: 243, duration: 16.792s, episode steps: 566, steps per second:  34, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.007859, mae: 0.300030, mean_q: 0.371457, mean_eps: 0.845526\n",
            " 172562/1000000: episode: 244, duration: 18.777s, episode steps: 641, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.008853, mae: 0.311485, mean_q: 0.386506, mean_eps: 0.844982\n",
            " 172970/1000000: episode: 245, duration: 12.020s, episode steps: 408, steps per second:  34, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.006800, mae: 0.303188, mean_q: 0.377461, mean_eps: 0.844511\n",
            " 173363/1000000: episode: 246, duration: 11.574s, episode steps: 393, steps per second:  34, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.008960, mae: 0.310535, mean_q: 0.385342, mean_eps: 0.844151\n",
            " 173852/1000000: episode: 247, duration: 14.452s, episode steps: 489, steps per second:  34, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.007108, mae: 0.301038, mean_q: 0.374357, mean_eps: 0.843755\n",
            " 174713/1000000: episode: 248, duration: 25.491s, episode steps: 861, steps per second:  34, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.008065, mae: 0.313739, mean_q: 0.388669, mean_eps: 0.843146\n",
            " 175241/1000000: episode: 249, duration: 15.659s, episode steps: 528, steps per second:  34, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.007547, mae: 0.310149, mean_q: 0.384595, mean_eps: 0.842520\n",
            " 175900/1000000: episode: 250, duration: 19.426s, episode steps: 659, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.007760, mae: 0.307295, mean_q: 0.379903, mean_eps: 0.841987\n",
            " 176536/1000000: episode: 251, duration: 18.838s, episode steps: 636, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.007784, mae: 0.313904, mean_q: 0.389084, mean_eps: 0.841406\n",
            " 177272/1000000: episode: 252, duration: 21.821s, episode steps: 736, steps per second:  34, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.007762, mae: 0.312755, mean_q: 0.388275, mean_eps: 0.840788\n",
            " 177910/1000000: episode: 253, duration: 18.826s, episode steps: 638, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007933, mae: 0.310003, mean_q: 0.386114, mean_eps: 0.840169\n",
            " 178608/1000000: episode: 254, duration: 20.639s, episode steps: 698, steps per second:  34, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.006069, mae: 0.311580, mean_q: 0.386429, mean_eps: 0.839568\n",
            " 179366/1000000: episode: 255, duration: 22.529s, episode steps: 758, steps per second:  34, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.007042, mae: 0.312111, mean_q: 0.388167, mean_eps: 0.838913\n",
            " 180062/1000000: episode: 256, duration: 20.660s, episode steps: 696, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.007855, mae: 0.313329, mean_q: 0.389108, mean_eps: 0.838257\n",
            " 180840/1000000: episode: 257, duration: 23.219s, episode steps: 778, steps per second:  34, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.008450, mae: 0.348345, mean_q: 0.432593, mean_eps: 0.837595\n",
            " 181481/1000000: episode: 258, duration: 19.183s, episode steps: 641, steps per second:  33, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.007762, mae: 0.346299, mean_q: 0.428806, mean_eps: 0.836956\n",
            " 182281/1000000: episode: 259, duration: 23.755s, episode steps: 800, steps per second:  34, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.008336, mae: 0.338492, mean_q: 0.418889, mean_eps: 0.836306\n",
            " 182777/1000000: episode: 260, duration: 14.590s, episode steps: 496, steps per second:  34, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.007602, mae: 0.340856, mean_q: 0.421138, mean_eps: 0.835723\n",
            " 183411/1000000: episode: 261, duration: 18.774s, episode steps: 634, steps per second:  34, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.007980, mae: 0.343756, mean_q: 0.424947, mean_eps: 0.835215\n",
            " 184251/1000000: episode: 262, duration: 24.783s, episode steps: 840, steps per second:  34, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.008070, mae: 0.343231, mean_q: 0.424502, mean_eps: 0.834553\n",
            " 185191/1000000: episode: 263, duration: 27.934s, episode steps: 940, steps per second:  34, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.008144, mae: 0.346460, mean_q: 0.429603, mean_eps: 0.833752\n",
            " 186044/1000000: episode: 264, duration: 25.595s, episode steps: 853, steps per second:  33, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.008468, mae: 0.348334, mean_q: 0.432048, mean_eps: 0.832946\n",
            " 186647/1000000: episode: 265, duration: 18.037s, episode steps: 603, steps per second:  33, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.006990, mae: 0.343689, mean_q: 0.424672, mean_eps: 0.832290\n",
            " 187250/1000000: episode: 266, duration: 17.815s, episode steps: 603, steps per second:  34, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.007680, mae: 0.342391, mean_q: 0.424983, mean_eps: 0.831747\n",
            " 187874/1000000: episode: 267, duration: 18.528s, episode steps: 624, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.007324, mae: 0.338368, mean_q: 0.418227, mean_eps: 0.831194\n",
            " 188539/1000000: episode: 268, duration: 19.566s, episode steps: 665, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.008823, mae: 0.347223, mean_q: 0.429737, mean_eps: 0.830615\n",
            " 189673/1000000: episode: 269, duration: 33.674s, episode steps: 1134, steps per second:  34, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.008003, mae: 0.347326, mean_q: 0.430680, mean_eps: 0.829805\n",
            " 190601/1000000: episode: 270, duration: 27.447s, episode steps: 928, steps per second:  34, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.008188, mae: 0.352366, mean_q: 0.437260, mean_eps: 0.828876\n",
            " 191522/1000000: episode: 271, duration: 27.291s, episode steps: 921, steps per second:  34, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.008035, mae: 0.358031, mean_q: 0.442940, mean_eps: 0.828044\n",
            " 191944/1000000: episode: 272, duration: 12.569s, episode steps: 422, steps per second:  34, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.006275, mae: 0.355265, mean_q: 0.440407, mean_eps: 0.827441\n",
            " 192545/1000000: episode: 273, duration: 17.892s, episode steps: 601, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.007981, mae: 0.359379, mean_q: 0.446715, mean_eps: 0.826980\n",
            " 193232/1000000: episode: 274, duration: 20.577s, episode steps: 687, steps per second:  33, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.008154, mae: 0.356043, mean_q: 0.440048, mean_eps: 0.826401\n",
            " 193897/1000000: episode: 275, duration: 19.811s, episode steps: 665, steps per second:  34, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.007321, mae: 0.355758, mean_q: 0.439325, mean_eps: 0.825792\n",
            " 194429/1000000: episode: 276, duration: 15.858s, episode steps: 532, steps per second:  34, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.008069, mae: 0.366362, mean_q: 0.452929, mean_eps: 0.825252\n",
            " 195238/1000000: episode: 277, duration: 23.821s, episode steps: 809, steps per second:  34, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.008283, mae: 0.357993, mean_q: 0.441193, mean_eps: 0.824649\n",
            " 195818/1000000: episode: 278, duration: 17.257s, episode steps: 580, steps per second:  34, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007433, mae: 0.358362, mean_q: 0.442231, mean_eps: 0.824025\n",
            " 196240/1000000: episode: 279, duration: 12.488s, episode steps: 422, steps per second:  34, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.009359, mae: 0.362889, mean_q: 0.447502, mean_eps: 0.823575\n",
            " 197541/1000000: episode: 280, duration: 38.361s, episode steps: 1301, steps per second:  34, episode reward: 18.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007764, mae: 0.363417, mean_q: 0.447892, mean_eps: 0.822799\n",
            " 198551/1000000: episode: 281, duration: 29.711s, episode steps: 1010, steps per second:  34, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.007746, mae: 0.358011, mean_q: 0.441690, mean_eps: 0.821759\n",
            " 198935/1000000: episode: 282, duration: 11.256s, episode steps: 384, steps per second:  34, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: 0.008753, mae: 0.360741, mean_q: 0.446096, mean_eps: 0.821132\n",
            " 199331/1000000: episode: 283, duration: 11.680s, episode steps: 396, steps per second:  34, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.007165, mae: 0.355472, mean_q: 0.439575, mean_eps: 0.820781\n",
            " 200176/1000000: episode: 284, duration: 25.000s, episode steps: 845, steps per second:  34, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.007854, mae: 0.361501, mean_q: 0.446260, mean_eps: 0.820223\n",
            " 200916/1000000: episode: 285, duration: 22.139s, episode steps: 740, steps per second:  33, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.008991, mae: 0.390003, mean_q: 0.482197, mean_eps: 0.819510\n",
            " 201592/1000000: episode: 286, duration: 20.071s, episode steps: 676, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.008328, mae: 0.384062, mean_q: 0.476726, mean_eps: 0.818873\n",
            " 202178/1000000: episode: 287, duration: 17.432s, episode steps: 586, steps per second:  34, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.008321, mae: 0.396987, mean_q: 0.492726, mean_eps: 0.818304\n",
            " 202772/1000000: episode: 288, duration: 17.642s, episode steps: 594, steps per second:  34, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.008286, mae: 0.387772, mean_q: 0.480551, mean_eps: 0.817773\n",
            " 203289/1000000: episode: 289, duration: 15.496s, episode steps: 517, steps per second:  33, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.009007, mae: 0.393981, mean_q: 0.485841, mean_eps: 0.817273\n",
            " 204464/1000000: episode: 290, duration: 34.934s, episode steps: 1175, steps per second:  34, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.008249, mae: 0.393898, mean_q: 0.488327, mean_eps: 0.816512\n",
            " 205216/1000000: episode: 291, duration: 22.352s, episode steps: 752, steps per second:  34, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.008321, mae: 0.389297, mean_q: 0.482125, mean_eps: 0.815646\n",
            " 205847/1000000: episode: 292, duration: 18.768s, episode steps: 631, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.007122, mae: 0.390175, mean_q: 0.482317, mean_eps: 0.815023\n",
            " 206624/1000000: episode: 293, duration: 23.299s, episode steps: 777, steps per second:  33, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.008024, mae: 0.393062, mean_q: 0.485376, mean_eps: 0.814389\n",
            " 207601/1000000: episode: 294, duration: 28.948s, episode steps: 977, steps per second:  34, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.007683, mae: 0.385773, mean_q: 0.475340, mean_eps: 0.813599\n",
            " 208148/1000000: episode: 295, duration: 16.329s, episode steps: 547, steps per second:  33, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.009495, mae: 0.401602, mean_q: 0.494023, mean_eps: 0.812913\n",
            " 208718/1000000: episode: 296, duration: 17.038s, episode steps: 570, steps per second:  33, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.008532, mae: 0.393360, mean_q: 0.484206, mean_eps: 0.812411\n",
            " 209525/1000000: episode: 297, duration: 23.874s, episode steps: 807, steps per second:  34, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.007658, mae: 0.394548, mean_q: 0.488667, mean_eps: 0.811790\n",
            " 210444/1000000: episode: 298, duration: 27.734s, episode steps: 919, steps per second:  33, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.008394, mae: 0.401897, mean_q: 0.496375, mean_eps: 0.811014\n",
            " 211104/1000000: episode: 299, duration: 20.454s, episode steps: 660, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.009567, mae: 0.424349, mean_q: 0.524038, mean_eps: 0.810305\n",
            " 211921/1000000: episode: 300, duration: 25.015s, episode steps: 817, steps per second:  33, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.008465, mae: 0.420733, mean_q: 0.517832, mean_eps: 0.809639\n",
            " 212323/1000000: episode: 301, duration: 12.217s, episode steps: 402, steps per second:  33, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.008812, mae: 0.419657, mean_q: 0.517118, mean_eps: 0.809090\n",
            " 213257/1000000: episode: 302, duration: 28.207s, episode steps: 934, steps per second:  33, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.008062, mae: 0.411202, mean_q: 0.508787, mean_eps: 0.808489\n",
            " 213889/1000000: episode: 303, duration: 19.054s, episode steps: 632, steps per second:  33, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.007691, mae: 0.414209, mean_q: 0.510164, mean_eps: 0.807783\n",
            " 214604/1000000: episode: 304, duration: 21.485s, episode steps: 715, steps per second:  33, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.008342, mae: 0.423890, mean_q: 0.522698, mean_eps: 0.807179\n",
            " 215415/1000000: episode: 305, duration: 24.187s, episode steps: 811, steps per second:  34, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.009001, mae: 0.416784, mean_q: 0.513244, mean_eps: 0.806493\n",
            " 216024/1000000: episode: 306, duration: 18.108s, episode steps: 609, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.008549, mae: 0.419715, mean_q: 0.517478, mean_eps: 0.805854\n",
            " 216534/1000000: episode: 307, duration: 15.367s, episode steps: 510, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.008717, mae: 0.427399, mean_q: 0.526891, mean_eps: 0.805350\n",
            " 217024/1000000: episode: 308, duration: 14.760s, episode steps: 490, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.008632, mae: 0.416529, mean_q: 0.513237, mean_eps: 0.804900\n",
            " 217719/1000000: episode: 309, duration: 21.070s, episode steps: 695, steps per second:  33, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.008757, mae: 0.421685, mean_q: 0.520136, mean_eps: 0.804367\n",
            " 218287/1000000: episode: 310, duration: 17.151s, episode steps: 568, steps per second:  33, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.727 [0.000, 5.000],  loss: 0.007794, mae: 0.418011, mean_q: 0.515580, mean_eps: 0.803798\n",
            " 218674/1000000: episode: 311, duration: 11.732s, episode steps: 387, steps per second:  33, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.007084, mae: 0.416162, mean_q: 0.512220, mean_eps: 0.803368\n",
            " 219444/1000000: episode: 312, duration: 23.298s, episode steps: 770, steps per second:  33, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.008719, mae: 0.417941, mean_q: 0.516323, mean_eps: 0.802848\n",
            " 219793/1000000: episode: 313, duration: 10.508s, episode steps: 349, steps per second:  33, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.008613, mae: 0.415467, mean_q: 0.511539, mean_eps: 0.802344\n",
            " 220455/1000000: episode: 314, duration: 19.784s, episode steps: 662, steps per second:  33, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.007099, mae: 0.439220, mean_q: 0.544123, mean_eps: 0.801888\n",
            " 220942/1000000: episode: 315, duration: 14.696s, episode steps: 487, steps per second:  33, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.008403, mae: 0.448641, mean_q: 0.553193, mean_eps: 0.801372\n",
            " 221326/1000000: episode: 316, duration: 11.501s, episode steps: 384, steps per second:  33, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.007891, mae: 0.438473, mean_q: 0.543131, mean_eps: 0.800979\n",
            " 221719/1000000: episode: 317, duration: 11.697s, episode steps: 393, steps per second:  34, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.009534, mae: 0.441179, mean_q: 0.544934, mean_eps: 0.800630\n",
            " 222229/1000000: episode: 318, duration: 15.330s, episode steps: 510, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.009308, mae: 0.444077, mean_q: 0.550454, mean_eps: 0.800223\n",
            " 222638/1000000: episode: 319, duration: 12.132s, episode steps: 409, steps per second:  34, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.008561, mae: 0.439045, mean_q: 0.543073, mean_eps: 0.799809\n",
            " 223189/1000000: episode: 320, duration: 16.421s, episode steps: 551, steps per second:  34, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.009217, mae: 0.444064, mean_q: 0.547012, mean_eps: 0.799377\n",
            " 223811/1000000: episode: 321, duration: 18.434s, episode steps: 622, steps per second:  34, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.008574, mae: 0.442668, mean_q: 0.545708, mean_eps: 0.798850\n",
            " 224185/1000000: episode: 322, duration: 11.145s, episode steps: 374, steps per second:  34, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.797 [0.000, 5.000],  loss: 0.008668, mae: 0.438798, mean_q: 0.541228, mean_eps: 0.798402\n",
            " 225405/1000000: episode: 323, duration: 36.508s, episode steps: 1220, steps per second:  33, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.008282, mae: 0.441613, mean_q: 0.543818, mean_eps: 0.797684\n",
            " 226282/1000000: episode: 324, duration: 26.143s, episode steps: 877, steps per second:  34, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.009354, mae: 0.443808, mean_q: 0.547528, mean_eps: 0.796740\n",
            " 226771/1000000: episode: 325, duration: 14.689s, episode steps: 489, steps per second:  33, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.007960, mae: 0.445929, mean_q: 0.551054, mean_eps: 0.796127\n",
            " 227856/1000000: episode: 326, duration: 32.416s, episode steps: 1085, steps per second:  33, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.009419, mae: 0.440198, mean_q: 0.542389, mean_eps: 0.795419\n",
            " 228364/1000000: episode: 327, duration: 15.321s, episode steps: 508, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007202, mae: 0.437412, mean_q: 0.539168, mean_eps: 0.794703\n",
            " 228972/1000000: episode: 328, duration: 18.167s, episode steps: 608, steps per second:  33, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.009457, mae: 0.450278, mean_q: 0.556257, mean_eps: 0.794201\n",
            " 229555/1000000: episode: 329, duration: 17.478s, episode steps: 583, steps per second:  33, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.007288, mae: 0.436937, mean_q: 0.539372, mean_eps: 0.793664\n",
            " 230049/1000000: episode: 330, duration: 14.818s, episode steps: 494, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.009318, mae: 0.440025, mean_q: 0.542292, mean_eps: 0.793178\n",
            " 230987/1000000: episode: 331, duration: 27.973s, episode steps: 938, steps per second:  34, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.008622, mae: 0.466481, mean_q: 0.574918, mean_eps: 0.792534\n",
            " 231488/1000000: episode: 332, duration: 14.973s, episode steps: 501, steps per second:  33, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.009421, mae: 0.482594, mean_q: 0.593381, mean_eps: 0.791888\n",
            " 232745/1000000: episode: 333, duration: 37.802s, episode steps: 1257, steps per second:  33, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.008747, mae: 0.465200, mean_q: 0.573716, mean_eps: 0.791096\n",
            " 233161/1000000: episode: 334, duration: 12.414s, episode steps: 416, steps per second:  34, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.009172, mae: 0.467039, mean_q: 0.574837, mean_eps: 0.790341\n",
            " 233797/1000000: episode: 335, duration: 19.091s, episode steps: 636, steps per second:  33, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.008914, mae: 0.469880, mean_q: 0.578882, mean_eps: 0.789868\n",
            " 234579/1000000: episode: 336, duration: 23.428s, episode steps: 782, steps per second:  33, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.008378, mae: 0.472065, mean_q: 0.583710, mean_eps: 0.789231\n",
            " 235196/1000000: episode: 337, duration: 18.525s, episode steps: 617, steps per second:  33, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.008733, mae: 0.471366, mean_q: 0.581032, mean_eps: 0.788603\n",
            " 235566/1000000: episode: 338, duration: 11.149s, episode steps: 370, steps per second:  33, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.011505, mae: 0.465470, mean_q: 0.571660, mean_eps: 0.788158\n",
            " 235963/1000000: episode: 339, duration: 11.882s, episode steps: 397, steps per second:  33, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.007620, mae: 0.463708, mean_q: 0.572563, mean_eps: 0.787812\n",
            " 236592/1000000: episode: 340, duration: 18.915s, episode steps: 629, steps per second:  33, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.008890, mae: 0.472343, mean_q: 0.581066, mean_eps: 0.787352\n",
            " 237131/1000000: episode: 341, duration: 16.220s, episode steps: 539, steps per second:  33, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.010162, mae: 0.473099, mean_q: 0.582815, mean_eps: 0.786826\n",
            " 237771/1000000: episode: 342, duration: 19.377s, episode steps: 640, steps per second:  33, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.009519, mae: 0.474907, mean_q: 0.584571, mean_eps: 0.786295\n",
            " 238283/1000000: episode: 343, duration: 15.328s, episode steps: 512, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.008201, mae: 0.476733, mean_q: 0.586963, mean_eps: 0.785777\n",
            " 239136/1000000: episode: 344, duration: 25.677s, episode steps: 853, steps per second:  33, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.008819, mae: 0.466813, mean_q: 0.575335, mean_eps: 0.785163\n",
            " 239584/1000000: episode: 345, duration: 13.485s, episode steps: 448, steps per second:  33, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.732 [0.000, 5.000],  loss: 0.007951, mae: 0.470472, mean_q: 0.578200, mean_eps: 0.784578\n",
            " 240594/1000000: episode: 346, duration: 30.432s, episode steps: 1010, steps per second:  33, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.008917, mae: 0.492537, mean_q: 0.605287, mean_eps: 0.783921\n",
            " 241412/1000000: episode: 347, duration: 24.611s, episode steps: 818, steps per second:  33, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.008176, mae: 0.505276, mean_q: 0.621236, mean_eps: 0.783098\n",
            " 242349/1000000: episode: 348, duration: 28.152s, episode steps: 937, steps per second:  33, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.008533, mae: 0.496297, mean_q: 0.609455, mean_eps: 0.782308\n",
            " 242694/1000000: episode: 349, duration: 10.296s, episode steps: 345, steps per second:  34, episode reward:  1.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.008019, mae: 0.497752, mean_q: 0.611052, mean_eps: 0.781730\n",
            " 243057/1000000: episode: 350, duration: 10.984s, episode steps: 363, steps per second:  33, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.007614, mae: 0.496998, mean_q: 0.611969, mean_eps: 0.781412\n",
            " 243732/1000000: episode: 351, duration: 20.292s, episode steps: 675, steps per second:  33, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.009493, mae: 0.510239, mean_q: 0.628955, mean_eps: 0.780945\n",
            " 244134/1000000: episode: 352, duration: 12.052s, episode steps: 402, steps per second:  33, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.008768, mae: 0.505098, mean_q: 0.622234, mean_eps: 0.780461\n",
            " 244939/1000000: episode: 353, duration: 24.019s, episode steps: 805, steps per second:  34, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.008755, mae: 0.502421, mean_q: 0.618318, mean_eps: 0.779918\n",
            " 245581/1000000: episode: 354, duration: 19.241s, episode steps: 642, steps per second:  33, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.009275, mae: 0.504607, mean_q: 0.619177, mean_eps: 0.779266\n",
            " 246702/1000000: episode: 355, duration: 33.428s, episode steps: 1121, steps per second:  34, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.009983, mae: 0.509730, mean_q: 0.628122, mean_eps: 0.778472\n",
            " 247325/1000000: episode: 356, duration: 18.794s, episode steps: 623, steps per second:  33, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: 0.009696, mae: 0.500722, mean_q: 0.616766, mean_eps: 0.777687\n",
            " 247995/1000000: episode: 357, duration: 20.227s, episode steps: 670, steps per second:  33, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.009508, mae: 0.501085, mean_q: 0.615767, mean_eps: 0.777106\n",
            " 248652/1000000: episode: 358, duration: 19.755s, episode steps: 657, steps per second:  33, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.746 [0.000, 5.000],  loss: 0.008869, mae: 0.505626, mean_q: 0.623159, mean_eps: 0.776510\n",
            " 249162/1000000: episode: 359, duration: 15.353s, episode steps: 510, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.007814, mae: 0.501712, mean_q: 0.616199, mean_eps: 0.775985\n",
            " 249915/1000000: episode: 360, duration: 22.596s, episode steps: 753, steps per second:  33, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.008898, mae: 0.501011, mean_q: 0.616017, mean_eps: 0.775416\n",
            " 250556/1000000: episode: 361, duration: 19.457s, episode steps: 641, steps per second:  33, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.009408, mae: 0.525752, mean_q: 0.648968, mean_eps: 0.774789\n",
            " 251084/1000000: episode: 362, duration: 15.957s, episode steps: 528, steps per second:  33, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.009300, mae: 0.528407, mean_q: 0.650779, mean_eps: 0.774264\n",
            " 252199/1000000: episode: 363, duration: 33.564s, episode steps: 1115, steps per second:  33, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.008289, mae: 0.524849, mean_q: 0.646015, mean_eps: 0.773524\n",
            " 253015/1000000: episode: 364, duration: 24.624s, episode steps: 816, steps per second:  33, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.716 [0.000, 5.000],  loss: 0.009380, mae: 0.528266, mean_q: 0.648602, mean_eps: 0.772655\n",
            " 253556/1000000: episode: 365, duration: 16.391s, episode steps: 541, steps per second:  33, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.009085, mae: 0.527841, mean_q: 0.648263, mean_eps: 0.772044\n",
            " 254377/1000000: episode: 366, duration: 24.789s, episode steps: 821, steps per second:  33, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.009541, mae: 0.531799, mean_q: 0.651561, mean_eps: 0.771431\n",
            " 255007/1000000: episode: 367, duration: 19.140s, episode steps: 630, steps per second:  33, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.008985, mae: 0.525132, mean_q: 0.642719, mean_eps: 0.770777\n",
            " 255429/1000000: episode: 368, duration: 12.742s, episode steps: 422, steps per second:  33, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.008008, mae: 0.520487, mean_q: 0.639096, mean_eps: 0.770304\n",
            " 256037/1000000: episode: 369, duration: 18.400s, episode steps: 608, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.008513, mae: 0.528583, mean_q: 0.648690, mean_eps: 0.769839\n",
            " 257210/1000000: episode: 370, duration: 35.348s, episode steps: 1173, steps per second:  33, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.008786, mae: 0.530356, mean_q: 0.652511, mean_eps: 0.769038\n",
            " 258140/1000000: episode: 371, duration: 28.279s, episode steps: 930, steps per second:  33, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.008528, mae: 0.529346, mean_q: 0.652958, mean_eps: 0.768093\n",
            " 258830/1000000: episode: 372, duration: 20.951s, episode steps: 690, steps per second:  33, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.009511, mae: 0.530954, mean_q: 0.654251, mean_eps: 0.767364\n",
            " 259647/1000000: episode: 373, duration: 24.855s, episode steps: 817, steps per second:  33, episode reward:  6.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.008740, mae: 0.538004, mean_q: 0.661853, mean_eps: 0.766686\n",
            " 260160/1000000: episode: 374, duration: 15.519s, episode steps: 513, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.011263, mae: 0.538739, mean_q: 0.665137, mean_eps: 0.766088\n",
            " 261236/1000000: episode: 375, duration: 32.868s, episode steps: 1076, steps per second:  33, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.010248, mae: 0.572534, mean_q: 0.706189, mean_eps: 0.765374\n",
            " 262181/1000000: episode: 376, duration: 28.713s, episode steps: 945, steps per second:  33, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.008861, mae: 0.555711, mean_q: 0.685875, mean_eps: 0.764463\n",
            " 263144/1000000: episode: 377, duration: 29.213s, episode steps: 963, steps per second:  33, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.011053, mae: 0.564716, mean_q: 0.695514, mean_eps: 0.763604\n",
            " 263827/1000000: episode: 378, duration: 20.608s, episode steps: 683, steps per second:  33, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.008184, mae: 0.568965, mean_q: 0.703226, mean_eps: 0.762864\n",
            " 264382/1000000: episode: 379, duration: 16.833s, episode steps: 555, steps per second:  33, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.009487, mae: 0.569075, mean_q: 0.702112, mean_eps: 0.762306\n",
            " 264925/1000000: episode: 380, duration: 16.461s, episode steps: 543, steps per second:  33, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.669 [0.000, 5.000],  loss: 0.009021, mae: 0.573892, mean_q: 0.708441, mean_eps: 0.761811\n",
            " 265514/1000000: episode: 381, duration: 17.848s, episode steps: 589, steps per second:  33, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.007723, mae: 0.567121, mean_q: 0.697960, mean_eps: 0.761302\n",
            " 265880/1000000: episode: 382, duration: 11.269s, episode steps: 366, steps per second:  32, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.008217, mae: 0.552218, mean_q: 0.679375, mean_eps: 0.760874\n",
            " 266461/1000000: episode: 383, duration: 17.764s, episode steps: 581, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.009499, mae: 0.561138, mean_q: 0.690852, mean_eps: 0.760447\n",
            " 267019/1000000: episode: 384, duration: 16.843s, episode steps: 558, steps per second:  33, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.009569, mae: 0.561030, mean_q: 0.692303, mean_eps: 0.759934\n",
            " 267509/1000000: episode: 385, duration: 14.977s, episode steps: 490, steps per second:  33, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.743 [0.000, 5.000],  loss: 0.008785, mae: 0.567348, mean_q: 0.698003, mean_eps: 0.759462\n",
            " 268258/1000000: episode: 386, duration: 22.781s, episode steps: 749, steps per second:  33, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.008755, mae: 0.564867, mean_q: 0.695567, mean_eps: 0.758904\n",
            " 268835/1000000: episode: 387, duration: 17.489s, episode steps: 577, steps per second:  33, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.008652, mae: 0.561504, mean_q: 0.689502, mean_eps: 0.758309\n",
            " 269667/1000000: episode: 388, duration: 25.152s, episode steps: 832, steps per second:  33, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.009607, mae: 0.569739, mean_q: 0.701248, mean_eps: 0.757675\n",
            " 270906/1000000: episode: 389, duration: 37.862s, episode steps: 1239, steps per second:  33, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.009414, mae: 0.585675, mean_q: 0.723039, mean_eps: 0.756743\n",
            " 271593/1000000: episode: 390, duration: 21.005s, episode steps: 687, steps per second:  33, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.009965, mae: 0.598670, mean_q: 0.735843, mean_eps: 0.755875\n",
            " 272530/1000000: episode: 391, duration: 28.362s, episode steps: 937, steps per second:  33, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.009615, mae: 0.608049, mean_q: 0.746593, mean_eps: 0.755144\n",
            " 273160/1000000: episode: 392, duration: 19.192s, episode steps: 630, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.008967, mae: 0.598995, mean_q: 0.735402, mean_eps: 0.754440\n",
            " 273779/1000000: episode: 393, duration: 18.974s, episode steps: 619, steps per second:  33, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.008944, mae: 0.591087, mean_q: 0.726573, mean_eps: 0.753879\n",
            " 274237/1000000: episode: 394, duration: 14.054s, episode steps: 458, steps per second:  33, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.799 [0.000, 5.000],  loss: 0.008962, mae: 0.598079, mean_q: 0.736057, mean_eps: 0.753393\n",
            " 274622/1000000: episode: 395, duration: 11.735s, episode steps: 385, steps per second:  33, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.009499, mae: 0.581919, mean_q: 0.714688, mean_eps: 0.753013\n",
            " 275273/1000000: episode: 396, duration: 19.954s, episode steps: 651, steps per second:  33, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.009159, mae: 0.591853, mean_q: 0.729565, mean_eps: 0.752547\n",
            " 276086/1000000: episode: 397, duration: 24.810s, episode steps: 813, steps per second:  33, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.009084, mae: 0.599201, mean_q: 0.736396, mean_eps: 0.751888\n",
            " 277070/1000000: episode: 398, duration: 30.047s, episode steps: 984, steps per second:  33, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.008937, mae: 0.594162, mean_q: 0.731595, mean_eps: 0.751080\n",
            " 277649/1000000: episode: 399, duration: 17.623s, episode steps: 579, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.009972, mae: 0.602290, mean_q: 0.741319, mean_eps: 0.750376\n",
            " 278363/1000000: episode: 400, duration: 21.795s, episode steps: 714, steps per second:  33, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.009023, mae: 0.598096, mean_q: 0.736000, mean_eps: 0.749795\n",
            " 278826/1000000: episode: 401, duration: 14.132s, episode steps: 463, steps per second:  33, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.009978, mae: 0.607846, mean_q: 0.746472, mean_eps: 0.749265\n",
            " 279519/1000000: episode: 402, duration: 20.992s, episode steps: 693, steps per second:  33, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.009280, mae: 0.602333, mean_q: 0.740605, mean_eps: 0.748745\n",
            " 280191/1000000: episode: 403, duration: 20.420s, episode steps: 672, steps per second:  33, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.008734, mae: 0.612217, mean_q: 0.754186, mean_eps: 0.748131\n",
            " 280928/1000000: episode: 404, duration: 22.480s, episode steps: 737, steps per second:  33, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.009179, mae: 0.628369, mean_q: 0.777406, mean_eps: 0.747498\n",
            " 282005/1000000: episode: 405, duration: 32.736s, episode steps: 1077, steps per second:  33, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.009516, mae: 0.628376, mean_q: 0.775291, mean_eps: 0.746681\n",
            " 282498/1000000: episode: 406, duration: 14.856s, episode steps: 493, steps per second:  33, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.009834, mae: 0.631742, mean_q: 0.778504, mean_eps: 0.745973\n",
            " 283023/1000000: episode: 407, duration: 15.930s, episode steps: 525, steps per second:  33, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.009722, mae: 0.630991, mean_q: 0.777051, mean_eps: 0.745516\n",
            " 283384/1000000: episode: 408, duration: 11.083s, episode steps: 361, steps per second:  33, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.009850, mae: 0.625800, mean_q: 0.769743, mean_eps: 0.745118\n",
            " 284078/1000000: episode: 409, duration: 21.109s, episode steps: 694, steps per second:  33, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.009359, mae: 0.628137, mean_q: 0.772007, mean_eps: 0.744643\n",
            " 284829/1000000: episode: 410, duration: 22.900s, episode steps: 751, steps per second:  33, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.009325, mae: 0.626336, mean_q: 0.771320, mean_eps: 0.743991\n",
            " 285383/1000000: episode: 411, duration: 16.944s, episode steps: 554, steps per second:  33, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.009826, mae: 0.626338, mean_q: 0.770030, mean_eps: 0.743405\n",
            " 286173/1000000: episode: 412, duration: 24.046s, episode steps: 790, steps per second:  33, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.009375, mae: 0.628181, mean_q: 0.771689, mean_eps: 0.742800\n",
            " 286712/1000000: episode: 413, duration: 16.413s, episode steps: 539, steps per second:  33, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.008888, mae: 0.625829, mean_q: 0.769920, mean_eps: 0.742202\n",
            " 287461/1000000: episode: 414, duration: 22.810s, episode steps: 749, steps per second:  33, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.009639, mae: 0.633001, mean_q: 0.777104, mean_eps: 0.741623\n",
            " 288032/1000000: episode: 415, duration: 17.381s, episode steps: 571, steps per second:  33, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.009913, mae: 0.630695, mean_q: 0.777279, mean_eps: 0.741029\n",
            " 288751/1000000: episode: 416, duration: 22.160s, episode steps: 719, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.009208, mae: 0.634685, mean_q: 0.782917, mean_eps: 0.740449\n",
            " 289247/1000000: episode: 417, duration: 15.189s, episode steps: 496, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.683 [0.000, 5.000],  loss: 0.009069, mae: 0.627390, mean_q: 0.772011, mean_eps: 0.739902\n",
            " 289604/1000000: episode: 418, duration: 10.968s, episode steps: 357, steps per second:  33, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.832 [0.000, 5.000],  loss: 0.010048, mae: 0.634251, mean_q: 0.777487, mean_eps: 0.739518\n",
            " 290192/1000000: episode: 419, duration: 18.110s, episode steps: 588, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.009111, mae: 0.647413, mean_q: 0.796693, mean_eps: 0.739094\n",
            " 290730/1000000: episode: 420, duration: 16.467s, episode steps: 538, steps per second:  33, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.008969, mae: 0.674007, mean_q: 0.829460, mean_eps: 0.738586\n",
            " 291517/1000000: episode: 421, duration: 24.083s, episode steps: 787, steps per second:  33, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.009048, mae: 0.651959, mean_q: 0.801689, mean_eps: 0.737988\n",
            " 292268/1000000: episode: 422, duration: 23.031s, episode steps: 751, steps per second:  33, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.009875, mae: 0.664218, mean_q: 0.815416, mean_eps: 0.737297\n",
            " 293127/1000000: episode: 423, duration: 26.215s, episode steps: 859, steps per second:  33, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.011513, mae: 0.679618, mean_q: 0.835599, mean_eps: 0.736574\n",
            " 293901/1000000: episode: 424, duration: 23.624s, episode steps: 774, steps per second:  33, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.009777, mae: 0.669223, mean_q: 0.823012, mean_eps: 0.735837\n",
            " 294650/1000000: episode: 425, duration: 22.881s, episode steps: 749, steps per second:  33, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.010288, mae: 0.670383, mean_q: 0.823208, mean_eps: 0.735152\n",
            " 295084/1000000: episode: 426, duration: 13.332s, episode steps: 434, steps per second:  33, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.009935, mae: 0.677300, mean_q: 0.832117, mean_eps: 0.734621\n",
            " 295453/1000000: episode: 427, duration: 11.306s, episode steps: 369, steps per second:  33, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.702 [0.000, 5.000],  loss: 0.010871, mae: 0.677621, mean_q: 0.833803, mean_eps: 0.734259\n",
            " 296076/1000000: episode: 428, duration: 19.051s, episode steps: 623, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.684 [0.000, 5.000],  loss: 0.008547, mae: 0.657909, mean_q: 0.810662, mean_eps: 0.733812\n",
            " 296640/1000000: episode: 429, duration: 17.590s, episode steps: 564, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.010335, mae: 0.660454, mean_q: 0.812576, mean_eps: 0.733280\n",
            " 297355/1000000: episode: 430, duration: 22.028s, episode steps: 715, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.683 [0.000, 5.000],  loss: 0.011028, mae: 0.662336, mean_q: 0.816842, mean_eps: 0.732704\n",
            " 298019/1000000: episode: 431, duration: 20.615s, episode steps: 664, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.010985, mae: 0.671933, mean_q: 0.826472, mean_eps: 0.732083\n",
            " 298413/1000000: episode: 432, duration: 12.267s, episode steps: 394, steps per second:  32, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.009642, mae: 0.660481, mean_q: 0.812826, mean_eps: 0.731606\n",
            " 299043/1000000: episode: 433, duration: 19.318s, episode steps: 630, steps per second:  33, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.009077, mae: 0.661605, mean_q: 0.813442, mean_eps: 0.731145\n",
            " 299667/1000000: episode: 434, duration: 19.302s, episode steps: 624, steps per second:  32, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.009983, mae: 0.665821, mean_q: 0.821348, mean_eps: 0.730581\n",
            " 300761/1000000: episode: 435, duration: 33.692s, episode steps: 1094, steps per second:  32, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.009818, mae: 0.687387, mean_q: 0.847731, mean_eps: 0.729807\n",
            " 301480/1000000: episode: 436, duration: 22.100s, episode steps: 719, steps per second:  33, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.009483, mae: 0.700791, mean_q: 0.863510, mean_eps: 0.728992\n",
            " 302147/1000000: episode: 437, duration: 20.499s, episode steps: 667, steps per second:  33, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.011392, mae: 0.698722, mean_q: 0.857358, mean_eps: 0.728369\n",
            " 302564/1000000: episode: 438, duration: 12.931s, episode steps: 417, steps per second:  32, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.009702, mae: 0.693392, mean_q: 0.852711, mean_eps: 0.727881\n",
            " 303134/1000000: episode: 439, duration: 17.645s, episode steps: 570, steps per second:  32, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.010974, mae: 0.706634, mean_q: 0.866220, mean_eps: 0.727437\n",
            " 303643/1000000: episode: 440, duration: 15.577s, episode steps: 509, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.009871, mae: 0.706656, mean_q: 0.869800, mean_eps: 0.726951\n",
            " 304199/1000000: episode: 441, duration: 17.197s, episode steps: 556, steps per second:  32, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.011319, mae: 0.715848, mean_q: 0.878943, mean_eps: 0.726472\n",
            " 304655/1000000: episode: 442, duration: 14.293s, episode steps: 456, steps per second:  32, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.842 [0.000, 5.000],  loss: 0.009383, mae: 0.704238, mean_q: 0.867047, mean_eps: 0.726017\n",
            " 305022/1000000: episode: 443, duration: 11.436s, episode steps: 367, steps per second:  32, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.010610, mae: 0.706337, mean_q: 0.868437, mean_eps: 0.725646\n",
            " 305690/1000000: episode: 444, duration: 20.590s, episode steps: 668, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.011402, mae: 0.713394, mean_q: 0.875283, mean_eps: 0.725180\n",
            " 306203/1000000: episode: 445, duration: 15.955s, episode steps: 513, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.009118, mae: 0.702510, mean_q: 0.864645, mean_eps: 0.724649\n",
            " 307176/1000000: episode: 446, duration: 30.211s, episode steps: 973, steps per second:  32, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.009616, mae: 0.706678, mean_q: 0.869594, mean_eps: 0.723981\n",
            " 307707/1000000: episode: 447, duration: 16.641s, episode steps: 531, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.716 [0.000, 5.000],  loss: 0.010236, mae: 0.704808, mean_q: 0.867860, mean_eps: 0.723304\n",
            " 308183/1000000: episode: 448, duration: 14.879s, episode steps: 476, steps per second:  32, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.009671, mae: 0.706110, mean_q: 0.868492, mean_eps: 0.722850\n",
            " 308853/1000000: episode: 449, duration: 21.038s, episode steps: 670, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.009540, mae: 0.695445, mean_q: 0.854633, mean_eps: 0.722334\n",
            " 309336/1000000: episode: 450, duration: 14.916s, episode steps: 483, steps per second:  32, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.797 [0.000, 5.000],  loss: 0.011287, mae: 0.704071, mean_q: 0.865091, mean_eps: 0.721815\n",
            " 310453/1000000: episode: 451, duration: 34.569s, episode steps: 1117, steps per second:  32, episode reward: 25.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.009642, mae: 0.704587, mean_q: 0.867108, mean_eps: 0.721095\n",
            " 311074/1000000: episode: 452, duration: 19.103s, episode steps: 621, steps per second:  33, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.009805, mae: 0.720982, mean_q: 0.885779, mean_eps: 0.720312\n",
            " 311673/1000000: episode: 453, duration: 18.708s, episode steps: 599, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.010497, mae: 0.732734, mean_q: 0.901272, mean_eps: 0.719763\n",
            " 312240/1000000: episode: 454, duration: 17.581s, episode steps: 567, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.010432, mae: 0.729015, mean_q: 0.896941, mean_eps: 0.719240\n",
            " 313292/1000000: episode: 455, duration: 32.719s, episode steps: 1052, steps per second:  32, episode reward: 27.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.010046, mae: 0.724519, mean_q: 0.892062, mean_eps: 0.718512\n",
            " 313666/1000000: episode: 456, duration: 11.777s, episode steps: 374, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.011082, mae: 0.715116, mean_q: 0.881308, mean_eps: 0.717870\n",
            " 314325/1000000: episode: 457, duration: 20.562s, episode steps: 659, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.009803, mae: 0.714786, mean_q: 0.881373, mean_eps: 0.717404\n",
            " 314948/1000000: episode: 458, duration: 19.169s, episode steps: 623, steps per second:  33, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.009585, mae: 0.725495, mean_q: 0.893322, mean_eps: 0.716828\n",
            " 315974/1000000: episode: 459, duration: 31.911s, episode steps: 1026, steps per second:  32, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.713 [0.000, 5.000],  loss: 0.010413, mae: 0.713520, mean_q: 0.878227, mean_eps: 0.716086\n",
            " 316810/1000000: episode: 460, duration: 25.864s, episode steps: 836, steps per second:  32, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.009153, mae: 0.715079, mean_q: 0.878153, mean_eps: 0.715247\n",
            " 317403/1000000: episode: 461, duration: 18.461s, episode steps: 593, steps per second:  32, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.009468, mae: 0.711380, mean_q: 0.872591, mean_eps: 0.714605\n",
            " 317982/1000000: episode: 462, duration: 18.034s, episode steps: 579, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.009534, mae: 0.729348, mean_q: 0.896071, mean_eps: 0.714077\n",
            " 318354/1000000: episode: 463, duration: 11.699s, episode steps: 372, steps per second:  32, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.258 [0.000, 5.000],  loss: 0.009063, mae: 0.724360, mean_q: 0.889716, mean_eps: 0.713649\n",
            " 319005/1000000: episode: 464, duration: 20.523s, episode steps: 651, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.009844, mae: 0.722671, mean_q: 0.887387, mean_eps: 0.713188\n",
            " 319609/1000000: episode: 465, duration: 18.882s, episode steps: 604, steps per second:  32, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.009820, mae: 0.721756, mean_q: 0.886777, mean_eps: 0.712623\n",
            " 319980/1000000: episode: 466, duration: 11.675s, episode steps: 371, steps per second:  32, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.009926, mae: 0.722632, mean_q: 0.888312, mean_eps: 0.712185\n",
            " 321159/1000000: episode: 467, duration: 36.959s, episode steps: 1179, steps per second:  32, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.008976, mae: 0.756152, mean_q: 0.930594, mean_eps: 0.711489\n",
            " 321640/1000000: episode: 468, duration: 15.096s, episode steps: 481, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.010187, mae: 0.765600, mean_q: 0.941572, mean_eps: 0.710742\n",
            " 322459/1000000: episode: 469, duration: 25.504s, episode steps: 819, steps per second:  32, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.010676, mae: 0.766324, mean_q: 0.941906, mean_eps: 0.710157\n",
            " 322989/1000000: episode: 470, duration: 16.467s, episode steps: 530, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.009369, mae: 0.763606, mean_q: 0.939543, mean_eps: 0.709548\n",
            " 323691/1000000: episode: 471, duration: 21.879s, episode steps: 702, steps per second:  32, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.010365, mae: 0.755847, mean_q: 0.928262, mean_eps: 0.708994\n",
            " 324438/1000000: episode: 472, duration: 23.389s, episode steps: 747, steps per second:  32, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.010689, mae: 0.780325, mean_q: 0.957929, mean_eps: 0.708342\n",
            " 324881/1000000: episode: 473, duration: 13.851s, episode steps: 443, steps per second:  32, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.675 [0.000, 5.000],  loss: 0.009634, mae: 0.760060, mean_q: 0.933878, mean_eps: 0.707806\n",
            " 325863/1000000: episode: 474, duration: 30.559s, episode steps: 982, steps per second:  32, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.010537, mae: 0.763689, mean_q: 0.938386, mean_eps: 0.707165\n",
            " 326347/1000000: episode: 475, duration: 15.267s, episode steps: 484, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.010013, mae: 0.762171, mean_q: 0.936716, mean_eps: 0.706506\n",
            " 326996/1000000: episode: 476, duration: 20.321s, episode steps: 649, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.010264, mae: 0.770616, mean_q: 0.945207, mean_eps: 0.705997\n",
            " 327642/1000000: episode: 477, duration: 20.208s, episode steps: 646, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.011412, mae: 0.759555, mean_q: 0.931547, mean_eps: 0.705414\n",
            " 328133/1000000: episode: 478, duration: 15.306s, episode steps: 491, steps per second:  32, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.009573, mae: 0.755239, mean_q: 0.927442, mean_eps: 0.704901\n",
            " 329163/1000000: episode: 479, duration: 32.147s, episode steps: 1030, steps per second:  32, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.010824, mae: 0.765861, mean_q: 0.939765, mean_eps: 0.704217\n",
            " 329920/1000000: episode: 480, duration: 23.572s, episode steps: 757, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.010267, mae: 0.763706, mean_q: 0.938463, mean_eps: 0.703414\n",
            " 330620/1000000: episode: 481, duration: 21.939s, episode steps: 700, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.009494, mae: 0.805660, mean_q: 0.990703, mean_eps: 0.702759\n",
            " 331272/1000000: episode: 482, duration: 20.361s, episode steps: 652, steps per second:  32, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.011665, mae: 0.819705, mean_q: 1.007117, mean_eps: 0.702150\n",
            " 331771/1000000: episode: 483, duration: 15.646s, episode steps: 499, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.008778, mae: 0.802242, mean_q: 0.985477, mean_eps: 0.701632\n",
            " 332409/1000000: episode: 484, duration: 19.859s, episode steps: 638, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.011362, mae: 0.819170, mean_q: 1.006478, mean_eps: 0.701119\n",
            " 333145/1000000: episode: 485, duration: 22.955s, episode steps: 736, steps per second:  32, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.010021, mae: 0.817533, mean_q: 1.002835, mean_eps: 0.700500\n",
            " 333625/1000000: episode: 486, duration: 15.021s, episode steps: 480, steps per second:  32, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.010904, mae: 0.806375, mean_q: 0.989896, mean_eps: 0.699953\n",
            " 334030/1000000: episode: 487, duration: 12.727s, episode steps: 405, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.009839, mae: 0.811242, mean_q: 0.996976, mean_eps: 0.699555\n",
            " 334687/1000000: episode: 488, duration: 20.270s, episode steps: 657, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.010359, mae: 0.816616, mean_q: 1.003969, mean_eps: 0.699078\n",
            " 335198/1000000: episode: 489, duration: 16.057s, episode steps: 511, steps per second:  32, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.010897, mae: 0.813962, mean_q: 0.999897, mean_eps: 0.698552\n",
            " 335634/1000000: episode: 490, duration: 13.619s, episode steps: 436, steps per second:  32, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.009123, mae: 0.803434, mean_q: 0.988161, mean_eps: 0.698126\n",
            " 336402/1000000: episode: 491, duration: 23.940s, episode steps: 768, steps per second:  32, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.011456, mae: 0.810839, mean_q: 0.995045, mean_eps: 0.697584\n",
            " 337503/1000000: episode: 492, duration: 34.263s, episode steps: 1101, steps per second:  32, episode reward: 28.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.011381, mae: 0.821493, mean_q: 1.009368, mean_eps: 0.696743\n",
            " 338246/1000000: episode: 493, duration: 23.354s, episode steps: 743, steps per second:  32, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.010785, mae: 0.826381, mean_q: 1.014782, mean_eps: 0.695913\n",
            " 339005/1000000: episode: 494, duration: 23.767s, episode steps: 759, steps per second:  32, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.010657, mae: 0.806053, mean_q: 0.988893, mean_eps: 0.695237\n",
            " 340433/1000000: episode: 495, duration: 44.468s, episode steps: 1428, steps per second:  32, episode reward: 24.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.010964, mae: 0.823439, mean_q: 1.011377, mean_eps: 0.694252\n",
            " 340988/1000000: episode: 496, duration: 17.395s, episode steps: 555, steps per second:  32, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.732 [0.000, 5.000],  loss: 0.011338, mae: 0.846660, mean_q: 1.039957, mean_eps: 0.693361\n",
            " 341645/1000000: episode: 497, duration: 20.572s, episode steps: 657, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.011328, mae: 0.842349, mean_q: 1.035051, mean_eps: 0.692816\n",
            " 342175/1000000: episode: 498, duration: 16.597s, episode steps: 530, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.758 [0.000, 5.000],  loss: 0.011838, mae: 0.842208, mean_q: 1.035581, mean_eps: 0.692281\n",
            " 343145/1000000: episode: 499, duration: 30.356s, episode steps: 970, steps per second:  32, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.011019, mae: 0.844411, mean_q: 1.037212, mean_eps: 0.691606\n",
            " 344008/1000000: episode: 500, duration: 27.084s, episode steps: 863, steps per second:  32, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.010595, mae: 0.841166, mean_q: 1.031873, mean_eps: 0.690782\n",
            " 344656/1000000: episode: 501, duration: 20.417s, episode steps: 648, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.011952, mae: 0.839611, mean_q: 1.029861, mean_eps: 0.690103\n",
            " 345132/1000000: episode: 502, duration: 15.063s, episode steps: 476, steps per second:  32, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.010861, mae: 0.845779, mean_q: 1.038215, mean_eps: 0.689597\n",
            " 345848/1000000: episode: 503, duration: 22.457s, episode steps: 716, steps per second:  32, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.728 [0.000, 5.000],  loss: 0.012006, mae: 0.846243, mean_q: 1.038695, mean_eps: 0.689061\n",
            " 346464/1000000: episode: 504, duration: 19.511s, episode steps: 616, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.011848, mae: 0.834119, mean_q: 1.024623, mean_eps: 0.688461\n",
            " 347044/1000000: episode: 505, duration: 18.359s, episode steps: 580, steps per second:  32, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.010301, mae: 0.839007, mean_q: 1.029783, mean_eps: 0.687923\n",
            " 347782/1000000: episode: 506, duration: 23.195s, episode steps: 738, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: 0.010776, mae: 0.847770, mean_q: 1.042025, mean_eps: 0.687329\n",
            " 348132/1000000: episode: 507, duration: 11.144s, episode steps: 350, steps per second:  31, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.010201, mae: 0.833546, mean_q: 1.026107, mean_eps: 0.686840\n",
            " 348829/1000000: episode: 508, duration: 22.039s, episode steps: 697, steps per second:  32, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.012685, mae: 0.852250, mean_q: 1.048742, mean_eps: 0.686368\n",
            " 349553/1000000: episode: 509, duration: 22.788s, episode steps: 724, steps per second:  32, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.831 [0.000, 5.000],  loss: 0.009961, mae: 0.835673, mean_q: 1.029116, mean_eps: 0.685727\n",
            " 350319/1000000: episode: 510, duration: 24.028s, episode steps: 766, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.011363, mae: 0.849609, mean_q: 1.046138, mean_eps: 0.685058\n",
            " 350811/1000000: episode: 511, duration: 15.419s, episode steps: 492, steps per second:  32, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.010253, mae: 0.878252, mean_q: 1.078392, mean_eps: 0.684492\n",
            " 351605/1000000: episode: 512, duration: 25.054s, episode steps: 794, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.010128, mae: 0.864852, mean_q: 1.063136, mean_eps: 0.683913\n",
            " 351998/1000000: episode: 513, duration: 12.379s, episode steps: 393, steps per second:  32, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.014033, mae: 0.893993, mean_q: 1.099126, mean_eps: 0.683378\n",
            " 352964/1000000: episode: 514, duration: 30.604s, episode steps: 966, steps per second:  32, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.011588, mae: 0.879567, mean_q: 1.084988, mean_eps: 0.682768\n",
            " 353668/1000000: episode: 515, duration: 22.404s, episode steps: 704, steps per second:  31, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.011381, mae: 0.882757, mean_q: 1.086337, mean_eps: 0.682017\n",
            " 354093/1000000: episode: 516, duration: 13.526s, episode steps: 425, steps per second:  31, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.011756, mae: 0.880194, mean_q: 1.082504, mean_eps: 0.681508\n",
            " 354647/1000000: episode: 517, duration: 17.427s, episode steps: 554, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.011656, mae: 0.887612, mean_q: 1.091628, mean_eps: 0.681067\n",
            " 355272/1000000: episode: 518, duration: 19.842s, episode steps: 625, steps per second:  31, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.011880, mae: 0.883266, mean_q: 1.088634, mean_eps: 0.680538\n",
            " 356010/1000000: episode: 519, duration: 23.414s, episode steps: 738, steps per second:  32, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.011563, mae: 0.888430, mean_q: 1.091955, mean_eps: 0.679924\n",
            " 356711/1000000: episode: 520, duration: 22.062s, episode steps: 701, steps per second:  32, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.012535, mae: 0.885939, mean_q: 1.089567, mean_eps: 0.679276\n",
            " 357163/1000000: episode: 521, duration: 14.322s, episode steps: 452, steps per second:  32, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.010499, mae: 0.885846, mean_q: 1.090111, mean_eps: 0.678758\n",
            " 357743/1000000: episode: 522, duration: 18.312s, episode steps: 580, steps per second:  32, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.714 [0.000, 5.000],  loss: 0.010944, mae: 0.875560, mean_q: 1.076747, mean_eps: 0.678293\n",
            " 358600/1000000: episode: 523, duration: 27.324s, episode steps: 857, steps per second:  31, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.010995, mae: 0.879756, mean_q: 1.081293, mean_eps: 0.677647\n",
            " 359500/1000000: episode: 524, duration: 28.475s, episode steps: 900, steps per second:  32, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.012741, mae: 0.892004, mean_q: 1.096788, mean_eps: 0.676857\n",
            " 360257/1000000: episode: 525, duration: 24.097s, episode steps: 757, steps per second:  31, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.011175, mae: 0.888232, mean_q: 1.091927, mean_eps: 0.676110\n",
            " 360863/1000000: episode: 526, duration: 19.242s, episode steps: 606, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.012532, mae: 0.927530, mean_q: 1.142121, mean_eps: 0.675496\n",
            " 361898/1000000: episode: 527, duration: 32.805s, episode steps: 1035, steps per second:  32, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.010481, mae: 0.927083, mean_q: 1.140335, mean_eps: 0.674758\n",
            " 362381/1000000: episode: 528, duration: 15.533s, episode steps: 483, steps per second:  31, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.010954, mae: 0.923050, mean_q: 1.133502, mean_eps: 0.674074\n",
            " 363027/1000000: episode: 529, duration: 20.371s, episode steps: 646, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.009834, mae: 0.921078, mean_q: 1.132008, mean_eps: 0.673566\n",
            " 363719/1000000: episode: 530, duration: 21.873s, episode steps: 692, steps per second:  32, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.011354, mae: 0.924601, mean_q: 1.135245, mean_eps: 0.672965\n",
            " 364751/1000000: episode: 531, duration: 32.664s, episode steps: 1032, steps per second:  32, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.011671, mae: 0.924554, mean_q: 1.136164, mean_eps: 0.672189\n",
            " 365656/1000000: episode: 532, duration: 28.594s, episode steps: 905, steps per second:  32, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: 0.012003, mae: 0.932914, mean_q: 1.145393, mean_eps: 0.671318\n",
            " 366387/1000000: episode: 533, duration: 23.149s, episode steps: 731, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.012278, mae: 0.940422, mean_q: 1.155130, mean_eps: 0.670582\n",
            " 366922/1000000: episode: 534, duration: 17.028s, episode steps: 535, steps per second:  31, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.009594, mae: 0.923915, mean_q: 1.134038, mean_eps: 0.670011\n",
            " 367504/1000000: episode: 535, duration: 18.645s, episode steps: 582, steps per second:  31, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.011409, mae: 0.938727, mean_q: 1.153133, mean_eps: 0.669509\n",
            " 367836/1000000: episode: 536, duration: 10.708s, episode steps: 332, steps per second:  31, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.011212, mae: 0.925727, mean_q: 1.136263, mean_eps: 0.669099\n",
            " 368340/1000000: episode: 537, duration: 16.086s, episode steps: 504, steps per second:  31, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.010948, mae: 0.926223, mean_q: 1.135634, mean_eps: 0.668723\n",
            " 368764/1000000: episode: 538, duration: 13.576s, episode steps: 424, steps per second:  31, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: 0.011303, mae: 0.920432, mean_q: 1.127626, mean_eps: 0.668305\n",
            " 369698/1000000: episode: 539, duration: 29.656s, episode steps: 934, steps per second:  31, episode reward: 25.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.010956, mae: 0.926165, mean_q: 1.136891, mean_eps: 0.667693\n",
            " 370412/1000000: episode: 540, duration: 22.709s, episode steps: 714, steps per second:  31, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.010211, mae: 0.935321, mean_q: 1.148395, mean_eps: 0.666951\n",
            " 371347/1000000: episode: 541, duration: 29.495s, episode steps: 935, steps per second:  32, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.012325, mae: 0.948200, mean_q: 1.166833, mean_eps: 0.666210\n",
            " 372095/1000000: episode: 542, duration: 23.695s, episode steps: 748, steps per second:  32, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.012766, mae: 0.958511, mean_q: 1.179968, mean_eps: 0.665452\n",
            " 372627/1000000: episode: 543, duration: 17.111s, episode steps: 532, steps per second:  31, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.011068, mae: 0.953731, mean_q: 1.176154, mean_eps: 0.664876\n",
            " 373569/1000000: episode: 544, duration: 29.946s, episode steps: 942, steps per second:  31, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.011410, mae: 0.941402, mean_q: 1.158678, mean_eps: 0.664212\n",
            " 374321/1000000: episode: 545, duration: 23.926s, episode steps: 752, steps per second:  31, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.012735, mae: 0.960817, mean_q: 1.181970, mean_eps: 0.663449\n",
            " 374822/1000000: episode: 546, duration: 15.885s, episode steps: 501, steps per second:  32, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.679 [0.000, 5.000],  loss: 0.013846, mae: 0.963932, mean_q: 1.184343, mean_eps: 0.662885\n",
            " 375895/1000000: episode: 547, duration: 34.151s, episode steps: 1073, steps per second:  31, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.011414, mae: 0.946239, mean_q: 1.161462, mean_eps: 0.662178\n",
            " 376732/1000000: episode: 548, duration: 27.021s, episode steps: 837, steps per second:  31, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.011110, mae: 0.947527, mean_q: 1.163945, mean_eps: 0.661319\n",
            " 377142/1000000: episode: 549, duration: 13.197s, episode steps: 410, steps per second:  31, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.013320, mae: 0.957283, mean_q: 1.177413, mean_eps: 0.660758\n",
            " 377650/1000000: episode: 550, duration: 16.371s, episode steps: 508, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.011359, mae: 0.949289, mean_q: 1.167060, mean_eps: 0.660344\n",
            " 378481/1000000: episode: 551, duration: 26.711s, episode steps: 831, steps per second:  31, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.012040, mae: 0.957003, mean_q: 1.172806, mean_eps: 0.659741\n",
            " 379139/1000000: episode: 552, duration: 20.961s, episode steps: 658, steps per second:  31, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.011869, mae: 0.951114, mean_q: 1.167713, mean_eps: 0.659071\n",
            " 379880/1000000: episode: 553, duration: 23.872s, episode steps: 741, steps per second:  31, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.011744, mae: 0.957056, mean_q: 1.178500, mean_eps: 0.658443\n",
            " 380280/1000000: episode: 554, duration: 13.028s, episode steps: 400, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.745 [0.000, 5.000],  loss: 0.012197, mae: 0.976743, mean_q: 1.199743, mean_eps: 0.657930\n",
            " 380793/1000000: episode: 555, duration: 16.455s, episode steps: 513, steps per second:  31, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.010937, mae: 0.975443, mean_q: 1.198121, mean_eps: 0.657518\n",
            " 381466/1000000: episode: 556, duration: 21.587s, episode steps: 673, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: 0.011750, mae: 0.971843, mean_q: 1.192243, mean_eps: 0.656983\n",
            " 381958/1000000: episode: 557, duration: 15.688s, episode steps: 492, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.012015, mae: 0.965581, mean_q: 1.185939, mean_eps: 0.656459\n",
            " 382667/1000000: episode: 558, duration: 22.628s, episode steps: 709, steps per second:  31, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.012908, mae: 0.988140, mean_q: 1.213647, mean_eps: 0.655919\n",
            " 383404/1000000: episode: 559, duration: 23.665s, episode steps: 737, steps per second:  31, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.011795, mae: 0.988162, mean_q: 1.215239, mean_eps: 0.655269\n",
            " 384140/1000000: episode: 560, duration: 23.572s, episode steps: 736, steps per second:  31, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.010933, mae: 0.989879, mean_q: 1.219738, mean_eps: 0.654607\n",
            " 384904/1000000: episode: 561, duration: 24.480s, episode steps: 764, steps per second:  31, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.011441, mae: 0.986831, mean_q: 1.213213, mean_eps: 0.653932\n",
            " 386042/1000000: episode: 562, duration: 36.451s, episode steps: 1138, steps per second:  31, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.011807, mae: 0.987161, mean_q: 1.211702, mean_eps: 0.653075\n",
            " 386581/1000000: episode: 563, duration: 17.470s, episode steps: 539, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.011506, mae: 0.987396, mean_q: 1.210871, mean_eps: 0.652319\n",
            " 387275/1000000: episode: 564, duration: 22.329s, episode steps: 694, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.012611, mae: 0.982473, mean_q: 1.204192, mean_eps: 0.651765\n",
            " 387775/1000000: episode: 565, duration: 16.237s, episode steps: 500, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.012575, mae: 0.995761, mean_q: 1.224001, mean_eps: 0.651228\n",
            " 388994/1000000: episode: 566, duration: 39.096s, episode steps: 1219, steps per second:  31, episode reward: 30.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.012564, mae: 0.992675, mean_q: 1.219626, mean_eps: 0.650454\n",
            " 389557/1000000: episode: 567, duration: 18.136s, episode steps: 563, steps per second:  31, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.012558, mae: 0.991789, mean_q: 1.217023, mean_eps: 0.649652\n",
            " 390370/1000000: episode: 568, duration: 26.023s, episode steps: 813, steps per second:  31, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.012404, mae: 1.006102, mean_q: 1.239449, mean_eps: 0.649032\n",
            " 391001/1000000: episode: 569, duration: 20.291s, episode steps: 631, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.011918, mae: 1.034090, mean_q: 1.273080, mean_eps: 0.648383\n",
            " 391503/1000000: episode: 570, duration: 17.511s, episode steps: 502, steps per second:  29, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.739 [0.000, 5.000],  loss: 0.013315, mae: 1.022831, mean_q: 1.259567, mean_eps: 0.647873\n",
            " 392076/1000000: episode: 571, duration: 19.553s, episode steps: 573, steps per second:  29, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.013013, mae: 1.023672, mean_q: 1.259502, mean_eps: 0.647391\n",
            " 392549/1000000: episode: 572, duration: 15.517s, episode steps: 473, steps per second:  30, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.011776, mae: 1.026534, mean_q: 1.264373, mean_eps: 0.646919\n",
            " 393168/1000000: episode: 573, duration: 20.004s, episode steps: 619, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.012952, mae: 1.038237, mean_q: 1.278466, mean_eps: 0.646428\n",
            " 393982/1000000: episode: 574, duration: 26.414s, episode steps: 814, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.011524, mae: 1.021955, mean_q: 1.256621, mean_eps: 0.645783\n",
            " 394587/1000000: episode: 575, duration: 19.326s, episode steps: 605, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.012767, mae: 1.034138, mean_q: 1.270646, mean_eps: 0.645144\n",
            " 395171/1000000: episode: 576, duration: 19.027s, episode steps: 584, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.012711, mae: 1.030587, mean_q: 1.267258, mean_eps: 0.644610\n",
            " 395880/1000000: episode: 577, duration: 23.004s, episode steps: 709, steps per second:  31, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.012895, mae: 1.027421, mean_q: 1.261482, mean_eps: 0.644028\n",
            " 396420/1000000: episode: 578, duration: 17.457s, episode steps: 540, steps per second:  31, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.012698, mae: 1.038047, mean_q: 1.275490, mean_eps: 0.643467\n",
            " 396896/1000000: episode: 579, duration: 15.570s, episode steps: 476, steps per second:  31, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.118 [0.000, 5.000],  loss: 0.014464, mae: 1.029398, mean_q: 1.263634, mean_eps: 0.643010\n",
            " 397613/1000000: episode: 580, duration: 23.269s, episode steps: 717, steps per second:  31, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.014771, mae: 1.037816, mean_q: 1.275783, mean_eps: 0.642471\n",
            " 398093/1000000: episode: 581, duration: 15.479s, episode steps: 480, steps per second:  31, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.014665, mae: 1.024851, mean_q: 1.262429, mean_eps: 0.641931\n",
            " 398948/1000000: episode: 582, duration: 27.550s, episode steps: 855, steps per second:  31, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.013423, mae: 1.042650, mean_q: 1.280225, mean_eps: 0.641332\n",
            " 399797/1000000: episode: 583, duration: 27.324s, episode steps: 849, steps per second:  31, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.011804, mae: 1.027775, mean_q: 1.264793, mean_eps: 0.640565\n",
            " 400178/1000000: episode: 584, duration: 12.320s, episode steps: 381, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.013346, mae: 1.037027, mean_q: 1.273387, mean_eps: 0.640011\n",
            " 400799/1000000: episode: 585, duration: 20.220s, episode steps: 621, steps per second:  31, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.011455, mae: 1.066514, mean_q: 1.311259, mean_eps: 0.639561\n",
            " 401473/1000000: episode: 586, duration: 21.983s, episode steps: 674, steps per second:  31, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.012843, mae: 1.059731, mean_q: 1.300125, mean_eps: 0.638978\n",
            " 402206/1000000: episode: 587, duration: 23.741s, episode steps: 733, steps per second:  31, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.012994, mae: 1.063726, mean_q: 1.305852, mean_eps: 0.638344\n",
            " 402823/1000000: episode: 588, duration: 19.811s, episode steps: 617, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.012233, mae: 1.050494, mean_q: 1.290984, mean_eps: 0.637737\n",
            " 403432/1000000: episode: 589, duration: 19.783s, episode steps: 609, steps per second:  31, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.012200, mae: 1.076123, mean_q: 1.323427, mean_eps: 0.637187\n",
            " 404071/1000000: episode: 590, duration: 20.632s, episode steps: 639, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.012855, mae: 1.064403, mean_q: 1.307054, mean_eps: 0.636625\n",
            " 404769/1000000: episode: 591, duration: 22.585s, episode steps: 698, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.013358, mae: 1.068457, mean_q: 1.312879, mean_eps: 0.636022\n",
            " 405974/1000000: episode: 592, duration: 38.798s, episode steps: 1205, steps per second:  31, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.012358, mae: 1.062701, mean_q: 1.304810, mean_eps: 0.635165\n",
            " 406721/1000000: episode: 593, duration: 24.305s, episode steps: 747, steps per second:  31, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.013019, mae: 1.065506, mean_q: 1.306798, mean_eps: 0.634287\n",
            " 407905/1000000: episode: 594, duration: 38.172s, episode steps: 1184, steps per second:  31, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.312 [0.000, 5.000],  loss: 0.012273, mae: 1.056241, mean_q: 1.297536, mean_eps: 0.633417\n",
            " 408275/1000000: episode: 595, duration: 11.885s, episode steps: 370, steps per second:  31, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.968 [0.000, 5.000],  loss: 0.011145, mae: 1.052729, mean_q: 1.293986, mean_eps: 0.632719\n",
            " 409365/1000000: episode: 596, duration: 35.304s, episode steps: 1090, steps per second:  31, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.012970, mae: 1.066113, mean_q: 1.308477, mean_eps: 0.632062\n",
            " 410324/1000000: episode: 597, duration: 31.043s, episode steps: 959, steps per second:  31, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.012820, mae: 1.080266, mean_q: 1.325444, mean_eps: 0.631140\n",
            " 410930/1000000: episode: 598, duration: 19.721s, episode steps: 606, steps per second:  31, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.013113, mae: 1.132101, mean_q: 1.389350, mean_eps: 0.630437\n",
            " 411363/1000000: episode: 599, duration: 13.891s, episode steps: 433, steps per second:  31, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.014261, mae: 1.130786, mean_q: 1.388629, mean_eps: 0.629969\n",
            " 412451/1000000: episode: 600, duration: 35.063s, episode steps: 1088, steps per second:  31, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.012637, mae: 1.125374, mean_q: 1.381111, mean_eps: 0.629285\n",
            " 413328/1000000: episode: 601, duration: 28.468s, episode steps: 877, steps per second:  31, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.013733, mae: 1.129107, mean_q: 1.386565, mean_eps: 0.628401\n",
            " 414038/1000000: episode: 602, duration: 22.998s, episode steps: 710, steps per second:  31, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: 0.014007, mae: 1.124769, mean_q: 1.381474, mean_eps: 0.627686\n",
            " 414378/1000000: episode: 603, duration: 10.984s, episode steps: 340, steps per second:  31, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.012991, mae: 1.135275, mean_q: 1.394080, mean_eps: 0.627213\n",
            " 414779/1000000: episode: 604, duration: 12.931s, episode steps: 401, steps per second:  31, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.012975, mae: 1.114190, mean_q: 1.368749, mean_eps: 0.626880\n",
            " 415173/1000000: episode: 605, duration: 12.884s, episode steps: 394, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.013845, mae: 1.130886, mean_q: 1.386082, mean_eps: 0.626522\n",
            " 415683/1000000: episode: 606, duration: 16.519s, episode steps: 510, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.015522, mae: 1.134611, mean_q: 1.392225, mean_eps: 0.626115\n",
            " 416350/1000000: episode: 607, duration: 21.820s, episode steps: 667, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.012812, mae: 1.126843, mean_q: 1.379985, mean_eps: 0.625586\n",
            " 416902/1000000: episode: 608, duration: 17.855s, episode steps: 552, steps per second:  31, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.011585, mae: 1.128740, mean_q: 1.384240, mean_eps: 0.625037\n",
            " 417281/1000000: episode: 609, duration: 12.260s, episode steps: 379, steps per second:  31, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.015262, mae: 1.137388, mean_q: 1.395206, mean_eps: 0.624617\n",
            " 418072/1000000: episode: 610, duration: 25.678s, episode steps: 791, steps per second:  31, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.013869, mae: 1.123449, mean_q: 1.376922, mean_eps: 0.624092\n",
            " 419105/1000000: episode: 611, duration: 33.412s, episode steps: 1033, steps per second:  31, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.013341, mae: 1.127557, mean_q: 1.383259, mean_eps: 0.623271\n",
            " 419599/1000000: episode: 612, duration: 15.934s, episode steps: 494, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.012832, mae: 1.131291, mean_q: 1.386797, mean_eps: 0.622583\n",
            " 420431/1000000: episode: 613, duration: 27.090s, episode steps: 832, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.013022, mae: 1.162073, mean_q: 1.426964, mean_eps: 0.621987\n",
            " 421264/1000000: episode: 614, duration: 27.214s, episode steps: 833, steps per second:  31, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.013508, mae: 1.186731, mean_q: 1.458003, mean_eps: 0.621239\n",
            " 421847/1000000: episode: 615, duration: 18.840s, episode steps: 583, steps per second:  31, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.013600, mae: 1.202414, mean_q: 1.477651, mean_eps: 0.620601\n",
            " 422505/1000000: episode: 616, duration: 21.439s, episode steps: 658, steps per second:  31, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.013174, mae: 1.175317, mean_q: 1.445389, mean_eps: 0.620042\n",
            " 423058/1000000: episode: 617, duration: 17.975s, episode steps: 553, steps per second:  31, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.012556, mae: 1.171390, mean_q: 1.440035, mean_eps: 0.619496\n",
            " 423498/1000000: episode: 618, duration: 14.351s, episode steps: 440, steps per second:  31, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.014143, mae: 1.179238, mean_q: 1.448396, mean_eps: 0.619050\n",
            " 423919/1000000: episode: 619, duration: 13.606s, episode steps: 421, steps per second:  31, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.012793, mae: 1.184277, mean_q: 1.451969, mean_eps: 0.618663\n",
            " 424414/1000000: episode: 620, duration: 16.063s, episode steps: 495, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.014008, mae: 1.207893, mean_q: 1.484069, mean_eps: 0.618251\n",
            " 425136/1000000: episode: 621, duration: 23.535s, episode steps: 722, steps per second:  31, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.141 [0.000, 5.000],  loss: 0.014199, mae: 1.198202, mean_q: 1.469863, mean_eps: 0.617703\n",
            " 425895/1000000: episode: 622, duration: 24.730s, episode steps: 759, steps per second:  31, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.015760, mae: 1.193195, mean_q: 1.463802, mean_eps: 0.617037\n",
            " 426728/1000000: episode: 623, duration: 27.221s, episode steps: 833, steps per second:  31, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.013161, mae: 1.182562, mean_q: 1.451578, mean_eps: 0.616321\n",
            " 427636/1000000: episode: 624, duration: 29.631s, episode steps: 908, steps per second:  31, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.013249, mae: 1.186059, mean_q: 1.454190, mean_eps: 0.615538\n",
            " 428507/1000000: episode: 625, duration: 28.227s, episode steps: 871, steps per second:  31, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.012380, mae: 1.182087, mean_q: 1.451509, mean_eps: 0.614737\n",
            " 428837/1000000: episode: 626, duration: 10.802s, episode steps: 330, steps per second:  31, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.897 [0.000, 5.000],  loss: 0.012171, mae: 1.181726, mean_q: 1.450887, mean_eps: 0.614195\n",
            " 429398/1000000: episode: 627, duration: 18.324s, episode steps: 561, steps per second:  31, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.012842, mae: 1.187554, mean_q: 1.454243, mean_eps: 0.613794\n",
            " 430018/1000000: episode: 628, duration: 20.141s, episode steps: 620, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.013890, mae: 1.175759, mean_q: 1.442055, mean_eps: 0.613263\n",
            " 430599/1000000: episode: 629, duration: 18.928s, episode steps: 581, steps per second:  31, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.013560, mae: 1.246909, mean_q: 1.530735, mean_eps: 0.612723\n",
            " 431070/1000000: episode: 630, duration: 15.342s, episode steps: 471, steps per second:  31, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.735 [0.000, 5.000],  loss: 0.015348, mae: 1.246836, mean_q: 1.528752, mean_eps: 0.612249\n",
            " 432179/1000000: episode: 631, duration: 36.184s, episode steps: 1109, steps per second:  31, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.014168, mae: 1.256644, mean_q: 1.542323, mean_eps: 0.611538\n",
            " 432945/1000000: episode: 632, duration: 25.053s, episode steps: 766, steps per second:  31, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.013820, mae: 1.248626, mean_q: 1.533189, mean_eps: 0.610694\n",
            " 433668/1000000: episode: 633, duration: 23.625s, episode steps: 723, steps per second:  31, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.015566, mae: 1.253123, mean_q: 1.537697, mean_eps: 0.610025\n",
            " 434458/1000000: episode: 634, duration: 25.843s, episode steps: 790, steps per second:  31, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.014436, mae: 1.269484, mean_q: 1.556147, mean_eps: 0.609344\n",
            " 435183/1000000: episode: 635, duration: 23.831s, episode steps: 725, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.015673, mae: 1.253010, mean_q: 1.535588, mean_eps: 0.608662\n",
            " 435807/1000000: episode: 636, duration: 20.568s, episode steps: 624, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.015260, mae: 1.237929, mean_q: 1.517654, mean_eps: 0.608055\n",
            " 436325/1000000: episode: 637, duration: 16.958s, episode steps: 518, steps per second:  31, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.014068, mae: 1.243542, mean_q: 1.523633, mean_eps: 0.607541\n",
            " 437213/1000000: episode: 638, duration: 28.976s, episode steps: 888, steps per second:  31, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.014740, mae: 1.253435, mean_q: 1.534001, mean_eps: 0.606907\n",
            " 437766/1000000: episode: 639, duration: 18.114s, episode steps: 553, steps per second:  31, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.130 [0.000, 5.000],  loss: 0.014762, mae: 1.259033, mean_q: 1.543062, mean_eps: 0.606259\n",
            " 438744/1000000: episode: 640, duration: 32.028s, episode steps: 978, steps per second:  31, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.796 [0.000, 5.000],  loss: 0.013345, mae: 1.244346, mean_q: 1.525144, mean_eps: 0.605571\n",
            " 439289/1000000: episode: 641, duration: 17.895s, episode steps: 545, steps per second:  30, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.013249, mae: 1.257987, mean_q: 1.545093, mean_eps: 0.604886\n",
            " 440148/1000000: episode: 642, duration: 28.039s, episode steps: 859, steps per second:  31, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.014723, mae: 1.252317, mean_q: 1.536028, mean_eps: 0.604254\n",
            " 440717/1000000: episode: 643, duration: 18.661s, episode steps: 569, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.013130, mae: 1.310639, mean_q: 1.607702, mean_eps: 0.603611\n",
            " 441558/1000000: episode: 644, duration: 27.560s, episode steps: 841, steps per second:  31, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.014431, mae: 1.292066, mean_q: 1.586708, mean_eps: 0.602976\n",
            " 441970/1000000: episode: 645, duration: 13.472s, episode steps: 412, steps per second:  31, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.013668, mae: 1.282292, mean_q: 1.572994, mean_eps: 0.602412\n",
            " 442903/1000000: episode: 646, duration: 30.458s, episode steps: 933, steps per second:  31, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.013968, mae: 1.304115, mean_q: 1.598475, mean_eps: 0.601808\n",
            " 443430/1000000: episode: 647, duration: 17.548s, episode steps: 527, steps per second:  30, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.778 [0.000, 5.000],  loss: 0.012847, mae: 1.300129, mean_q: 1.594167, mean_eps: 0.601151\n",
            " 444081/1000000: episode: 648, duration: 21.414s, episode steps: 651, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.013600, mae: 1.301565, mean_q: 1.593706, mean_eps: 0.600620\n",
            " 444714/1000000: episode: 649, duration: 20.891s, episode steps: 633, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.013385, mae: 1.281922, mean_q: 1.569861, mean_eps: 0.600042\n",
            " 445590/1000000: episode: 650, duration: 28.866s, episode steps: 876, steps per second:  30, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.013481, mae: 1.294127, mean_q: 1.585637, mean_eps: 0.599363\n",
            " 446662/1000000: episode: 651, duration: 35.235s, episode steps: 1072, steps per second:  30, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.014036, mae: 1.295378, mean_q: 1.583609, mean_eps: 0.598487\n",
            " 447765/1000000: episode: 652, duration: 36.183s, episode steps: 1103, steps per second:  30, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.014191, mae: 1.292350, mean_q: 1.582675, mean_eps: 0.597507\n",
            " 448820/1000000: episode: 653, duration: 34.627s, episode steps: 1055, steps per second:  30, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.013246, mae: 1.290352, mean_q: 1.578498, mean_eps: 0.596537\n",
            " 449783/1000000: episode: 654, duration: 31.729s, episode steps: 963, steps per second:  30, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.016188, mae: 1.295899, mean_q: 1.585922, mean_eps: 0.595630\n",
            " 450443/1000000: episode: 655, duration: 21.899s, episode steps: 660, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.015301, mae: 1.331323, mean_q: 1.628793, mean_eps: 0.594899\n",
            " 451206/1000000: episode: 656, duration: 25.094s, episode steps: 763, steps per second:  30, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.015694, mae: 1.340325, mean_q: 1.642757, mean_eps: 0.594258\n",
            " 452008/1000000: episode: 657, duration: 26.407s, episode steps: 802, steps per second:  30, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.015424, mae: 1.326619, mean_q: 1.624297, mean_eps: 0.593555\n",
            " 452586/1000000: episode: 658, duration: 19.205s, episode steps: 578, steps per second:  30, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.016467, mae: 1.338362, mean_q: 1.638814, mean_eps: 0.592934\n",
            " 453246/1000000: episode: 659, duration: 21.811s, episode steps: 660, steps per second:  30, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.014614, mae: 1.348792, mean_q: 1.652223, mean_eps: 0.592376\n",
            " 453860/1000000: episode: 660, duration: 20.284s, episode steps: 614, steps per second:  30, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.938 [0.000, 5.000],  loss: 0.015595, mae: 1.349644, mean_q: 1.654660, mean_eps: 0.591803\n",
            " 454384/1000000: episode: 661, duration: 17.571s, episode steps: 524, steps per second:  30, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.014618, mae: 1.339765, mean_q: 1.641287, mean_eps: 0.591292\n",
            " 454887/1000000: episode: 662, duration: 16.598s, episode steps: 503, steps per second:  30, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.016031, mae: 1.371385, mean_q: 1.678077, mean_eps: 0.590829\n",
            " 455634/1000000: episode: 663, duration: 24.751s, episode steps: 747, steps per second:  30, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.014854, mae: 1.344534, mean_q: 1.644215, mean_eps: 0.590266\n",
            " 456666/1000000: episode: 664, duration: 33.939s, episode steps: 1032, steps per second:  30, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.016153, mae: 1.347436, mean_q: 1.647686, mean_eps: 0.589465\n",
            " 457744/1000000: episode: 665, duration: 35.696s, episode steps: 1078, steps per second:  30, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.015400, mae: 1.345039, mean_q: 1.647189, mean_eps: 0.588516\n",
            " 458473/1000000: episode: 666, duration: 24.210s, episode steps: 729, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.014659, mae: 1.327323, mean_q: 1.623217, mean_eps: 0.587703\n",
            " 458945/1000000: episode: 667, duration: 15.512s, episode steps: 472, steps per second:  30, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.014912, mae: 1.352930, mean_q: 1.654288, mean_eps: 0.587161\n",
            " 459414/1000000: episode: 668, duration: 15.676s, episode steps: 469, steps per second:  30, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.016344, mae: 1.359559, mean_q: 1.663626, mean_eps: 0.586738\n",
            " 459830/1000000: episode: 669, duration: 13.718s, episode steps: 416, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.015661, mae: 1.336716, mean_q: 1.633904, mean_eps: 0.586340\n",
            " 460409/1000000: episode: 670, duration: 19.080s, episode steps: 579, steps per second:  30, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.014887, mae: 1.365183, mean_q: 1.671665, mean_eps: 0.585892\n",
            " 461031/1000000: episode: 671, duration: 20.511s, episode steps: 622, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.132 [0.000, 5.000],  loss: 0.015448, mae: 1.381590, mean_q: 1.690447, mean_eps: 0.585352\n",
            " 461662/1000000: episode: 672, duration: 20.990s, episode steps: 631, steps per second:  30, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.015879, mae: 1.383428, mean_q: 1.691773, mean_eps: 0.584789\n",
            " 462425/1000000: episode: 673, duration: 25.365s, episode steps: 763, steps per second:  30, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.015557, mae: 1.394431, mean_q: 1.703607, mean_eps: 0.584160\n",
            " 462932/1000000: episode: 674, duration: 16.848s, episode steps: 507, steps per second:  30, episode reward: 13.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.015752, mae: 1.384765, mean_q: 1.695651, mean_eps: 0.583590\n",
            " 463419/1000000: episode: 675, duration: 16.360s, episode steps: 487, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: 0.015214, mae: 1.399486, mean_q: 1.714012, mean_eps: 0.583143\n",
            " 464163/1000000: episode: 676, duration: 24.801s, episode steps: 744, steps per second:  30, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.016474, mae: 1.391445, mean_q: 1.702294, mean_eps: 0.582589\n",
            " 464916/1000000: episode: 677, duration: 25.157s, episode steps: 753, steps per second:  30, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.016773, mae: 1.385784, mean_q: 1.695141, mean_eps: 0.581916\n",
            " 467271/1000000: episode: 678, duration: 77.888s, episode steps: 2355, steps per second:  30, episode reward: 34.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.015533, mae: 1.378674, mean_q: 1.686817, mean_eps: 0.580517\n",
            " 467980/1000000: episode: 679, duration: 23.656s, episode steps: 709, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.001 [0.000, 5.000],  loss: 0.014597, mae: 1.391586, mean_q: 1.701806, mean_eps: 0.579138\n",
            " 468618/1000000: episode: 680, duration: 21.423s, episode steps: 638, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.015578, mae: 1.394876, mean_q: 1.706736, mean_eps: 0.578532\n",
            " 469183/1000000: episode: 681, duration: 18.870s, episode steps: 565, steps per second:  30, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.015358, mae: 1.392016, mean_q: 1.702255, mean_eps: 0.577990\n",
            " 469866/1000000: episode: 682, duration: 22.562s, episode steps: 683, steps per second:  30, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.015290, mae: 1.396561, mean_q: 1.706752, mean_eps: 0.577428\n",
            " 470437/1000000: episode: 683, duration: 19.063s, episode steps: 571, steps per second:  30, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.015503, mae: 1.428054, mean_q: 1.746347, mean_eps: 0.576863\n",
            " 471038/1000000: episode: 684, duration: 19.983s, episode steps: 601, steps per second:  30, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.015259, mae: 1.430684, mean_q: 1.748892, mean_eps: 0.576336\n",
            " 471968/1000000: episode: 685, duration: 30.990s, episode steps: 930, steps per second:  30, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.014693, mae: 1.421276, mean_q: 1.736179, mean_eps: 0.575648\n",
            " 472541/1000000: episode: 686, duration: 19.133s, episode steps: 573, steps per second:  30, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.033 [0.000, 5.000],  loss: 0.014506, mae: 1.439257, mean_q: 1.760062, mean_eps: 0.574971\n",
            " 473183/1000000: episode: 687, duration: 21.399s, episode steps: 642, steps per second:  30, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.014240, mae: 1.448327, mean_q: 1.769728, mean_eps: 0.574424\n",
            " 473812/1000000: episode: 688, duration: 20.924s, episode steps: 629, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.015755, mae: 1.419123, mean_q: 1.734306, mean_eps: 0.573854\n",
            " 474330/1000000: episode: 689, duration: 17.320s, episode steps: 518, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.014962, mae: 1.427898, mean_q: 1.748054, mean_eps: 0.573337\n",
            " 474828/1000000: episode: 690, duration: 16.550s, episode steps: 498, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.014416, mae: 1.429342, mean_q: 1.746898, mean_eps: 0.572880\n",
            " 475606/1000000: episode: 691, duration: 25.887s, episode steps: 778, steps per second:  30, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.013831, mae: 1.437018, mean_q: 1.753473, mean_eps: 0.572306\n",
            " 476075/1000000: episode: 692, duration: 15.518s, episode steps: 469, steps per second:  30, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.014506, mae: 1.438215, mean_q: 1.758189, mean_eps: 0.571744\n",
            " 476794/1000000: episode: 693, duration: 23.975s, episode steps: 719, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.015785, mae: 1.445484, mean_q: 1.766993, mean_eps: 0.571209\n",
            " 477723/1000000: episode: 694, duration: 30.829s, episode steps: 929, steps per second:  30, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.015401, mae: 1.442465, mean_q: 1.763093, mean_eps: 0.570468\n",
            " 478289/1000000: episode: 695, duration: 18.994s, episode steps: 566, steps per second:  30, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.802 [0.000, 5.000],  loss: 0.014955, mae: 1.429138, mean_q: 1.747507, mean_eps: 0.569795\n",
            " 479004/1000000: episode: 696, duration: 23.892s, episode steps: 715, steps per second:  30, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.016843, mae: 1.439245, mean_q: 1.756496, mean_eps: 0.569219\n",
            " 479663/1000000: episode: 697, duration: 21.912s, episode steps: 659, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.016285, mae: 1.441461, mean_q: 1.761259, mean_eps: 0.568601\n",
            " 480506/1000000: episode: 698, duration: 28.247s, episode steps: 843, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.014547, mae: 1.439064, mean_q: 1.758231, mean_eps: 0.567924\n",
            " 481189/1000000: episode: 699, duration: 23.012s, episode steps: 683, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.015437, mae: 1.457539, mean_q: 1.780512, mean_eps: 0.567237\n",
            " 481906/1000000: episode: 700, duration: 24.015s, episode steps: 717, steps per second:  30, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.287 [0.000, 5.000],  loss: 0.013501, mae: 1.448370, mean_q: 1.770950, mean_eps: 0.566607\n",
            " 483089/1000000: episode: 701, duration: 39.481s, episode steps: 1183, steps per second:  30, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.014800, mae: 1.449278, mean_q: 1.770909, mean_eps: 0.565752\n",
            " 483641/1000000: episode: 702, duration: 18.442s, episode steps: 552, steps per second:  30, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.016820, mae: 1.434120, mean_q: 1.755397, mean_eps: 0.564971\n",
            " 484592/1000000: episode: 703, duration: 32.265s, episode steps: 951, steps per second:  29, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.015663, mae: 1.441477, mean_q: 1.759942, mean_eps: 0.564296\n",
            " 485164/1000000: episode: 704, duration: 19.632s, episode steps: 572, steps per second:  29, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.016281, mae: 1.435188, mean_q: 1.751084, mean_eps: 0.563612\n",
            " 485746/1000000: episode: 705, duration: 20.202s, episode steps: 582, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.016709, mae: 1.443125, mean_q: 1.761366, mean_eps: 0.563091\n",
            " 486719/1000000: episode: 706, duration: 33.004s, episode steps: 973, steps per second:  29, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.014825, mae: 1.447828, mean_q: 1.767555, mean_eps: 0.562391\n",
            " 487437/1000000: episode: 707, duration: 24.530s, episode steps: 718, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.702 [0.000, 5.000],  loss: 0.014676, mae: 1.436495, mean_q: 1.754506, mean_eps: 0.561630\n",
            " 488396/1000000: episode: 708, duration: 32.837s, episode steps: 959, steps per second:  29, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.016189, mae: 1.441469, mean_q: 1.762225, mean_eps: 0.560876\n",
            " 488889/1000000: episode: 709, duration: 16.863s, episode steps: 493, steps per second:  29, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.015186, mae: 1.437001, mean_q: 1.756078, mean_eps: 0.560222\n",
            " 489768/1000000: episode: 710, duration: 30.005s, episode steps: 879, steps per second:  29, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.014926, mae: 1.454306, mean_q: 1.776564, mean_eps: 0.559605\n",
            " 490457/1000000: episode: 711, duration: 23.648s, episode steps: 689, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.016011, mae: 1.508751, mean_q: 1.843857, mean_eps: 0.558899\n",
            " 490948/1000000: episode: 712, duration: 16.913s, episode steps: 491, steps per second:  29, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.015248, mae: 1.529629, mean_q: 1.870544, mean_eps: 0.558368\n",
            " 491652/1000000: episode: 713, duration: 24.384s, episode steps: 704, steps per second:  29, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.016049, mae: 1.525248, mean_q: 1.861725, mean_eps: 0.557832\n",
            " 492236/1000000: episode: 714, duration: 20.036s, episode steps: 584, steps per second:  29, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.015780, mae: 1.539332, mean_q: 1.882175, mean_eps: 0.557252\n",
            " 493050/1000000: episode: 715, duration: 27.564s, episode steps: 814, steps per second:  30, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.015895, mae: 1.521051, mean_q: 1.856864, mean_eps: 0.556622\n",
            " 493610/1000000: episode: 716, duration: 19.111s, episode steps: 560, steps per second:  29, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.015688, mae: 1.519291, mean_q: 1.854209, mean_eps: 0.556003\n",
            " 494290/1000000: episode: 717, duration: 23.216s, episode steps: 680, steps per second:  29, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.017515, mae: 1.527857, mean_q: 1.865774, mean_eps: 0.555445\n",
            " 495123/1000000: episode: 718, duration: 28.368s, episode steps: 833, steps per second:  29, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.016880, mae: 1.529823, mean_q: 1.867747, mean_eps: 0.554765\n",
            " 495870/1000000: episode: 719, duration: 25.514s, episode steps: 747, steps per second:  29, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.016076, mae: 1.500927, mean_q: 1.833178, mean_eps: 0.554054\n",
            " 496307/1000000: episode: 720, duration: 14.731s, episode steps: 437, steps per second:  30, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.016051, mae: 1.526062, mean_q: 1.862539, mean_eps: 0.553521\n",
            " 496901/1000000: episode: 721, duration: 20.347s, episode steps: 594, steps per second:  29, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.016815, mae: 1.526550, mean_q: 1.861236, mean_eps: 0.553056\n",
            " 497647/1000000: episode: 722, duration: 25.318s, episode steps: 746, steps per second:  29, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.016609, mae: 1.535050, mean_q: 1.873650, mean_eps: 0.552453\n",
            " 498392/1000000: episode: 723, duration: 25.430s, episode steps: 745, steps per second:  29, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.016052, mae: 1.511748, mean_q: 1.843544, mean_eps: 0.551784\n",
            " 499031/1000000: episode: 724, duration: 21.758s, episode steps: 639, steps per second:  29, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.017944, mae: 1.539074, mean_q: 1.878623, mean_eps: 0.551161\n",
            " 499591/1000000: episode: 725, duration: 19.053s, episode steps: 560, steps per second:  29, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.017015, mae: 1.521263, mean_q: 1.854669, mean_eps: 0.550621\n",
            " 500166/1000000: episode: 726, duration: 19.590s, episode steps: 575, steps per second:  29, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.017021, mae: 1.524886, mean_q: 1.859308, mean_eps: 0.550110\n",
            " 500697/1000000: episode: 727, duration: 18.292s, episode steps: 531, steps per second:  29, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.014998, mae: 1.577442, mean_q: 1.925102, mean_eps: 0.549611\n",
            " 501899/1000000: episode: 728, duration: 40.815s, episode steps: 1202, steps per second:  29, episode reward: 29.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.017308, mae: 1.580316, mean_q: 1.927688, mean_eps: 0.548832\n",
            " 502455/1000000: episode: 729, duration: 19.145s, episode steps: 556, steps per second:  29, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.694 [0.000, 5.000],  loss: 0.016596, mae: 1.585481, mean_q: 1.934516, mean_eps: 0.548042\n",
            " 503048/1000000: episode: 730, duration: 20.360s, episode steps: 593, steps per second:  29, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.015297, mae: 1.581422, mean_q: 1.930048, mean_eps: 0.547525\n",
            " 503878/1000000: episode: 731, duration: 28.484s, episode steps: 830, steps per second:  29, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.015562, mae: 1.568489, mean_q: 1.913393, mean_eps: 0.546884\n",
            " 504535/1000000: episode: 732, duration: 22.438s, episode steps: 657, steps per second:  29, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.015081, mae: 1.578223, mean_q: 1.926442, mean_eps: 0.546215\n",
            " 505215/1000000: episode: 733, duration: 23.194s, episode steps: 680, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.016353, mae: 1.585574, mean_q: 1.937412, mean_eps: 0.545613\n",
            " 506054/1000000: episode: 734, duration: 28.732s, episode steps: 839, steps per second:  29, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.017614, mae: 1.583823, mean_q: 1.932166, mean_eps: 0.544929\n",
            " 506733/1000000: episode: 735, duration: 23.101s, episode steps: 679, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.013887, mae: 1.568924, mean_q: 1.917196, mean_eps: 0.544245\n",
            " 507479/1000000: episode: 736, duration: 25.439s, episode steps: 746, steps per second:  29, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.015987, mae: 1.575657, mean_q: 1.923473, mean_eps: 0.543605\n",
            " 507950/1000000: episode: 737, duration: 16.032s, episode steps: 471, steps per second:  29, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.017729, mae: 1.591301, mean_q: 1.940951, mean_eps: 0.543057\n",
            " 508904/1000000: episode: 738, duration: 32.740s, episode steps: 954, steps per second:  29, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.734 [0.000, 5.000],  loss: 0.014977, mae: 1.563508, mean_q: 1.905702, mean_eps: 0.542417\n",
            " 509494/1000000: episode: 739, duration: 20.396s, episode steps: 590, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.825 [0.000, 5.000],  loss: 0.016097, mae: 1.584486, mean_q: 1.933958, mean_eps: 0.541722\n",
            " 509921/1000000: episode: 740, duration: 14.707s, episode steps: 427, steps per second:  29, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.998 [0.000, 5.000],  loss: 0.016776, mae: 1.590669, mean_q: 1.940953, mean_eps: 0.541263\n",
            " 510614/1000000: episode: 741, duration: 23.763s, episode steps: 693, steps per second:  29, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.013953, mae: 1.584636, mean_q: 1.932575, mean_eps: 0.540759\n",
            " 511297/1000000: episode: 742, duration: 23.528s, episode steps: 683, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.135 [0.000, 5.000],  loss: 0.016636, mae: 1.585903, mean_q: 1.932101, mean_eps: 0.540140\n",
            " 511736/1000000: episode: 743, duration: 15.258s, episode steps: 439, steps per second:  29, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.015182, mae: 1.571170, mean_q: 1.917448, mean_eps: 0.539636\n",
            " 512092/1000000: episode: 744, duration: 12.425s, episode steps: 356, steps per second:  29, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.014954, mae: 1.578289, mean_q: 1.925189, mean_eps: 0.539279\n",
            " 512682/1000000: episode: 745, duration: 20.328s, episode steps: 590, steps per second:  29, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.034 [0.000, 5.000],  loss: 0.015477, mae: 1.587323, mean_q: 1.935412, mean_eps: 0.538853\n",
            " 513351/1000000: episode: 746, duration: 22.785s, episode steps: 669, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.015035, mae: 1.582511, mean_q: 1.929758, mean_eps: 0.538286\n",
            " 513951/1000000: episode: 747, duration: 20.483s, episode steps: 600, steps per second:  29, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.015543, mae: 1.575502, mean_q: 1.921135, mean_eps: 0.537715\n",
            " 515061/1000000: episode: 748, duration: 38.212s, episode steps: 1110, steps per second:  29, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.014857, mae: 1.582508, mean_q: 1.931274, mean_eps: 0.536945\n",
            " 515893/1000000: episode: 749, duration: 28.728s, episode steps: 832, steps per second:  29, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.014675, mae: 1.591335, mean_q: 1.939097, mean_eps: 0.536070\n",
            " 516545/1000000: episode: 750, duration: 22.421s, episode steps: 652, steps per second:  29, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.014074, mae: 1.573678, mean_q: 1.915582, mean_eps: 0.535402\n",
            " 517460/1000000: episode: 751, duration: 31.422s, episode steps: 915, steps per second:  29, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.014720, mae: 1.580411, mean_q: 1.926993, mean_eps: 0.534698\n",
            " 517947/1000000: episode: 752, duration: 16.976s, episode steps: 487, steps per second:  29, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.015765, mae: 1.574784, mean_q: 1.919797, mean_eps: 0.534068\n",
            " 518501/1000000: episode: 753, duration: 19.151s, episode steps: 554, steps per second:  29, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.922 [0.000, 5.000],  loss: 0.017624, mae: 1.581045, mean_q: 1.925481, mean_eps: 0.533598\n",
            " 519034/1000000: episode: 754, duration: 18.377s, episode steps: 533, steps per second:  29, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.014151, mae: 1.581285, mean_q: 1.927852, mean_eps: 0.533109\n",
            " 519857/1000000: episode: 755, duration: 28.323s, episode steps: 823, steps per second:  29, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.015862, mae: 1.585096, mean_q: 1.932611, mean_eps: 0.532499\n",
            " 520582/1000000: episode: 756, duration: 24.904s, episode steps: 725, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.017907, mae: 1.609748, mean_q: 1.965101, mean_eps: 0.531802\n",
            " 521058/1000000: episode: 757, duration: 16.489s, episode steps: 476, steps per second:  29, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.016506, mae: 1.624313, mean_q: 1.978883, mean_eps: 0.531262\n",
            " 521622/1000000: episode: 758, duration: 19.645s, episode steps: 564, steps per second:  29, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.243 [0.000, 5.000],  loss: 0.015654, mae: 1.651437, mean_q: 2.012329, mean_eps: 0.530794\n",
            " 522300/1000000: episode: 759, duration: 23.422s, episode steps: 678, steps per second:  29, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.015464, mae: 1.624515, mean_q: 1.982169, mean_eps: 0.530236\n",
            " 523166/1000000: episode: 760, duration: 29.810s, episode steps: 866, steps per second:  29, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.015574, mae: 1.621259, mean_q: 1.977417, mean_eps: 0.529541\n",
            " 523851/1000000: episode: 761, duration: 23.501s, episode steps: 685, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.016197, mae: 1.618356, mean_q: 1.970527, mean_eps: 0.528843\n",
            " 524335/1000000: episode: 762, duration: 16.751s, episode steps: 484, steps per second:  29, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.021479, mae: 1.620195, mean_q: 1.970798, mean_eps: 0.528317\n",
            " 525003/1000000: episode: 763, duration: 23.148s, episode steps: 668, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.016873, mae: 1.632085, mean_q: 1.986954, mean_eps: 0.527799\n",
            " 525823/1000000: episode: 764, duration: 28.266s, episode steps: 820, steps per second:  29, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.016745, mae: 1.608318, mean_q: 1.957768, mean_eps: 0.527129\n",
            " 526817/1000000: episode: 765, duration: 34.500s, episode steps: 994, steps per second:  29, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.017197, mae: 1.620639, mean_q: 1.977002, mean_eps: 0.526312\n",
            " 527293/1000000: episode: 766, duration: 16.403s, episode steps: 476, steps per second:  29, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: 0.016737, mae: 1.608067, mean_q: 1.959906, mean_eps: 0.525650\n",
            " 527831/1000000: episode: 767, duration: 18.596s, episode steps: 538, steps per second:  29, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.017519, mae: 1.623526, mean_q: 1.977868, mean_eps: 0.525194\n",
            " 528464/1000000: episode: 768, duration: 22.131s, episode steps: 633, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.016280, mae: 1.608518, mean_q: 1.963781, mean_eps: 0.524669\n",
            " 529428/1000000: episode: 769, duration: 33.724s, episode steps: 964, steps per second:  29, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.015424, mae: 1.621673, mean_q: 1.975200, mean_eps: 0.523950\n",
            " 530329/1000000: episode: 770, duration: 31.253s, episode steps: 901, steps per second:  29, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.838 [0.000, 5.000],  loss: 0.014748, mae: 1.639988, mean_q: 1.999361, mean_eps: 0.523110\n",
            " 530972/1000000: episode: 771, duration: 22.339s, episode steps: 643, steps per second:  29, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.894 [0.000, 5.000],  loss: 0.016617, mae: 1.681767, mean_q: 2.049613, mean_eps: 0.522415\n",
            " 531621/1000000: episode: 772, duration: 22.994s, episode steps: 649, steps per second:  28, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.015225, mae: 1.685492, mean_q: 2.054444, mean_eps: 0.521834\n",
            " 532202/1000000: episode: 773, duration: 20.580s, episode steps: 581, steps per second:  28, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.015384, mae: 1.688247, mean_q: 2.054965, mean_eps: 0.521279\n",
            " 532620/1000000: episode: 774, duration: 14.609s, episode steps: 418, steps per second:  29, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.016622, mae: 1.685688, mean_q: 2.052189, mean_eps: 0.520831\n",
            " 533138/1000000: episode: 775, duration: 18.150s, episode steps: 518, steps per second:  29, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.019377, mae: 1.681740, mean_q: 2.046109, mean_eps: 0.520410\n",
            " 533859/1000000: episode: 776, duration: 25.019s, episode steps: 721, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.017717, mae: 1.656083, mean_q: 2.014668, mean_eps: 0.519852\n",
            " 534790/1000000: episode: 777, duration: 31.938s, episode steps: 931, steps per second:  29, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.016252, mae: 1.660480, mean_q: 2.021160, mean_eps: 0.519108\n",
            " 535161/1000000: episode: 778, duration: 12.733s, episode steps: 371, steps per second:  29, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.016579, mae: 1.686471, mean_q: 2.049709, mean_eps: 0.518522\n",
            " 535896/1000000: episode: 779, duration: 25.165s, episode steps: 735, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.705 [0.000, 5.000],  loss: 0.016477, mae: 1.670653, mean_q: 2.031827, mean_eps: 0.518025\n",
            " 536639/1000000: episode: 780, duration: 25.888s, episode steps: 743, steps per second:  29, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.016749, mae: 1.685010, mean_q: 2.049979, mean_eps: 0.517361\n",
            " 537029/1000000: episode: 781, duration: 13.295s, episode steps: 390, steps per second:  29, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: 0.019593, mae: 1.669587, mean_q: 2.031805, mean_eps: 0.516849\n",
            " 537748/1000000: episode: 782, duration: 24.543s, episode steps: 719, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.015864, mae: 1.672993, mean_q: 2.036213, mean_eps: 0.516351\n",
            " 538175/1000000: episode: 783, duration: 14.800s, episode steps: 427, steps per second:  29, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.112 [0.000, 5.000],  loss: 0.017388, mae: 1.693900, mean_q: 2.062326, mean_eps: 0.515836\n",
            " 538577/1000000: episode: 784, duration: 13.937s, episode steps: 402, steps per second:  29, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.016434, mae: 1.688785, mean_q: 2.057851, mean_eps: 0.515462\n",
            " 539110/1000000: episode: 785, duration: 18.383s, episode steps: 533, steps per second:  29, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.017203, mae: 1.682773, mean_q: 2.047019, mean_eps: 0.515040\n",
            " 539844/1000000: episode: 786, duration: 25.305s, episode steps: 734, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.017182, mae: 1.663941, mean_q: 2.024651, mean_eps: 0.514472\n",
            " 540510/1000000: episode: 787, duration: 23.069s, episode steps: 666, steps per second:  29, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.099 [0.000, 5.000],  loss: 0.014342, mae: 1.706669, mean_q: 2.080580, mean_eps: 0.513842\n",
            " 541144/1000000: episode: 788, duration: 21.824s, episode steps: 634, steps per second:  29, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.014937, mae: 1.682731, mean_q: 2.049204, mean_eps: 0.513257\n",
            " 541625/1000000: episode: 789, duration: 16.592s, episode steps: 481, steps per second:  29, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.017138, mae: 1.697946, mean_q: 2.070873, mean_eps: 0.512754\n",
            " 542320/1000000: episode: 790, duration: 23.621s, episode steps: 695, steps per second:  29, episode reward: 19.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.016821, mae: 1.689541, mean_q: 2.055558, mean_eps: 0.512225\n",
            " 543195/1000000: episode: 791, duration: 29.834s, episode steps: 875, steps per second:  29, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.016560, mae: 1.686914, mean_q: 2.053413, mean_eps: 0.511520\n",
            " 544131/1000000: episode: 792, duration: 31.797s, episode steps: 936, steps per second:  29, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.146 [0.000, 5.000],  loss: 0.016285, mae: 1.700726, mean_q: 2.070035, mean_eps: 0.510704\n",
            " 544700/1000000: episode: 793, duration: 19.570s, episode steps: 569, steps per second:  29, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.195 [0.000, 5.000],  loss: 0.018496, mae: 1.699164, mean_q: 2.068213, mean_eps: 0.510027\n",
            " 545388/1000000: episode: 794, duration: 23.764s, episode steps: 688, steps per second:  29, episode reward: 18.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.015260, mae: 1.691517, mean_q: 2.061470, mean_eps: 0.509462\n",
            " 546372/1000000: episode: 795, duration: 34.109s, episode steps: 984, steps per second:  29, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.016854, mae: 1.707512, mean_q: 2.076281, mean_eps: 0.508710\n",
            " 547216/1000000: episode: 796, duration: 28.913s, episode steps: 844, steps per second:  29, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.017123, mae: 1.704616, mean_q: 2.074812, mean_eps: 0.507887\n",
            " 548007/1000000: episode: 797, duration: 27.191s, episode steps: 791, steps per second:  29, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.017585, mae: 1.703053, mean_q: 2.072612, mean_eps: 0.507151\n",
            " 548625/1000000: episode: 798, duration: 21.162s, episode steps: 618, steps per second:  29, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.017674, mae: 1.694010, mean_q: 2.063537, mean_eps: 0.506516\n",
            " 549213/1000000: episode: 799, duration: 20.048s, episode steps: 588, steps per second:  29, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.017063, mae: 1.689015, mean_q: 2.052798, mean_eps: 0.505972\n",
            " 550240/1000000: episode: 800, duration: 35.134s, episode steps: 1027, steps per second:  29, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.017429, mae: 1.713874, mean_q: 2.084414, mean_eps: 0.505247\n",
            " 550911/1000000: episode: 801, duration: 22.958s, episode steps: 671, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.258 [0.000, 5.000],  loss: 0.017219, mae: 1.763487, mean_q: 2.147085, mean_eps: 0.504483\n",
            " 551625/1000000: episode: 802, duration: 24.549s, episode steps: 714, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.018458, mae: 1.756248, mean_q: 2.139224, mean_eps: 0.503859\n",
            " 552273/1000000: episode: 803, duration: 22.191s, episode steps: 648, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.872 [0.000, 5.000],  loss: 0.016257, mae: 1.760879, mean_q: 2.142574, mean_eps: 0.503245\n",
            " 553402/1000000: episode: 804, duration: 38.432s, episode steps: 1129, steps per second:  29, episode reward: 27.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.018429, mae: 1.740846, mean_q: 2.117545, mean_eps: 0.502446\n",
            " 553823/1000000: episode: 805, duration: 14.271s, episode steps: 421, steps per second:  30, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.018970, mae: 1.736904, mean_q: 2.111778, mean_eps: 0.501749\n",
            " 554924/1000000: episode: 806, duration: 37.872s, episode steps: 1101, steps per second:  29, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.016965, mae: 1.747506, mean_q: 2.127722, mean_eps: 0.501065\n",
            " 555362/1000000: episode: 807, duration: 15.050s, episode steps: 438, steps per second:  29, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.017945, mae: 1.771441, mean_q: 2.153136, mean_eps: 0.500372\n",
            " 556161/1000000: episode: 808, duration: 27.423s, episode steps: 799, steps per second:  29, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.017198, mae: 1.748064, mean_q: 2.126214, mean_eps: 0.499814\n",
            " 557266/1000000: episode: 809, duration: 37.738s, episode steps: 1105, steps per second:  29, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.018681, mae: 1.754511, mean_q: 2.135472, mean_eps: 0.498957\n",
            " 558299/1000000: episode: 810, duration: 35.547s, episode steps: 1033, steps per second:  29, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.017222, mae: 1.753100, mean_q: 2.132884, mean_eps: 0.497996\n",
            " 559195/1000000: episode: 811, duration: 31.205s, episode steps: 896, steps per second:  29, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.018547, mae: 1.747990, mean_q: 2.126305, mean_eps: 0.497129\n",
            " 560069/1000000: episode: 812, duration: 30.319s, episode steps: 874, steps per second:  29, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.017545, mae: 1.748563, mean_q: 2.126179, mean_eps: 0.496331\n",
            " 561075/1000000: episode: 813, duration: 34.789s, episode steps: 1006, steps per second:  29, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.016520, mae: 1.825120, mean_q: 2.221171, mean_eps: 0.495485\n",
            " 562123/1000000: episode: 814, duration: 36.391s, episode steps: 1048, steps per second:  29, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.017855, mae: 1.796796, mean_q: 2.186809, mean_eps: 0.494562\n",
            " 562848/1000000: episode: 815, duration: 25.242s, episode steps: 725, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.017196, mae: 1.804457, mean_q: 2.195589, mean_eps: 0.493764\n",
            " 563656/1000000: episode: 816, duration: 28.290s, episode steps: 808, steps per second:  29, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.017094, mae: 1.814157, mean_q: 2.206513, mean_eps: 0.493075\n",
            " 564252/1000000: episode: 817, duration: 20.771s, episode steps: 596, steps per second:  29, episode reward: 16.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.020041, mae: 1.799694, mean_q: 2.188452, mean_eps: 0.492443\n",
            " 564789/1000000: episode: 818, duration: 18.810s, episode steps: 537, steps per second:  29, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.017329, mae: 1.810607, mean_q: 2.202604, mean_eps: 0.491932\n",
            " 565910/1000000: episode: 819, duration: 38.899s, episode steps: 1121, steps per second:  29, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.148 [0.000, 5.000],  loss: 0.018664, mae: 1.808720, mean_q: 2.199991, mean_eps: 0.491185\n",
            " 566487/1000000: episode: 820, duration: 20.037s, episode steps: 577, steps per second:  29, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.018489, mae: 1.803265, mean_q: 2.194515, mean_eps: 0.490422\n",
            " 567188/1000000: episode: 821, duration: 24.456s, episode steps: 701, steps per second:  29, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.017447, mae: 1.800530, mean_q: 2.192012, mean_eps: 0.489848\n",
            " 568327/1000000: episode: 822, duration: 39.645s, episode steps: 1139, steps per second:  29, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.196 [0.000, 5.000],  loss: 0.018621, mae: 1.817877, mean_q: 2.210787, mean_eps: 0.489020\n",
            " 569436/1000000: episode: 823, duration: 38.633s, episode steps: 1109, steps per second:  29, episode reward: 27.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.018082, mae: 1.801801, mean_q: 2.193535, mean_eps: 0.488008\n",
            " 570111/1000000: episode: 824, duration: 23.478s, episode steps: 675, steps per second:  29, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.016862, mae: 1.813974, mean_q: 2.205504, mean_eps: 0.487205\n",
            " 570864/1000000: episode: 825, duration: 26.379s, episode steps: 753, steps per second:  29, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.016350, mae: 1.850335, mean_q: 2.250593, mean_eps: 0.486563\n",
            " 571754/1000000: episode: 826, duration: 31.063s, episode steps: 890, steps per second:  29, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.027606, mae: 1.853920, mean_q: 2.252179, mean_eps: 0.485823\n",
            " 572441/1000000: episode: 827, duration: 24.034s, episode steps: 687, steps per second:  29, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.017804, mae: 1.851807, mean_q: 2.251651, mean_eps: 0.485112\n",
            " 572984/1000000: episode: 828, duration: 18.946s, episode steps: 543, steps per second:  29, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.015606, mae: 1.838717, mean_q: 2.234415, mean_eps: 0.484559\n",
            " 573947/1000000: episode: 829, duration: 33.642s, episode steps: 963, steps per second:  29, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.018944, mae: 1.838571, mean_q: 2.233739, mean_eps: 0.483882\n",
            " 574818/1000000: episode: 830, duration: 30.417s, episode steps: 871, steps per second:  29, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.018261, mae: 1.868605, mean_q: 2.270855, mean_eps: 0.483056\n",
            " 575901/1000000: episode: 831, duration: 37.922s, episode steps: 1083, steps per second:  29, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.018055, mae: 1.843370, mean_q: 2.240249, mean_eps: 0.482176\n",
            " 576419/1000000: episode: 832, duration: 17.885s, episode steps: 518, steps per second:  29, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.018988, mae: 1.826085, mean_q: 2.218217, mean_eps: 0.481456\n",
            " 577101/1000000: episode: 833, duration: 24.130s, episode steps: 682, steps per second:  28, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.019028, mae: 1.831375, mean_q: 2.224712, mean_eps: 0.480916\n",
            " 577830/1000000: episode: 834, duration: 25.433s, episode steps: 729, steps per second:  29, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.019267, mae: 1.843310, mean_q: 2.238035, mean_eps: 0.480281\n",
            " 578570/1000000: episode: 835, duration: 25.705s, episode steps: 740, steps per second:  29, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.018714, mae: 1.848273, mean_q: 2.249309, mean_eps: 0.479620\n",
            " 579167/1000000: episode: 836, duration: 20.667s, episode steps: 597, steps per second:  29, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.020658, mae: 1.856130, mean_q: 2.255349, mean_eps: 0.479019\n",
            " 580064/1000000: episode: 837, duration: 31.422s, episode steps: 897, steps per second:  29, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.018694, mae: 1.855643, mean_q: 2.254695, mean_eps: 0.478347\n",
            " 580816/1000000: episode: 838, duration: 26.327s, episode steps: 752, steps per second:  29, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.018874, mae: 1.881012, mean_q: 2.286836, mean_eps: 0.477606\n",
            " 581765/1000000: episode: 839, duration: 33.563s, episode steps: 949, steps per second:  28, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.020152, mae: 1.901675, mean_q: 2.311402, mean_eps: 0.476839\n",
            " 582162/1000000: episode: 840, duration: 14.026s, episode steps: 397, steps per second:  28, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.021086, mae: 1.884085, mean_q: 2.290132, mean_eps: 0.476232\n",
            " 583280/1000000: episode: 841, duration: 39.610s, episode steps: 1118, steps per second:  28, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: 0.019270, mae: 1.879535, mean_q: 2.284838, mean_eps: 0.475552\n",
            " 584065/1000000: episode: 842, duration: 28.094s, episode steps: 785, steps per second:  28, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.017206, mae: 1.885464, mean_q: 2.291100, mean_eps: 0.474695\n",
            " 585098/1000000: episode: 843, duration: 36.435s, episode steps: 1033, steps per second:  28, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.020963, mae: 1.891958, mean_q: 2.299985, mean_eps: 0.473876\n",
            " 585664/1000000: episode: 844, duration: 20.140s, episode steps: 566, steps per second:  28, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.018375, mae: 1.877686, mean_q: 2.279998, mean_eps: 0.473158\n",
            " 586376/1000000: episode: 845, duration: 25.212s, episode steps: 712, steps per second:  28, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.019652, mae: 1.883474, mean_q: 2.291621, mean_eps: 0.472584\n",
            " 587014/1000000: episode: 846, duration: 22.715s, episode steps: 638, steps per second:  28, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.679 [0.000, 5.000],  loss: 0.018582, mae: 1.890169, mean_q: 2.298709, mean_eps: 0.471975\n",
            " 587703/1000000: episode: 847, duration: 24.288s, episode steps: 689, steps per second:  28, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.806 [0.000, 5.000],  loss: 0.018831, mae: 1.887613, mean_q: 2.293989, mean_eps: 0.471378\n",
            " 588256/1000000: episode: 848, duration: 19.754s, episode steps: 553, steps per second:  28, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.020916, mae: 1.885960, mean_q: 2.290163, mean_eps: 0.470820\n",
            " 588596/1000000: episode: 849, duration: 12.108s, episode steps: 340, steps per second:  28, episode reward:  8.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.829 [0.000, 5.000],  loss: 0.018185, mae: 1.895285, mean_q: 2.301326, mean_eps: 0.470418\n",
            " 589330/1000000: episode: 850, duration: 25.947s, episode steps: 734, steps per second:  28, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.102 [0.000, 5.000],  loss: 0.017707, mae: 1.899173, mean_q: 2.307173, mean_eps: 0.469934\n",
            " 589744/1000000: episode: 851, duration: 14.656s, episode steps: 414, steps per second:  28, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: 0.019185, mae: 1.876605, mean_q: 2.278486, mean_eps: 0.469418\n",
            " 590323/1000000: episode: 852, duration: 20.705s, episode steps: 579, steps per second:  28, episode reward: 17.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: 0.016178, mae: 1.870697, mean_q: 2.274079, mean_eps: 0.468971\n",
            " 591317/1000000: episode: 853, duration: 35.139s, episode steps: 994, steps per second:  28, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.016162, mae: 1.904281, mean_q: 2.314178, mean_eps: 0.468262\n",
            " 592035/1000000: episode: 854, duration: 25.151s, episode steps: 718, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.019121, mae: 1.895913, mean_q: 2.303380, mean_eps: 0.467492\n",
            " 592856/1000000: episode: 855, duration: 28.922s, episode steps: 821, steps per second:  28, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.018617, mae: 1.905594, mean_q: 2.314968, mean_eps: 0.466800\n",
            " 593659/1000000: episode: 856, duration: 28.389s, episode steps: 803, steps per second:  28, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.017066, mae: 1.887370, mean_q: 2.293394, mean_eps: 0.466070\n",
            " 594239/1000000: episode: 857, duration: 20.398s, episode steps: 580, steps per second:  28, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.714 [0.000, 5.000],  loss: 0.019230, mae: 1.900597, mean_q: 2.309205, mean_eps: 0.465447\n",
            " 594885/1000000: episode: 858, duration: 22.910s, episode steps: 646, steps per second:  28, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.017591, mae: 1.890649, mean_q: 2.299232, mean_eps: 0.464894\n",
            " 595667/1000000: episode: 859, duration: 27.528s, episode steps: 782, steps per second:  28, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.017780, mae: 1.892776, mean_q: 2.299157, mean_eps: 0.464252\n",
            " 596706/1000000: episode: 860, duration: 36.525s, episode steps: 1039, steps per second:  28, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.018100, mae: 1.892008, mean_q: 2.298340, mean_eps: 0.463433\n",
            " 597428/1000000: episode: 861, duration: 25.555s, episode steps: 722, steps per second:  28, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.019346, mae: 1.909817, mean_q: 2.321759, mean_eps: 0.462641\n",
            " 598135/1000000: episode: 862, duration: 25.134s, episode steps: 707, steps per second:  28, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.016666, mae: 1.886605, mean_q: 2.292079, mean_eps: 0.461998\n",
            " 598786/1000000: episode: 863, duration: 23.323s, episode steps: 651, steps per second:  28, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.019111, mae: 1.923789, mean_q: 2.338151, mean_eps: 0.461386\n",
            " 599594/1000000: episode: 864, duration: 28.707s, episode steps: 808, steps per second:  28, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.017269, mae: 1.904736, mean_q: 2.316059, mean_eps: 0.460729\n",
            " 600667/1000000: episode: 865, duration: 38.156s, episode steps: 1073, steps per second:  28, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.021306, mae: 1.919633, mean_q: 2.335441, mean_eps: 0.459883\n",
            " 601271/1000000: episode: 866, duration: 21.451s, episode steps: 604, steps per second:  28, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.020507, mae: 1.944242, mean_q: 2.365150, mean_eps: 0.459129\n",
            " 601636/1000000: episode: 867, duration: 13.016s, episode steps: 365, steps per second:  28, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.017428, mae: 1.903987, mean_q: 2.315028, mean_eps: 0.458693\n",
            " 602498/1000000: episode: 868, duration: 30.545s, episode steps: 862, steps per second:  28, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.020226, mae: 1.926689, mean_q: 2.339981, mean_eps: 0.458141\n",
            " 603130/1000000: episode: 869, duration: 22.584s, episode steps: 632, steps per second:  28, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.018553, mae: 1.932935, mean_q: 2.349013, mean_eps: 0.457467\n",
            " 603488/1000000: episode: 870, duration: 12.791s, episode steps: 358, steps per second:  28, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.212 [0.000, 5.000],  loss: 0.019183, mae: 1.910486, mean_q: 2.322135, mean_eps: 0.457023\n",
            " 604397/1000000: episode: 871, duration: 32.056s, episode steps: 909, steps per second:  28, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.019129, mae: 1.927539, mean_q: 2.342851, mean_eps: 0.456452\n",
            " 605362/1000000: episode: 872, duration: 34.090s, episode steps: 965, steps per second:  28, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.019732, mae: 1.929082, mean_q: 2.343257, mean_eps: 0.455608\n",
            " 606267/1000000: episode: 873, duration: 31.980s, episode steps: 905, steps per second:  28, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.017748, mae: 1.928730, mean_q: 2.343179, mean_eps: 0.454767\n",
            " 606975/1000000: episode: 874, duration: 25.222s, episode steps: 708, steps per second:  28, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.018444, mae: 1.907012, mean_q: 2.317767, mean_eps: 0.454042\n",
            " 607549/1000000: episode: 875, duration: 20.779s, episode steps: 574, steps per second:  28, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.020773, mae: 1.941998, mean_q: 2.360275, mean_eps: 0.453464\n",
            " 608138/1000000: episode: 876, duration: 21.072s, episode steps: 589, steps per second:  28, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.018318, mae: 1.947341, mean_q: 2.365617, mean_eps: 0.452940\n",
            " 608883/1000000: episode: 877, duration: 26.533s, episode steps: 745, steps per second:  28, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.018322, mae: 1.930899, mean_q: 2.345010, mean_eps: 0.452341\n",
            " 609991/1000000: episode: 878, duration: 39.528s, episode steps: 1108, steps per second:  28, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.021182, mae: 1.907131, mean_q: 2.313848, mean_eps: 0.451508\n",
            " 611031/1000000: episode: 879, duration: 37.136s, episode steps: 1040, steps per second:  28, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.016919, mae: 1.962516, mean_q: 2.382297, mean_eps: 0.450541\n",
            " 612223/1000000: episode: 880, duration: 42.364s, episode steps: 1192, steps per second:  28, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.017591, mae: 1.958137, mean_q: 2.376928, mean_eps: 0.449537\n",
            " 613190/1000000: episode: 881, duration: 34.254s, episode steps: 967, steps per second:  28, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.254 [0.000, 5.000],  loss: 0.017549, mae: 1.963419, mean_q: 2.384260, mean_eps: 0.448565\n",
            " 614017/1000000: episode: 882, duration: 29.501s, episode steps: 827, steps per second:  28, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.019697, mae: 1.955572, mean_q: 2.373682, mean_eps: 0.447756\n",
            " 614924/1000000: episode: 883, duration: 32.371s, episode steps: 907, steps per second:  28, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.018945, mae: 1.969931, mean_q: 2.389281, mean_eps: 0.446977\n",
            " 615608/1000000: episode: 884, duration: 24.450s, episode steps: 684, steps per second:  28, episode reward: 18.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.018072, mae: 1.961119, mean_q: 2.380981, mean_eps: 0.446262\n",
            " 616281/1000000: episode: 885, duration: 24.113s, episode steps: 673, steps per second:  28, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.022382, mae: 1.989408, mean_q: 2.416625, mean_eps: 0.445650\n",
            " 617261/1000000: episode: 886, duration: 34.865s, episode steps: 980, steps per second:  28, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.159 [0.000, 5.000],  loss: 0.017481, mae: 1.961573, mean_q: 2.380658, mean_eps: 0.444905\n",
            " 618231/1000000: episode: 887, duration: 34.491s, episode steps: 970, steps per second:  28, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.019222, mae: 1.956032, mean_q: 2.373803, mean_eps: 0.444029\n",
            " 618885/1000000: episode: 888, duration: 23.338s, episode steps: 654, steps per second:  28, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.018559, mae: 1.959351, mean_q: 2.378489, mean_eps: 0.443298\n",
            " 619802/1000000: episode: 889, duration: 32.598s, episode steps: 917, steps per second:  28, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.019332, mae: 1.952823, mean_q: 2.368414, mean_eps: 0.442590\n",
            " 620285/1000000: episode: 890, duration: 17.157s, episode steps: 483, steps per second:  28, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.016169, mae: 1.994678, mean_q: 2.419828, mean_eps: 0.441960\n",
            " 620839/1000000: episode: 891, duration: 19.676s, episode steps: 554, steps per second:  28, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.017761, mae: 1.979708, mean_q: 2.402538, mean_eps: 0.441494\n",
            " 621709/1000000: episode: 892, duration: 31.247s, episode steps: 870, steps per second:  28, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.018135, mae: 1.998636, mean_q: 2.426297, mean_eps: 0.440853\n",
            " 622577/1000000: episode: 893, duration: 30.845s, episode steps: 868, steps per second:  28, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.018995, mae: 1.991900, mean_q: 2.416514, mean_eps: 0.440070\n",
            " 623425/1000000: episode: 894, duration: 30.440s, episode steps: 848, steps per second:  28, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.019322, mae: 1.987897, mean_q: 2.413640, mean_eps: 0.439298\n",
            " 623805/1000000: episode: 895, duration: 13.602s, episode steps: 380, steps per second:  28, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.016090, mae: 1.963748, mean_q: 2.387051, mean_eps: 0.438746\n",
            " 624744/1000000: episode: 896, duration: 33.982s, episode steps: 939, steps per second:  28, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.695 [0.000, 5.000],  loss: 0.018851, mae: 1.999357, mean_q: 2.426885, mean_eps: 0.438153\n",
            " 625477/1000000: episode: 897, duration: 26.722s, episode steps: 733, steps per second:  27, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.020305, mae: 1.987449, mean_q: 2.408269, mean_eps: 0.437401\n",
            " 626045/1000000: episode: 898, duration: 20.774s, episode steps: 568, steps per second:  27, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.020777, mae: 1.981646, mean_q: 2.405102, mean_eps: 0.436814\n",
            " 626604/1000000: episode: 899, duration: 20.167s, episode steps: 559, steps per second:  28, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.017821, mae: 1.986361, mean_q: 2.408121, mean_eps: 0.436308\n",
            " 627575/1000000: episode: 900, duration: 35.172s, episode steps: 971, steps per second:  28, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.019997, mae: 1.986203, mean_q: 2.408322, mean_eps: 0.435621\n",
            " 628651/1000000: episode: 901, duration: 39.670s, episode steps: 1076, steps per second:  27, episode reward: 28.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.018237, mae: 1.968362, mean_q: 2.387973, mean_eps: 0.434699\n",
            " 629375/1000000: episode: 902, duration: 27.059s, episode steps: 724, steps per second:  27, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.019326, mae: 1.981573, mean_q: 2.402780, mean_eps: 0.433889\n",
            " 629949/1000000: episode: 903, duration: 21.236s, episode steps: 574, steps per second:  27, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.019824, mae: 1.978049, mean_q: 2.397614, mean_eps: 0.433304\n",
            " 630607/1000000: episode: 904, duration: 24.273s, episode steps: 658, steps per second:  27, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.018726, mae: 2.045997, mean_q: 2.480426, mean_eps: 0.432750\n",
            " 631341/1000000: episode: 905, duration: 27.283s, episode steps: 734, steps per second:  27, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.020057, mae: 2.041534, mean_q: 2.477837, mean_eps: 0.432123\n",
            " 632160/1000000: episode: 906, duration: 30.387s, episode steps: 819, steps per second:  27, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.017042, mae: 2.040099, mean_q: 2.473664, mean_eps: 0.431425\n",
            " 633371/1000000: episode: 907, duration: 45.001s, episode steps: 1211, steps per second:  27, episode reward: 28.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.018726, mae: 2.042842, mean_q: 2.476070, mean_eps: 0.430512\n",
            " 634447/1000000: episode: 908, duration: 39.540s, episode steps: 1076, steps per second:  27, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.019128, mae: 2.060135, mean_q: 2.497038, mean_eps: 0.429483\n",
            " 635543/1000000: episode: 909, duration: 40.515s, episode steps: 1096, steps per second:  27, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.017672, mae: 2.041384, mean_q: 2.474947, mean_eps: 0.428505\n",
            " 636065/1000000: episode: 910, duration: 19.402s, episode steps: 522, steps per second:  27, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.020934, mae: 2.036260, mean_q: 2.468077, mean_eps: 0.427776\n",
            " 636961/1000000: episode: 911, duration: 33.311s, episode steps: 896, steps per second:  27, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.017907, mae: 2.029463, mean_q: 2.461245, mean_eps: 0.427137\n",
            " 637863/1000000: episode: 912, duration: 33.587s, episode steps: 902, steps per second:  27, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.019812, mae: 2.044361, mean_q: 2.479805, mean_eps: 0.426329\n",
            " 638913/1000000: episode: 913, duration: 39.345s, episode steps: 1050, steps per second:  27, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.019398, mae: 2.043099, mean_q: 2.476516, mean_eps: 0.425451\n",
            " 639522/1000000: episode: 914, duration: 22.497s, episode steps: 609, steps per second:  27, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.020553, mae: 2.043988, mean_q: 2.479931, mean_eps: 0.424704\n",
            " 640428/1000000: episode: 915, duration: 33.879s, episode steps: 906, steps per second:  27, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.018149, mae: 2.063369, mean_q: 2.502122, mean_eps: 0.424023\n",
            " 641973/1000000: episode: 916, duration: 57.766s, episode steps: 1545, steps per second:  27, episode reward: 34.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.019618, mae: 2.088911, mean_q: 2.535011, mean_eps: 0.422920\n",
            " 642623/1000000: episode: 917, duration: 23.911s, episode steps: 650, steps per second:  27, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.017256, mae: 2.103848, mean_q: 2.550521, mean_eps: 0.421932\n",
            " 643241/1000000: episode: 918, duration: 22.905s, episode steps: 618, steps per second:  27, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.788 [0.000, 5.000],  loss: 0.018578, mae: 2.093042, mean_q: 2.538748, mean_eps: 0.421361\n",
            " 643941/1000000: episode: 919, duration: 25.631s, episode steps: 700, steps per second:  27, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.019645, mae: 2.111544, mean_q: 2.560971, mean_eps: 0.420767\n",
            " 644562/1000000: episode: 920, duration: 22.768s, episode steps: 621, steps per second:  27, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.018255, mae: 2.099274, mean_q: 2.545289, mean_eps: 0.420173\n",
            " 645250/1000000: episode: 921, duration: 25.351s, episode steps: 688, steps per second:  27, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.016 [0.000, 5.000],  loss: 0.017447, mae: 2.119480, mean_q: 2.569213, mean_eps: 0.419585\n",
            " 646036/1000000: episode: 922, duration: 28.987s, episode steps: 786, steps per second:  27, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.018896, mae: 2.074026, mean_q: 2.515978, mean_eps: 0.418922\n",
            " 646873/1000000: episode: 923, duration: 30.729s, episode steps: 837, steps per second:  27, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.021397, mae: 2.094537, mean_q: 2.537432, mean_eps: 0.418191\n",
            " 647607/1000000: episode: 924, duration: 27.004s, episode steps: 734, steps per second:  27, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.842 [0.000, 5.000],  loss: 0.019187, mae: 2.102008, mean_q: 2.548573, mean_eps: 0.417484\n",
            " 648572/1000000: episode: 925, duration: 35.495s, episode steps: 965, steps per second:  27, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.018737, mae: 2.074306, mean_q: 2.512851, mean_eps: 0.416721\n",
            " 649863/1000000: episode: 926, duration: 47.398s, episode steps: 1291, steps per second:  27, episode reward: 14.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.018970, mae: 2.100701, mean_q: 2.548384, mean_eps: 0.415706\n",
            " 650909/1000000: episode: 927, duration: 38.662s, episode steps: 1046, steps per second:  27, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.018296, mae: 2.118930, mean_q: 2.570503, mean_eps: 0.414653\n",
            " 651366/1000000: episode: 928, duration: 16.798s, episode steps: 457, steps per second:  27, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.254 [0.000, 5.000],  loss: 0.018998, mae: 2.123223, mean_q: 2.571452, mean_eps: 0.413976\n",
            " 652108/1000000: episode: 929, duration: 27.253s, episode steps: 742, steps per second:  27, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.019148, mae: 2.135459, mean_q: 2.588977, mean_eps: 0.413438\n",
            " 652787/1000000: episode: 930, duration: 24.980s, episode steps: 679, steps per second:  27, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.021483, mae: 2.139994, mean_q: 2.593538, mean_eps: 0.412799\n",
            " 653732/1000000: episode: 931, duration: 34.843s, episode steps: 945, steps per second:  27, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.861 [0.000, 5.000],  loss: 0.019594, mae: 2.128817, mean_q: 2.579484, mean_eps: 0.412068\n",
            " 654346/1000000: episode: 932, duration: 22.630s, episode steps: 614, steps per second:  27, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.134 [0.000, 5.000],  loss: 0.021420, mae: 2.135807, mean_q: 2.588795, mean_eps: 0.411366\n",
            " 654948/1000000: episode: 933, duration: 22.326s, episode steps: 602, steps per second:  27, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.022612, mae: 2.126942, mean_q: 2.576101, mean_eps: 0.410819\n",
            " 655621/1000000: episode: 934, duration: 24.688s, episode steps: 673, steps per second:  27, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.174 [0.000, 5.000],  loss: 0.020891, mae: 2.128018, mean_q: 2.580255, mean_eps: 0.410244\n",
            " 656575/1000000: episode: 935, duration: 34.896s, episode steps: 954, steps per second:  27, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.150 [0.000, 5.000],  loss: 0.021225, mae: 2.129090, mean_q: 2.582062, mean_eps: 0.409512\n",
            " 657521/1000000: episode: 936, duration: 34.891s, episode steps: 946, steps per second:  27, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.021178, mae: 2.111142, mean_q: 2.559790, mean_eps: 0.408657\n",
            " 658406/1000000: episode: 937, duration: 32.503s, episode steps: 885, steps per second:  27, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.259 [0.000, 5.000],  loss: 0.016815, mae: 2.125267, mean_q: 2.577433, mean_eps: 0.407832\n",
            " 659410/1000000: episode: 938, duration: 36.944s, episode steps: 1004, steps per second:  27, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.736 [0.000, 5.000],  loss: 0.020799, mae: 2.142194, mean_q: 2.597495, mean_eps: 0.406983\n",
            " 660068/1000000: episode: 939, duration: 24.015s, episode steps: 658, steps per second:  27, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.681 [0.000, 5.000],  loss: 0.017871, mae: 2.155441, mean_q: 2.615732, mean_eps: 0.406236\n",
            " 660672/1000000: episode: 940, duration: 22.322s, episode steps: 604, steps per second:  27, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.017698, mae: 2.200457, mean_q: 2.667997, mean_eps: 0.405669\n",
            " 661423/1000000: episode: 941, duration: 27.564s, episode steps: 751, steps per second:  27, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.044 [0.000, 5.000],  loss: 0.018356, mae: 2.193001, mean_q: 2.656474, mean_eps: 0.405059\n",
            " 662229/1000000: episode: 942, duration: 29.539s, episode steps: 806, steps per second:  27, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.019207, mae: 2.176992, mean_q: 2.637523, mean_eps: 0.404357\n",
            " 663054/1000000: episode: 943, duration: 30.091s, episode steps: 825, steps per second:  27, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.021877, mae: 2.204849, mean_q: 2.672327, mean_eps: 0.403622\n",
            " 663939/1000000: episode: 944, duration: 32.243s, episode steps: 885, steps per second:  27, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.022908, mae: 2.196540, mean_q: 2.662055, mean_eps: 0.402854\n",
            " 665027/1000000: episode: 945, duration: 39.859s, episode steps: 1088, steps per second:  27, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.142 [0.000, 5.000],  loss: 0.018407, mae: 2.169471, mean_q: 2.629538, mean_eps: 0.401966\n",
            " 666002/1000000: episode: 946, duration: 35.716s, episode steps: 975, steps per second:  27, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.018228, mae: 2.187238, mean_q: 2.650650, mean_eps: 0.401037\n",
            " 666903/1000000: episode: 947, duration: 32.889s, episode steps: 901, steps per second:  27, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: 0.019166, mae: 2.170630, mean_q: 2.628975, mean_eps: 0.400193\n",
            " 667682/1000000: episode: 948, duration: 28.953s, episode steps: 779, steps per second:  27, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.017748, mae: 2.176707, mean_q: 2.633568, mean_eps: 0.399437\n",
            " 668230/1000000: episode: 949, duration: 20.154s, episode steps: 548, steps per second:  27, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.021943, mae: 2.194390, mean_q: 2.657291, mean_eps: 0.398840\n",
            " 669265/1000000: episode: 950, duration: 38.130s, episode steps: 1035, steps per second:  27, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.019819, mae: 2.187470, mean_q: 2.650595, mean_eps: 0.398127\n",
            " 669837/1000000: episode: 951, duration: 21.142s, episode steps: 572, steps per second:  27, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.016941, mae: 2.190748, mean_q: 2.659917, mean_eps: 0.397403\n",
            " 670599/1000000: episode: 952, duration: 28.040s, episode steps: 762, steps per second:  27, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.849 [0.000, 5.000],  loss: 0.019140, mae: 2.193079, mean_q: 2.657175, mean_eps: 0.396804\n",
            " 671477/1000000: episode: 953, duration: 32.508s, episode steps: 878, steps per second:  27, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.018621, mae: 2.221464, mean_q: 2.688532, mean_eps: 0.396066\n",
            " 672546/1000000: episode: 954, duration: 39.640s, episode steps: 1069, steps per second:  27, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.703 [0.000, 5.000],  loss: 0.019698, mae: 2.209352, mean_q: 2.676204, mean_eps: 0.395189\n",
            " 673301/1000000: episode: 955, duration: 27.995s, episode steps: 755, steps per second:  27, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: 0.018054, mae: 2.201994, mean_q: 2.666686, mean_eps: 0.394368\n",
            " 674054/1000000: episode: 956, duration: 28.012s, episode steps: 753, steps per second:  27, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.021633, mae: 2.208817, mean_q: 2.675866, mean_eps: 0.393690\n",
            " 675184/1000000: episode: 957, duration: 41.894s, episode steps: 1130, steps per second:  27, episode reward: 29.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.018542, mae: 2.215889, mean_q: 2.684232, mean_eps: 0.392844\n",
            " 676168/1000000: episode: 958, duration: 36.960s, episode steps: 984, steps per second:  27, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.019781, mae: 2.210477, mean_q: 2.677250, mean_eps: 0.391893\n",
            " 676659/1000000: episode: 959, duration: 18.293s, episode steps: 491, steps per second:  27, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.020728, mae: 2.218480, mean_q: 2.687495, mean_eps: 0.391229\n",
            " 677365/1000000: episode: 960, duration: 26.418s, episode steps: 706, steps per second:  27, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.299 [0.000, 5.000],  loss: 0.020258, mae: 2.217589, mean_q: 2.686774, mean_eps: 0.390689\n",
            " 678669/1000000: episode: 961, duration: 48.179s, episode steps: 1304, steps per second:  27, episode reward: 32.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.169 [0.000, 5.000],  loss: 0.019408, mae: 2.212512, mean_q: 2.678495, mean_eps: 0.389784\n",
            " 679405/1000000: episode: 962, duration: 27.354s, episode steps: 736, steps per second:  27, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.026179, mae: 2.221474, mean_q: 2.694614, mean_eps: 0.388866\n",
            " 679980/1000000: episode: 963, duration: 21.333s, episode steps: 575, steps per second:  27, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.019700, mae: 2.216796, mean_q: 2.684114, mean_eps: 0.388277\n",
            " 680828/1000000: episode: 964, duration: 31.754s, episode steps: 848, steps per second:  27, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.020938, mae: 2.210472, mean_q: 2.678406, mean_eps: 0.387638\n",
            " 681827/1000000: episode: 965, duration: 37.189s, episode steps: 999, steps per second:  27, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.019238, mae: 2.206926, mean_q: 2.675314, mean_eps: 0.386807\n",
            " 682822/1000000: episode: 966, duration: 37.040s, episode steps: 995, steps per second:  27, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.856 [0.000, 5.000],  loss: 0.019587, mae: 2.222609, mean_q: 2.694551, mean_eps: 0.385908\n",
            " 683703/1000000: episode: 967, duration: 32.653s, episode steps: 881, steps per second:  27, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.177 [0.000, 5.000],  loss: 0.016618, mae: 2.222138, mean_q: 2.691324, mean_eps: 0.385064\n",
            " 684725/1000000: episode: 968, duration: 37.942s, episode steps: 1022, steps per second:  27, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.183 [0.000, 5.000],  loss: 0.018936, mae: 2.229588, mean_q: 2.698848, mean_eps: 0.384207\n",
            " 685366/1000000: episode: 969, duration: 23.730s, episode steps: 641, steps per second:  27, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.019948, mae: 2.225550, mean_q: 2.698195, mean_eps: 0.383459\n",
            " 685865/1000000: episode: 970, duration: 18.459s, episode steps: 499, steps per second:  27, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.017224, mae: 2.194002, mean_q: 2.657709, mean_eps: 0.382946\n",
            " 686481/1000000: episode: 971, duration: 22.959s, episode steps: 616, steps per second:  27, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.018033, mae: 2.211950, mean_q: 2.676783, mean_eps: 0.382443\n",
            " 687399/1000000: episode: 972, duration: 34.047s, episode steps: 918, steps per second:  27, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.020638, mae: 2.241387, mean_q: 2.714029, mean_eps: 0.381754\n",
            " 688335/1000000: episode: 973, duration: 34.693s, episode steps: 936, steps per second:  27, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.746 [0.000, 5.000],  loss: 0.019167, mae: 2.218037, mean_q: 2.684920, mean_eps: 0.380921\n",
            " 689333/1000000: episode: 974, duration: 37.181s, episode steps: 998, steps per second:  27, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.021947, mae: 2.235994, mean_q: 2.709078, mean_eps: 0.380049\n",
            " 690106/1000000: episode: 975, duration: 28.464s, episode steps: 773, steps per second:  27, episode reward: 19.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.019802, mae: 2.235543, mean_q: 2.705534, mean_eps: 0.379252\n",
            " 690990/1000000: episode: 976, duration: 32.602s, episode steps: 884, steps per second:  27, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: 0.017978, mae: 2.266915, mean_q: 2.745520, mean_eps: 0.378507\n",
            " 691901/1000000: episode: 977, duration: 33.765s, episode steps: 911, steps per second:  27, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.017870, mae: 2.241294, mean_q: 2.714123, mean_eps: 0.377699\n",
            " 692471/1000000: episode: 978, duration: 21.184s, episode steps: 570, steps per second:  27, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.018955, mae: 2.258147, mean_q: 2.735695, mean_eps: 0.377033\n",
            " 693158/1000000: episode: 979, duration: 25.521s, episode steps: 687, steps per second:  27, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.118 [0.000, 5.000],  loss: 0.019578, mae: 2.243063, mean_q: 2.716922, mean_eps: 0.376467\n",
            " 694087/1000000: episode: 980, duration: 34.441s, episode steps: 929, steps per second:  27, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.019294, mae: 2.255410, mean_q: 2.730778, mean_eps: 0.375740\n",
            " 694698/1000000: episode: 981, duration: 22.824s, episode steps: 611, steps per second:  27, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.867 [0.000, 5.000],  loss: 0.019253, mae: 2.259277, mean_q: 2.735617, mean_eps: 0.375047\n",
            " 695496/1000000: episode: 982, duration: 29.759s, episode steps: 798, steps per second:  27, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.019723, mae: 2.264109, mean_q: 2.743102, mean_eps: 0.374414\n",
            " 696290/1000000: episode: 983, duration: 29.764s, episode steps: 794, steps per second:  27, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.017781, mae: 2.264427, mean_q: 2.743195, mean_eps: 0.373697\n",
            " 697265/1000000: episode: 984, duration: 36.337s, episode steps: 975, steps per second:  27, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.022795, mae: 2.249891, mean_q: 2.725131, mean_eps: 0.372900\n",
            " 698044/1000000: episode: 985, duration: 29.197s, episode steps: 779, steps per second:  27, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.877 [0.000, 5.000],  loss: 0.019560, mae: 2.262391, mean_q: 2.740828, mean_eps: 0.372111\n",
            " 698628/1000000: episode: 986, duration: 21.954s, episode steps: 584, steps per second:  27, episode reward: 16.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.019445, mae: 2.256917, mean_q: 2.736503, mean_eps: 0.371499\n",
            " 699033/1000000: episode: 987, duration: 15.240s, episode steps: 405, steps per second:  27, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.018045, mae: 2.253852, mean_q: 2.730181, mean_eps: 0.371053\n",
            " 699894/1000000: episode: 988, duration: 32.135s, episode steps: 861, steps per second:  27, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.702 [0.000, 5.000],  loss: 0.020296, mae: 2.252913, mean_q: 2.729847, mean_eps: 0.370482\n",
            " 700845/1000000: episode: 989, duration: 35.570s, episode steps: 951, steps per second:  27, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.018102, mae: 2.265809, mean_q: 2.746191, mean_eps: 0.369667\n",
            " 701354/1000000: episode: 990, duration: 18.865s, episode steps: 509, steps per second:  27, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.017933, mae: 2.288368, mean_q: 2.770439, mean_eps: 0.369010\n",
            " 701979/1000000: episode: 991, duration: 23.062s, episode steps: 625, steps per second:  27, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.020432, mae: 2.274892, mean_q: 2.756632, mean_eps: 0.368501\n",
            " 702836/1000000: episode: 992, duration: 31.762s, episode steps: 857, steps per second:  27, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.908 [0.000, 5.000],  loss: 0.020886, mae: 2.287589, mean_q: 2.770042, mean_eps: 0.367835\n",
            " 703614/1000000: episode: 993, duration: 28.818s, episode steps: 778, steps per second:  27, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.020521, mae: 2.294383, mean_q: 2.778464, mean_eps: 0.367098\n",
            " 704250/1000000: episode: 994, duration: 23.562s, episode steps: 636, steps per second:  27, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.841 [0.000, 5.000],  loss: 0.020097, mae: 2.286660, mean_q: 2.771736, mean_eps: 0.366461\n",
            " 705027/1000000: episode: 995, duration: 28.710s, episode steps: 777, steps per second:  27, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.019809, mae: 2.299185, mean_q: 2.783548, mean_eps: 0.365826\n",
            " 705677/1000000: episode: 996, duration: 24.168s, episode steps: 650, steps per second:  27, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.020557, mae: 2.296830, mean_q: 2.781266, mean_eps: 0.365183\n",
            " 706204/1000000: episode: 997, duration: 19.532s, episode steps: 527, steps per second:  27, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.019643, mae: 2.284084, mean_q: 2.767345, mean_eps: 0.364654\n",
            " 706770/1000000: episode: 998, duration: 21.058s, episode steps: 566, steps per second:  27, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.017805, mae: 2.287766, mean_q: 2.768132, mean_eps: 0.364163\n",
            " 707363/1000000: episode: 999, duration: 21.915s, episode steps: 593, steps per second:  27, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.002 [0.000, 5.000],  loss: 0.021747, mae: 2.300784, mean_q: 2.783691, mean_eps: 0.363641\n",
            " 708507/1000000: episode: 1000, duration: 42.173s, episode steps: 1144, steps per second:  27, episode reward: 29.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.020568, mae: 2.286882, mean_q: 2.773517, mean_eps: 0.362859\n",
            " 709316/1000000: episode: 1001, duration: 30.282s, episode steps: 809, steps per second:  27, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.682 [0.000, 5.000],  loss: 0.019832, mae: 2.296919, mean_q: 2.783748, mean_eps: 0.361981\n",
            " 710334/1000000: episode: 1002, duration: 37.618s, episode steps: 1018, steps per second:  27, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.021529, mae: 2.304311, mean_q: 2.789764, mean_eps: 0.361158\n",
            " 710872/1000000: episode: 1003, duration: 19.871s, episode steps: 538, steps per second:  27, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.018744, mae: 2.289206, mean_q: 2.773410, mean_eps: 0.360458\n",
            " 711538/1000000: episode: 1004, duration: 24.671s, episode steps: 666, steps per second:  27, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.018193, mae: 2.313640, mean_q: 2.804805, mean_eps: 0.359916\n",
            " 712215/1000000: episode: 1005, duration: 25.019s, episode steps: 677, steps per second:  27, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.017976, mae: 2.316291, mean_q: 2.807893, mean_eps: 0.359312\n",
            " 712880/1000000: episode: 1006, duration: 25.016s, episode steps: 665, steps per second:  27, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.131 [0.000, 5.000],  loss: 0.018616, mae: 2.314814, mean_q: 2.805455, mean_eps: 0.358709\n",
            " 713412/1000000: episode: 1007, duration: 19.927s, episode steps: 532, steps per second:  27, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.016865, mae: 2.291360, mean_q: 2.775751, mean_eps: 0.358170\n",
            " 714043/1000000: episode: 1008, duration: 23.369s, episode steps: 631, steps per second:  27, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.020144, mae: 2.300987, mean_q: 2.785111, mean_eps: 0.357647\n",
            " 714553/1000000: episode: 1009, duration: 19.050s, episode steps: 510, steps per second:  27, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.017043, mae: 2.338929, mean_q: 2.831463, mean_eps: 0.357132\n",
            " 715189/1000000: episode: 1010, duration: 23.606s, episode steps: 636, steps per second:  27, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.025131, mae: 2.320750, mean_q: 2.810715, mean_eps: 0.356615\n",
            " 716088/1000000: episode: 1011, duration: 33.518s, episode steps: 899, steps per second:  27, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.020663, mae: 2.331866, mean_q: 2.822906, mean_eps: 0.355926\n",
            " 716941/1000000: episode: 1012, duration: 31.813s, episode steps: 853, steps per second:  27, episode reward: 27.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.019687, mae: 2.317883, mean_q: 2.811169, mean_eps: 0.355137\n",
            " 718129/1000000: episode: 1013, duration: 44.342s, episode steps: 1188, steps per second:  27, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.051 [0.000, 5.000],  loss: 0.020440, mae: 2.305448, mean_q: 2.792303, mean_eps: 0.354218\n",
            " 718977/1000000: episode: 1014, duration: 31.457s, episode steps: 848, steps per second:  27, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.020470, mae: 2.305501, mean_q: 2.793730, mean_eps: 0.353301\n",
            " 719620/1000000: episode: 1015, duration: 23.955s, episode steps: 643, steps per second:  27, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.020765, mae: 2.327916, mean_q: 2.818695, mean_eps: 0.352632\n",
            " 720045/1000000: episode: 1016, duration: 15.846s, episode steps: 425, steps per second:  27, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.020282, mae: 2.345266, mean_q: 2.842602, mean_eps: 0.352151\n",
            " 721057/1000000: episode: 1017, duration: 37.763s, episode steps: 1012, steps per second:  27, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.017426, mae: 2.362839, mean_q: 2.862707, mean_eps: 0.351503\n",
            " 722000/1000000: episode: 1018, duration: 35.422s, episode steps: 943, steps per second:  27, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.021626, mae: 2.361716, mean_q: 2.859882, mean_eps: 0.350625\n",
            " 722495/1000000: episode: 1019, duration: 18.629s, episode steps: 495, steps per second:  27, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.018994, mae: 2.350605, mean_q: 2.847750, mean_eps: 0.349979\n",
            " 723034/1000000: episode: 1020, duration: 20.310s, episode steps: 539, steps per second:  27, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: 0.019130, mae: 2.352751, mean_q: 2.851070, mean_eps: 0.349512\n",
            " 723774/1000000: episode: 1021, duration: 27.639s, episode steps: 740, steps per second:  27, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.020485, mae: 2.352685, mean_q: 2.850682, mean_eps: 0.348936\n",
            " 724547/1000000: episode: 1022, duration: 28.876s, episode steps: 773, steps per second:  27, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.019377, mae: 2.330782, mean_q: 2.824653, mean_eps: 0.348256\n",
            " 725194/1000000: episode: 1023, duration: 24.208s, episode steps: 647, steps per second:  27, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: 0.018897, mae: 2.345037, mean_q: 2.838907, mean_eps: 0.347617\n",
            " 726403/1000000: episode: 1024, duration: 45.542s, episode steps: 1209, steps per second:  27, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.019929, mae: 2.362298, mean_q: 2.861115, mean_eps: 0.346782\n",
            " 727115/1000000: episode: 1025, duration: 26.577s, episode steps: 712, steps per second:  27, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.073 [0.000, 5.000],  loss: 0.019591, mae: 2.323161, mean_q: 2.812180, mean_eps: 0.345918\n",
            " 728067/1000000: episode: 1026, duration: 35.624s, episode steps: 952, steps per second:  27, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.021085, mae: 2.337162, mean_q: 2.830199, mean_eps: 0.345169\n",
            " 728876/1000000: episode: 1027, duration: 30.380s, episode steps: 809, steps per second:  27, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.241 [0.000, 5.000],  loss: 0.018497, mae: 2.362419, mean_q: 2.860727, mean_eps: 0.344377\n",
            " 729602/1000000: episode: 1028, duration: 27.403s, episode steps: 726, steps per second:  26, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.019668, mae: 2.359594, mean_q: 2.861185, mean_eps: 0.343686\n",
            " 730697/1000000: episode: 1029, duration: 41.197s, episode steps: 1095, steps per second:  27, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.023373, mae: 2.404456, mean_q: 2.910689, mean_eps: 0.342865\n",
            " 731346/1000000: episode: 1030, duration: 24.361s, episode steps: 649, steps per second:  27, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.020153, mae: 2.413276, mean_q: 2.921396, mean_eps: 0.342080\n",
            " 732370/1000000: episode: 1031, duration: 38.411s, episode steps: 1024, steps per second:  27, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.019266, mae: 2.419154, mean_q: 2.929455, mean_eps: 0.341328\n",
            " 732941/1000000: episode: 1032, duration: 21.508s, episode steps: 571, steps per second:  27, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.021405, mae: 2.421401, mean_q: 2.928362, mean_eps: 0.340610\n",
            " 733855/1000000: episode: 1033, duration: 34.312s, episode steps: 914, steps per second:  27, episode reward: 26.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.020918, mae: 2.445948, mean_q: 2.960527, mean_eps: 0.339942\n",
            " 734733/1000000: episode: 1034, duration: 33.251s, episode steps: 878, steps per second:  26, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.021154, mae: 2.442572, mean_q: 2.956068, mean_eps: 0.339135\n",
            " 735654/1000000: episode: 1035, duration: 34.637s, episode steps: 921, steps per second:  27, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.029 [0.000, 5.000],  loss: 0.020351, mae: 2.427923, mean_q: 2.938826, mean_eps: 0.338325\n",
            " 736459/1000000: episode: 1036, duration: 30.146s, episode steps: 805, steps per second:  27, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.021307, mae: 2.395615, mean_q: 2.900898, mean_eps: 0.337550\n",
            " 737421/1000000: episode: 1037, duration: 36.240s, episode steps: 962, steps per second:  27, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.021392, mae: 2.446454, mean_q: 2.961986, mean_eps: 0.336754\n",
            " 738010/1000000: episode: 1038, duration: 22.206s, episode steps: 589, steps per second:  27, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.098 [0.000, 5.000],  loss: 0.020251, mae: 2.406206, mean_q: 2.910306, mean_eps: 0.336056\n",
            " 739320/1000000: episode: 1039, duration: 49.426s, episode steps: 1310, steps per second:  27, episode reward: 26.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.024972, mae: 2.436138, mean_q: 2.949544, mean_eps: 0.335202\n",
            " 740149/1000000: episode: 1040, duration: 31.319s, episode steps: 829, steps per second:  26, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.022010, mae: 2.453382, mean_q: 2.970049, mean_eps: 0.334239\n",
            " 740804/1000000: episode: 1041, duration: 24.727s, episode steps: 655, steps per second:  26, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.185 [0.000, 5.000],  loss: 0.019956, mae: 2.470493, mean_q: 2.993840, mean_eps: 0.333572\n",
            " 741663/1000000: episode: 1042, duration: 32.274s, episode steps: 859, steps per second:  27, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.022189, mae: 2.470006, mean_q: 2.991003, mean_eps: 0.332891\n",
            " 742735/1000000: episode: 1043, duration: 40.680s, episode steps: 1072, steps per second:  26, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.255 [0.000, 5.000],  loss: 0.021714, mae: 2.463126, mean_q: 2.983393, mean_eps: 0.332022\n",
            " 743520/1000000: episode: 1044, duration: 29.640s, episode steps: 785, steps per second:  26, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.020358, mae: 2.446182, mean_q: 2.961201, mean_eps: 0.331187\n",
            " 744574/1000000: episode: 1045, duration: 39.613s, episode steps: 1054, steps per second:  27, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.023413, mae: 2.470391, mean_q: 2.988598, mean_eps: 0.330359\n",
            " 745355/1000000: episode: 1046, duration: 29.491s, episode steps: 781, steps per second:  26, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.155 [0.000, 5.000],  loss: 0.018738, mae: 2.455732, mean_q: 2.973152, mean_eps: 0.329532\n",
            " 746370/1000000: episode: 1047, duration: 38.206s, episode steps: 1015, steps per second:  27, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.021003, mae: 2.476738, mean_q: 2.998840, mean_eps: 0.328724\n",
            " 747489/1000000: episode: 1048, duration: 42.266s, episode steps: 1119, steps per second:  26, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.020669, mae: 2.472745, mean_q: 2.993148, mean_eps: 0.327763\n",
            " 748288/1000000: episode: 1049, duration: 30.201s, episode steps: 799, steps per second:  26, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.760 [0.000, 5.000],  loss: 0.020150, mae: 2.487936, mean_q: 3.012946, mean_eps: 0.326901\n",
            " 749278/1000000: episode: 1050, duration: 37.384s, episode steps: 990, steps per second:  26, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.022493, mae: 2.464681, mean_q: 2.984004, mean_eps: 0.326096\n",
            " 750158/1000000: episode: 1051, duration: 33.235s, episode steps: 880, steps per second:  26, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.020807, mae: 2.463275, mean_q: 2.981020, mean_eps: 0.325254\n",
            " 751166/1000000: episode: 1052, duration: 38.305s, episode steps: 1008, steps per second:  26, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.020531, mae: 2.481085, mean_q: 3.004102, mean_eps: 0.324404\n",
            " 752209/1000000: episode: 1053, duration: 39.415s, episode steps: 1043, steps per second:  26, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.823 [0.000, 5.000],  loss: 0.021311, mae: 2.485391, mean_q: 3.009668, mean_eps: 0.323481\n",
            " 752959/1000000: episode: 1054, duration: 28.315s, episode steps: 750, steps per second:  26, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.024249, mae: 2.500972, mean_q: 3.027660, mean_eps: 0.322674\n",
            " 753384/1000000: episode: 1055, duration: 16.311s, episode steps: 425, steps per second:  26, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.023283, mae: 2.512629, mean_q: 3.043863, mean_eps: 0.322147\n",
            " 754014/1000000: episode: 1056, duration: 24.041s, episode steps: 630, steps per second:  26, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.910 [0.000, 5.000],  loss: 0.022557, mae: 2.502003, mean_q: 3.032505, mean_eps: 0.321672\n",
            " 754912/1000000: episode: 1057, duration: 34.064s, episode steps: 898, steps per second:  26, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.020973, mae: 2.470607, mean_q: 2.994328, mean_eps: 0.320984\n",
            " 756137/1000000: episode: 1058, duration: 46.828s, episode steps: 1225, steps per second:  26, episode reward: 29.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.021750, mae: 2.486637, mean_q: 3.007772, mean_eps: 0.320028\n",
            " 756905/1000000: episode: 1059, duration: 29.356s, episode steps: 768, steps per second:  26, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.022213, mae: 2.486333, mean_q: 3.010686, mean_eps: 0.319130\n",
            " 758156/1000000: episode: 1060, duration: 47.961s, episode steps: 1251, steps per second:  26, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.929 [0.000, 5.000],  loss: 0.019956, mae: 2.480144, mean_q: 3.002342, mean_eps: 0.318223\n",
            " 759298/1000000: episode: 1061, duration: 43.954s, episode steps: 1142, steps per second:  26, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.023163, mae: 2.504955, mean_q: 3.036957, mean_eps: 0.317147\n",
            " 759877/1000000: episode: 1062, duration: 22.154s, episode steps: 579, steps per second:  26, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.021690, mae: 2.486497, mean_q: 3.010748, mean_eps: 0.316371\n",
            " 760760/1000000: episode: 1063, duration: 33.676s, episode steps: 883, steps per second:  26, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.955 [0.000, 5.000],  loss: 0.021831, mae: 2.535663, mean_q: 3.073245, mean_eps: 0.315714\n",
            " 761244/1000000: episode: 1064, duration: 18.589s, episode steps: 484, steps per second:  26, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.022366, mae: 2.582478, mean_q: 3.128559, mean_eps: 0.315100\n",
            " 762041/1000000: episode: 1065, duration: 30.637s, episode steps: 797, steps per second:  26, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.139 [0.000, 5.000],  loss: 0.020214, mae: 2.550936, mean_q: 3.091618, mean_eps: 0.314522\n",
            " 762776/1000000: episode: 1066, duration: 28.294s, episode steps: 735, steps per second:  26, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.022705, mae: 2.560783, mean_q: 3.104038, mean_eps: 0.313833\n",
            " 763560/1000000: episode: 1067, duration: 30.155s, episode steps: 784, steps per second:  26, episode reward: 20.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.198 [0.000, 5.000],  loss: 0.023286, mae: 2.545061, mean_q: 3.082434, mean_eps: 0.313151\n",
            " 764571/1000000: episode: 1068, duration: 39.089s, episode steps: 1011, steps per second:  26, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.022299, mae: 2.560130, mean_q: 3.100786, mean_eps: 0.312342\n",
            " 765242/1000000: episode: 1069, duration: 25.709s, episode steps: 671, steps per second:  26, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.000 [0.000, 5.000],  loss: 0.021026, mae: 2.567841, mean_q: 3.111692, mean_eps: 0.311585\n",
            " 766060/1000000: episode: 1070, duration: 31.354s, episode steps: 818, steps per second:  26, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.024288, mae: 2.538820, mean_q: 3.074652, mean_eps: 0.310915\n",
            " 766767/1000000: episode: 1071, duration: 27.413s, episode steps: 707, steps per second:  26, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.024871, mae: 2.541161, mean_q: 3.077111, mean_eps: 0.310229\n",
            " 767682/1000000: episode: 1072, duration: 34.935s, episode steps: 915, steps per second:  26, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.023553, mae: 2.543086, mean_q: 3.079812, mean_eps: 0.309498\n",
            " 768249/1000000: episode: 1073, duration: 21.681s, episode steps: 567, steps per second:  26, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.762 [0.000, 5.000],  loss: 0.022221, mae: 2.558724, mean_q: 3.100231, mean_eps: 0.308831\n",
            " 768782/1000000: episode: 1074, duration: 20.527s, episode steps: 533, steps per second:  26, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.060 [0.000, 5.000],  loss: 0.022356, mae: 2.533383, mean_q: 3.066397, mean_eps: 0.308336\n",
            " 769446/1000000: episode: 1075, duration: 25.455s, episode steps: 664, steps per second:  26, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.669 [0.000, 5.000],  loss: 0.023313, mae: 2.534578, mean_q: 3.065976, mean_eps: 0.307797\n",
            " 770696/1000000: episode: 1076, duration: 48.027s, episode steps: 1250, steps per second:  26, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.245 [0.000, 5.000],  loss: 0.022484, mae: 2.612320, mean_q: 3.166192, mean_eps: 0.306937\n",
            " 771684/1000000: episode: 1077, duration: 38.186s, episode steps: 988, steps per second:  26, episode reward: 26.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.023448, mae: 2.639981, mean_q: 3.199772, mean_eps: 0.305931\n",
            " 772708/1000000: episode: 1078, duration: 39.704s, episode steps: 1024, steps per second:  26, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.991 [0.000, 5.000],  loss: 0.024314, mae: 2.646246, mean_q: 3.204889, mean_eps: 0.305025\n",
            " 773707/1000000: episode: 1079, duration: 38.522s, episode steps: 999, steps per second:  26, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.024083, mae: 2.633512, mean_q: 3.189253, mean_eps: 0.304115\n",
            " 774367/1000000: episode: 1080, duration: 25.355s, episode steps: 660, steps per second:  26, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.025171, mae: 2.643488, mean_q: 3.198713, mean_eps: 0.303368\n",
            " 774905/1000000: episode: 1081, duration: 20.917s, episode steps: 538, steps per second:  26, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.022428, mae: 2.620293, mean_q: 3.174015, mean_eps: 0.302828\n",
            " 775800/1000000: episode: 1082, duration: 34.484s, episode steps: 895, steps per second:  26, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.022628, mae: 2.630286, mean_q: 3.185401, mean_eps: 0.302183\n",
            " 776474/1000000: episode: 1083, duration: 26.238s, episode steps: 674, steps per second:  26, episode reward: 18.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.024125, mae: 2.624249, mean_q: 3.176170, mean_eps: 0.301478\n",
            " 777275/1000000: episode: 1084, duration: 30.890s, episode steps: 801, steps per second:  26, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.022386, mae: 2.661619, mean_q: 3.225406, mean_eps: 0.300813\n",
            " 777642/1000000: episode: 1085, duration: 14.044s, episode steps: 367, steps per second:  26, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.024532, mae: 2.651471, mean_q: 3.210324, mean_eps: 0.300288\n",
            " 778100/1000000: episode: 1086, duration: 17.675s, episode steps: 458, steps per second:  26, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.793 [0.000, 5.000],  loss: 0.025898, mae: 2.615735, mean_q: 3.166831, mean_eps: 0.299917\n",
            " 778769/1000000: episode: 1087, duration: 25.693s, episode steps: 669, steps per second:  26, episode reward: 18.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.021837, mae: 2.637582, mean_q: 3.192195, mean_eps: 0.299409\n",
            " 779814/1000000: episode: 1088, duration: 40.042s, episode steps: 1045, steps per second:  26, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.021496, mae: 2.608234, mean_q: 3.157577, mean_eps: 0.298637\n",
            " 780335/1000000: episode: 1089, duration: 20.095s, episode steps: 521, steps per second:  26, episode reward: 14.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 3.100 [0.000, 5.000],  loss: 0.021652, mae: 2.647071, mean_q: 3.205580, mean_eps: 0.297933\n",
            " 781131/1000000: episode: 1090, duration: 30.729s, episode steps: 796, steps per second:  26, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.021005, mae: 2.666668, mean_q: 3.232540, mean_eps: 0.297341\n",
            " 782139/1000000: episode: 1091, duration: 38.649s, episode steps: 1008, steps per second:  26, episode reward: 28.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.022539, mae: 2.661422, mean_q: 3.225346, mean_eps: 0.296529\n",
            " 782791/1000000: episode: 1092, duration: 24.992s, episode steps: 652, steps per second:  26, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.024231, mae: 2.644720, mean_q: 3.203053, mean_eps: 0.295782\n",
            " 783800/1000000: episode: 1093, duration: 39.026s, episode steps: 1009, steps per second:  26, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.829 [0.000, 5.000],  loss: 0.021273, mae: 2.660862, mean_q: 3.223623, mean_eps: 0.295035\n",
            " 784301/1000000: episode: 1094, duration: 19.363s, episode steps: 501, steps per second:  26, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.025274, mae: 2.659010, mean_q: 3.221365, mean_eps: 0.294355\n",
            " 784915/1000000: episode: 1095, duration: 23.451s, episode steps: 614, steps per second:  26, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.865 [0.000, 5.000],  loss: 0.023399, mae: 2.635740, mean_q: 3.193397, mean_eps: 0.293853\n",
            " 785621/1000000: episode: 1096, duration: 27.384s, episode steps: 706, steps per second:  26, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.022433, mae: 2.660921, mean_q: 3.221627, mean_eps: 0.293259\n",
            " 786498/1000000: episode: 1097, duration: 33.887s, episode steps: 877, steps per second:  26, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.026269, mae: 2.644623, mean_q: 3.201396, mean_eps: 0.292546\n",
            " 787210/1000000: episode: 1098, duration: 27.595s, episode steps: 712, steps per second:  26, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.867 [0.000, 5.000],  loss: 0.021096, mae: 2.650593, mean_q: 3.211480, mean_eps: 0.291831\n",
            " 787986/1000000: episode: 1099, duration: 30.086s, episode steps: 776, steps per second:  26, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.021373, mae: 2.639283, mean_q: 3.196685, mean_eps: 0.291162\n",
            " 789730/1000000: episode: 1100, duration: 67.628s, episode steps: 1744, steps per second:  26, episode reward: 37.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.091 [0.000, 5.000],  loss: 0.024678, mae: 2.670837, mean_q: 3.233885, mean_eps: 0.290028\n",
            " 790278/1000000: episode: 1101, duration: 21.283s, episode steps: 548, steps per second:  26, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.023324, mae: 2.688963, mean_q: 3.255304, mean_eps: 0.288996\n",
            " 790952/1000000: episode: 1102, duration: 26.432s, episode steps: 674, steps per second:  25, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.016 [0.000, 5.000],  loss: 0.021254, mae: 2.686139, mean_q: 3.254310, mean_eps: 0.288447\n",
            " 791689/1000000: episode: 1103, duration: 28.837s, episode steps: 737, steps per second:  26, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.190 [0.000, 5.000],  loss: 0.020387, mae: 2.684446, mean_q: 3.248755, mean_eps: 0.287812\n",
            " 792538/1000000: episode: 1104, duration: 33.025s, episode steps: 849, steps per second:  26, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.024 [0.000, 5.000],  loss: 0.022993, mae: 2.669125, mean_q: 3.230326, mean_eps: 0.287097\n",
            " 793401/1000000: episode: 1105, duration: 33.629s, episode steps: 863, steps per second:  26, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.022275, mae: 2.687178, mean_q: 3.252824, mean_eps: 0.286327\n",
            " 794574/1000000: episode: 1106, duration: 45.566s, episode steps: 1173, steps per second:  26, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.812 [0.000, 5.000],  loss: 0.021303, mae: 2.676034, mean_q: 3.236761, mean_eps: 0.285411\n",
            " 795692/1000000: episode: 1107, duration: 43.641s, episode steps: 1118, steps per second:  26, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.020583, mae: 2.685010, mean_q: 3.247186, mean_eps: 0.284381\n",
            " 796681/1000000: episode: 1108, duration: 38.587s, episode steps: 989, steps per second:  26, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: 0.021657, mae: 2.684898, mean_q: 3.248540, mean_eps: 0.283433\n",
            " 797723/1000000: episode: 1109, duration: 40.645s, episode steps: 1042, steps per second:  26, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.021568, mae: 2.668150, mean_q: 3.226582, mean_eps: 0.282518\n",
            " 798323/1000000: episode: 1110, duration: 24.950s, episode steps: 600, steps per second:  24, episode reward: 16.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.021714, mae: 2.692512, mean_q: 3.258062, mean_eps: 0.281780\n",
            " 798850/1000000: episode: 1111, duration: 21.118s, episode steps: 527, steps per second:  25, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.019354, mae: 2.671367, mean_q: 3.233167, mean_eps: 0.281273\n",
            " 799237/1000000: episode: 1112, duration: 15.132s, episode steps: 387, steps per second:  26, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.871 [0.000, 5.000],  loss: 0.021943, mae: 2.661549, mean_q: 3.221140, mean_eps: 0.280860\n",
            " 800094/1000000: episode: 1113, duration: 33.420s, episode steps: 857, steps per second:  26, episode reward: 24.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.021463, mae: 2.683298, mean_q: 3.243910, mean_eps: 0.280301\n",
            " 801058/1000000: episode: 1114, duration: 37.485s, episode steps: 964, steps per second:  26, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.023273, mae: 2.675217, mean_q: 3.234241, mean_eps: 0.279482\n",
            " 801565/1000000: episode: 1115, duration: 19.800s, episode steps: 507, steps per second:  26, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.970 [0.000, 5.000],  loss: 0.020306, mae: 2.673567, mean_q: 3.233249, mean_eps: 0.278819\n",
            " 802556/1000000: episode: 1116, duration: 38.712s, episode steps: 991, steps per second:  26, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.022977, mae: 2.703301, mean_q: 3.269726, mean_eps: 0.278146\n",
            " 803615/1000000: episode: 1117, duration: 41.452s, episode steps: 1059, steps per second:  26, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.773 [0.000, 5.000],  loss: 0.021881, mae: 2.674021, mean_q: 3.236371, mean_eps: 0.277224\n",
            " 804061/1000000: episode: 1118, duration: 17.595s, episode steps: 446, steps per second:  25, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.760 [0.000, 5.000],  loss: 0.022361, mae: 2.631582, mean_q: 3.178791, mean_eps: 0.276546\n",
            " 805224/1000000: episode: 1119, duration: 45.473s, episode steps: 1163, steps per second:  26, episode reward: 28.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.023006, mae: 2.686691, mean_q: 3.252108, mean_eps: 0.275822\n",
            " 805895/1000000: episode: 1120, duration: 26.400s, episode steps: 671, steps per second:  25, episode reward: 18.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.023034, mae: 2.665224, mean_q: 3.223821, mean_eps: 0.274998\n",
            " 806690/1000000: episode: 1121, duration: 31.264s, episode steps: 795, steps per second:  25, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.097 [0.000, 5.000],  loss: 0.019395, mae: 2.677202, mean_q: 3.238622, mean_eps: 0.274337\n",
            " 807578/1000000: episode: 1122, duration: 34.789s, episode steps: 888, steps per second:  26, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.019623, mae: 2.672451, mean_q: 3.232045, mean_eps: 0.273579\n",
            " 808206/1000000: episode: 1123, duration: 24.691s, episode steps: 628, steps per second:  25, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.024558, mae: 2.699764, mean_q: 3.265382, mean_eps: 0.272897\n",
            " 809112/1000000: episode: 1124, duration: 35.721s, episode steps: 906, steps per second:  25, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.024404, mae: 2.696668, mean_q: 3.259681, mean_eps: 0.272208\n",
            " 810207/1000000: episode: 1125, duration: 43.103s, episode steps: 1095, steps per second:  25, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.193 [0.000, 5.000],  loss: 0.021946, mae: 2.677543, mean_q: 3.238002, mean_eps: 0.271308\n",
            " 810848/1000000: episode: 1126, duration: 25.350s, episode steps: 641, steps per second:  25, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.869 [0.000, 5.000],  loss: 0.017235, mae: 2.677383, mean_q: 3.241659, mean_eps: 0.270527\n",
            " 811679/1000000: episode: 1127, duration: 32.737s, episode steps: 831, steps per second:  25, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.019119, mae: 2.669257, mean_q: 3.229492, mean_eps: 0.269864\n",
            " 812315/1000000: episode: 1128, duration: 25.037s, episode steps: 636, steps per second:  25, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.022347, mae: 2.669947, mean_q: 3.230516, mean_eps: 0.269204\n",
            " 813247/1000000: episode: 1129, duration: 36.696s, episode steps: 932, steps per second:  25, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.022053, mae: 2.670210, mean_q: 3.231356, mean_eps: 0.268498\n",
            " 814341/1000000: episode: 1130, duration: 43.043s, episode steps: 1094, steps per second:  25, episode reward: 30.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.020700, mae: 2.686287, mean_q: 3.255209, mean_eps: 0.267585\n",
            " 814880/1000000: episode: 1131, duration: 21.349s, episode steps: 539, steps per second:  25, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.878 [0.000, 5.000],  loss: 0.024052, mae: 2.662315, mean_q: 3.225834, mean_eps: 0.266851\n",
            " 815632/1000000: episode: 1132, duration: 29.944s, episode steps: 752, steps per second:  25, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.020026, mae: 2.679027, mean_q: 3.240815, mean_eps: 0.266271\n",
            " 816187/1000000: episode: 1133, duration: 21.747s, episode steps: 555, steps per second:  26, episode reward: 14.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.022876, mae: 2.711461, mean_q: 3.282407, mean_eps: 0.265683\n",
            " 816553/1000000: episode: 1134, duration: 14.552s, episode steps: 366, steps per second:  25, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.019741, mae: 2.721796, mean_q: 3.296575, mean_eps: 0.265267\n",
            " 817183/1000000: episode: 1135, duration: 24.674s, episode steps: 630, steps per second:  26, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.020783, mae: 2.703837, mean_q: 3.269931, mean_eps: 0.264819\n",
            " 817789/1000000: episode: 1136, duration: 23.805s, episode steps: 606, steps per second:  25, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.718 [0.000, 5.000],  loss: 0.022530, mae: 2.667679, mean_q: 3.229394, mean_eps: 0.264263\n",
            " 818720/1000000: episode: 1137, duration: 36.626s, episode steps: 931, steps per second:  25, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: 0.020865, mae: 2.673419, mean_q: 3.233156, mean_eps: 0.263571\n",
            " 819600/1000000: episode: 1138, duration: 34.776s, episode steps: 880, steps per second:  25, episode reward: 25.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.022323, mae: 2.694635, mean_q: 3.261117, mean_eps: 0.262758\n",
            " 820120/1000000: episode: 1139, duration: 20.434s, episode steps: 520, steps per second:  25, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.158 [0.000, 5.000],  loss: 0.021423, mae: 2.676378, mean_q: 3.241779, mean_eps: 0.262128\n",
            " 820945/1000000: episode: 1140, duration: 32.591s, episode steps: 825, steps per second:  25, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.029 [0.000, 5.000],  loss: 0.020897, mae: 2.708313, mean_q: 3.277183, mean_eps: 0.261521\n",
            " 821917/1000000: episode: 1141, duration: 38.162s, episode steps: 972, steps per second:  25, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.070 [0.000, 5.000],  loss: 0.021205, mae: 2.704962, mean_q: 3.271132, mean_eps: 0.260711\n",
            " 822871/1000000: episode: 1142, duration: 37.535s, episode steps: 954, steps per second:  25, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.020766, mae: 2.688289, mean_q: 3.252537, mean_eps: 0.259845\n",
            " 823702/1000000: episode: 1143, duration: 33.003s, episode steps: 831, steps per second:  25, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.023409, mae: 2.711992, mean_q: 3.280125, mean_eps: 0.259043\n",
            " 824532/1000000: episode: 1144, duration: 33.048s, episode steps: 830, steps per second:  25, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.027331, mae: 2.698663, mean_q: 3.262604, mean_eps: 0.258296\n",
            " 825254/1000000: episode: 1145, duration: 28.571s, episode steps: 722, steps per second:  25, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.023571, mae: 2.707388, mean_q: 3.275382, mean_eps: 0.257597\n",
            " 825787/1000000: episode: 1146, duration: 20.930s, episode steps: 533, steps per second:  25, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.189 [0.000, 5.000],  loss: 0.020653, mae: 2.687908, mean_q: 3.248753, mean_eps: 0.257032\n",
            " 826460/1000000: episode: 1147, duration: 26.681s, episode steps: 673, steps per second:  25, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.021146, mae: 2.711616, mean_q: 3.277145, mean_eps: 0.256490\n",
            " 827350/1000000: episode: 1148, duration: 35.157s, episode steps: 890, steps per second:  25, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.222 [0.000, 5.000],  loss: 0.024025, mae: 2.710738, mean_q: 3.277889, mean_eps: 0.255786\n",
            " 827849/1000000: episode: 1149, duration: 19.557s, episode steps: 499, steps per second:  26, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.619 [0.000, 5.000],  loss: 0.019681, mae: 2.703310, mean_q: 3.267746, mean_eps: 0.255160\n",
            " 828888/1000000: episode: 1150, duration: 40.910s, episode steps: 1039, steps per second:  25, episode reward: 28.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.048 [0.000, 5.000],  loss: 0.022863, mae: 2.712655, mean_q: 3.279446, mean_eps: 0.254469\n",
            " 829809/1000000: episode: 1151, duration: 36.535s, episode steps: 921, steps per second:  25, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.019067, mae: 2.699088, mean_q: 3.263796, mean_eps: 0.253587\n",
            " 830492/1000000: episode: 1152, duration: 27.086s, episode steps: 683, steps per second:  25, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.022143, mae: 2.743744, mean_q: 3.321344, mean_eps: 0.252865\n",
            " 831469/1000000: episode: 1153, duration: 38.743s, episode steps: 977, steps per second:  25, episode reward: 26.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.776 [0.000, 5.000],  loss: 0.021325, mae: 2.755545, mean_q: 3.338667, mean_eps: 0.252118\n",
            " 832525/1000000: episode: 1154, duration: 42.112s, episode steps: 1056, steps per second:  25, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.050 [0.000, 5.000],  loss: 0.020123, mae: 2.751243, mean_q: 3.328052, mean_eps: 0.251202\n",
            " 833217/1000000: episode: 1155, duration: 27.585s, episode steps: 692, steps per second:  25, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.023385, mae: 2.718658, mean_q: 3.289841, mean_eps: 0.250415\n",
            " 833987/1000000: episode: 1156, duration: 30.665s, episode steps: 770, steps per second:  25, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.021576, mae: 2.779657, mean_q: 3.362381, mean_eps: 0.249758\n",
            " 834599/1000000: episode: 1157, duration: 24.352s, episode steps: 612, steps per second:  25, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.023509, mae: 2.791588, mean_q: 3.377488, mean_eps: 0.249137\n",
            " 835102/1000000: episode: 1158, duration: 20.022s, episode steps: 503, steps per second:  25, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.107 [0.000, 5.000],  loss: 0.021748, mae: 2.811524, mean_q: 3.403160, mean_eps: 0.248635\n",
            " 836292/1000000: episode: 1159, duration: 47.369s, episode steps: 1190, steps per second:  25, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.141 [0.000, 5.000],  loss: 0.022673, mae: 2.752277, mean_q: 3.329568, mean_eps: 0.247874\n",
            " 836819/1000000: episode: 1160, duration: 21.063s, episode steps: 527, steps per second:  25, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.165 [0.000, 5.000],  loss: 0.031679, mae: 2.778439, mean_q: 3.367915, mean_eps: 0.247101\n",
            " 837346/1000000: episode: 1161, duration: 21.095s, episode steps: 527, steps per second:  25, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.020001, mae: 2.749324, mean_q: 3.323522, mean_eps: 0.246626\n",
            " 838417/1000000: episode: 1162, duration: 42.921s, episode steps: 1071, steps per second:  25, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.020831, mae: 2.759195, mean_q: 3.337417, mean_eps: 0.245906\n",
            " 839146/1000000: episode: 1163, duration: 29.154s, episode steps: 729, steps per second:  25, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.682 [0.000, 5.000],  loss: 0.020277, mae: 2.748090, mean_q: 3.322901, mean_eps: 0.245096\n",
            " 839952/1000000: episode: 1164, duration: 31.935s, episode steps: 806, steps per second:  25, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.797 [0.000, 5.000],  loss: 0.021810, mae: 2.777474, mean_q: 3.358166, mean_eps: 0.244407\n",
            " 840906/1000000: episode: 1165, duration: 38.079s, episode steps: 954, steps per second:  25, episode reward: 26.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.024040, mae: 2.845497, mean_q: 3.441319, mean_eps: 0.243615\n",
            " 841760/1000000: episode: 1166, duration: 34.209s, episode steps: 854, steps per second:  25, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.224 [0.000, 5.000],  loss: 0.021699, mae: 2.861997, mean_q: 3.462589, mean_eps: 0.242801\n",
            " 842581/1000000: episode: 1167, duration: 32.909s, episode steps: 821, steps per second:  25, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.722 [0.000, 5.000],  loss: 0.022960, mae: 2.855528, mean_q: 3.452074, mean_eps: 0.242047\n",
            " 843596/1000000: episode: 1168, duration: 40.542s, episode steps: 1015, steps per second:  25, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.023370, mae: 2.859137, mean_q: 3.458704, mean_eps: 0.241221\n",
            " 844081/1000000: episode: 1169, duration: 19.495s, episode steps: 485, steps per second:  25, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.026470, mae: 2.831307, mean_q: 3.421758, mean_eps: 0.240546\n",
            " 844620/1000000: episode: 1170, duration: 21.567s, episode steps: 539, steps per second:  25, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.226 [0.000, 5.000],  loss: 0.025200, mae: 2.851105, mean_q: 3.452261, mean_eps: 0.240085\n",
            " 845499/1000000: episode: 1171, duration: 35.395s, episode steps: 879, steps per second:  25, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.023555, mae: 2.876106, mean_q: 3.479321, mean_eps: 0.239448\n",
            " 846207/1000000: episode: 1172, duration: 28.712s, episode steps: 708, steps per second:  25, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.864 [0.000, 5.000],  loss: 0.023421, mae: 2.844743, mean_q: 3.440677, mean_eps: 0.238733\n",
            " 846727/1000000: episode: 1173, duration: 21.015s, episode steps: 520, steps per second:  25, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.202 [0.000, 5.000],  loss: 0.026787, mae: 2.808881, mean_q: 3.403090, mean_eps: 0.238181\n",
            " 847374/1000000: episode: 1174, duration: 25.858s, episode steps: 647, steps per second:  25, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.026 [0.000, 5.000],  loss: 0.020434, mae: 2.853740, mean_q: 3.449021, mean_eps: 0.237655\n",
            " 847853/1000000: episode: 1175, duration: 19.336s, episode steps: 479, steps per second:  25, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.023389, mae: 2.834721, mean_q: 3.431862, mean_eps: 0.237147\n",
            " 848295/1000000: episode: 1176, duration: 17.612s, episode steps: 442, steps per second:  25, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.054 [0.000, 5.000],  loss: 0.027712, mae: 2.828813, mean_q: 3.419490, mean_eps: 0.236733\n",
            " 849293/1000000: episode: 1177, duration: 40.093s, episode steps: 998, steps per second:  25, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.023665, mae: 2.852272, mean_q: 3.449997, mean_eps: 0.236085\n",
            " 849830/1000000: episode: 1178, duration: 21.363s, episode steps: 537, steps per second:  25, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.143 [0.000, 5.000],  loss: 0.022085, mae: 2.837262, mean_q: 3.430096, mean_eps: 0.235394\n",
            " 850357/1000000: episode: 1179, duration: 21.210s, episode steps: 527, steps per second:  25, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.022287, mae: 2.949174, mean_q: 3.569885, mean_eps: 0.234915\n",
            " 851015/1000000: episode: 1180, duration: 26.242s, episode steps: 658, steps per second:  25, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.871 [0.000, 5.000],  loss: 0.021974, mae: 2.885945, mean_q: 3.490840, mean_eps: 0.234383\n",
            " 851947/1000000: episode: 1181, duration: 37.433s, episode steps: 932, steps per second:  25, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: 0.023346, mae: 2.924899, mean_q: 3.537569, mean_eps: 0.233668\n",
            " 852469/1000000: episode: 1182, duration: 21.249s, episode steps: 522, steps per second:  25, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.027762, mae: 2.915446, mean_q: 3.525957, mean_eps: 0.233013\n",
            " 852874/1000000: episode: 1183, duration: 16.380s, episode steps: 405, steps per second:  25, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.077 [0.000, 5.000],  loss: 0.021461, mae: 2.922320, mean_q: 3.533173, mean_eps: 0.232595\n",
            " 853619/1000000: episode: 1184, duration: 30.125s, episode steps: 745, steps per second:  25, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.021792, mae: 2.929382, mean_q: 3.544489, mean_eps: 0.232079\n",
            " 854551/1000000: episode: 1185, duration: 37.661s, episode steps: 932, steps per second:  25, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.026115, mae: 2.947238, mean_q: 3.567130, mean_eps: 0.231324\n",
            " 855220/1000000: episode: 1186, duration: 27.243s, episode steps: 669, steps per second:  25, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.852 [0.000, 5.000],  loss: 0.024507, mae: 2.907330, mean_q: 3.515000, mean_eps: 0.230604\n",
            " 855707/1000000: episode: 1187, duration: 19.632s, episode steps: 487, steps per second:  25, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.819 [0.000, 5.000],  loss: 0.028240, mae: 2.928088, mean_q: 3.543563, mean_eps: 0.230084\n",
            " 856445/1000000: episode: 1188, duration: 29.810s, episode steps: 738, steps per second:  25, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.024202, mae: 2.923009, mean_q: 3.536664, mean_eps: 0.229532\n",
            " 856988/1000000: episode: 1189, duration: 21.870s, episode steps: 543, steps per second:  25, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.807 [0.000, 5.000],  loss: 0.024395, mae: 2.938737, mean_q: 3.554614, mean_eps: 0.228956\n",
            " 857725/1000000: episode: 1190, duration: 29.671s, episode steps: 737, steps per second:  25, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.024976, mae: 2.916697, mean_q: 3.526157, mean_eps: 0.228380\n",
            " 858806/1000000: episode: 1191, duration: 43.430s, episode steps: 1081, steps per second:  25, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.026007, mae: 2.918239, mean_q: 3.532099, mean_eps: 0.227561\n",
            " 859521/1000000: episode: 1192, duration: 28.914s, episode steps: 715, steps per second:  25, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.026315, mae: 2.958863, mean_q: 3.579021, mean_eps: 0.226752\n",
            " 860185/1000000: episode: 1193, duration: 26.757s, episode steps: 664, steps per second:  25, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.759 [0.000, 5.000],  loss: 0.023569, mae: 2.927420, mean_q: 3.540407, mean_eps: 0.226131\n",
            " 861110/1000000: episode: 1194, duration: 37.319s, episode steps: 925, steps per second:  25, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.021118, mae: 2.930717, mean_q: 3.548006, mean_eps: 0.225417\n",
            " 862001/1000000: episode: 1195, duration: 35.782s, episode steps: 891, steps per second:  25, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.040 [0.000, 5.000],  loss: 0.023822, mae: 2.931989, mean_q: 3.551583, mean_eps: 0.224600\n",
            " 862665/1000000: episode: 1196, duration: 26.646s, episode steps: 664, steps per second:  25, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.745 [0.000, 5.000],  loss: 0.025135, mae: 2.925757, mean_q: 3.537221, mean_eps: 0.223899\n",
            " 863517/1000000: episode: 1197, duration: 34.336s, episode steps: 852, steps per second:  25, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.025270, mae: 2.946937, mean_q: 3.563457, mean_eps: 0.223217\n",
            " 864390/1000000: episode: 1198, duration: 35.236s, episode steps: 873, steps per second:  25, episode reward: 24.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.883 [0.000, 5.000],  loss: 0.026027, mae: 2.962539, mean_q: 3.584188, mean_eps: 0.222441\n",
            " 865435/1000000: episode: 1199, duration: 42.153s, episode steps: 1045, steps per second:  25, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.177 [0.000, 5.000],  loss: 0.022872, mae: 2.954266, mean_q: 3.569699, mean_eps: 0.221579\n",
            " 866270/1000000: episode: 1200, duration: 33.533s, episode steps: 835, steps per second:  25, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.023536, mae: 2.949415, mean_q: 3.570326, mean_eps: 0.220733\n",
            " 867267/1000000: episode: 1201, duration: 40.075s, episode steps: 997, steps per second:  25, episode reward: 28.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.027072, mae: 2.940156, mean_q: 3.557392, mean_eps: 0.219909\n",
            " 868462/1000000: episode: 1202, duration: 48.187s, episode steps: 1195, steps per second:  25, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.824 [0.000, 5.000],  loss: 0.026783, mae: 2.924547, mean_q: 3.535758, mean_eps: 0.218922\n",
            " 869212/1000000: episode: 1203, duration: 30.529s, episode steps: 750, steps per second:  25, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.023924, mae: 2.937238, mean_q: 3.552222, mean_eps: 0.218048\n",
            " 870072/1000000: episode: 1204, duration: 34.925s, episode steps: 860, steps per second:  25, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.027718, mae: 2.935552, mean_q: 3.549593, mean_eps: 0.217324\n",
            " 871065/1000000: episode: 1205, duration: 39.965s, episode steps: 993, steps per second:  25, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.026733, mae: 3.013444, mean_q: 3.649529, mean_eps: 0.216489\n",
            " 871517/1000000: episode: 1206, duration: 18.192s, episode steps: 452, steps per second:  25, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.022657, mae: 3.016227, mean_q: 3.652482, mean_eps: 0.215837\n",
            " 872582/1000000: episode: 1207, duration: 43.134s, episode steps: 1065, steps per second:  25, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.024962, mae: 3.022485, mean_q: 3.656390, mean_eps: 0.215155\n",
            " 873083/1000000: episode: 1208, duration: 20.187s, episode steps: 501, steps per second:  25, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.365 [0.000, 5.000],  loss: 0.025426, mae: 3.013678, mean_q: 3.653555, mean_eps: 0.214451\n",
            " 873610/1000000: episode: 1209, duration: 21.418s, episode steps: 527, steps per second:  25, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.981 [0.000, 5.000],  loss: 0.023800, mae: 2.966456, mean_q: 3.588629, mean_eps: 0.213989\n",
            " 874147/1000000: episode: 1210, duration: 21.766s, episode steps: 537, steps per second:  25, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.027368, mae: 3.007462, mean_q: 3.637898, mean_eps: 0.213510\n",
            " 875576/1000000: episode: 1211, duration: 57.914s, episode steps: 1429, steps per second:  25, episode reward: 32.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.684 [0.000, 5.000],  loss: 0.027266, mae: 3.001044, mean_q: 3.628966, mean_eps: 0.212626\n",
            " 876238/1000000: episode: 1212, duration: 26.962s, episode steps: 662, steps per second:  25, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.020536, mae: 2.995923, mean_q: 3.625515, mean_eps: 0.211685\n",
            " 877198/1000000: episode: 1213, duration: 38.978s, episode steps: 960, steps per second:  25, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.024812, mae: 2.989154, mean_q: 3.614342, mean_eps: 0.210954\n",
            " 877901/1000000: episode: 1214, duration: 28.503s, episode steps: 703, steps per second:  25, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.023656, mae: 2.992344, mean_q: 3.620057, mean_eps: 0.210205\n",
            " 878564/1000000: episode: 1215, duration: 27.070s, episode steps: 663, steps per second:  24, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.023182, mae: 2.995357, mean_q: 3.624735, mean_eps: 0.209591\n",
            " 879304/1000000: episode: 1216, duration: 29.975s, episode steps: 740, steps per second:  25, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.759 [0.000, 5.000],  loss: 0.024489, mae: 2.997492, mean_q: 3.625868, mean_eps: 0.208961\n",
            " 880386/1000000: episode: 1217, duration: 43.987s, episode steps: 1082, steps per second:  25, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.028209, mae: 3.018474, mean_q: 3.654230, mean_eps: 0.208140\n",
            " 881175/1000000: episode: 1218, duration: 32.126s, episode steps: 789, steps per second:  25, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.023484, mae: 3.009558, mean_q: 3.640402, mean_eps: 0.207298\n",
            " 882257/1000000: episode: 1219, duration: 43.932s, episode steps: 1082, steps per second:  25, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.241 [0.000, 5.000],  loss: 0.025333, mae: 2.994272, mean_q: 3.618776, mean_eps: 0.206456\n",
            " 883150/1000000: episode: 1220, duration: 36.349s, episode steps: 893, steps per second:  25, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.023069, mae: 2.980115, mean_q: 3.603557, mean_eps: 0.205566\n",
            " 883547/1000000: episode: 1221, duration: 16.074s, episode steps: 397, steps per second:  25, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.023515, mae: 2.986038, mean_q: 3.610935, mean_eps: 0.204987\n",
            " 884292/1000000: episode: 1222, duration: 30.392s, episode steps: 745, steps per second:  25, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: 0.024021, mae: 2.984293, mean_q: 3.608822, mean_eps: 0.204474\n",
            " 885173/1000000: episode: 1223, duration: 35.897s, episode steps: 881, steps per second:  25, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.024879, mae: 2.988838, mean_q: 3.611812, mean_eps: 0.203741\n",
            " 886259/1000000: episode: 1224, duration: 43.753s, episode steps: 1086, steps per second:  25, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.023343, mae: 2.986421, mean_q: 3.612578, mean_eps: 0.202856\n",
            " 887099/1000000: episode: 1225, duration: 33.904s, episode steps: 840, steps per second:  25, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: 0.025261, mae: 2.988346, mean_q: 3.612786, mean_eps: 0.201990\n",
            " 887756/1000000: episode: 1226, duration: 26.799s, episode steps: 657, steps per second:  25, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.027558, mae: 2.987263, mean_q: 3.609091, mean_eps: 0.201317\n",
            " 888885/1000000: episode: 1227, duration: 45.972s, episode steps: 1129, steps per second:  25, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.714 [0.000, 5.000],  loss: 0.027221, mae: 3.015068, mean_q: 3.640726, mean_eps: 0.200512\n",
            " 889876/1000000: episode: 1228, duration: 40.279s, episode steps: 991, steps per second:  25, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.172 [0.000, 5.000],  loss: 0.026136, mae: 2.996511, mean_q: 3.619643, mean_eps: 0.199558\n",
            " 890854/1000000: episode: 1229, duration: 39.927s, episode steps: 978, steps per second:  24, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.022027, mae: 3.014800, mean_q: 3.642438, mean_eps: 0.198672\n",
            " 891620/1000000: episode: 1230, duration: 31.258s, episode steps: 766, steps per second:  25, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.219 [0.000, 5.000],  loss: 0.021854, mae: 3.017237, mean_q: 3.648242, mean_eps: 0.197888\n",
            " 892066/1000000: episode: 1231, duration: 18.251s, episode steps: 446, steps per second:  24, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.061 [0.000, 5.000],  loss: 0.024367, mae: 3.056978, mean_q: 3.692609, mean_eps: 0.197342\n",
            " 893232/1000000: episode: 1232, duration: 47.816s, episode steps: 1166, steps per second:  24, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.130 [0.000, 5.000],  loss: 0.024434, mae: 3.013053, mean_q: 3.639997, mean_eps: 0.196617\n",
            " 893868/1000000: episode: 1233, duration: 26.229s, episode steps: 636, steps per second:  24, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.868 [0.000, 5.000],  loss: 0.025317, mae: 3.032602, mean_q: 3.668805, mean_eps: 0.195807\n",
            " 894643/1000000: episode: 1234, duration: 31.633s, episode steps: 775, steps per second:  24, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.881 [0.000, 5.000],  loss: 0.026161, mae: 3.052317, mean_q: 3.687508, mean_eps: 0.195171\n",
            " 895374/1000000: episode: 1235, duration: 30.082s, episode steps: 731, steps per second:  24, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.027450, mae: 3.039261, mean_q: 3.673357, mean_eps: 0.194493\n",
            " 896109/1000000: episode: 1236, duration: 29.920s, episode steps: 735, steps per second:  25, episode reward: 25.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.024441, mae: 3.013861, mean_q: 3.643282, mean_eps: 0.193832\n",
            " 896984/1000000: episode: 1237, duration: 35.871s, episode steps: 875, steps per second:  24, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.023148, mae: 3.007600, mean_q: 3.635556, mean_eps: 0.193109\n",
            " 897637/1000000: episode: 1238, duration: 26.671s, episode steps: 653, steps per second:  24, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.027521, mae: 3.028727, mean_q: 3.659367, mean_eps: 0.192421\n",
            " 898234/1000000: episode: 1239, duration: 24.473s, episode steps: 597, steps per second:  24, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.985 [0.000, 5.000],  loss: 0.026075, mae: 3.010286, mean_q: 3.635063, mean_eps: 0.191858\n",
            " 898929/1000000: episode: 1240, duration: 28.439s, episode steps: 695, steps per second:  24, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.239 [0.000, 5.000],  loss: 0.029096, mae: 2.979601, mean_q: 3.603590, mean_eps: 0.191276\n",
            " 900230/1000000: episode: 1241, duration: 53.246s, episode steps: 1301, steps per second:  24, episode reward: 32.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.804 [0.000, 5.000],  loss: 0.025294, mae: 3.005530, mean_q: 3.636877, mean_eps: 0.190378\n",
            " 901301/1000000: episode: 1242, duration: 43.916s, episode steps: 1071, steps per second:  24, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.024233, mae: 2.979847, mean_q: 3.603464, mean_eps: 0.189311\n",
            " 902016/1000000: episode: 1243, duration: 29.118s, episode steps: 715, steps per second:  25, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.024111, mae: 2.974535, mean_q: 3.596384, mean_eps: 0.188508\n",
            " 902413/1000000: episode: 1244, duration: 16.298s, episode steps: 397, steps per second:  24, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.026051, mae: 3.020680, mean_q: 3.655096, mean_eps: 0.188007\n",
            " 903718/1000000: episode: 1245, duration: 53.018s, episode steps: 1305, steps per second:  25, episode reward: 32.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.023668, mae: 2.991101, mean_q: 3.615796, mean_eps: 0.187241\n",
            " 904826/1000000: episode: 1246, duration: 45.520s, episode steps: 1108, steps per second:  24, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.132 [0.000, 5.000],  loss: 0.023863, mae: 3.014112, mean_q: 3.644737, mean_eps: 0.186155\n",
            " 905454/1000000: episode: 1247, duration: 25.745s, episode steps: 628, steps per second:  24, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.723 [0.000, 5.000],  loss: 0.022764, mae: 2.984675, mean_q: 3.606374, mean_eps: 0.185374\n",
            " 906357/1000000: episode: 1248, duration: 36.744s, episode steps: 903, steps per second:  25, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.118 [0.000, 5.000],  loss: 0.023061, mae: 2.995470, mean_q: 3.618320, mean_eps: 0.184685\n",
            " 907172/1000000: episode: 1249, duration: 33.593s, episode steps: 815, steps per second:  24, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.026024, mae: 2.972048, mean_q: 3.590376, mean_eps: 0.183912\n",
            " 907916/1000000: episode: 1250, duration: 30.520s, episode steps: 744, steps per second:  24, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.585 [0.000, 5.000],  loss: 0.028587, mae: 2.988297, mean_q: 3.608619, mean_eps: 0.183212\n",
            " 908691/1000000: episode: 1251, duration: 31.705s, episode steps: 775, steps per second:  24, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.026885, mae: 3.005673, mean_q: 3.630845, mean_eps: 0.182528\n",
            " 909452/1000000: episode: 1252, duration: 31.415s, episode steps: 761, steps per second:  24, episode reward: 21.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.023791, mae: 2.993623, mean_q: 3.616011, mean_eps: 0.181837\n",
            " 909955/1000000: episode: 1253, duration: 20.666s, episode steps: 503, steps per second:  24, episode reward: 13.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.024615, mae: 2.981350, mean_q: 3.602002, mean_eps: 0.181268\n",
            " 910617/1000000: episode: 1254, duration: 27.028s, episode steps: 662, steps per second:  24, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.630 [0.000, 5.000],  loss: 0.023191, mae: 2.990639, mean_q: 3.615634, mean_eps: 0.180743\n",
            " 911248/1000000: episode: 1255, duration: 25.827s, episode steps: 631, steps per second:  24, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.799 [0.000, 5.000],  loss: 0.032820, mae: 3.007118, mean_q: 3.635650, mean_eps: 0.180161\n",
            " 912329/1000000: episode: 1256, duration: 44.266s, episode steps: 1081, steps per second:  24, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.920 [0.000, 5.000],  loss: 0.027657, mae: 3.012642, mean_q: 3.640088, mean_eps: 0.179391\n",
            " 912992/1000000: episode: 1257, duration: 27.353s, episode steps: 663, steps per second:  24, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.030463, mae: 3.007394, mean_q: 3.636435, mean_eps: 0.178606\n",
            " 913607/1000000: episode: 1258, duration: 25.100s, episode steps: 615, steps per second:  25, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.034966, mae: 3.015952, mean_q: 3.645114, mean_eps: 0.178032\n",
            " 914226/1000000: episode: 1259, duration: 25.437s, episode steps: 619, steps per second:  24, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.024882, mae: 2.999503, mean_q: 3.623939, mean_eps: 0.177476\n",
            " 914855/1000000: episode: 1260, duration: 26.258s, episode steps: 629, steps per second:  24, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.824 [0.000, 5.000],  loss: 0.022932, mae: 2.994956, mean_q: 3.620052, mean_eps: 0.176914\n",
            " 915839/1000000: episode: 1261, duration: 40.484s, episode steps: 984, steps per second:  24, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.024509, mae: 2.997171, mean_q: 3.622835, mean_eps: 0.176189\n",
            " 916765/1000000: episode: 1262, duration: 38.562s, episode steps: 926, steps per second:  24, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.784 [0.000, 5.000],  loss: 0.022668, mae: 3.002230, mean_q: 3.630693, mean_eps: 0.175328\n",
            " 917693/1000000: episode: 1263, duration: 38.154s, episode steps: 928, steps per second:  24, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.052 [0.000, 5.000],  loss: 0.026344, mae: 2.999866, mean_q: 3.626761, mean_eps: 0.174493\n",
            " 918402/1000000: episode: 1264, duration: 28.931s, episode steps: 709, steps per second:  25, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.035 [0.000, 5.000],  loss: 0.030710, mae: 3.016417, mean_q: 3.645801, mean_eps: 0.173757\n",
            " 918907/1000000: episode: 1265, duration: 20.787s, episode steps: 505, steps per second:  24, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.802 [0.000, 5.000],  loss: 0.025146, mae: 3.018587, mean_q: 3.646604, mean_eps: 0.173211\n",
            " 919700/1000000: episode: 1266, duration: 32.745s, episode steps: 793, steps per second:  24, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.858 [0.000, 5.000],  loss: 0.024218, mae: 3.010709, mean_q: 3.639347, mean_eps: 0.172628\n",
            " 920350/1000000: episode: 1267, duration: 26.776s, episode steps: 650, steps per second:  24, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.703 [0.000, 5.000],  loss: 0.023659, mae: 3.004577, mean_q: 3.636426, mean_eps: 0.171978\n",
            " 921284/1000000: episode: 1268, duration: 38.888s, episode steps: 934, steps per second:  24, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.024495, mae: 3.041821, mean_q: 3.679710, mean_eps: 0.171266\n",
            " 921927/1000000: episode: 1269, duration: 26.689s, episode steps: 643, steps per second:  24, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.025714, mae: 3.035289, mean_q: 3.671956, mean_eps: 0.170556\n",
            " 922560/1000000: episode: 1270, duration: 26.428s, episode steps: 633, steps per second:  24, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: 0.027343, mae: 3.027533, mean_q: 3.665024, mean_eps: 0.169982\n",
            " 923284/1000000: episode: 1271, duration: 29.982s, episode steps: 724, steps per second:  24, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.022 [0.000, 5.000],  loss: 0.025639, mae: 3.025873, mean_q: 3.660102, mean_eps: 0.169372\n",
            " 924425/1000000: episode: 1272, duration: 46.869s, episode steps: 1141, steps per second:  24, episode reward: 30.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.023859, mae: 3.027494, mean_q: 3.664836, mean_eps: 0.168531\n",
            " 925384/1000000: episode: 1273, duration: 39.461s, episode steps: 959, steps per second:  24, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.026001, mae: 3.042477, mean_q: 3.680454, mean_eps: 0.167586\n",
            " 926030/1000000: episode: 1274, duration: 27.178s, episode steps: 646, steps per second:  24, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.026879, mae: 3.037392, mean_q: 3.670880, mean_eps: 0.166865\n",
            " 926663/1000000: episode: 1275, duration: 26.733s, episode steps: 633, steps per second:  24, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.025339, mae: 3.060025, mean_q: 3.698612, mean_eps: 0.166289\n",
            " 927711/1000000: episode: 1276, duration: 43.233s, episode steps: 1048, steps per second:  24, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.025137, mae: 3.043810, mean_q: 3.682479, mean_eps: 0.165533\n",
            " 928227/1000000: episode: 1277, duration: 21.441s, episode steps: 516, steps per second:  24, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.023309, mae: 3.089288, mean_q: 3.736351, mean_eps: 0.164829\n",
            " 928771/1000000: episode: 1278, duration: 22.888s, episode steps: 544, steps per second:  24, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.027266, mae: 3.030426, mean_q: 3.667015, mean_eps: 0.164352\n",
            " 929930/1000000: episode: 1279, duration: 48.457s, episode steps: 1159, steps per second:  24, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.025787, mae: 3.027667, mean_q: 3.665238, mean_eps: 0.163585\n",
            " 930442/1000000: episode: 1280, duration: 21.601s, episode steps: 512, steps per second:  24, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.025077, mae: 3.018640, mean_q: 3.649540, mean_eps: 0.162833\n",
            " 931412/1000000: episode: 1281, duration: 40.304s, episode steps: 970, steps per second:  24, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.024201, mae: 3.041502, mean_q: 3.681844, mean_eps: 0.162167\n",
            " 932054/1000000: episode: 1282, duration: 26.668s, episode steps: 642, steps per second:  24, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.134 [0.000, 5.000],  loss: 0.024093, mae: 3.065657, mean_q: 3.712077, mean_eps: 0.161441\n",
            " 932983/1000000: episode: 1283, duration: 38.447s, episode steps: 929, steps per second:  24, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.707 [0.000, 5.000],  loss: 0.028193, mae: 3.046972, mean_q: 3.689557, mean_eps: 0.160734\n",
            " 933905/1000000: episode: 1284, duration: 38.429s, episode steps: 922, steps per second:  24, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.028870, mae: 3.053264, mean_q: 3.694196, mean_eps: 0.159900\n",
            " 934698/1000000: episode: 1285, duration: 32.727s, episode steps: 793, steps per second:  24, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.871 [0.000, 5.000],  loss: 0.026075, mae: 3.058180, mean_q: 3.697555, mean_eps: 0.159128\n",
            " 935237/1000000: episode: 1286, duration: 22.406s, episode steps: 539, steps per second:  24, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.028989, mae: 3.084163, mean_q: 3.735852, mean_eps: 0.158529\n",
            " 935719/1000000: episode: 1287, duration: 19.968s, episode steps: 482, steps per second:  24, episode reward: 12.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.023885, mae: 3.071583, mean_q: 3.716197, mean_eps: 0.158070\n",
            " 936346/1000000: episode: 1288, duration: 25.857s, episode steps: 627, steps per second:  24, episode reward: 16.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.858 [0.000, 5.000],  loss: 0.029543, mae: 3.008686, mean_q: 3.636768, mean_eps: 0.157571\n",
            " 937182/1000000: episode: 1289, duration: 34.627s, episode steps: 836, steps per second:  24, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.027280, mae: 3.064573, mean_q: 3.704559, mean_eps: 0.156912\n",
            " 938205/1000000: episode: 1290, duration: 42.271s, episode steps: 1023, steps per second:  24, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.093 [0.000, 5.000],  loss: 0.026460, mae: 3.068955, mean_q: 3.712602, mean_eps: 0.156075\n",
            " 939199/1000000: episode: 1291, duration: 41.106s, episode steps: 994, steps per second:  24, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.026106, mae: 3.074264, mean_q: 3.724113, mean_eps: 0.155168\n",
            " 939739/1000000: episode: 1292, duration: 22.246s, episode steps: 540, steps per second:  24, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.359 [0.000, 5.000],  loss: 0.032233, mae: 3.056712, mean_q: 3.693983, mean_eps: 0.154479\n",
            " 940648/1000000: episode: 1293, duration: 37.973s, episode steps: 909, steps per second:  24, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.021902, mae: 3.070586, mean_q: 3.716796, mean_eps: 0.153827\n",
            " 941471/1000000: episode: 1294, duration: 34.094s, episode steps: 823, steps per second:  24, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.027401, mae: 3.058327, mean_q: 3.699862, mean_eps: 0.153048\n",
            " 942403/1000000: episode: 1295, duration: 38.768s, episode steps: 932, steps per second:  24, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.030183, mae: 3.054863, mean_q: 3.691873, mean_eps: 0.152258\n",
            " 942773/1000000: episode: 1296, duration: 15.410s, episode steps: 370, steps per second:  24, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.189 [0.000, 5.000],  loss: 0.024527, mae: 3.065805, mean_q: 3.710459, mean_eps: 0.151671\n",
            " 943501/1000000: episode: 1297, duration: 30.206s, episode steps: 728, steps per second:  24, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.738 [0.000, 5.000],  loss: 0.024713, mae: 3.053741, mean_q: 3.695743, mean_eps: 0.151176\n",
            " 944264/1000000: episode: 1298, duration: 31.631s, episode steps: 763, steps per second:  24, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.186 [0.000, 5.000],  loss: 0.030895, mae: 3.086116, mean_q: 3.733985, mean_eps: 0.150506\n",
            " 944820/1000000: episode: 1299, duration: 23.267s, episode steps: 556, steps per second:  24, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.032967, mae: 3.075660, mean_q: 3.722770, mean_eps: 0.149914\n",
            " 945674/1000000: episode: 1300, duration: 35.484s, episode steps: 854, steps per second:  24, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.993 [0.000, 5.000],  loss: 0.024782, mae: 3.083028, mean_q: 3.733631, mean_eps: 0.149279\n",
            " 946320/1000000: episode: 1301, duration: 27.049s, episode steps: 646, steps per second:  24, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.029921, mae: 3.084511, mean_q: 3.730795, mean_eps: 0.148604\n",
            " 947060/1000000: episode: 1302, duration: 30.728s, episode steps: 740, steps per second:  24, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.025118, mae: 3.052480, mean_q: 3.692659, mean_eps: 0.147981\n",
            " 947942/1000000: episode: 1303, duration: 36.802s, episode steps: 882, steps per second:  24, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.028037, mae: 3.080120, mean_q: 3.723174, mean_eps: 0.147250\n",
            " 948968/1000000: episode: 1304, duration: 42.973s, episode steps: 1026, steps per second:  24, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.028040, mae: 3.080936, mean_q: 3.726376, mean_eps: 0.146391\n",
            " 949497/1000000: episode: 1305, duration: 22.013s, episode steps: 529, steps per second:  24, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.022801, mae: 3.048301, mean_q: 3.684067, mean_eps: 0.145691\n",
            " 950549/1000000: episode: 1306, duration: 43.907s, episode steps: 1052, steps per second:  24, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.026325, mae: 3.081141, mean_q: 3.728129, mean_eps: 0.144978\n",
            " 951417/1000000: episode: 1307, duration: 36.006s, episode steps: 868, steps per second:  24, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.858 [0.000, 5.000],  loss: 0.023668, mae: 3.139647, mean_q: 3.795212, mean_eps: 0.144114\n",
            " 951878/1000000: episode: 1308, duration: 19.379s, episode steps: 461, steps per second:  24, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.798 [0.000, 5.000],  loss: 0.025220, mae: 3.161146, mean_q: 3.821334, mean_eps: 0.143517\n",
            " 952939/1000000: episode: 1309, duration: 44.314s, episode steps: 1061, steps per second:  24, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.026949, mae: 3.140129, mean_q: 3.797401, mean_eps: 0.142833\n",
            " 953684/1000000: episode: 1310, duration: 31.021s, episode steps: 745, steps per second:  24, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.026443, mae: 3.134309, mean_q: 3.788262, mean_eps: 0.142021\n",
            " 954497/1000000: episode: 1311, duration: 34.175s, episode steps: 813, steps per second:  24, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.095 [0.000, 5.000],  loss: 0.028077, mae: 3.148694, mean_q: 3.806372, mean_eps: 0.141319\n",
            " 955592/1000000: episode: 1312, duration: 45.734s, episode steps: 1095, steps per second:  24, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.027447, mae: 3.119638, mean_q: 3.770783, mean_eps: 0.140460\n",
            " 956451/1000000: episode: 1313, duration: 35.813s, episode steps: 859, steps per second:  24, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.193 [0.000, 5.000],  loss: 0.025315, mae: 3.149562, mean_q: 3.813968, mean_eps: 0.139582\n",
            " 957294/1000000: episode: 1314, duration: 35.102s, episode steps: 843, steps per second:  24, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.028074, mae: 3.125135, mean_q: 3.779787, mean_eps: 0.138815\n",
            " 958350/1000000: episode: 1315, duration: 43.750s, episode steps: 1056, steps per second:  24, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.028798, mae: 3.140470, mean_q: 3.798126, mean_eps: 0.137960\n",
            " 959492/1000000: episode: 1316, duration: 47.787s, episode steps: 1142, steps per second:  24, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.989 [0.000, 5.000],  loss: 0.029446, mae: 3.142453, mean_q: 3.796172, mean_eps: 0.136972\n",
            " 960247/1000000: episode: 1317, duration: 31.547s, episode steps: 755, steps per second:  24, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.027632, mae: 3.145429, mean_q: 3.805750, mean_eps: 0.136119\n",
            " 960906/1000000: episode: 1318, duration: 27.334s, episode steps: 659, steps per second:  24, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.028012, mae: 3.157217, mean_q: 3.818152, mean_eps: 0.135482\n",
            " 961408/1000000: episode: 1319, duration: 21.107s, episode steps: 502, steps per second:  24, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.016 [0.000, 5.000],  loss: 0.028020, mae: 3.196849, mean_q: 3.866405, mean_eps: 0.134960\n",
            " 962071/1000000: episode: 1320, duration: 27.696s, episode steps: 663, steps per second:  24, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.024986, mae: 3.168143, mean_q: 3.832454, mean_eps: 0.134436\n",
            " 962464/1000000: episode: 1321, duration: 16.549s, episode steps: 393, steps per second:  24, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.081 [0.000, 5.000],  loss: 0.027412, mae: 3.134080, mean_q: 3.793296, mean_eps: 0.133961\n",
            " 963051/1000000: episode: 1322, duration: 24.721s, episode steps: 587, steps per second:  24, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.172 [0.000, 5.000],  loss: 0.027020, mae: 3.173627, mean_q: 3.841249, mean_eps: 0.133520\n",
            " 964150/1000000: episode: 1323, duration: 46.005s, episode steps: 1099, steps per second:  24, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.031600, mae: 3.192670, mean_q: 3.862061, mean_eps: 0.132760\n",
            " 965094/1000000: episode: 1324, duration: 39.511s, episode steps: 944, steps per second:  24, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.283 [0.000, 5.000],  loss: 0.029023, mae: 3.167171, mean_q: 3.827964, mean_eps: 0.131840\n",
            " 966096/1000000: episode: 1325, duration: 43.234s, episode steps: 1002, steps per second:  23, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.075 [0.000, 5.000],  loss: 0.027290, mae: 3.188783, mean_q: 3.855760, mean_eps: 0.130965\n",
            " 966689/1000000: episode: 1326, duration: 25.979s, episode steps: 593, steps per second:  23, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.028657, mae: 3.191347, mean_q: 3.856428, mean_eps: 0.130247\n",
            " 967614/1000000: episode: 1327, duration: 39.624s, episode steps: 925, steps per second:  23, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.174 [0.000, 5.000],  loss: 0.024222, mae: 3.178854, mean_q: 3.840738, mean_eps: 0.129563\n",
            " 968725/1000000: episode: 1328, duration: 46.629s, episode steps: 1111, steps per second:  24, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.026755, mae: 3.185381, mean_q: 3.850920, mean_eps: 0.128647\n",
            " 969692/1000000: episode: 1329, duration: 40.761s, episode steps: 967, steps per second:  24, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.025688, mae: 3.184020, mean_q: 3.847016, mean_eps: 0.127713\n",
            " 970655/1000000: episode: 1330, duration: 40.521s, episode steps: 963, steps per second:  24, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.026976, mae: 3.188239, mean_q: 3.856468, mean_eps: 0.126845\n",
            " 971977/1000000: episode: 1331, duration: 55.621s, episode steps: 1322, steps per second:  24, episode reward: 20.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.025052, mae: 3.220359, mean_q: 3.894141, mean_eps: 0.125816\n",
            " 972503/1000000: episode: 1332, duration: 22.030s, episode steps: 526, steps per second:  24, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.026768, mae: 3.222808, mean_q: 3.894268, mean_eps: 0.124984\n",
            " 973564/1000000: episode: 1333, duration: 44.835s, episode steps: 1061, steps per second:  24, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.092 [0.000, 5.000],  loss: 0.028781, mae: 3.220534, mean_q: 3.892804, mean_eps: 0.124271\n",
            " 974355/1000000: episode: 1334, duration: 33.327s, episode steps: 791, steps per second:  24, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.882 [0.000, 5.000],  loss: 0.027811, mae: 3.200285, mean_q: 3.867633, mean_eps: 0.123438\n",
            " 975405/1000000: episode: 1335, duration: 44.274s, episode steps: 1050, steps per second:  24, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.872 [0.000, 5.000],  loss: 0.029077, mae: 3.207406, mean_q: 3.875945, mean_eps: 0.122608\n",
            " 976492/1000000: episode: 1336, duration: 45.897s, episode steps: 1087, steps per second:  24, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.023 [0.000, 5.000],  loss: 0.028366, mae: 3.218016, mean_q: 3.896156, mean_eps: 0.121647\n",
            " 977143/1000000: episode: 1337, duration: 27.608s, episode steps: 651, steps per second:  24, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.026702, mae: 3.200718, mean_q: 3.868731, mean_eps: 0.120866\n",
            " 977650/1000000: episode: 1338, duration: 21.540s, episode steps: 507, steps per second:  24, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.150 [0.000, 5.000],  loss: 0.023074, mae: 3.215146, mean_q: 3.888157, mean_eps: 0.120344\n",
            " 978247/1000000: episode: 1339, duration: 25.132s, episode steps: 597, steps per second:  24, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.027612, mae: 3.227740, mean_q: 3.902481, mean_eps: 0.119847\n",
            " 978814/1000000: episode: 1340, duration: 24.120s, episode steps: 567, steps per second:  24, episode reward: 14.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.822 [0.000, 5.000],  loss: 0.026700, mae: 3.203969, mean_q: 3.875315, mean_eps: 0.119323\n",
            " 979526/1000000: episode: 1341, duration: 30.086s, episode steps: 712, steps per second:  24, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.809 [0.000, 5.000],  loss: 0.028129, mae: 3.235600, mean_q: 3.914270, mean_eps: 0.118747\n",
            " 980585/1000000: episode: 1342, duration: 44.562s, episode steps: 1059, steps per second:  24, episode reward: 27.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.142 [0.000, 5.000],  loss: 0.027128, mae: 3.212474, mean_q: 3.884156, mean_eps: 0.117950\n",
            " 981299/1000000: episode: 1343, duration: 30.296s, episode steps: 714, steps per second:  24, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.776 [0.000, 5.000],  loss: 0.027532, mae: 3.214130, mean_q: 3.883377, mean_eps: 0.117152\n",
            " 982066/1000000: episode: 1344, duration: 32.679s, episode steps: 767, steps per second:  23, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.729 [0.000, 5.000],  loss: 0.025074, mae: 3.202673, mean_q: 3.867574, mean_eps: 0.116486\n",
            " 982703/1000000: episode: 1345, duration: 27.339s, episode steps: 637, steps per second:  23, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.061 [0.000, 5.000],  loss: 0.026032, mae: 3.218009, mean_q: 3.888470, mean_eps: 0.115854\n",
            " 983218/1000000: episode: 1346, duration: 22.163s, episode steps: 515, steps per second:  23, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.957 [0.000, 5.000],  loss: 0.030625, mae: 3.218691, mean_q: 3.886227, mean_eps: 0.115336\n",
            " 983724/1000000: episode: 1347, duration: 21.720s, episode steps: 506, steps per second:  23, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.029802, mae: 3.216493, mean_q: 3.886259, mean_eps: 0.114877\n",
            " 984760/1000000: episode: 1348, duration: 45.303s, episode steps: 1036, steps per second:  23, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.027897, mae: 3.216032, mean_q: 3.887340, mean_eps: 0.114184\n",
            " 985782/1000000: episode: 1349, duration: 44.089s, episode steps: 1022, steps per second:  23, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.026851, mae: 3.209453, mean_q: 3.877884, mean_eps: 0.113257\n",
            " 986510/1000000: episode: 1350, duration: 31.269s, episode steps: 728, steps per second:  23, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.028575, mae: 3.182061, mean_q: 3.847733, mean_eps: 0.112469\n",
            " 987411/1000000: episode: 1351, duration: 38.578s, episode steps: 901, steps per second:  23, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.027942, mae: 3.214367, mean_q: 3.885674, mean_eps: 0.111736\n",
            " 988260/1000000: episode: 1352, duration: 36.733s, episode steps: 849, steps per second:  23, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.084 [0.000, 5.000],  loss: 0.026831, mae: 3.219629, mean_q: 3.889649, mean_eps: 0.110949\n",
            " 988789/1000000: episode: 1353, duration: 22.879s, episode steps: 529, steps per second:  23, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.025049, mae: 3.221638, mean_q: 3.896985, mean_eps: 0.110328\n",
            " 989408/1000000: episode: 1354, duration: 26.541s, episode steps: 619, steps per second:  23, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.027809, mae: 3.225631, mean_q: 3.895516, mean_eps: 0.109812\n",
            " 990284/1000000: episode: 1355, duration: 37.634s, episode steps: 876, steps per second:  23, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.031 [0.000, 5.000],  loss: 0.026519, mae: 3.200209, mean_q: 3.869979, mean_eps: 0.109140\n",
            " 991454/1000000: episode: 1356, duration: 50.225s, episode steps: 1170, steps per second:  23, episode reward: 29.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.028070, mae: 3.223840, mean_q: 3.902074, mean_eps: 0.108219\n",
            " 992387/1000000: episode: 1357, duration: 39.877s, episode steps: 933, steps per second:  23, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.940 [0.000, 5.000],  loss: 0.029957, mae: 3.230062, mean_q: 3.904754, mean_eps: 0.107272\n",
            " 993241/1000000: episode: 1358, duration: 36.722s, episode steps: 854, steps per second:  23, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.022721, mae: 3.219140, mean_q: 3.892859, mean_eps: 0.106467\n",
            " 994346/1000000: episode: 1359, duration: 47.383s, episode steps: 1105, steps per second:  23, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.762 [0.000, 5.000],  loss: 0.024986, mae: 3.204003, mean_q: 3.874524, mean_eps: 0.105585\n",
            " 994861/1000000: episode: 1360, duration: 22.286s, episode steps: 515, steps per second:  23, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.026676, mae: 3.243818, mean_q: 3.922119, mean_eps: 0.104856\n",
            " 995478/1000000: episode: 1361, duration: 26.345s, episode steps: 617, steps per second:  23, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.028756, mae: 3.238379, mean_q: 3.916854, mean_eps: 0.104347\n",
            " 996438/1000000: episode: 1362, duration: 41.675s, episode steps: 960, steps per second:  23, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.024297, mae: 3.235706, mean_q: 3.911578, mean_eps: 0.103638\n",
            " 997225/1000000: episode: 1363, duration: 33.715s, episode steps: 787, steps per second:  23, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.032374, mae: 3.226831, mean_q: 3.905111, mean_eps: 0.102851\n",
            " 998037/1000000: episode: 1364, duration: 34.919s, episode steps: 812, steps per second:  23, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.143 [0.000, 5.000],  loss: 0.030171, mae: 3.231013, mean_q: 3.903079, mean_eps: 0.102131\n",
            " 998688/1000000: episode: 1365, duration: 28.169s, episode steps: 651, steps per second:  23, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.175 [0.000, 5.000],  loss: 0.026230, mae: 3.239209, mean_q: 3.916918, mean_eps: 0.101474\n",
            " 999661/1000000: episode: 1366, duration: 41.998s, episode steps: 973, steps per second:  23, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.027661, mae: 3.227543, mean_q: 3.903435, mean_eps: 0.100743\n",
            "done, took 33195.694 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 26.000, steps: 1018\n",
            "Episode 2: reward: 15.000, steps: 489\n",
            "Episode 3: reward: 12.000, steps: 512\n",
            "Episode 4: reward: 15.000, steps: 635\n",
            "Episode 5: reward: 18.000, steps: 762\n",
            "Episode 6: reward: 14.000, steps: 561\n",
            "Episode 7: reward: 12.000, steps: 484\n",
            "Episode 8: reward: 19.000, steps: 814\n",
            "Episode 9: reward: 9.000, steps: 381\n",
            "Episode 10: reward: 18.000, steps: 726\n",
            "Episode 11: reward: 12.000, steps: 567\n",
            "Episode 12: reward: 18.000, steps: 767\n",
            "Episode 13: reward: 22.000, steps: 941\n",
            "Episode 14: reward: 16.000, steps: 725\n",
            "Episode 15: reward: 13.000, steps: 495\n",
            "Episode 16: reward: 20.000, steps: 901\n",
            "Episode 17: reward: 18.000, steps: 658\n",
            "Episode 18: reward: 15.000, steps: 725\n",
            "Episode 19: reward: 17.000, steps: 764\n",
            "Episode 20: reward: 21.000, steps: 1160\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78d1276e66d0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam  # ✅ IMPORTANTE: usar legacy\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# ==== Constantes ====\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "\n",
        "# ==== Procesador para observaciones ====\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3\n",
        "        img = Image.fromarray(observation)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        return batch.astype('float32') / 255.\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "# ==== Preparar entorno ====\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "# ==== Modelo CNN tipo DeepMind ====\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 3, 1), input_shape=input_shape))  # (4, 84, 84) → (84, 84, 4)\n",
        "model.add(Conv2D(32, kernel_size=8, strides=4, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(nb_actions, activation='linear'))\n",
        "\n",
        "# ==== Memoria y política ====\n",
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=1.0, value_min=0.1, value_test=0.05,\n",
        "                              nb_steps=1000000)\n",
        "\n",
        "# ==== Agente DQN ====\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               memory=memory,\n",
        "               processor=AtariProcessor(),\n",
        "               nb_steps_warmup=50000,\n",
        "               target_model_update=10000,\n",
        "               train_interval=4,\n",
        "               gamma=0.99,\n",
        "               policy=policy)\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.00025), metrics=['mae'])\n",
        "\n",
        "# ==== Callbacks ====\n",
        "checkpoint_weights_filename = 'dqn_{}_weights_{{step}}.h5f'.format(ENV_NAME)\n",
        "log_filename = 'dqn_{}_log.json'.format(ENV_NAME)\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000),\n",
        "    FileLogger(log_filename, interval=100)\n",
        "]\n",
        "\n",
        "# ==== Entrenamiento ====\n",
        "dqn.fit(env,\n",
        "        nb_steps=1000000,  # ENTRENAMIENTO EXTENDIDO\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "# ==== Guardar pesos finales ====\n",
        "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
        "\n",
        "# ==== Evaluación ====\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "P_UBBHLAU0Ok",
        "outputId": "99ae7f97-2c12-400b-a2af-2bab8fac1849"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAIjCAYAAADWYVDIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnXeYFFXWh3+dJ8/AMDCEIeeMIIhIkiQYVjGHVdA1Z8W8KoqKmF0/F8MaUGFVFOOaUAFBBZWcYUhDnBy7p1N1fX/0VE1VdVV3VXd1nPM+Dzpd4d5zQ926p8655xpYlmVBEARBEARBEARBAACM8RaAIAiCIAiCIAgikSAliSAIgiAIgiAIQgApSQRBEARBEARBEAJISSIIgiAIgiAIghBAShJBEARBEARBEIQAUpIIgiAIgiAIgiAEkJJEEARBEARBEAQhgJQkgiAIgiAIgiAIAaQkEQSR0rz99tt4/fXX4y0GQRAEQRBJBClJBEFEDYPBgLlz50Yt/QkTJmDChAmK55cuXYrbb78dJ598ctRkEPLuu+/CYDDg4MGDmu+dO3cuDAaD/kIlAbNmzULXrl3Dvr9r166YNWuWbvKkMtF+Jgk/K1euhMFgwMqVK+MtCkEQYUJKEkGkONzEXenf2rVr4y1iVNi7dy9uuOEGfPzxxzjppJPiLQ5BYMeOHZg7d25YSnSy89tvv2Hu3LmoqamJtygpxVNPPYXPP/883mIQREpijrcABEHEhscffxzdunULON6zZ884SKMPP/zwg+K5zZs345133sH06dNjKBFBKLNjxw489thjmDBhQkSWs2Tkt99+w2OPPYZZs2YhLy8v3uJEnXHjxqGxsRFWqzWq+Tz11FO44IILcO6550Y1H4JoiZCSRBAthOnTp2PEiBHxFkNXgk1ALrjgghhKEl8cDgcyMjLiLYYiTqcTVqsVRmPiOy+wLAun04n09PR4i9Ji8fl8cLvdSEtLi7coYWM0GpNafoIgyN2OIAgAHo8HrVu3xuzZswPO1dXVIS0tDXPmzOGPlZWV4ZprrkG7du2QlpaGIUOGYNGiRSHzUVp7orQe54MPPsDIkSORkZGBVq1aYdy4cSLrkdyaJDWyHTx4EAaDAc899xzeeOMN9OjRAzabDSeffDL+/PPPkOUAgO3bt+P0009Heno6OnXqhCeeeAI+n0/22m+//RZjx45FZmYmsrOzceaZZ2L79u2q8pEyYcIEDBw4EOvXr8e4ceOQkZGBBx98EADgcrnw6KOPomfPnrDZbCgqKsK9994Ll8vF3z9z5swA98Ozzz4bBoMBX375JX9s3bp1MBgM+PbbbwEAVVVVmDNnDgYNGoSsrCzk5ORg+vTp2Lx5sygtbi3Ghx9+iH/+85/o2LEjMjIyUFdXBwD4/PPPMXDgQKSlpWHgwIH47LPPVJedZVk88cQT6NSpEzIyMjBx4kTZelTqT3Jrxrp27YqzzjoL33//PUaMGIH09HQ+0Mc777yD008/HW3btoXNZkP//v2xcOHCgHS5NNasWYORI0ciLS0N3bt3x3vvvSfK+8ILLwQATJw4kXd3Fa5ZiaSf1NTU4I477kBRURFsNht69uyJBQsWKPbJUKjpS4B/jdMtt9zCt6vNZsOAAQPw3Xff8dfMnTsX99xzDwCgW7dufNm5duDSWLx4MQYMGACbzcbff/ToUVx99dVo164dn/bbb78tkoHrcx9//DGefPJJdOrUCWlpaZg0aRKKi4tF165evRoXXnghOnfuzJfrzjvvRGNjo+i6WbNmISsrCyUlJTjrrLOQlZWFjh074tVXXwUAbN26FaeffjoyMzPRpUsXLFmyRFYm6ZqkdevW4YwzzkBubi4yMjIwfvx4/Prrr6JruP5bXFzMW95yc3Mxe/ZsOBwOUd3b7XYsWrSIr1Ph2ryNGzdi+vTpyMnJQVZWFiZNmpSy7tUEEQ3IkkQQLYTa2lpUVFSIjhkMBuTn58NiseC8887DsmXL8Prrr4ssNJ9//jlcLhcuueQSAEBjYyMmTJiA4uJi3HLLLejWrRuWLl2KWbNmoaamBrfffrsu8j722GOYO3cuTj31VDz++OOwWq1Yt24dfv75Z0ydOlX2Hq2yLVmyBPX19bj++uthMBjwzDPPYObMmdi/fz8sFouibCdOnMDEiRPh9Xpx//33IzMzE2+88Yas9eH999/HVVddhWnTpmHBggVwOBxYuHAhTjvtNGzcuDEst6vKykpMnz4dl1xyCa644gq0a9cOPp8P55xzDtasWYPrrrsO/fr1w9atW/Hiiy9iz549/LqFsWPH4osvvkBdXR1ycnLAsix+/fVXGI1GrF69Gueccw4A/2TSaDRizJgxAID9+/fj888/x4UXXohu3bqhtLQUr7/+OsaPH48dO3agQ4cOIhnnzZsHq9WKOXPmwOVywWq14ocffsD555+P/v37Y/78+aisrMTs2bPRqVMnVeV+5JFH8MQTT2DGjBmYMWMGNmzYgKlTp8LtdmuuQyG7d+/GpZdeiuuvvx7XXnst+vTpAwBYuHAhBgwYgHPOOQdmsxlfffUVbrrpJvh8Ptx8882iNIqLi3HBBRfgmmuuwVVXXYW3334bs2bNwvDhwzFgwACMGzcOt912G/71r3/hwQcfRL9+/QCA/38k/cThcGD8+PE4evQorr/+enTu3Bm//fYbHnjgARw/fhwvvfSSpvpQ25c41qxZg2XLluGmm25CdnY2/vWvf+H8889HSUkJ8vPzMXPmTOzZswf//e9/8eKLL6JNmzYAgIKCAj6Nn3/+GR9//DFuueUWtGnTBl27dkVpaSlOOeUUXokqKCjAt99+i2uuuQZ1dXW44447RHI8/fTTMBqNmDNnDmpra/HMM8/g8ssvx7p16/hrli5dCofDgRtvvBH5+fn4448/8Morr+DIkSNYunSpKD2GYTB9+nSMGzcOzzzzDBYvXoxbbrkFmZmZeOihh3D55Zdj5syZeO2113DllVdi9OjRsi7NwjJOnz4dw4cPx6OPPgqj0cgr4qtXr8bIkSNF11900UXo1q0b5s+fjw0bNuA///kP2rZtiwULFgDw95l//OMfGDlyJK677joAQI8ePQD4P+KMHTsWOTk5uPfee2GxWPD6669jwoQJWLVqFUaNGqWiJxBEC4clCCKleeedd1gAsv9sNht/3ffff88CYL/66ivR/TNmzGC7d+/O/37ppZdYAOwHH3zAH3O73ezo0aPZrKwstq6ujj8OgH300Uf531dddRXbpUuXABkfffRRVjgc7d27lzUajex5553HMgwjutbn8/F/jx8/nh0/frxm2Q4cOMACYPPz89mqqir+2i+++EK2DqTccccdLAB23bp1/LGysjI2NzeXBcAeOHCAZVmWra+vZ/Py8thrr71WdP+JEyfY3Nxc0XFpHSgxfvx4FgD72muviY6///77rNFoZFevXi06/tprr7EA2F9//ZVlWZb9888/WQDsN998w7Isy27ZsoUFwF544YXsqFGj+PvOOeccdtiwYfxvp9MZ0BYHDhxgbTYb+/jjj/PHVqxYwQJgu3fvzjocDtH1Q4cOZdu3b8/W1NTwx3744QcWgGy/EFJWVsZarVb2zDPPFPWBBx98kAXAXnXVVfwxpbrkngWufViWZbt06cICYL/77ruA66XysyzLTps2TfQ8CNP45ZdfRPLabDb27rvv5o8tXbqUBcCuWLFCdL+WfiLHvHnz2MzMTHbPnj2i4/fffz9rMpnYkpIS/pj0mZRDbV/i0rNarWxxcTF/bPPmzSwA9pVXXuGPPfvsswF1L0zDaDSy27dvFx2/5ppr2Pbt27MVFRWi45dccgmbm5vLtw/X5/r168e6XC7+updffpkFwG7dupU/Jtem8+fPZw0GA3vo0CH+2FVXXcUCYJ966in+WHV1NZuens4aDAb2ww8/5I/v2rUroF45mbi29vl8bK9evdhp06aJ+q/D4WC7devGTpkyhT/G9d+rr75aJOd5553H5ufni45lZmaK+j7Hueeey1qtVnbfvn38sWPHjrHZ2dnsuHHjAq4nCCIQcrcjiBbCq6++iuXLl4v+ca5UAHD66aejTZs2+Oijj/hj1dXVWL58OS6++GL+2DfffIPCwkJceuml/DGLxYLbbrsNDQ0NWLVqVcSyfv755/D5fHjkkUcC1rEEC5OtVbaLL74YrVq14n+PHTsWgN9qEoxvvvkGp5xyiujLb0FBAS6//HLRdcuXL0dNTQ0uvfRSVFRU8P9MJhNGjRqFFStWBM1HCZvNFuAauXTpUvTr1w99+/YV5XX66acDAJ/XsGHDkJWVhV9++QWA32LUqVMnXHnlldiwYQMcDgdYlsWaNWv4+uDy5NqCYRhUVlYiKysLffr0wYYNGwJkvOqqq0SWtePHj2PTpk246qqrkJubyx+fMmUK+vfvH7LMP/74I9xuN2699VZRH5BaE8KhW7dumDZtWsBxofycJXb8+PHYv38/amtrRdf2799fVF8FBQXo06dPyL4ERN5Pli5dirFjx6JVq1ai+ydPngyGYfi2VovavsQxefJk3oIBAIMHD0ZOTo6qsnOMHz9e1A9YlsWnn36Ks88+GyzLiuSYNm0aamtrA/rd7NmzRVZwuedZ2KZ2ux0VFRU49dRTwbIsNm7cGCDXP/7xD/7vvLw89OnTB5mZmbjooov443369EFeXl7Q8m7atAl79+7FZZddhsrKSr4sdrsdkyZNwi+//BLgGnnDDTeIfo8dOxaVlZW866oSDMPghx9+wLnnnovu3bvzx9u3b4/LLrsMa9asCZkGQRDkbkcQLYaRI0cGDdxgNptx/vnnY8mSJXC5XLDZbFi2bBk8Ho9ISTp06BB69eoVoLxwbkOHDh2KWNZ9+/bBaDSqmjwL0Spb586dRb85ham6ujpkPnLuKpybFsfevXsBgJ9cSsnJyQmajxIdO3YMCFqxd+9e7Ny5U+TCJKSsrAwAYDKZMHr0aKxevRqAX0kaO3YsTjvtNDAMg7Vr16Jdu3aoqqoSTfp9Ph9efvll/Pvf/8aBAwfAMAx/Lj8/PyA/qdsRV/e9evUKuFZJ0VJzf0FBgUjRDQclF6lff/0Vjz76KH7//XfRWhDArzQJlT1pXwL8/SlUXwIi7yd79+7Fli1bQra9WtT2JY5Iys4hbYPy8nLU1NTgjTfewBtvvBGWHHLPc0lJCR555BF8+eWXAfJJFd+0tLSAOsjNzUWnTp0CPtbk5uYGLS/XxldddZXiNbW1taK+HKw8wfpEeXk5HA5HwHgE+MdCn8+Hw4cPY8CAAYppEARBShJBEAIuueQSvP766/j2229x7rnn4uOPP0bfvn0xZMgQXdJXsgIJJ9yxxGQyyR5nWVaX9Lkvw++//z4KCwsDzpvN4Q3BcmuffD4fBg0ahBdeeEH2nqKiIv7v0047DU8++SScTidWr16Nhx56CHl5eRg4cCBWr16Ndu3aAYBISXrqqafw8MMP4+qrr8a8efPQunVrGI1G3HHHHbLBAeIZHU5rP5OTdd++fZg0aRL69u2LF154AUVFRbBarfjmm2/w4osvBpQ5kr4UaT/x+XyYMmUK7r33XtnzvXv3DimDND21fQnQ5zmStgFXJ1dccYWiYjF48GBNcjAMgylTpqCqqgr33Xcf+vbti8zMTBw9ehSzZs1S3abhlJdL+9lnn8XQoUNlr8nKyoo4H4Ig9IOUJIIgeMaNG4f27dvjo48+wmmnnYaff/4ZDz30kOiaLl26YMuWLfD5fCKLza5du/jzSrRq1Up2M0mphadHjx7w+XzYsWOH4oRCjkhk00KXLl34L8NCdu/eLfrNuSC1bdsWkydP1iVvJXr06IHNmzdj0qRJQV0SAb/y43a78d///hdHjx7llaFx48bxSlLv3r15ZQkAPvnkE0ycOBFvvfWWKK2amhp+IX4wuLpXU2+h7he6EJWXlwd8wee+uNfU1Ij25NFi5fzqq6/gcrnw5Zdfir7oh+siCSgrb5H2kx49eqChoUG3PqalL6lFazoFBQXIzs4GwzC6lWvr1q3Ys2cPFi1ahCuvvJI/vnz5cl3SDwbXxjk5ObqOBXL1WlBQgIyMDNnnateuXTAajQGKLkEQgdCaJIIgeIxGIy644AJ89dVXeP/99+H1ekWudgAwY8YMnDhxQrR2yev14pVXXkFWVhbGjx+vmH6PHj1QW1uLLVu28MeOHz8eEAb63HPPhdFoxOOPPx7wdTfYV9RIZNPCjBkzsHbtWvzxxx/8sfLycixevFh03bRp05CTk4OnnnoKHo8nIJ3y8nJd5AH8kbCOHj2KN998M+BcY2Mj7HY7/3vUqFGwWCxYsGABWrduzbvdjB07FmvXrsWqVatEViTA/1VbWvdLly7F0aNHVcnXvn17DB06FIsWLRK5NS1fvhw7duwIef/kyZNhsVjwyiuviOSQi9zGTUiFa3G4UMlq4b7iC/Oqra3FO++8ozoNKZmZmQAQ8KEg0n5y0UUX4ffff8f3338fcK6mpgZer1eTnFr6klqUyq6EyWTC+eefj08//RTbtm0LOB/OsyPXpizL4uWXX9acllaGDx+OHj164LnnnkNDQ0PA+XDHgszMzIA6NZlMmDp1Kr744gtRuPvS0lIsWbIEp512WtiuvgTRkiBLEkG0EL799lveoiLk1FNPFX2Zv/jii/HKK6/g0UcfxaBBg/j1PBzXXXcdXn/9dcyaNQvr169H165d8cknn+DXX3/FSy+9hOzsbEUZLrnkEtx3330477zzcNttt/Fhjnv37i1ak9KzZ0889NBDmDdvHsaOHYuZM2fCZrPhzz//RIcOHTB//nzZ9CORTQv33nsv3n//fZxxxhm4/fbb+RDgnCWLIycnBwsXLsTf//53nHTSSbjkkktQUFCAkpIS/O9//8OYMWPwf//3f7rI9Pe//x0ff/wxbrjhBqxYsQJjxowBwzDYtWsXPv74Y34fIADIyMjA8OHDsXbtWn6PJMBvSbLb7bDb7QFK0llnnYXHH38cs2fPxqmnnoqtW7di8eLFor4Tivnz5+PMM8/EaaedhquvvhpVVVV45ZVXMGDAANmJo5CCggLMmTMH8+fPx1lnnYUZM2Zg48aN+PbbbwMsWVOnTkXnzp1xzTXX4J577oHJZMLbb7/N170apk6dCqvVirPPPhvXX389Ghoa8Oabb6Jt27Y4fvy46jILGTp0KEwmExYsWIDa2lrYbDZ+H6ZI+sk999yDL7/8EmeddRYfdtxut2Pr1q345JNPcPDgQVXWPg4tfUktw4cPBwA89NBDuOSSS2CxWHD22WfzypMcTz/9NFasWIFRo0bh2muvRf/+/VFVVYUNGzbgxx9/RFVVlSYZ+vbtix49emDOnDk4evQocnJy8Omnn2paOxUuRqMR//nPfzB9+nQMGDAAs2fPRseOHXH06FGsWLECOTk5+OqrrzSnO3z4cPz444944YUX0KFDB3Tr1g2jRo3CE088geXLl+O0007DTTfdBLPZjNdffx0ulwvPPPNMFEpIEClI7APqEQQRS4KFAAfAvvPOO6LrfT4fW1RUxAJgn3jiCdk0S0tL2dmzZ7Nt2rRhrVYrO2jQoIB0WFY+3PAPP/zADhw4kLVarWyfPn3YDz74QDFk89tvv80OGzaMtdlsbKtWrdjx48ezy5cv589LQ4CrlY0LAf7ss8+qklmOLVu2sOPHj2fT0tLYjh07svPmzWPfeust2TDHK1asYKdNm8bm5uayaWlpbI8ePdhZs2axf/31F3+NlhDgAwYMkD3ndrvZBQsWsAMGDODrbPjw4exjjz3G1tbWiq695557WADsggULRMd79uzJAhCFDmZZfwjwu+++m23fvj2bnp7Ojhkzhv39998D2oALfbx06VJZGT/99FO2X79+rM1mY/v3788uW7ZMMTS8FIZh2Mcee4yXYcKECey2bdvYLl26BIRBXr9+PTtq1CjWarWynTt3Zl944QXFEOBnnnmmbH5ffvklO3jwYDYtLY3t2rUru2DBAvbtt99WnYZc/3zzzTfZ7t27syaTKSAcuJp+okR9fT37wAMPsD179mStVivbpk0b9tRTT2Wfe+451u1289ep7d9q+xIA9uabbw64X65N5s2bx3bs2JE1Go2iOlRKg2X9z/PNN9/MFhUVsRaLhS0sLGQnTZrEvvHGG/w1Sn2Oe86Fz/+OHTvYyZMns1lZWWybNm3Ya6+9lg9ZLrzuqquuYjMzMwPkUXr+pH1AGgKcY+PGjezMmTPZ/Px81mazsV26dGEvuugi9qeffuKv4caC8vJy0b1y/XfXrl3suHHj2PT09IBQ+Bs2bGCnTZvGZmVlsRkZGezEiRPZ3377LUB2giDkMbAsrQAkCIIgCIIgCILgoDVJBEEQBEEQBEEQAkhJIgiCIAiCIAiCEEBKEkEQBEEQBEEQhABSkgiCIAiCIAiCIASQkkQQBEEQBEEQBCGAlCSCIAiCIAiCIAgBKb+ZrM/nw7Fjx5Cdnc1vmEgQBEEQBEEQRMuDZVnU19ejQ4cOMBqV7UUpryQdO3YMRUVF8RaDIAiCIAiCIIgE4fDhw+jUqZPi+ZRXkrKzswH4KyInJyeusng8Hvzwww+YOnUqLBZLXGUhxFDbJC7UNokLtU1iQ+2TuFDbJC7UNomLXm1TV1eHoqIiXkdQIuWVJM7FLicnJyGUpIyMDOTk5NCDl2BQ2yQu1DaJC7VNYkPtk7hQ2yQu1DaJi95tE2oZDgVuIAiCIAiCIAiCEEBKEkEQBEEQBEEQhABSkgiCIAiCIAiCIASk/JokNbAsC6/XC4ZhopqPx+OB2WyG0+mMel6ENlpa25hMJpjNZgqLTxAEQRAEIUOLV5LcbjeOHz8Oh8MR9bxYlkVhYSEOHz5Mk9MEoyW2TUZGBtq3bw+r1RpvUQiCIAiCIBKKFq0k+Xw+HDhwACaTCR06dIDVao3qBNnn86GhoQFZWVlBN68iYk9LahuWZeF2u1FeXo4DBw6gV69eKV9mgiAIgiAILbRoJcntdsPn86GoqAgZGRlRz8/n88HtdiMtLY0mpQlGS2ub9PR0WCwWHDp0iC83QRAEQRAE4Sf1Z4MqaAmTYoKQQv2eIAiCIAhCHpolEQRBEARBEARBCCAliSAIgiAIgiAIQgApSUTMmTBhAu644454i6Ers2bNwrnnnhu19A8ePAiDwYBNmzYBAFauXAmDwYCampqo5UkQBEEQBNFSISUpCZk1axYMBgMMBgMsFgu6deuGe++9F06nM96itVhefvllvPvuuzHL79RTT8Xx48eRm5sbszwJgiAIgiBaCi06ul0yc8YZZ+Cdd96Bx+PB+vXrcdVVV8FgMGDBggXxFg2AP8w0wzAwmxOni3k8HlgslqikHWtlxWq1orCwMKZ5EgRBEARBtBTIkiSB8bFx+acVm82GwsJCFBUV4dxzz8XkyZOxfPly/rzP58P8+fPRrVs3pKenY8iQIfjkk0/48yNGjMBzzz3H/z733HNhsVjQ0NAAADhy5AgMBgOKi4sBAO+//z5GjBiB7OxsFBYW4rLLLkNZWRl/P+f+9e2332L48OGw2WxYs2YN7HY7rrzySmRlZaF9+/Z4/vnnQ5Zt7ty5GDp0KF5//XU+PPtFF12E2tpaUfkef/xxdOrUCTabDUOHDsV3333Hn+fc0z766COMHz8eaWlpWLx4sWx+NTU1uPbaa9GzZ0/k5eXh9NNPx+bNmzXJI3W3++STTzBo0CCkp6cjPz8fkydPht1uVyU7APzxxx8YNmwY0tLSMGLECGzcuFF0Xs7d7tNPP8WAAQNgs9nQtWtXVXVNEARBEARBBJI4n/kTAMbHYsWustAXhgnL+uBwNCIjwwmDQayfTuzbFiZjeBvZbtu2Db/99hu6dOnCH5s/fz4++OADvPbaa+jVqxd++eUXXHHFFSgoKMD48eMxfvx4rFy5EnPmzAHLsli9ejXy8vKwZs0anHHGGVi1ahU6duyInj17AvBbYebNm4c+ffqgrKwMd911F2bNmoVvvvlGJMv999+P5557Dt27d0erVq1wzz33YNWqVfjiiy/Qtm1bPPjgg9iwYQOGDh0atEzFxcX4+OOP8dVXX6Gurg7XXHMNbrrpJl7Refnll/H888/j9ddfx7Bhw/D222/jnHPOwfbt29GrVy+RPM8//zyvcMhx4YUXIi0tDUuXLkWHDh3w5ptvYtKkSdizZw9at26tSh4hx48fx6WXXopnnnkG5513Hurr67F69WqwLKtK9oaGBpx11lmYMmUKPvjgAxw4cAC333570Ppav349LrroIsydOxcXX3wxfvvtN9x0003Iz8/HrFmzgt5LEARBEARBiCElKUn5+uuvkZWVBa/XC5fLBaPRiP/7v/8DALhcLjz11FP48ccfMXr0aABA9+7dsWbNGrz++usYP348JkyYgLfeegsMw2Dbtm2wWq24+OKLsXLlSpxxxhlYuXIlxo8fz+d39dVX8393794d//rXv3DyySejoaEBWVlZ/LnHH38cU6ZMAQA0NDTgrbfewgcffIBJkyYBABYtWoROnTqFLJ/T6cR7772Hjh07AgBeeeUVnHnmmXj++edRWFiI5557Dvfddx8uueQSAMCCBQuwYsUKvPTSS3j11Vf5dO644w7MnDlTMZ81a9bgjz/+wIkTJ+ByuZCTk4PnnnsOn3/+OT755BNcd911quQRcvz4cXi9XsycOZNXXAcNGsSfDyX7kiVL4PP58NZbbyEtLQ0DBgzAkSNHcOONNyqW44UXXsCkSZPw8MMPAwB69+6NHTt24NlnnyUliSAIgiAIQiOkJAkwGQ2Y2Ldt1NL3+Xyoq6tDTk5OwEaeWq1IEydOxMKFC2G32/Hiiy/CbDbj/PPPB+C3ejgcDl5Z4XC73Rg2bBgAYOzYsaivr8fGjRvx22+/8YrT008/DQBYtWoV7rnnHv7e9evXY+7cudi8eTOqq6vh8/kAACUlJejfvz9/3YgRI/i/9+3bB7fbjVGjRvHHWrdujT59+oQsX+fOnXmFBABGjx4Nn8+H3bt3IyMjA8eOHcOYMWNE94wZM0bkJieVR47NmzejoaEBBQUFouONjY3Yt2+fKnmkStKQIUMwadIkDBo0CNOmTcPUqVNxwQUXoFWrVqirqwsp+86dOzF48GCR5YtTdpXYuXMn/va3vwWk+dJLL4FhGJhMpqD3EwRBEEQ4MD4WDU4vctLNMBjC84ghiESElCQJ4bq8qcEAA0xG/z9jhPlkZmbyrnBvv/02hgwZgrfeegvXXHMNv67of//7n2hiD/jXMgFAXl4ehgwZgpUrV+L333/HlClTMG7cOFx88cXYs2cP9u7dy1uS7HY7pk2bhmnTpmHx4sUoKChASUkJpk2bBrfbHSBXIhFKnoaGBrRv3x4///wzbxXjFNi8vLyw8jSZTFi+fDl+++03/PDDD3jllVfw0EMPYd26dcjPzw8rTYIgCIJIRDYdrkG13Y3e7bLROT8j3uIQhG5Q4IYUwGg04sEHH8Q///lPNDY2on///rDZbCgpKUHPnj1F/4qKivj7xo8fjxUrVuCXX37BhAkT0Lp1a/Tr1w9PPvkk2rdvj969ewMAdu3ahcrKSjz99NMYO3Ys+vbtKwraoESPHj1gsViwbt06/lh1dTX27NkT8t6SkhIcO3aM/7127VoYjUb06dMHOTk56NChA3799VfRPb/++qvIqqWGk046CSdOnIDZbEb37t1FddWmTRtV8shhMBgwZswYPPbYY9i4cSOsVis+++wzVbL369cPW7ZsEYV0X7t2bdBy9OvXTzbN3r17kxWJIAiCiBrVdv/H0iM1jjhLQhD6QkpSinDhhRfCZDLh1VdfRXZ2NubMmYM777wTixYtwr59+7Bhwwa88sorWLRoEX/PhAkT8P3338NsNqNv3778scWLF4vWI3Xu3BlWqxWvvPIK9u/fjy+//BLz5s0LKVNWVhauueYa3HPPPfj555+xbds2zJo1K8DVUI60tDRcddVV2Lx5M1avXo3bbrsNF110Ee/ads8992DBggX46KOPsHv3btx///3YtGlTyAAHUiZPnozRo0dj5syZ+Pnnn3Hw4EH89ttveOihh/DXX3+plkfIunXr8NRTT+Gvv/5CSUkJli1bhvLycvTr10+V7JdddhkMBgOuvfZa7NixA998840oEqEcd999N3766SfMmzcPe/bswaJFi/B///d/mDNnjqb6IAiCIAiCIMjdLmUwm8245ZZb8Mwzz+DGG2/EvHnzUFBQgPnz52P//v3Iy8vDSSedhAcffJC/Z+zYsfD5fCKFaMKECXj55ZcxYcIE/lhBQQHeffddPPjgg/jXv/6Fk046Cc899xzOOeeckHI9++yzaGhowNlnn43s7GzcfffdotDZSvTs2RMzZ87EjBkzUFVVhbPOOgv//ve/+fO33XYbamtrcffdd6OsrAz9+/fHl19+KYpspwaDwYBvvvkGDz74IG655RZUVFSgsLAQ48aNQ7t27VTLIyQnJwe//PILXnrpJdTV1aFLly54/vnnMX36dFWyZ2Vl4auvvsINN9yAYcOGoX///liwYAG/5kyOk046CR9//DEeeeQRzJs3D+3bt8fjjz9OQRsIgiAIgiDCwMBycYlTlLq6OuTm5qK2thY5OTmic06nEwcOHEC3bt0Uw0PrSbDADUQzc+fOxeeff45NmzbFLM9gbRMPeWJBrPt/uHg8HnzzzTeYMWNG1DYDJsKD2iaxofZJXFKpbX7cUQoAyLCZcGqPNiGuTnxSqW1SDb3aJphuIIRm6gRBEARBEARBEAJISSIIgiAIgiAIghBAShKRcMydOzehXNsSTR6CIAiCIAgiupCSRBAEQRAEQRAEIYCUJIIgCIIgCIIgCAGkJBEEQRAEQRAEQQggJYkgCIIgCIIgCEIAKUlEUlFcXIynnnoKjY2N8RaFIAiCIAiCSFFISSJkWblyJQwGA2pqagAA7777LvLy8uIqk9PpxAUXXIAOHTogPT1d9X3hluWtt97C1KlTw5RWHrfbja5du+Kvv/7SNV2CIAiCIAhCP0hJSkJmzZoFg8GAG264IeDczTffDIPBgFmzZuma58UXX4w9e/bomqZWbr31Vpx77rmay3bqqafi+PHjyM3NVX2P0+nEww8/jEcffZQ/tn37dpx//vno2rUrDAYDXnrpJdl7X331VXTt2hVpaWkYNWoU/vjjD/6c1WrFnDlzcN9992kqA0EQBEEQBBE7SElKUoqKivDhhx+K3M6cTieWLFmCzp07655feno62rZtq3u6WnjzzTcxd+5czfdZrVYUFhbCYDCovueTTz5BTk4OxowZwx9zOBzo3r07nn76aRQWFsre99FHH+Guu+7Co48+ig0bNmDIkCGYNm0aysrK+Gsuv/xyrFmzBtu3b9dcFoIgCIIgCCL6kJKUpJx00kkoKirCsmXL+GPLli1D586dMWzYMNG1Pp8P8+fPR7du3ZCeno4hQ4bgk08+EV3zzTffoHfv3khPT8fEiRNx8OBB0Xmpi9q+ffvwt7/9De3atUNWVhZOPvlk/Pjjj0Flnjt3LoYOHYq3334bnTt3RlZWFm666SYwDINnnnkGhYWFaNu2LZ588knRfSUlJfjb3/6GrKws5OTk4KKLLkJpaSkAYM+ePTAYDNi1a5fonhdffBE9evQAEOhup4YPP/wQZ599tujYySefjGeffRaXXHIJbDab7H0vvPACrr32WsyePRv9+/fHa6+9hoyMDLz99tv8Na1atcKYMWPw4YcfqpaHIAiCIAiCiB2kJAlhWcBuj88/ltUs7tVXX4133nmH//32229j9uzZAdfNnz8f7733Hl577TVs374dd955J6644gqsWrUKAHD48GHMnDkTZ599NjZt2oR//OMfuP/++4Pm3dDQgBkzZuCnn37Cxo0bccYZZ+Dss89GSUlJ0Pv27duHb7/9Ft999x3++9//4q233sKZZ56JI0eOYNWqVViwYAH++c9/Yt26dQD8Ct7f/vY3VFVVYdWqVVi+fDn279+Piy++GADQu3dvjBgxAosXLxbls3jxYlx22WWhK1GBNWvWYMSIEZrucbvdWL9+PSZPnswfMxqNmDx5Mn7//XfRtSNHjsTq1avDlo8gCIIgCIKIHuZ4C5BQOBxAVlbUkjcCyFM62dAAZGZqSu+KK67AAw88gEOHDgEAfv31V3z44YdYuXIlf43L5cJTTz2FH3/8EaNHjwYAdO/eHWvWrMHrr7+O8ePHY+HChejRoweef/55AECfPn2wdetWLFiwQDHvIUOGYMiQIfzvefPm4bPPPsOXX36JW265RfE+n8+Ht99+G9nZ2ejfvz8mTpyI3bt345tvvoHRaESfPn2wYMECrFixAqNGjcJPP/2ErVu34sCBAygqKgIAvPfeexgwYAD+/PNPnHzyybj88svxf//3f5g3bx4Av3Vp/fr1+OCDDzTVJ0dNTQ1qa2vRoUMHTfdVVFSAYRi0a9dOdLxdu3YBlq4OHTrw7UYQBEEQBEEkFqQkJTEFBQU488wz8e6774JlWZx55plo06aN6Jri4mI4HA5MmTJFdNztdvNueTt37sSoUaNE5zmFSomGhgbMnTsX//vf/3D8+HF4vV40NjaGtCR17doV2dnZ/O927drBZDLBaDSKjnFreHbu3ImioiJeQQKA/v37Iy8vDzt37sTJJ5+MSy65BHPmzMHatWtxyimnYPHixTjppJPQt2/foLIowa3zSktLC+t+NaSnp8PhcEQtfYIgCIIgCCJ84qokLVy4EAsXLuTXvwwYMACPPPIIpk+fDgCYMGEC7xLGcf311+O1116LjkAZGX6LTpTw+Xyoq6tDTk6OSCng8w6Dq6++mrfcvPrqqwHnG5rK87///Q8dO3YUnVNaV6OGOXPmYPny5XjuuefQs2dPpKen44ILLoDb7Q56n8ViEf02GAyyx3w+n2pZCgsLcfrpp2PJkiU45ZRTsGTJEtx4443qCyMhPz8fBoMB1dXVmu5r06YNTCYTv16Ko7S0NCDQQ1VVFQoKCsKWkSAIgiAIgogecVWSOnXqhKeffhq9evUCy7JYtGgR/va3v2Hjxo0YMGAAAODaa6/F448/zt+TEaYyoQqDQbPLmyZ8PoBh/HlIlaQwOeOMM+B2u2EwGDBt2rSA8/3794fNZkNJSQnGjx8vm0a/fv3w5Zdfio6tXbs2aL6//vorZs2ahfPOOw+AXxmTBnvQg379+uHw4cM4fPgwb03asWMHampq0L9/f/66yy+/HPfeey8uvfRS7N+/H5dccknYeVqtVvTv3x87duzQtE+S1WrF8OHD8dNPP+Hcc88F4FeMf/rppwAXxG3btgUE2CAIgiCIZMUA9RFkCSIZiGvghrPPPhszZsxAr1690Lt3bzz55JPIysoSTdAzMjJQWFjI/8vJyYmjxImHyWTCzp07sWPHDphMpoDz2dnZmDNnDu68804sWrQI+/btw4YNG/DKK69g0aJFAIAbbrgBe/fuxT333IPdu3djyZIlePfdd4Pm26tXLyxbtgybNm3C5s2bcdlll2my/qhl8uTJGDRoEC6//HJs2LABf/zxB6688kqMHz9eFFhh5syZqK+vx4033oiJEydqXk8kZdq0aVizZo3omNvtxqZNm7Bp0ya43W4cPXoUmzZtQnFxMX/NXXfdhTfffBOLFi3Czp07ceONN8JutwcE1Fi9erXuG9USBEEQBEEQ+pAwa5IYhsHSpUtht9tF62EWL16MDz74AIWFhTj77LPx8MMPB7UmuVwuuFwu/nddXR0AwOPxwOPxiK71eDxgWRY+ny8qE3wpbFMEOy7PSNIRppHVFGyC+y09/9hjj6FNmzaYP38+9u/fj7y8PAwbNgwPPPAAfD4fOnXqhKVLl+Luu+/GK6+8gpEjR+KJJ57AP/7xD75uuLS4/z/33HP4xz/+gVNPPRVt2rTBvffei7q6uqBl48ovPC+VVXicO/bZZ5/htttuw7hx42A0GjFt2jT861//Et2TmZmJs846C0uXLsV//vMf0Tmh7HJlEcrG5Tt79myMHDkS1dXV/Ca0R44cEVl/nnvuOTz33HMYP348fv75ZwDAhRdeiLKyMjzyyCM4ceIEhg4dim+++QYFBQV8fr///jtqa2sxc+bMmPQ7JXw+H1iWhcfjkVWwEwXuuZU+v0T8obZJbKh9EpdUahsv4wXgd5RJhfKkUtukGnq1jdr7DSwbRuxpHdm6dStGjx4Np9OJrKwsLFmyBDNmzAAAvPHGG+jSpQs6dOiALVu24L777sPIkSNFewNJmTt3Lh577LGA40uWLAlQrsxmMwoLC1FUVASr1apvwYikZ9asWRg8eDDuuusuXdO9+uqrMWDAANx99926pqsVt9uNw4cP48SJE/B6vXGVhSAIgkhOtlX53exsJqBXblynlAShCofDgcsuuwy1tbVBPdTiriS53W6UlJSgtrYWn3zyCf7zn/9g1apVovUmHD///DMmTZqE4uJifqNQKXKWpKKiIlRUVARUhNPpxOHDh9G1a9eoRjLjYFkW9fX1yM7OhsFAvruJhFzbHDx4EF9//XXQkOZacbvdePbZZ3HXXXchPT1dt3TDwel04uDBgygqKopJ/w8Xj8eD5cuXY8qUKQFBPoj4Qm2T2FD7JC6p1DY/7fJHo82ymTGqW+s4SxM5qdQ2qYZebVNXV4c2bdqEVJLi7m5ntVrRs2dPAMDw4cPx559/4uWXX8brr78ecC0XpjqYkmSz2WSjtlksloAKZRgGBoMBRqMxMNpcFOBcq7g8icRBrm26d++O2267Tdd80tLS8PDDD+uaZrgYjUY+umAyvAiSRc6WCLVNYkPtk7ikQtuYTf6ppMlkTvqyCEmFtklVIm0btfcm3Ezd5/OJLEFCNm3aBABo3759DCUiCIIgCIIgCKIlEVdL0gMPPIDp06ejc+fOqK+vx5IlS7By5Up8//332LdvH78+KT8/H1u2bMGdd96JcePGYfDgwfEUmyAIgiAIgiCIFCauSlJZWRmuvPJKHD9+HLm5uRg8eDC+//57TJkyBYcPH8aPP/6Il156CXa7HUVFRTj//PPxz3/+M54iEwRBEARBEASR4sRVSXrrrbcUzxUVFWHVqlUxkSPOsSsIIi5QvycIgiAIgpAn4dYkxRJu4ZbD4YizJAQRe7h+TwtTCYIgCIIgxMQ9ul08MZlMyMvLQ1mZP3xlRkZGVENz+3w+uN1uOJ1Oim6XYLSktmFZFg6HA2VlZcjLy0vojWQJgiAIgiDiQYtWkgCgsLAQAHhFKZqwLIvGxkakp6fTPkkJRktsm7y8PL7/EwRBEARBEM20eCXJYDCgffv2aNu2LTweT1Tz8ng8+OWXXzBu3DhycUowWlrbWCwWsiARKQ/Lsqhr9CI7zQyjsWV8/Gip+Hws6p1e5KSbW8yHLoIgokuLV5I4TCZT1CeNJpMJXq8XaWlpLWIinkxQ2xBE6rG/wo4D5Xa0y0nDoE658RaHiCJbjtaiot6Fnm2z0LVNZrzFIQgiBUjtxRcEQRBEi6Wk0h+cpLTOGWdJiGhTUe/fhP5wNQViIghCH0hJIgiCIAiCIAiCEEBKEkEQBEEQBEEQhABSkgiCIAiCIAiCIASQkkQQBEEQBEEQBCGAlCSCIAiCIAiCIAgBpCQRBEEQBEEQBEEIICWJIAiCIAiCIAhCAClJBEEQBEEQBEEQAkhJIgiCIAiCIAiCEEBKEkEQBEEQBEEQhABSkgiCIAiCIAiCIASQkkQQBEEQBEEQBCGAlCSCIAiCIAiCIAgBpCQRBEEQBEEQBEEIICWJIAiCIAiCiAiDId4SEIS+kJJEEARBEARBEAQhgJQkgiAIgiBSAgPInEEQhD6QkkQQBEEQBEEQBCGAlCSCIAiCIAiCIAgBpCQRBEEQBEEQBEEIICWJIAiCIAiCIAhCAClJBEEQBEEQCjS4vFiztwLHahrjLQoRJxxuL34trsDhKkdY9+8prcfv+yqxt7QevxVXwMP4dJaQiAakJBEEQRAEQSiw41gdnB4GO47VxVsUIk7sOlGPRjeD3Sfqw7q/pNIBu8uLQ5UOONwMSsJUtojYQkoSQRAEQRCEAj6WjbcIRJxhde4DeqdHRAdSkgiCIAiCIAiCIASQkkQQBEEQBEEQBCGAlCSCIAiCIAiCiBHkbZcckJJEEARBEARBEAQhgJQkgiAIgiAIglDEoGtqZEhKDkhJIgiCIAiCIAiCEEBKEkEQBEEQBEEQhABSkgiCIAiCIAgiRlDghuSAlCSCIAiCIAiCIAgBpCQRBEEQBEEQBEEIICWJIAiCIAiCIGIES/HtkgJSkgiCIAiCIAiCIASQkkQQBEGkJPS1liCIRIQCNyQHpCQRBEEQBJESGPTd85MgiBYMKUkEQRAEQRAEQRACSEkiCIIgCIIgiBhB7nbJASlJBEEQREpiAPleEQRBEOERVyVp4cKFGDx4MHJycpCTk4PRo0fj22+/5c87nU7cfPPNyM/PR1ZWFs4//3yUlpbGUWKCIAgiWaDADQRBEES4xFVJ6tSpE55++mmsX78ef/31F04//XT87W9/w/bt2wEAd955J7766issXboUq1atwrFjxzBz5sx4ikwQBEEQBEEQYUMfcJIDczwzP/vss0W/n3zySSxcuBBr165Fp06d8NZbb2HJkiU4/fTTAQDvvPMO+vXrh7Vr1+KUU06Jh8gEQRAEQRAEQaQ4cVWShDAMg6VLl8Jut2P06NFYv349PB4PJk+ezF/Tt29fdO7cGb///ruikuRyueByufjfdXV1AACPxwOPxxPdQoSAyz/echCBUNskLtQ2+uPzsThQ6UDrTAtaZVjDTifR28brZeBrWiGdqDJGk0RvHz3xMl7//72s7uX1er18+nqlnUpt01z34ZXnYKUdmVYzCrJteosWFnJtw0TYB7h7m/PwakqnosGFeqcX3dpkas47ldDruVF7v4Fl4xtjY+vWrRg9ejScTieysrKwZMkSzJgxA0uWLMHs2bNFCg8AjBw5EhMnTsSCBQtk05s7dy4ee+yxgONLlixBRkZGVMpAEASRTFQ6geMOf1CDga1T1+1je7WBjyKVyuUkgG1V/v5sMQF9cvVt6+JawMmk/vMSLlzdp5lY9MzVdm+DBzhYn/h1e6AesHvCl5OrI448G4tOGvQd7v4u2SyyLZqzJyQ4HA5cdtllqK2tRU5OjuJ1cbck9enTB5s2bUJtbS0++eQTXHXVVVi1alXY6T3wwAO46667+N91dXUoKirC1KlTg1ZELPB4PFi+fDmmTJkCi4V6eSJBbZO4UNvoz57SehyubgQATOrbNux0Er1t0neX85akSMqZrCR6++iJbVcZACDdYsKpPfJ1TXvdgSo0uPyWAL36USq1DVf3WTYzRnVrrene47VO5B/3e/wkyjMq1zYbS2pQ5XADCE9Oro44CnPSMKCD+jkpd3/fwmx0zEvXnH+qoNdzw3mZhSLuSpLVakXPnj0BAMOHD8eff/6Jl19+GRdffDHcbjdqamqQl5fHX19aWorCwkLF9Gw2G2y2QJOtxWJJmIEokWQhxFDbJC7UNvphNltgNvndDfSo00RtG7PZBJ/P/3ciyhcrErV99MRs8k9nzGaT7mU1m80wN3lL6Z12KrRNc92bNZfFYvHy9ydaPQjbxmQ2w2zy8ce1wpWR/62xriKp41Qk0udG7b0Jt0+Sz+eDy+XC8OHDYbFY8NNPP/Hndu/ejZKSEowePTqOEhIEQRAEQRAEkcrE1ZL0wAMPYPr06ejcuTPq6+uxZMkSrFy5Et9//z1yc3NxzTXX4K677kLr1q2Rk5ODW2+9FaNHj6bIdgRBEARBxATakpggWiZxVZLKyspw5ZVX4vjx48jNzcXgwYPx/fffY8qUKQCAF198EUajEeeffz5cLhemTZuGf//73/EUmSAIgiCIFkTihhMgkpX4hkwj1BJXJemtt94Kej4tLQ2vvvoqXn311RhJRBAEQRAEQRCJBylXsSXh1iQRBEEQBEEkCuRuRxAtE1KSCIIgCIIgCEIBg86aMktOnEkBKUkEQRAEQRBEzCH3MSKRISWJIAiCIIiUgFzjiGSAlMPkgJQkgud4bSPW7K1AvdMTb1EIgiCShmM1NHamIrUOT1O7enVN1+314ff9lShr1DXZkDS6GfxaXIGSSkdU0icFlQCAKrsbq/eWo6LBFW9RIoaUJIJn+9E6OD0Mth2ti7coBEEQScOOY/6xc8cxGjtTiU1HauD0MLqne6jSDoebQVljbNWK4rIGNLoZ7Cmtj2m+RMtiw6FquDw+bCqpibcoEUNKEhEAS3ZggiAIzfho6EwpfFF6F8arm0SrPIR2qCWSA1KSCIIgCIIgCIIgBJCSRBAEQRAEQRAJDhkDYwspSQRBEARBEBIoEAERLWhZQ3JAShJBEARBEARBEIQAUpIIgiAIgiAIIkaQHSk5ICWJCIAeXoIgCIIgog3NN4hEhpQkgiAIgiAIgiAIAaQkEQRBEARBEARBCCAliSAIIkqwLItahwc+2mWUICKmttEDpulZqnN64GF8Uc3PYKD4dnLUOT3whlH3bq8P9U5P2PlGer9aWJaFw4uojtsU3C45ICWJIAgiSuyvsOPPg1XYfqwu3qIQRFJzrKYRfx6owvpD1ai2u/HH/ir8tq8y3mK1OCoaXPhjfxXW7q/SfO/qveVYt78KdWEqOpHer5a9ZQ3YX2fAnrKGqOYTDiyt4ooppCQRBEFEiUOVdgBAaZ0zzpIQRHJzrKYRAFDX6EF5gwsA4PFG15JEBMKNZU4Po/leznpSbXeHlTd3f1VDePer5XC1v68dbepzkSK/JxIpO8kAKUkEQRAEQRBESBLBTSwBRCBaCKQkEQRBEASRNNBKIYIgYgEpSQRBEARBEBKipYyRkhcZ8u5ryUW4RUiBoicVpCQRBEFECQNNhwhCF1JpbphKZQmHSCf6Lb3+iNhBShJBEARBEESKk4gRzVPBKhSKFlDElIWUJIIgCIIgkoZEnOxrIcnFjzupoHSkQBFaBKQkEQRBEASR0KTCxJjQi+h2BtpEmOAgJYkgCIIgCEICzZVbJonc7PStILaQkkQQBEEQRBKRyNNYIhSRTvSjbVWMhXJMltHkgJQkgiAIAQ63F3tK6wN2lPcyPuwtrUed0xMnyeJPRYML+8ob4i0GoQGvD9hb1oAGlzfodQ0uL/aW1sPt9cVIMm20hAX+AHC4yoGdx+sCxp9EIRGaIdoiRKojOT0M9pTWo9EdnTZkWRbFZQ2osrujkr4aahxuFJfVg/ElQIeIIqQkEQRBCPjrYDVKKh3YerRWdHxvWQMOVTrwx/6qOEkWfzaV1OBAuR1l9c54i0Ko5KgDKKlyYO2+yqDXrd1XiUOV/gk6ER88jA+7T9TjaHUjjtU0xlucFkuka5I2ltSgpNKBDSXVAOSVukiU/qM1jThYYceGQ9VhpxEpfx2sxsEKBw5V2uMmQywgJYkgCEIA9yW91iG2GIX6Et+ScHkS09pABNLo1TbhSwZLaaquFfIJJs4p/oE+IhLBmhUMe9O7IlqWpGilGw6OBJIlGpCSRBAEQRAEgBTYAFlH8WNdF4k++U8U2GhHt4tq6kQyQUoSEQAN1ARBEC2TRLXStLzXUssocTjzjajPUWSeAb0fCy1FSOT1eAksmi6QkkQQBEEQOpCoCgZB6EW0rTiqZIh2dLsEtiUlssKUipCSRBAEES0S911LELIkQ5dNBhkJZRJ9oq/3x45ELy+hDClJBEEQ0YLejQRBhAHNq5VJhTVJkbQvdY3YQUoSQRAEQRB+EtRMI5xURhqiWS3kPhkIKW+xh+o8fpCSRBAEES1SdJJFL22C0B96rtQR9TVJMRi3I7GGpehrJSEhJYkgCIIgCACJvWi9JdES9aVEWbuTyM8Ai5bZN+IFKUkEQRAEQQBIXBezRIiqFm2SvYxq3SATvZS6B27QNzkihpCSRBAEQRAAyuqcWLO3ArUOT7xFiQrHahrjLQKhEx7Gh9/2VaC4rAE+H4t1+yux41id6vsPVtgVz20oqcbK3WWobHDpIarunKh14mCFHV7Gh9/3VWJPaT1YlsVfB6uw7WitrnnVOT1Ys7cClQ1uXdMlzSk5ICWJIAiCIABsOVILp4fBpiM18RYlKmiZRCcysTJ2RSsfPSwVR6ob4XAxOFhhR5XDjXqnV5MSXFzWIHvcy/hQ1eCGl2FRnqBKEuCX/3itE3aXFyWVDtQ1elHj8OBErTPitIXts+2of0yIJ6RPxQ9SkgiCIAhCgC/MtREJsqQiIhLU2y6lZopq+kmoa4Trd/Tsd6GSStRm0NNVUbgmKRWeaSJ8SEkiCIIgCIKIMy19Qp4o5Y9NdLsw70uQOmopkJJEEARBEAIS1poSA2K1B1EkJIGIQVEjf7IHcUhmEq17JUrUv5YIKUkEQRAEQQBIPgUklSaQWkoSLWU2FtWZQk2mCrnytrQ6SFZISSIIgiAIHUg2BSOZEM4pE3kfm3gQy36XSkqpEslgTSViAylJBEEQBEEASDxXo1BEdc4e48qIVjAGQhvJ9gwQ0YOUJIIgCIIQQF+SiZZKKqyFitjaJXj8o6Wsaqnn5G+R5CWuStL8+fNx8sknIzs7G23btsW5556L3bt3i66ZMGECDAaD6N8NN9wQJ4kJgiDUQ1NtItlINv2QJpDRI9bWrERsy8RTGhNNntQmrkrSqlWrcPPNN2Pt2rVYvnw5PB4Ppk6dCrtdvBP0tddei+PHj/P/nnnmmThJTBAEoR56nRGEPrQ097NELa/eYkWjnDoaknQh8RQtQi3meGb+3XffiX6/++67aNu2LdavX49x48bxxzMyMlBYWBhr8VosLFg43F4YDQakWUzxFkcTdpcXJmPyyU3EH5+PRb3TG1cZwum/9U4PbGYTrObU9p52e32wu7wwmwzITrNENa8kM6boTGxLz/hYNLi8yE1X36ZCa5eH8cFkjM54H+sAEcGm0m6vD27Ghyybf9rWIBirpFI2uhkAQLpVe70IFQypssE9g9EmEvn1QOhu64tQv6l1eGCzBI7NiaoEB6O20YMsmxkmo/rngmVZ1DV6kZ1mhlHDfYlCXJUkKbW1tQCA1q1bi44vXrwYH3zwAQoLC3H22Wfj4YcfRkZGhmwaLpcLLpeL/11XVwcA8Hg88Hg8UZJcHVz+8ZZDCS/jH/wMMOKX3aUAgNP7FCSNf77Lw2DNvkoAwKS+bTXdm+ht05KJVdtsPFyDKrtbNm//317+GVEri49h4GV8qu5xeX1YU1wBQH3/rXd68cfBKhgMBpzep0DVPQDg9Xo0lwVoHiM8Xo9oTI3Fc/PzrjL+75FdWyM7LfTry+tl4GuajaiRkSuf0WAMq1683sQaQzhZGC8TcEwKVwaG0Vb2SPnzYDXqnB70b5+D9rlpitd5GS+8jL8cHkH/XbnrBCb1bcv/9jH6tQHDND/zHHqk7fF4+TYRpuf1eAR9ySs6x/X/U7q1hpvx4Wh1Q3N63mY5nS43Vu0pBwBM7F0gmph6veLyyJXF62EUZVixu1y03oc713y9IWj9CMccfuyQjEVeQFl+aVuI7hWPz5FMyBlv07PgZeA1efkxnM83RB8Qyvn7vjLkpVsCZNcyxngYn6icLIuwxu9IOF7rxI7jdchOM2Nk19aKfQQQl39/WR32ljWgdaYVw4ryIpZDr3eO2vsNbILEc/T5fDjnnHNQU1ODNWvW8MffeOMNdOnSBR06dMCWLVtw3333YeTIkVi2bJlsOnPnzsVjjz0WcHzJkiWKihXhZ1tV4KDSvxWLZFH+GzzAwXq/sANbJ0S3JpIIuf4v7Ef76oBGr7b+tbPaAIYNTEuOcPpvhRM44dDe5485gCqn9vu4OirMYNFGeT4bFYTtozb/7dUG/outmnJyeZiNQN887fWSZmLRM1f1bTFhV40BXsEcT6keuDJkWVh0zY6FZOJ8My0sugXJV1iO9hksjjua+8PA1iyfjs0E9MrVZ/zfW2uAixEf0+PdcsIBVMg8fw4vsL/Of7yVjUXHzOZ7uPJ1yGThYoBKZ3P5u2az/NjRJ4/F7hr/3/3yWJgERoySBqDOLa43KR4f+PuVZJDezx1PN7PokaNcbu66NmksCpumY8IxrH8rFgwLRfml+Qv7QbdsFgfqm9OJZN5yqAGob6onkwH8GM4Rqg/IvUukaBljvD5//wf8dceiuf1jNdc5UA/YPc15cmXMsbLonCW+Vlh+iwnwND1DiTQvczgcuOyyy1BbW4ucHOVOmzCWpJtvvhnbtm0TKUgAcN111/F/Dxo0CO3bt8ekSZOwb98+9OjRIyCdBx54AHfddRf/u66uDkVFRZg6dWrQiogFHo8Hy5cvx5QpU2CxRNddJBxsgi+1HNIvOYlMpd2NTYdrAIRnSUrktmnJxKpt5Pq/sB9xX7ylx4ORtbcCnqavkKHuqXa4saGkRlP6JVUO7C1r0HQPAOwprcfh6kbN93F11LNtFrq0zojpcyNsn97tslDUKvRHr/Td5bwlSU05uTxsZhNO65mvWbYsmxmjurUOcXXs8Hg82LX0RwwdOhQms991SakeuDLo9cVXLXy+GVYM66ycb05xJVxN1pc+7bKxu7SePzepb9uotMG6A1VokLiXaX23yFFc1oD9ZfXYtGmT6Nmpa/Tgz0PVAID2uWno3755zsKVr19hNuwuBiXVDv7c0KI8/t03pkc+spo8Ksb1agOLQMvYerQWZfXNnjZyZXF5GP5+JRmk93PHc9IsOLlrK8Vyc9d1aZ2Bnm39M2vhGDa+Vxt4fSyf//hebWAWyC/Nv3e7LOwp9d87vHMrrC/x192E3gWaXMKkbDhYiR/X/IGhQ4fCZjXDK/G5C9UH5N4lUqwmI8b2aqNKHrfXh8wmL4POrTMAFnz769Ef1bCxpAZVDjefJ1fGttk2DOoo/jIkLH+6xYTGJi1JD1n1eudwXmahSAgl6ZZbbsHXX3+NX375BZ06dQp67ahRowAAxcXFskqSzWaDzWYLOG6xWBJm8ptIsggxmwK7g8ViSRolyWL28WUIt34TtW2I6LeNUv/nz5vNMJvYgOPBMJlMYJvi44S6x2JmNfdfi9kSVp83my0wmzza7+PyMptF98XiuRG2j8WsLj+z2QRfk/VB1fVNeZjNxrDqxSypl0TBZDaF7CdKbRtt+LqzBM/XbDaBYZssfWazuD9Ymp8Dk0k/+c1mM8ySJTh6pG2xmHmlVfjsmD3Kfam5niww+wyS58Esal/h30IlyV9vzaYxubIwMIaUQXq/2v7fLFfzdQFjGNM8DlqtVpGyE5C/4F6zpA4iUZLM5qa+ZDbBZDYHmJJC9QG5d4kUk4YxhjX4RM8nC0Q819GKyWyG2eTj8wzW5sLym80mmH0G3WWN9J2j9t64Kkksy+LWW2/FZ599hpUrV6Jbt24h79m0aRMAoH379lGWjiAIgiBaFvFag2pMkrWviU5iLKAIH2EkOP9qEO39Itz7CEJKXJWkm2++GUuWLMEXX3yB7OxsnDhxAgCQm5uL9PR07Nu3D0uWLMGMGTOQn5+PLVu24M4778S4ceMwePDgeIpOEARBEIROhJrSJvvkXytayhstxTZqG6kGSTfcPKOmYydAv6MQ4vEjrkrSwoULAfg3jBXyzjvvYNasWbBarfjxxx/x0ksvwW63o6ioCOeffz7++c9/xkFagiAIoiUQ69DPiUS8Sk6GJH0mw8HSUNOv462Mhpu9KHS5LpIkJslWtmR/rOPubheMoqIirFq1KkbSEARBxA+aJBItGXK30594KzxaYRF6XpgqtJRyJjupvfsgQRAEQRCqSVRdhaaUqYnU8kXtHIhUnyL9KnaQkkQQBEEQAhJVUUhlWladyxdWj8mv2O1Me4LxXv+ih9tcpPXIiv5OLI2EFKTYQkoSQRAEQbRghK4/8VqPpSXfWE0Uk0VvE8qppWpCuXxFLXBD2Ccll7ZQhSEeHxRa1keMZkhJasHUONwoLquHz6c80rTQMahFUdvowd7SehSXNaCszhlvcVKWgxV21demqr8642Oxt7QetQ6PbmnWOf3919u0aa9eHK1pxBHBhp1acXoY7Cmth8PtDX1xDNlX3gCfj0VxWT2q7G5//TVt5gnEbzJkDDEbSZRnorhM3/4rRI8SCutpx7G6oP0v0iqtsrtljx+pduBojX+z6tI6J7Yfqw3YlJebfzA+qbtd9Nu52t489+HGD27T78NVDlQ0uEKk4K/nfeUNqFRxrZ5U2l0oqdQ+LnkZn3/sbQyv7wbrK/WSOhTicDMydyQPCbGZLBEf/jro353aYjKiS35mnKXRF5Zl47bfR7Lx54Eq0e/J/dPiJElqU1zWgFaZVuSmJ95mo7HiQEUDDlU6cKjSgcn924WdjvDR/mO/v/8yLIu+hTmRiggA8LEsdh7z78jeNjsNVrP274lbjtSirtGD0jonxvYq0EUuPThQbke13Y0ahwcHK8JXAvUmWSIKHqxw4GBFZP1XDUqT0pDWH8HflQ1uHKp0oF97+eciUnVkw6HqgHrwMD7sOl4PAGiXbcPWI7UAAK9kQ1Zu/mEyidtdF5fDECVbf8ift9Vkwp5Sv6xeH4tubTKx+0S9qjxK61w4UO7/8BXtviDE4QpP6dhXbsfhqsjHXjnWNY3BTo8Pgzrl6pp2vCFLEgF7mA8dQRDacHvVWTsS5KO57kRzrGlw6mexEX7c9oXZGHVNX2xdHn0tXHpQEyVLSCTQNy19kHZXqaVGfG3guUjXNAnzE2btVrD0MozUkhQ7HJ7mMaPB5Q1aV1IaPck1b2pwRfbMq3k+65yJN65ECilJBEEQMSLYiyacL+nJNrGMprx6Tq6SrFqTFuEk3aih0mO1mD7W3gi6uBTG+AOLnm6QLCtOL1TSwuYRBVtQKZJ0zJVr7risy0pSUvHjHilJREqSig8rQSQK4T5fybIXTpKIGRViWXZxP2rBlS6DFkVQrCyovy/UleE85/HrP7El2XprLOoq0SIB6gEpSQRBEAlG6r1qog99GEk+hK6MoSbX1Lzq0PIcyF2rZz2HF4I8zLx0GAC0WPNb8oeUlgQpSURQEiWiEEEQyY9eEws5N6hojVUtbQiMZQAF4RIQmnOqVxD02lw0Gl/+1fSfYPIm2vOWCPIkggxqSBY5tUBKEpGSpOCzSiQhFGFRTDQn4PquSaJ2iwXCSbqWZyXYZCxVHrnwFR/98oj0mQqnDLF02UqVvqKGWNQql0cq1SspSQRBEImAcF1BKn6SQ+i9cIj4E8tJqqZuHodHItaTPdUBByRyiYMWRFZRWu8XXh5pfbFgRYXRc32VGrTIH/GHlBQc4lPxvUWvLCIlScWHlUh+kvkDW6x9/rVCj3zyIVyTRGO2PuhpSQovf/lE1ealIQq3sgwp1pX0+HARm8ANqQcpSQRBEAlGKr5sgGiHAE/VWktdYuFS1hLQEjY73HRjRbjPcaSi+sOPq78+lVzKdCMFH0xSkoigpGCfJwgiToQ7r1A1WaPBShat1RLLebHIkhTi2lRVgkUKDtTXhygN0d9aXNSiW6dhrUnSZasodYm0JD0nFoFtUvEZNcdbAIKIBqn3qKYOxWUNKKt34uSurWExBf9Os+VIDRpdnpRzn5Ajmb5MFpc14FCVAx1yLJruS7RAFl7Ghz8PVqNNlhW92mXLXqP1xV9e78LuE/V6iIetR2rhZhic1LmVqrpjWRYbSqphMRkxuFOeLjJEEz1cqwBg7f5KfRIKgyPVDhyscGBY5zxk2mIzpZKOh5tKagQnxedO1DpR0eBCusWENIspIB3Gx+LPg1XIy7Cgb2GOROGKXDaOukaPIF3llIVnth2tBcsCw7uE7v+6uKSpTMPt9UX8jEdDoSird2LPiQYM7JiDvAxr2OlsLKkGAAzr3ErTfan4niZLEkEQMeVghR0OF4Mj1Y0hry2rc6Ha4YbbFwPBEohEfNlIZfJ4fdhXbteURrg6kjRvuWTCqbLjtU7YXV4cqnSEI5Ysmw/XwOlhdEmrtM6JarsHdre69BpcXlTbPSirc6m6Pu6BNIRfoSPo8w1Ob+SyyKCmu+46Xg+nh8EunRTjSJGrRi/Dot7pRaXdFXBteb0LDU4vjlQFH4/DsURoVQT8Lm/N91TbPahxeNDgik77CtEyNpVUaRv3YsWWw7VwehhsPFwTcE5tS7i8DCob3KhscMPDhH7xijYyTsD3VqTEe4gkCIKQhRZypx7CeYhPLzNCE/Fy7YkWsej/aWZT6IuiSGq55+jiJ9b8p0L7hwzbrUEMlmVFLo+JgC7udlEeC3QeukKitTwME76AomiFYaeSOpCSRKQkCTbuE2FAbZh6CF1m9J6cpdaEO/LJiholK5lqjFWhQCQjehdFa9hs6dXiepb/W5qGYvo6KSuq3HQpKp4uUB2IISWJIAgiwUi1CT+HUeiaoeG+aNVGItezULJw3BSTYbIjljEJBA5K5N/d1a4HCtYfgm60K5FR6t6mN3qlrFTcSJ/fcN1/pbclg9KuVkStwUPklVp1eSUDpCQRKUkiT36IlkuiBS6INcJJmu6WpBR75MNbA6JHvjok0gKJ5aMdrI0ibr4wLEaKSYXhMig3Lmg1JMW6C6fSM5NKZdEDUpIIgogLod57LW2sVuPaIiWmEzNd0hB8pYwgQblyp3J/CWcT3nC/AscS0cRWw1qbRGzrpPz8wYaq9zAU9QgbR+52RVc/3V0VY4emtWN65KcyFS3PZEuAlCQiKMn0kCSRqIQKhF8hk3ICQgRF6wLzlkZLKHGit2twtzax7HpYifUJWhDU3058rZb1SzGybMrlo5SO0oRevaz6vFkSuxdrQ7x3WSqVLDxISSJSkgR/9xJILb9lQh3C51J/d7voPPTxGktEgRvCWpOkJnCD3IQ0PgVOtiFbTVh6PdOPxn2sjCVJL2tvuPfLW5Ji0zvCzSfRlX0Aqh+wZChKLCEliUgZ6OFOLag5UxstSpIq17HwRQkgERT4lvAVN5lLqJfs8awDf3Q77W5YouOS51iUnk7R7dTmHS8SQwp9ENZpglRvXCEliWgRL2OCiAea5toJ/hjqMSHRa3F1OGt05EjkSUA01nakConQboHudjqkqUOrJZIbq1J5tK6DUiOm1qhsehLt/hhLZTDWe0AlOqQkJREuL6Nq52mfj0Wtw5MwX1k41MpPtAz0muhGSr3TA7c39M7iepAYJU4MWL2rXMVw5/b6UO/0aErW7m5ZY1Ykrw3u3SP8vxBp/asJVuL0MHBE0AZODwO75L3jYXwor3fBwzR3wgaXF9V2t+S9qfzE1jZ64BXcX+/08veyrHz5+VRVDQRhun4FuU8u22hGynO4Gc33yFaZUuAGzakHR216jKTSfKz2OVesp2dqsxOWocruRrXdHfD8hMvx2kbUONy6pBUrzPEWgFDP6j0VAIAxPdsg3aq8U/qO43U4UetE1zaZ6Nk2K6I89bQyqZU/XMgillrE4iVS5/Tgj/1VCeFeJSTBvm9EBU3udhq/JCvxy55yAMCo7q2RnWZRlfeWw7UY38cKiynxvylKlY6QESR17mfbj9WhtM7J/+7UOh19C3P436v3loNltdX/mr0VEcnE3T+2dxvYzP73ztajtahqcKNVphXDu7SC2+vD2n2VAICBHXNRmJsWMt2NJTWicaPRzeBIdSOKWmdgT2kDDlc5AsofCn0CN2i4FoGTZz0jye04VqeQryAojyG0sqzm2Q5HvnDH/SNVjaLfmw7XoMHpRZ/CbBS1zggv0QRBqKQK2y8rLXJ1YfvROrTOsuKkztaI04oViT/qEwHUhfgSeqLW/5I6VGmPhTiaCSW/HrSESWaqEwult9ru/6pF/SU0elRRoli3q+3axiCnR/sX8UgJJyS86P44fDQSKkhA4GSSK0cV99yJXKSiK6/d1dyGVQ3+/Lnn3+VtPif8OxTSdjlc5RD9X1p++TTUKAD6rt9rTlf9edVrl9R80AhDEUtkK02D029p4do9EVG9mazChZFYc4Uk2PfIkJCSRMScZHtICCLWhDNhTBQFRC26u8pEsfjx2ASYLOPB0F43wVqQEXw+j6QfSd2wIiH86Hbabox03Ii0xNJHSzbiogqlSp+POJHdnwrreZTK0FI3QicliYg90XrWUmCAakmEGnOTbM4fMeFMipPtxRVuk+rtbpMM1RZW/9dofdKw/ENXeNkitJbpBaPT7DbSZHSZ6Ac5Jx0vWJknS+l+PdtHa1qas1Z5g97DgN7bGnDo0y9UWgIVrkuCITMqkJJEpCT0FZYgUpdkUHIiJTwdKTnGPRkdKa6ILEmC41r7WbQmyVrQrIDo5OLG36PqGr2sXTrXd8SWpPi3f6RE2xqWbB/2SEkiYk60opol//BEpDpq3w9hrUFJggdArw0y9SprIleZaL+SKEmaSC6aWjdB1RO93OSiplRoSjZx2lSJ4IqZzDFVacZufZuiDHHJVV+UIjIGa7Mk03s0QUoSEZRovENT+YEiiFQlgebTMSdZhix9oqNFv6GbQ2VHPStVeBnhmqTw1yf5IgxrL57oxwpxTrGQQdkupDxBl1WeEqT/cETr2Yll1EPF9V/BQstrGCCTZSzlICWJiAnCwSMWD0miDZ6EdqgNY0O8rAmJZMVIRCJckpTQz0+iiZYKblIcmoqioHxElr+a9YMa3e2UlCdRmirTEs5FZNZoRUKkSnKkBFNW1JZMqQ60lC1R9kDUA1KSiJggHMCi5ZOaQu85IkVR/SKPrhhxJHVLpjfhuVzKuBwlcJXHMgR4sNeO0pqkWKOLxSBK1+sauCFG+cQj/Xiix9QqnDVJybbOSAukJCUhydgdRYthY5wfkZiEjG6HxJi4xIpIX94toY5iRUKMsTFoULksYtGPYtXX1Vos9AoBrid6rd8Leq3keml9RbLnkdp7VN2vYzAK5XsSpOHjTDhW1YQYL6MEKUlETPCJTNxxFIQgkoBEfGHr8aVfv4ALsa2feIxZYe2VJfw78bqQgMA1SXrJG05TKQduiMX6LBXXaEjPtvEvDLv2EmTu2RmePIrH9awLre52CsfDUYaCnUvUZ0alXMHc3NS+U6JdB8k2/yMliYj5wBC96HaxH+FYlsW+8gZUNLhinjcA1Do8KC6r122fD8C/s/ae0no4Pep3nldLMH/wwGt1z55IMNT231j3BYdb/76vlWgoEIGZKJ9yehjsKa2Hw+2NUubRV0HU1pswcAMn1dGaRlTbPZrz3FNar+n6Kodbcx7B6HzedOT/thLDrr9U1fV6vzdVGYY09m01wQT2ltULjospq3fiQIU94H7hG6je6UVpvTO0MDpSXFaP4rJ6lNeL5w/cs9eoYhz662BV8/0aplYsy6K4rAGVkrlLOB/oyN2OSEoSqd+KTLgxkCtWX+JL61w4UG7HppKamOQn5c+DVThY4ZB9AYSfZjVKKh3YerRWtzQJP9HslYlofQpFc/9tiLcoCUdYgRuEk88I899ypBYllQ6sP1QdYUqBROxup3NXl7oY+Xwsdh6rCyutkkqHpuu3K+QT7vNsdPknvWllJ0KmKY0aFxBqX+jyHKs1STJn1ShywQILbDlci31lDahxuIPW65GqxpD56MnBCgcOVjiw+XCN6PimwzUoqXRgQ0noZ6/G4eHvDza1kpa6tM6FgxV2bJTMXcJpZi1TumQL6kBKEhETYjF/i8ccMRrWlnCwu/T72uvx+t82tQ7tX1FDodVfPtnR8qEi8Ft2bIjlc6OUVYMr+HMknSTp5rYnCvecWD0uvD13Ii8Pd1tdo//5d3n0D9nFSZYodS5VFOIllaLFJIr1FK09yLTkqf9x+RNury8p3isNTv/7XI0lSYjY3TZ4SRsV5i7htH/Aey659KCgmNVeeNddd6lO9IUXXghLGKKFkAyjFBF1UmgcbRHoHipY3+QiJkHm6zElXptuRopaudWWLlofKBLJmwMIo2wqLJPCtjBArftcZOvt9CLR2kcJ1c9pojzOiSKHDqhWkjZu3Cj6vWHDBni9XvTp0wcAsGfPHphMJgwfPlxfCYmUINYTkFhll0JjQUzQUl+J8pU5kRG+45OhtuLxpTxZCWviniTVyDV3qLUpevYLLYvaE6E/RkUCGXe6eEQR1Ro8QVFBi38zJQ+q9azoVmqyKKYcqpWkFStW8H+/8MILyM7OxqJFi9CqVSsAQHV1NWbPno2xY8fqLyWR9MTiiyWNl0SiQxGG5AlV3JY4GYo0clf4VRaLsTqyPIwVFTj1zMk4fvYFOHDT3cr5qH3eQvwOF63PWXyCD6mTQdUmsWHmGfp6/eollceSeFmGk22dkRbCWpP0/PPPY/78+byCBACtWrXCE088geeff1434YjUIeaWpBQeCJMZcXS7ENdGWRatJMLX5WRHr5d4NFoi0Vo3rBDgISwziYyW8rZe+C9klBxAj1ef1SfvBK83vUQKVccBFrXwMolYjoDrlSzQSgqdjnknK6GU32iqNalUx2EpSXV1dSgvLw84Xl5ejvp6beEviZZBOBuUEakH9QJlRBMUqqiYk3BKcBwX0Mcq33DzN3jUBapRb9kQupyxOu7ZJD8V1RqIQC0ZB4o1JRi3QDqKSg8RCXr0W61rylgknmeCnoSlJJ133nmYPXs2li1bhiNHjuDIkSP49NNPcc0112DmzJl6y0hIiWGHjMZLNFpfGRJukhNDUrHkLbg5wyLZ6kvL1/twi6ZfFDx90tGUpyh/tW5jkSvaepZVafIkv/5IvSxsOO/AIPcEutvF/2EKpx0GzblB9NvoEu/7o6WOo4nWLP2hygPvCkfZTHSroRxq5VRbbkI9YSlJr732GqZPn47LLrsMXbp0QZcuXXDZZZfhjDPOwL///W/V6cyfPx8nn3wysrOz0bZtW5x77rnYvXu36Bqn04mbb74Z+fn5yMrKwvnnn4/S0tJwxCbiiI57naqDBoSERLxdlvqZTktrzlhO0mJZt4n2otZnDU90CGtNkkhHUrGGJM6FDrufR/DpOtRkW9c6ifEX9uxd20S/jW7xRrXyQRHEVgEo1IVahUTVnkYaKzkRlNaWityjJm0+UQAhVj9LbCKgWUliGAZ//fUXnnzySVRWVmLjxo3YuHEjqqqq8O9//xuZmZmq01q1ahVuvvlmrF27FsuXL4fH48HUqVNhtzdvjHnnnXfiq6++wtKlS7Fq1SocO3aMrFXJSAq7jhBRgtqzBaFtrYRaUtkNJBlQtCRF+HCzKrUP9RYrVnReP3c7bajJNphsrvw24vw9boUrm/NLxfdmIipVlspymBrULUeJ57gl7Q9GjcKE6k/JNiarjm7HYTKZMHXqVOzcuRPdunXD4MGDw878u+++E/1+99130bZtW6xfvx7jxo1DbW0t3nrrLSxZsgSnn346AOCdd95Bv379sHbtWpxyyilh503EllgPWrHKL1Fc/BJFjlAk4ssrlkSz9NGu21j5u6tLR6X7mZY1F8FcVdQnoxthBW4Q/p3Aj5psCHAtCURiSZJJJhGrSrwxsLp7HF17wlZZwf+WWpLk81Eng6qADCrlDOZZEm2XwHgs/cxdvw4jrjoXTEYmfv3hD3jyWge93mDQX86w1//JWZIiEyWp0KwkAcDAgQOxf/9+dOvWTVdhamtrAQCtW/s70Pr16+HxeDB58mT+mr59+6Jz5874/fffZZUkl8sFl8vF/66rqwMAeDweeDweXeXVCpd/uHJ4Gf9iVa/HGzQN7jqjz6DqOq/Xnx73Wyqz2eDDjuN1sLsYDO+cB6NR+wvKLUjf4/HC49H/c4LHqz0PL+PDX4dqkJdmbLpPW9t4vV5BnuH3r2M1jThQ6cCQTrlodDPYU9aAAe1zkJdhCZ4/34bGiPuVHGrSZHws/jpUjVYZFvRulx30Wo+Haa4vrwcej4k/d6LOiX3ldgzumIPsNAvfZxgvo1oWrXgE7Scvb3OeXkZ7W3u9DLxM887mu47VAACGd86D2SQ25AtlcXs8ov5b7/Riy9FadG+Tifa5aYL0vaI+b2R96uTyiMviU/FMC9uOQ2vbCOX1ip5X8Vi18XANquxutM60YlhRHjwecTtxYxYg7r9SObwMwytUwjGOH/Mk9aDUF9YWl2FcrzYwKEzOm9OVf544uRrdDDYerkFR63QUtcqQTav5HnHbCh6VIPc0l6G8zoH1lQ1gWH87ZR7YhxE3XIb919yCwxf9XTkNryGgLjweD+wuL9YeqAIA9Gqbhc6tA+WXll36DuLOH6lqQPf8NNGY7fWa4PF4UNHgwu7SBvRvn43cNItsfQrdtaTnvUxzfW8sqRG8Nz3wmP1jPnfMYGgqq6BfllTWo8buDDouqMXLACt3nUCH3DQcq3WiW34GOuSlw+ttHtcYL9PclwX1wXiBjQcr4fIyGNgxlz++41i1Yn5Ge4Pot8/VGLQcWw9XIctm5q9ZW1yORg/D16/JYMKmQ5Vo9DDoWZAlm9ave8vgZXxN8hsCnlU5DDDy9whxu8VtweF/V5gDjyvkJZ0jNb9zvPB4hM+r/DMvbButLN9+DIxEC8zauhEGloXZ3gDrwX1oHJQTcJ9IXm9zG3y39aiqfKXPrNvjgUkwrgvP7SutBcs2H9txpBq92mU15S2uU6MhsK3cbrfouWWY5neD2+OBx6vc/sKxOxwinUdL0wlFWErSE088gTlz5mDevHkYPnx4gItdTk5gBwiFz+fDHXfcgTFjxmDgwIEAgBMnTsBqtSIvL090bbt27XDixAnZdObPn4/HHnss4PgPP/yAjIzgL6VYsXz5cs33sCywvdrf4ct3scixKl+7rcp/ncEANO5T1vm563KtLA5lNf8WUr+XhdXUfO5ANous4PN2WRo8wMF6fxpVu1lkhpFGKCqdwHGHtjwqnMCJpnsGttbeNmWNQFmj/37X/vC/rxxqAOrdBhzIZHHM7k/vNwMwoFXwNLl2ybKwOBZcPwmZhhxqylTlAi/zwNbBr/f4gN01/mtLM1nk2QLl+NME9M5lYfcAB5r6TM+c8J6bUAjbXw5h+YvrAKdXW1vvqjHAK6O37NnIIj9NfKzeAxxSeEaKawEnY8CvENdxtQs42lT39mIWZpUO1McdQKXTf1/jPhZqvnu4GWBPbeCFWp6bo3ag2tU8jpU0+P/OMLMo3S6fT0keC68P2FfXfOx4JovWTX1H2H+l7bKt2sB/9nTtZ/lrj2X467+0EShvbK6/XTXKFVG2U3lM4dJNM7FwMoFpcHIdbgBq3eqeFeFzVbuHRZqKt7XwnvWC45s2bcJlzz6M9ONHMeCJB/B59/6KaaSbWZRtD6zXA/WA3dOctpz80rFE+g4Snj+83X+cGz+zLCyOZjdf86sB6J/HYkd1YH0WHD2Kdk1/b/jjD7DGZg0yzcyiYkdgftV7WGSYAcYH7OTa2QA497HYW2uAS/t8WDPc83vCAVQ0PX+bNm2Ct2QjAPH7xGryPwsAsD+b5cdCWXw+nP3Wy8iVrEnatWEjKkorw5bXbAQ/fm1LZ3nZlEg3sziYjuCyAjAZAEam+9fuYVHubH5GOA6n+5/XnZK+kGtlA64FAudIXD8o28UizQTsbRpfDoco06ZNm4KWQy3pe3ejX9Pfe7ZuwxFX4EtBOHZtrzZotvwIxzcgcFwXnlsPoDCD5d99wudZOEYDgMXof28Lcexj+bbItrBw+5qfH+E5OVrZWBxUvypHkUjnAw6HQ9V1YSlJM2bMAACcc845oi9rLMvCYDCAYbSPNjfffDO2bduGNWvWhCMSzwMPPIC77rqL/11XV4eioiJMnTo1LOVNTzweD5YvX44pU6bAYtGmJbAsi7Td/rDrgzvmoiDbpnitbVcZAL8v6cQ+BSGvK8xJw4AOOfxvIaO7t0aG1cyfG9opF/lZynkrUWl3Y9PhGgDASZ3z0CojiJYXJoerHdhT2qApj0OVDhSXN4DxMvCWbNTcNgcq7Nhf4V9DN6lv2/AEB7D5SC0qGlzo0y4bu0ub/ZZDpcm1S36mFUOL8sLKW67d1eYP+K1gO0/Uq7re5WGQtc//0u7fPkdkFeHkSLeYcGqPfFQ73NhQUgPGy6Bhv/a2UcOhKgeKyxoUzwvL88fBKtQ7vQHHg5FT7P8SLKV3u6wAS0Jlgwubjvit6dL+u3Z/FezuwLyFdX9aj3zYLCrMDQD2lNbjcHUjAGBC7wLRF0clGt0MsveLJ1xan5sdx+twvNYfcWtwx1xsOeovb166BcO7+Pfdc3oYZO9rzue0HvlwMz78cbD5C3rfwmx0zEsHIO6/0nZJ213OW5Im9W3LX9unXTY6tUrH/nI7DlT6n9/TerZBZnEFlAg2pnDpZtnMaHAFfkXl5Np6tBZl9S5ZWaUcrWnErqa2Hdm1FbLTQtfvkepG0fjBeBls2rQJI7p3Q7edW/jjw0cMV0wjN92CEV1aBdTrX4eqUdvoER2TIh1LTEYDJvQukD3fo8A/U9pX7q9/bgwTXjOhdwHS9wRuN9LxrxX83yMGDYIvPZ3/nZ1mxsiurcGyLGy7m+8d0aUVctMtcHt9yGhqZ+4d+fv+SjjcMdCS4K+34rIG7C+rx6ZNmzB06FBMHdgegPh9YjUb4W7SUEZ0aYW/DilbkFr/+RsG/74y4PjA3r1Q329g2LIKZeian4mDlfag1+ekWdCzbSY2lNQEvc5sNMAr43M3smtrHKy0888IR7f8TBS1TkfGXvHz2TbbFnAtAAzqmIu2gjkS16cGdcxFls2EnP1+i2iPgkzsK7cje/cOdPziYxTfcAc6/O8zeGzp+LpzLwwdOhQms7oxNRidV37D/92vR3e0k3n+hM9T5p5y2foJhnB8AwLHdemz2bNtlujdx+XPjdG2shPo9u5rKLt8Nqo6dhHdO65XG74t2mTZ4PQw/LgnPCfXzh1y09GvfZhfdBHZPFoI52UWirCUpBUrVoS+SAO33HILvv76a/zyyy/o1KkTf7ywsBButxs1NTUia1JpaSkKCwtl07LZbLDZAifxFotF9wlWuIQji8/HwmzyN5fZYg56P3ed0QhV15nN/vS434GymvlzJnN49Wgy+fg0LGGmEQqzyaI5D7O5uWxeaG8bk+D+SMrkl4MRyaMmzeZ2Cd4n1KQhh6o6tHhV1wEDo+BasczN/dHkbwczG1AXevcbi6S+A85L5OPel2rlMJtNYGTiFZtNgWUxW3yCOhCfN5lNMDMyMgnq3myxwKJSSTKbLTCbPE1/mwNc/+TwsAbZutLy3Aj7t1k0rjT3BWEf8V9ngc/oEx0zmZqvD/a8WMwm+HzN5wLGPIEM0mdPSrAxRZSGjKcJd5/FbIHZxMjKKsVk8kjaVk39emTL0P/lp2Tllc838H1gsVhgMplhNrGiYwH5S9I1mQyyzzjgrwsfywb0AWm+crIaBZYjK8PAK+wvTfIL35lcfhaLBayhuS9x70ij0QyzKTYryrl3Kjf5NjWNd/6/m/ugwWDgn0urVb4e+DQVXIcsPl/Q+0JhNhnha3LhNZlMIdMym81NY0vw60wKpiSLxcy/C0XXK8xR5K4F/OO6XL+zmM2i59zfp80YcdPfYSsvReuNfyBnu/9jwv/+s8w/7kZQfxxWgRukhWEU51rCcsma2oIgN3cQKknSPKXvPn48bTo+7O7rkbd5PdquW4PfPl8pyUs8lppZAz/uCdvJKjRFCuTU4z0e6XxA9Ts8nMTHjx8fzm0BsCyLW2+9FZ999hlWrlwZsMZp+PDhsFgs+Omnn3D++ecDAHbv3o2SkhKMHj1aFxmI2BD7wA3JRbIEXoiUuG1eSCQE4XZzve/jF+zHuJNFO7KTUnnytm3SIW19K8toMIAJudmpUtzp5omxUnACpZTl3kWJGFBGuq4lGEJ3QwBw57aCtbYaRneglSVcgkljbHQga+8u4OSTI05Mvsnlb1DsHuqk4LGV+7eV4RQkADCrCHoREoZBq79+R87WjfwhQ5TWxgeEYmdZhBODnksnb7PfYTdj7y5N9wvXC8qNdykf3U6Iw+FASUkJ3JLOpDbi3c0334wlS5bgiy++QHZ2Nr/OKDc3F+np6cjNzcU111yDu+66C61bt0ZOTg5uvfVWjB49miLbxYmwXyaJ9w4CkDhicXK0EF0JQJAJLH++BVUGpHuStNyypzJaJgi6RvQyqt/tQ6nvhSNOsOJGNFnyCBaWe+QVAcVysIF/p1r/8+RxSlJkE31htQTb22jIbbOR/9sqHHjyBeD2m1WkG78KZ2X+9pnNMEqCDVh0UDAL/7cMAx+4VXTMGCIsO4CmZSza6kjr3lNq9yn0yVhcgrVfqj1LYSlJ5eXlmD17Nr799lvZ82rXJC1cuBAAMGHCBNHxd955B7NmzQIAvPjiizAajTj//PPhcrkwbdo0TRvWpiJqO7eWzTqjjdzApH8eKfZ0piDURmGic7Ul29c8teXn1sUmKuGOyWonHkrPl9TSEE0Zwk1TS/oGweRfrSUp6MROfda6oHZj1lDHOUwup+i3N8u/5iPUPkla8AUJnJn/2yoAQMGH78F1201h56Fo/dNoMQoazl/mpLOwAzKOlIiO6aEkpR89HHBMjSUpnFFC1z4sqCNPQbtgp4OSSHPQcNG8mSwA3HHHHaipqcG6deuQnp6O7777DosWLUKvXr3w5Zdfqk7HvzNv4D9OQQKAtLQ0vPrqq6iqqoLdbseyZcsU1yOlMgkztYyxu0y4JNuXeP6LZuK0dEJBtZKCJJjlLJQIekioyZKkU69vf2AvcndujTgdvccmrVtJ9HnyQYw6byKMjQ7R5N+goCQpfVmXtyRp/AqfYHM/Y2Oj6Ddr9a/LjtiSJKgXNZYKJjcvovwU5YhKqoL0zTLr63Rwt5NTiNRZkrTnpdWSpET29//D5KZAIgDAZIUfZEGORHt2QhGWkvTzzz/jhRdewIgRI2A0GtGlSxdcccUVeOaZZzB//ny9ZSRSgFhM/hNgnhUxqVCGYLS0NUlhWw7UXieo0LDX7ajOK7z09UDt+BGJjLEYo6Ltbid3z5T/vhV4MIhZQDHbMOQJZtUzBCQqt1aomaIlbyN7z060++5L0eRTad2NsvUheD7BsFRXYugNl6HtD1+pvEMnQlqSxEoS5yIVqZIkm1d9HYbc9He0+99nAee8KpUkrRs3K1vYtHdKUY9r+mFqDAwHHYklKXvnVgy79mLkbfwj4JwxRmuSwqXVkvdEvw0a9wsLtSYp2QjL3c5ut6NtW3+4wFatWqG8vBy9e/fGoEGDsGHDBl0FJOJLwGLAMNPRGM0yadBv4hhZQsmoXCWhyESE6LXQujk9DYvbQwYJCFMIDRg1zBrCEUfuHsYsEx3O2Qhfhg6blUSAwRC8zpWqyuD1qnK3U0Iuz1B9o+33XyGj5ABsx4+izeqf0Wb1zyjdLr9XY2SE1wmlliSf1R+qXo3VQi3c5LfbGy+jYNVyFKxajtIzzwMEyyu8uXmqJpVanzUWbFSfT72VpL5z70GuQrAUNS6Q4Xxc02WuxrJI37JRdMjoCAz7nozzjXAJS0nq06cPdu/eja5du2LIkCF4/fXX0bVrV7z22mto37596AQIzSSCOwqgz8MRi7IkRm2pp9ndLrXRUr4E6fIxg1wt1aO3shXpvWrRMvURjZMRCFfXuk3AMVMYSlI4IgQN3CA5q3qdg48RTTQV1yRpWMemhMluR7vvvkD/R/x7L3qy47PXYsDYwLIo/PpT1A0YAkf3XqI1SazBAJ9e7naCv7kPndYq8V5F1uoq/m8mKxuRr36TkUPrmiSNgQVMMhuLRqIkySldHGosSXFzt6ushKVcstdZQ+A+gtL6lbqwtlq7BjAArrHjA+5NtnVKYSlJt99+O44fPw4AePTRR3HGGWdg8eLFsFqtePfdd/WUj0gRfDEwJemZg8/Hot7pRU66OaEXgscat9cHl5dBmsXk3/RTxQaXQjR9+dd52uryMvAwLLJske97IaXB5YXVZPTvC6EDYblaxUnJcsh4YzQ2bczp9vqQnWbm15/oLaMm980E0EGlQ4mX8cHuZpCbHtm+IYyPRYPTKztRcqVnBBwzORuhNFVrdDN8+0mP64nREDhm2wUb8bIs0Ohhmn80YfD5JO524qAF/P2S1N1en+xGv4Cy92GvZ+ei09L3+d+WenUbUIZCcXKvso+2++4LDLz/FgDAj9tPwOhstiQxaelgOXc7hch/amEEe/XwfUvSia2Vgs1+g0V3UIncO8Ku0G5K1DZ6kJfut6alW4OrbQa3G0Zv4NNgcYVfd/X9ByNr3x75/GIUuKG20YPWGVYYDEBdY2D91Tll5JBRiEwOu79jqpwH+RoaMPyaCwAAa7ccBExpwW9IcMKaLVxxxRX838OHD8ehQ4ewa9cudO7cGW3aBH61IohYE+mEaHdpPY5WN6KodQb6FOq7cFEOTtxEsRgq8cuectHv4V1a6Z+JzFisR62s3uP/Anpqz3xkWPVTlOwuL9buqwQATO4fGAkoVVBqg/11BpTWOdEpv2kzWB+LX4ubvza3z0vDgA65QdMLGTRBk1VAk71Gcm+otCNFLNufB6thd3kxqFMu2uWIJxNactt8pAZVDW7ZDVG5L+KugnYweDyw1lTJfjnnkLYfAByuUr4+GEHnVVKF0cfi96bniOOP/X4rhXBiafB6Ya5qvk6tJWnLkVoAwKBOuUGvE1L4TeC6Gw6T3Q4mMz4ui63W/SqWxdmsKNb3H8xbkvTck0epnoSWJbn8DB4PDB63KsulUh41Dg+8MgqY0vVHqhpxpMqvOE7oUyC5SfxDyepjjsCSxKSlK57T0wVSiHR82lRSgw556ciymbGntD7g+hO1Mh8XZMYFA8PA6HLCJyhTQL2zLMx1tfDm5IoULXNtLdBaPK4l2zfnsD577t+/X/Q7IyMDJ510EilIUSRRps7hfglO8Ll/AEer/QNsuJMDrSSru115g7YXSSKUr7ZR34WzNWGkF+o5ikWgAj0prWvuB27JDuvHawSuQBoW04dDsFRC5RCLqhQGdGNZlv9CflxmwqKlbasa/BMvLxN4Exel69Dsm8Ck+yc6vZ6dqz5xAEdrGgOO6aE0CpPwMMpWCGFwhj5PP4ysv9Y1n3PKW5KU3I9qHB5V1wEIOqMbeuPl/N8Ztmg4mTUjFVEaqMEocLfb9vT/Na9J0jFwA9febBBLksHrCZD1lPMmYuKoXjDZA60UWvB4w+tvbkm/ko41nJLkk0S4s0SgzMhZpvhzCoqr6HkKy90u8NixmkaUqJzDsCwrqyQBCNl2Hf/9AiaM7oP8VcvBCtbHmWUsU8lGWEpSz5490blzZ/z973/HW2+9heLiYr3lIhKURJmUyZHoVpjoEp+yR/JRKGR7teTmTDJEVqEoNJzy2oPwkHOhjcXwIcw3VsMVZ0li0tPh6NoDAGCrKA92SwByASci9qCW3B8sPaNLXhEC/K6D2rKVrKeQuSZ/9c8YM2UEzA2BX+A5Wq1fi/SSgwCA/u31Wauktp9LAzWYmn4X33Y/XB068RN+pch/4cC3j1RJEvQlOUtS5oFiGHw+5GzdpCofbeuMIn+ITE2BCZgMsVuqWeJul35oP8ZMGYFO/30nZJoGr7J7YPQCN0RWFywLwB4YpAEIXGMlzanzi/6o1sNu+jvMK1byx831tRHJlAiEpSQdPnwY8+fPR3p6Op555hn07t0bnTp1wuWXX47//Oc/estIxJFovMdjMTdItkXw/Fe65BJbM6kYAjxRvAei3XfUvoRj0YfDeb4T4SOKsK8ILRjysgnOR/A0mJsmZT5bGvbc+xgAwHbimKY05AwqahaKh5rsCcsVrH2CWUSU3KWUlC5pNgHlYFkMu+EypB87opgnR2bx7pDXRANhoIYOSz/glUifze/axEbB3U6uvQt+/Aa9BVZJqZVEtIeVxn2xAvMPPKbmkZZpXtHflqbAE54csRumNHBD3yceRPqxI+j7xAMh8zSEZUkKmWxQIv1owQLKliTJ8WDPasZN1/F/m+taqJLUsWNHXH755XjjjTewe/du7N69G5MnT8bHH3+M66+/Xm8ZiTgj2osljnKEIpFlC0Uyy64JFQVNtug3usEq/B3tbHXOKyyXt5BrkuQvkB7Xuv+KtgsiR2iREU5qopk1b0lKS4OrnT/6rLWmSrTYPxRyT2TE/cbjQf7zCzD873/zu+kEuTSYRURqSWID/hATbNIMhHYtAgBvZpZfrqbACNEes6T9XGhJ6j93DvI2+N0PXW0LAfjbGggeZU0rzUpSc1mH3H616BqD1yNSfIVtwxojC2rDsizyV/+M7q8s0BQgIlQ3TSv1ByFzFXbA4Utm8celSpKWujR6IrQkxSG6XVB3uyBlD6YwmetqAo4l29s9rF7rcDjwww8/4MEHH8Spp56KwYMHY/PmzbjllluwbNkyvWUkIB7Ik23hG5C4lp3Ivy7rXS42Kds3GiTAh38iyYhknIn1GBVqUqNX/+fWJDFp6fDm5PLrkmyl6vf5kXNPjHRSlvHicyh47im02rAOw276e9ChVE5JchR19Z9rlFf21LantBxqXNS8rfIBCAIm6DRmB6vSrJ3b0PaHr/35StwP048dgTu3FcpPn+aXrylUuTmMaHzmmmp0+HQJTFJXQxbI3LMT7b79XPFeqeVKqIh3/HQxbE0KiSIhPnIMu+EydH/tRbRd/nWoy1VnYSv1W1WdhR2x+8EnUTFuEgDAIrFeatlUVWpJ2nfLvdh38z0Agq9XioSIlSSAd7erPHU8fv9iJRp69AYQ2t1OCXOdPtEg40lYIZ7y8vLQqlUrXH755bj//vsxduxYtGoVhShXREzQFkY3SWauSSImBx+4gQ29yWKw+xMdsXtNHAWJM9Eoe6JUZ7AxQmSV1sGSomeZU3WJHPdF3GdLBwwGONu2R+ah/bCVHUdjl26q0pD7cKOmDwf74JP2ycfi9ILUsFEmHHPNsJORcfggTE75r9xqg4RIr1Ozj403J0dRLjWE8/yfcsFkAMCfi7+WDVZRc/JoPgKZJycPgEzIcpZFztaNsHfvBSZLPmrroDnXI//3X9D6t5XY9vwb/HEfC5x23sSgMkqVA5NAgW3/5Sdo/dsvWL1qS9A0lOpGqASkHT8a9FpxekHGIwBpTa6nrnbtAZMJdQOHos0vPwVYkiJRkur7DkTGQf/afWtFGbJ2bkNDv4EBsvD3q85JIYFwabIkMRmZsPfsC6bJYmqWbCgr/mivLK1JZk1Ssn0EDsuSNGPGDDAMgw8//BAffvghli5dij175GPCE8lPskxmk0VOORLV0haKZBvwkoXk7A1+dLetaliLENTdLkQ6sV4r6VNQGPWGtyQ1WZC8uXn+4/XKQQmkyLrbqaixYMMDt26G/x3UkhToouTJaw1APBEXy6eQb4g1ScHWk3AwTXXIWZ30GgeV6lR4NHvHFpgcgS6BtYOG8X9zSpx04XzBj99g5KUzMPSWKxVlyP/9FwBA4Xdfio6bykJbHg0SNzOpK6StQrxRqSZEVdO071oYD470nrSmtWfOJldUpmldlzQEuCFI9EUh5rragMANPosFrMUfcbBg1Y845YLJyNmyQTGNcPZmjHhNEotmJalJ2Waa9lgzSt3wJHk5O3WRTTMVLElhKUmff/45Kioq8N1332H06NH44YcfMHbsWH6tEqE/YU2idRi4tfj8B08n8jQ05Rf9LKICi9Rek6MtcENytKJ+E6TERq184awLSlUrTjBCTWpES9QiqIBmS5J/8udtsiCY7eqVpGhEtzNI1xJpdLfjlD1lS5I6AaVXyVmSXPnivXa8TYv8uYAJsRyxjW4XrDXVAcedhR35v73ZfvmkC+c7v/8mAKDVn79rzjdr8/rQsnncogrVd02U4IeGQTdUL8jZvhkA0NCnvz+fpo8JUksSfKE3U+787mv+UNhrV4tlsFjgs4hDjOf/ulJ8jaC/6rkmSfV2EmADlaSmva1CtaPRJf+hosUGbuAYNGgQxowZg9GjR+Pkk09GWVkZPvroI71kIxRIZotJqqFbWwjc7VJYR9JErBXrRCKc8obrCquHMsrG2iTD56vh2hCCxcKVWNynRWpQROkGm1Rx0e14SxLnQqNhvUq40e2CpimdeAWNbieesLIGAzycNUfBkqRWiWMlBgK5hfU7nnxJ9JtpUpJ6vfAEej73mLqMIkBYNWZ7g2xocs41Cmhek2Spq8PAe27EhBHdUfjlUlhqA5UrtVjLQ4eND7YmST2hJ/tcEIhI1ySZjx1FWulx+Ewm1PUfDABg0vzWk4A1SQphvY3ORow673T0fexeUaQ/IT6LFaxESWKCbK4bzhQg8sAN4Nck+ZosSJwlKcDdThKVUukZNNXWyBxNrglOWErSCy+8gHPOOQf5+fkYNWoU/vvf/6J379749NNPUa7iQSKI6JAaM+nkGkK0yaumhciFTz16WHYTgVBr1fSQN9GsVaLodhGW2agUXpllYW1av8JNeLi1KH2ffBDtP1f3UVPOuq1KviDPssEuVpKC7S0jXfvjs6Xx5VH6yq3ousYC7b/4GCMvnIr2n38UGLhBMtFnrDbRhJY1GuHLbP7d9Z2FMO7fpyi7FhTrlGm2YnT/9/Pylwj2+eHCWVvLT6Dwm89gbnSg/VefwCJjgVKLUcbFj4Pbl0mqJCm5QioR7EOGqG4MhsBjau6T/DaXlAAAnB07w9fUxpwVJdDdTt6SlL/6Z2Tv2YFOH7+nKIPPaoU3U7wGjOu/vFzKRVCFLmM6Z0lKF7vbhbYkye9j1mL3SeKUovfeew8VFRX466+/eMWJAjjow+EqB44JdjmP56RGjdtHvdODvaX1irumK7vZsNhX3oCKBv02vfOnq2tyUYfl/8+K/JGdnuaBuazeiQMV8pu9CXG4vdhTWi+6N1HQ0s6J3oQ1DjeKy+qDfrGOVOFzeRnsKa2Hw514bamE6omOAoerpZGUAm9iFc5F8tyHVKKazvt8LIrL6lHjCB3KNyANwd97S9W7u4XCpNDRTA47jE2mEs7NTjhZG/DQ7SHTNhiUAjeIK+ygzNjk9vqw83gdDlXKjFuSiVewvZCk51ibjZ/IKW0me7Ra/nil3YV+j9yNnB1b0OeJBwJ6l1RZ82Znw9e0ngQAfDYb2KYQ2xzmNWsUZZdDq/V23+GKkNd4hZYkzh1QMLE32RtESpIhSH3LYbTLT5S96RnY/K+3AQCsx40tR5onxkqukEqU1bvQZvG7aP/FxwHnRP1Npy9zxiaLnFcQxELJ3U4xcIPJFFoEswXOwg6iY14FS1Kjm0GNI9Dls82KH9Dt388pDlTKAS9CigcA2FNaD6ahaWNdibudURrdTpim16sY7MSUAu52YUW3+/PPP/WWgxDg9DDYfcL/8LbPTQtrEV+sWbe/aUM2hkX/DsF3Hxe+IErrXDhQ7n8wJ/dvF5EMyaYYCRFFtxMc33y4BqO6+8PNbjnsH3By0szIz5Isehb8/dfBari9PtQ2enBy19ZRlFo7JZX6+ajHm78O+iccmbawhtGgcM/ItqN1qLZrn4xHA7XPl+rrZGYvjW5Gto/EYn2a2jwOVTlwsML/L5IxSzgRCpVzqPMmBUsS51LnM5l4FxpvtnxUs4Kfv4OroB3qBAEAOOTd7Zr/rnV4UFwWaGnwMiyvrLTLESgWPl9AhDaj2wkmU37iaHSLr/WlpfETOamrD8v6FdnKBvnnxsuwfBhmc6NDxpIkvo/JyBS5SjHWNLA2sZKEqirZvLSi9Ow460OPmyJ3u6zAd3DGwf2i8NOW2mq4C9T3XyVrgqd1Ph+UICBwg8Y1SWWbd+K0h+4G4A9E4ejeiz/nczW3C8sFbghjXBDeY2hyIxNa4bh+ZXEFsSSxLAq/+gR1A4aAkQQgkc+U5fco41HYN2pDSbMia3TYUfjN53C1bccH26gdNhJVo8cF3McodB6fSi2prM6FzpW1yIPA6qxgSRKmGMyl0iQTuCEJprMiwl6TtHr1alxxxRUYPXo0jh71h2N8//33sUbjFxUiECZEp47ngvZQeTe41IfJBJCQ1o54IBq4BYNIvTOwPp3e4FF23E3na2W+RiUSob/cJ4fW2xhk40Al5EomV9zaRvUKUqLUVqjRS/Zo02Gvhk0ihfc1px79WrBrHOPCRUtZ5AIrAIBF+KW86RqvTOjnzL07MeTWWRh5yfSAcwaDvLudsK2c3tDjuLCt5NywglqSAtzt0vlw13KWpGDrM6T7/zAS7wepyxhYVrTo3mezwWcTT4yNVZWK+emBVHGTQ+QSaLGIJv4AYJWsR7LUaFPsTA55LwZvVg5fP9I9gGTXqgRpm7xNf/F/t5NE1xNZvrj+rsbdLlhoee75ECiYvJIUxN2u8OtPMfCBWzHq4mkwqHhPGcDCJVFIpZYpLplGgddAr+fnof+jd2PYjVfwx5TWEipuuK1hHPFxa5J4S5LCmiRhkIkgLpWpYEkKS0n69NNPMW3aNKSnp2Pjxo1wNQ1gtbW1eOqpp3QVsKWTCPNELZPVRJnYJktkNCkBe3bIPKEMo65ssflik2SfhYioE8kYEM2nVnbdTxiZR+bSF50SKlqSuElgU7QzAAFrI8CyyNxfHDR9WUuSQLcI9WEP4FyJ/X8bBW5YnNtcsD2HTBKrk89mC7peIpg03L44fP51YqVJ6jpkrakOdLeLliVJQXK5NR87H1kg+i2c6AMAm5OLYFirZWRWWHdj8HphrZRfb+7NzgYrWJNkbHT4/zkbZdsm2Ga9Ods2838HKANySlKEGDj3MoGC6WtypTRLFFOhUsOt5TM1NqpTYG1pAW55wdbgcXT47MOAYx6Fdo002iTQ/MGBX5PUpCRJ3e2EcBZhTrkUYq6rTYxJbASEpSQ98cQTeO211/Dmm2/CIvjCMmbMGGzYoBz7nVBHInep8BeKx8JdJvbolafY3br5BSD3hVjJrJ5qtJBiyhLLsidCXsFE0BTBLhIFRvV1+ldYpIEbTApvcm6i6RFYj5gs8WTa6GyEwSd2JZISahxSG1mLu0w4GWNsTUpSkMmzVEnwpaUFXZMUTB6bREliK8RWIKklydxQL3K389nS+C/tvHxRdreTs7IdvfgquFvn878DAgEouHNxWMtKA46Z7WKXSW4iP+KKs9Fu+f9k0/Fm5YA1+12OTY4GjJswBKeP6I5RMyfxm74KCeaCZxZYu0ySsNKssA6aNHQ1vS5oaPmmjwhMhhpLUvNXgcz9e5vTUAhaAAAnpp+Lg7Nv5N0G7V26N6cnUZLkxhU1Chh/vw4DOdc24bjbMdIPB/Bb36QWyGT7rBqWkrR7926MGxfoE5mbm4uamppIZSISCOljp/f0IFrzM/XrIhIL4ddWQP4LsZqvtslMsg2i8SRUVDg192m4SdWpqHRPqVtdOJtIhgwBru7+aChikU5wlNatNluSmpWk6pPHoKFnH8E1DSJXIqmyYoBB9sO90KKtNcoYPxlLS+dd14IpSVJLEpOWBl8a95U7UEkKJo+tXKwcdDypP9JLDjZbuWQmpoGBGyTrUDS622ltbkUrm9BVUGqpECgV9m49A25NKz0WcMzcILbeGF0uDHjgFuRu3agomzc7h68fW2UF3+cyD+1H0YfvBlwfsDGpAKHCK23X/DtvaT7XpGCo6ndBDhiblEKhJUlxTZLgQ4LQytV7/sOKeR/8x60onvMo/3vjm82WIcVAEADAMBhy0xUwyLgfKwVJUBp35eqo6+sv4dQzRsFaLt7cl6tzrg644BJSdzshXD9jrVbRcW9mFjwF7RTdNJOFsJSkwsJCFBcHmufXrFmD7t27y9xBJDOpPSVPDLg6lgZukItaJfeVVG4gTLYFkkQzyfzMqd68kBX+rU+Jk7nepGipH6XTzWuSmhfyu9sUYO0Xq/iJbZd3XhV91ZYGVADkP1yEY0niMAkmY76myVXwNUniCbMoBLizMaACgsljrQh0G+v99MP8BylhXfjMZmx/4iWxJclsAStZk2So1MeSpIRQgWRsaTh4jV9hMATZ4FSoJDk6d+P/ZpteDLbS4/7rvF4MnHMDOr/7GkwNEkuSx432X34SVDYmPYO3JKkh2IRbaJUxCS00Ph8yfvi2Wa6mtU9qxppgz46haQ2OVxAwhItuZ/Z6RO6Hwn4h/KhgU3BDBBBQL86OnXFi+t8AAEaFNUkAULBqOQpW/Sgvs4KbnpZnsOe/nkbG4UPo8s6rouOcVcgnCQEuVWxFWTUpbT5JWVev34ctf+7QFBwkEQlLSbr22mtx++23Y926dTAYDDh27BgWL16Mu+++GzfeeKPeMrY4hA+1cPKslUSaI4fj+685jzjPkCJai6EQ3lRu/5NUsSTFa91YvPtJyqPS4iR7XmHdkLIFRqVMCK10qN+ZPnzCcTeMBO6Lt1ywBs5i0mXR6yK3KDmLjpylSjgOqVuTJMibd7fLgK8pOlgwtyWp4ubLzOLd7QwsK7qXBRvcklQR6GZmqyiFuck9jauXitMmYsWf+3D8vEtEliQYjAFrkgwHDyiu59GCktztv/4UAGDv3gsr1+5G8V3/BACUT/IH2qgZenLAPcJNcR1dmz9ec5umcmuz2vzyIwq//Ry9n52Ljp8uFqWhxt3LwDAB66GC0e77L9Hj5fmy9SUM6MH1EaOxWaHj81SxnocjWM/kgngIIwMK3RaFbmYia6tKNzifZANZAGBNfmVCGglQSO6GPxTPGbzyliTFsSVIBRgkz63RIXa38ym62zXfxyus5sCyys1CkyFas5CwYtfef//98Pl8mDRpEhwOB8aNGwebzYZ77rkH//jHP/SWkZASx0leogRmCEVySBmaluhuxyGa1EacVvTqzL+GLPL0I1Yao9wtoqlEaL0nGm5r6kOcJ8/zJ+duJ0dbwXoTqWsbFPZJEo5DaoYkYb1Zamv8aWRm8RPeYJYkk0SB8mZlwydQVEzORtE6oeCWpLKAY5nFe9D+k8U4dMa5/Jok1mIF26TACSe7rMkEX7Y4xLahoQGZ+/bA3rufYr78/bKeAP798ZSesaIl/n2IMvfv5WUCgJ2PPoNj512C+n6DAu4xCNzF7D2a3Ssb+g5E7vbNvNuh0HWs8wf/EaWh5CrlycmFpSlymcHHwNWuPRirDaYgLpMc3Ga4eX+txc7HnhOF+RZZkpr6ocFgQMah/aI0uCh6LAu0/f5LOLr2REOf/rL5BVUSOEuSMHCDLQ0+sxlGrxdmewOYXP/en0L3ODUR7YBASxLg7z/S9KQEXZ+n6G6nfVySKnFGgRssIHS3k7hICr/pNil7rCSt5FKFlAnLkmQwGPDQQw+hqqoK27Ztw9q1a1FeXo7c3Fx069YtdAJE0pLI04NkjWgHiOs1ZOCGBFaS9JhAJtuXpmigth4Tcb4eTKbwA78oHNfwzMtdqUkRZ1VeFwbyFjQtOclfy60x8cjsmyNEvBBd3RofsZKkrVYySg4AABqLuqpakyS1MjGZWWDNZt7CI12/EmyItDUpSUL3IJPLiR4P3oFur72EghXfB5wXfiX3ZufA2T9QKWnzi7x7lBTNz0eQsPis1YaaEaNFlhAO56SpAPzWp7IpZ/LH7T16A/BvLhsqfXND4IbH+2+4E2s/X9l8gGEAoxGNXbTN/VptWIdTzx4rOia1JNmOH0Xmwf18f+HgFOucv9Zi8F3X4ZSZpyNn83rZsgRsOC3Mj1uTJKw/g4G3jAnLbwjDUihnXeEjAQZJT0kRArRbkgLvb1bOpPLxFt40ibtdkGAbBq//44bPbIa9aw8AQMW4SeqESQI0KUkulwsPPPAARowYgTFjxuCbb75B//79sX37dvTp0wcvv/wy7rzzzmjJ2iLhJkvRVACCpc2y+kzEEnEypzcRlZGbgLEIHbhB4UtkqqFnn0/B6klYdA8KoWULAu05h5VPBLnEII9m0o/53ejk3O3WffQd/7fQfUgaJEDpk4VWJUl4RcZBv2XA0bV7s7udhsAN3CRWMQx4EHG4NUmOpgmdkG5vvISCVcv9SQitAIJIcZ6cXPha5fG/G3r1BQB0WPZf5UwlommKXGgP3KRXDVWvLMT+m+7Ghtf/C29OLta//Ql2PrIANSeN9KfbZCWSRrQTIneu5MrrRRujcn87usivRxdG4AuFyJLU6MDYycMx8ozRaLNyueg6ztqXuX0Lf2zkZWei03/fUZ0XABjtgSHAgeYw+TbB+jW11iMh0nU6AMCamyxJCsoOEOKDgcJ9aj9UCINz+CwC+RiGf/Z9Geqj2/GWJJMZG9/8EPtvuhvbn3xZ8WNnsn0C1aQkPfLII1i4cCG6du2KAwcO4MILL8R1112HF198Ec8//zwOHDiA++67L1qythgSeT4XOgKUijR0kSREHjGaFeudjXSCaZZRktTuoC23AaTeGBRccdSQioqLeguQ/oXXZFWJYt0H655y6y3FF+gujnzevFVIuwIWjbqTkyNSd9N2336Otk3WDW92oCWpfuBQ7Hz02YDjcoEb5BAFblCxB7CwPBmH9gHwT6z5wA1B9kkySsJ8e1q19sugEAY8aAjwJjczYTADOUwKUdi8OXkAgM2vvIsTM87D5lcWAfBHc5PKKYe8u13T/2Wut9SHtyEn27Yt9t98D1wdOgEAqkedhqMXX9XsQtWkIFgkm8wKMdkD3e28uXkAgE3/9x5OzDgPB/9xKwDAnd9GNo3aISOw8+GnVcksbMeMkoP835ziysFFtzOw4o4ndRcEIKpUaf0amwJVSNdUcfsDjbz2Yr/lJcz1ZnKWJB9nSZJswCxalhzUkhRZ4AZzXbOSZBSsixLWPW9JauorJrdLbIESysqvSTLD2aEI+2++B57W/r6QCk4hmpSkpUuX4r333sMnn3yCH374AQzDwOv1YvPmzbjkkktgkoSgJKJDCs4tdSHWk+4DFXYcrlI2Q2tBOEkSDnah1gIkAnrXe12jB7UOT0C6dpcXa/ZW4Ei1PnWuGzq9CMSBBZSvKy5rwG/FFfAw4gnCiTonVu8tx4pdZdh6JHBipbX+quxurN5bjvL60OsMhIQbnptlWfx5MDBK2PpD1YEuM6z4/9LjG0qqselwjSYZat54B6dNOgk5CuGOHW4Ga/ZWoNqufu8SKSE/MrEs1h+qwsrdZahxyE+UlNpfyoD7m0Mme2SUJMAf6U5KwPofhsXBisDJMiPQjFRN0ASXWJtCZjvbtefXFqmxJDX06ovawSfh0HmXAWieoPWdd7/oeiV5jA47bx1xtS0MKi635kaKJzcXBhhQfvoZ2PbsQjR26gw2Lw8AkC6Y2IeD3LNjrg1PSVL6ks+5lnGWJEuNspJktge623FUTJyKbc8uBNNkpQzYpLgJe9ceOHrJLKz+cb3s+Y4fv48xk4cjY98ekYIut/8VB2+FkbwL5db5CK8oLmsQjY1GO7dPktiSJOyL1sryoEFFgiHrbscFblCxJmnXP+cHWKOUFKhQ04I+8+7HxBHdMGb6KfwxoYWIc3VkDQb+meSURUDZ5c7R4K8b+cANyY8mJenIkSMYPnw4AGDgwIGw2Wy48847aQ1BFEmE6bB4gpIIEoVG/SLs8PPYVxaeG0QwWBZIszR/bJBzt0swHUmEXgrT5iM1Acd2naiH08Ng13HlF7cSsaqyWCjqByvscLgZHKsRTyKOVDXC5fGB8bEorQt8qWutvw2HquHy+LC5SdnQ45kKloSSUuBlWNhdKqNZsYDTw6CqwY2KeldIa4zw/MD7b0HaiWMY8OBtsknvK2uA0xN5BDNZmuRweX2otnvgZVjFvLj2F36gkatzT15r/m85dzsAvOuVELWWJOE4pM7drvkac5MC4s3OVRkC3C/T3rv+iT//+w18TZNaW2UFACB3ywa0XrMCQ6+7FGkH9yv2M+56Ji1d1romxFxXI3vcm5Mn/nhlMIDt5V/nIw0wIEewmgplSdrbFNVOLVlpge5enNXE6PXA4HYFVZKErn6M1YbiOx5UvFapj3ny/IEPXO07onrEKQHn+z12D9KPH0W/x+4NqhgJ4a0aEguP3DofYddsdIvPK7nbmQUWNIPXIxuQomLcJBxosqIF5GkwoL7vQN7SKTrXZExQcpsDmp8Fn8UauG5IMbJf8Gew6MN3RWu+ALGF1uj0jyesLY3/OstarLy8I648F/mrf2rKSfAht0nZC1DmFORINnVBk5LEMAysgg2jzGYzsrICFwwS+pMorknhyxH9AiRKHYVDMHcLVffLHUzAwchibh5ygpXVxwY6IHkTWTuMAwYYgtdhQH0ldv0FnTwqnAyl+ISDpWkiHQ1i0QJFH/wH7T//iJ+cAsEmsK1RfJvYCmN0h/fVXA0Gtws9X3iCD57gzclBbiu/bMFDgDft3yIJvS3kpOsvRZtfV6Drkw8rKm1cZDtXQVvA0DwWbfvg84BrhVHf/Pf493upGDc5MOFuXQEA+b+vQq8Fj8JaHhhmnENr/+zwmX+tU12/QTh0zS0hrm7GAGBUt9Y4vW9bFGQ3R8TzCUJcmx12mIO48/FWt4J2WLluDw5eK/8BAQAYwVyw5PJr+L+FyjprEE85fQIFwNxQH2DFVIJXMCT7RBm8XrTNEe9hFcyllttM1hugJDV/SDI1Nsq6gjLpGaJnjKN20DCs+nUn1n38vWgtGy+PRcHdTiAnF7jBZ7UGRMgzKIQfD/Z6VHIDFSqlnLXWlyZ4xgwG+JrGjuw9OzDshsv9sorc7eSj26UKmkKAsyyLWbNmwdYUjcbpdOKGG25AZqa4gy1btkw/CYm4o2coZml6qUQkxQpnj4NEQcuXoXgFmIhXvtHUUw0hIo/Hq+uEU9V6rHX0X6d8pVq5rLXVMDY6RJPJaBNOW8l5cKQdLUGf+X5rg/CrvZKSBADufLHLXUAIcAXUuocKr+nw+Ufo+tb/8cc82bkw8NHtQocAZ9LEX+br+g1Czs6t4msddngU5OHWI7nz24IVWOnZwkDXO6m73W9fr4GlthrOjp2RJ636Nv41GJ0+eg8AkLlvDza9IR/IQXb9GQCUlqL1hx+hZtLZor7HbeYqLWco/OtFDTAYxFFSWbMZvrR0GJ2NMNkbeMvh/hvvwtGZl8FWWY6+8+5DzvYt/OayjM0mCj0uh9DdrrFTF/5vkSIhURqE1hRTENc+APC0K4Sl9IS/bLwlSexyamC8sJrFeSj1TYPbzfc5aXRA4TPQ9sdvcGL6uQH3KylJRo+HX7clBx8CPJglyeNXyliLRaRIAsqWpGBrlW3lgWHvAUk0wSZrmUhJAsBmZwNNIfv5Y4K/hWuShCSbxUgJTZakq666Cm3btkVubi5yc3NxxRVXoEOHDvxv7h8RGXIvH1bhfPSFkfwMM+9kmOwnAqkYpS5cpHWRqFUjfBeon8yHOK8iITlXTCGBX9MFE6Uo1qUeiorqvCJMUOn2jp8slj8RZbR8LJFrfUt185ou4aaYwTb75EJwc6hdf6G17lkAGQf2iY4xmVlAWug1SdxEXmpJ2rTwA3hyxHMOV8cixXrkLEnuNm1h79m8dxBk5i1S1zAmKxvOjp3lE5ZEcMvdukH+OgR5BqZPR9f7bkfPF5+UPV3fZ4BimnIEC9zDNH3YbvXHr7w1oa7/ELg6dELdoGHwWf31zFmSQilIgFgRF0a/8wgUBlbGssJhrg+uJNWcdxH/NzcxN/ikSpIvYNsMpeoW7gEldberGHUa/3ePVxYgoyTQjZLJyIQnt3XAcSVLDy8PvyYpSOAGzt3Oagvcf0gxul3gMduJY8hf/RPSjh6WvUe4zoh/xiQfInwyz4bw2eeCP0iVOUB+jIpFQCk90WRJeuedd6IlB5EkJPJeRIksWzBCRvxKIqIpv3/SH94Amwz1qlVGuT20hEiVJKXLQ811OWUs6GUarQpaZYDHg7SjJXB2KApqQmPZIONAEBmli5LzNqzD4b9fG0Io7YRSgsIdw7i7hPurcIuyD/fsB1e79oove6mSESzKnFyeqmVkWaSdOCo+aDQCKvZJ4i1JkjUe7oJ2OHLJLHR74+XmY20KYFR0t/OHdHa1KUDptHOQdvwoaoaMQFqueH3S/pvuxpGLZynKEzDRayNWkrj9m5QIDETCAhs3AgAKv16GPQ/6FSVhRLEdjz8fNM0AGQ3yfwOALzMLqKzAgH82b9niE9Qtt8moydHQ9Dt4eQDAK9iLy1nYofl4tqB/GYIoSU2hqVmjMUD5AYATd92HnE8/gq28lJ+YSxUSA+MNVJIU+oK5qWyMjCKy9amXMXHScP535r49Afcz6RnwyigQStHnOPjodsECNwjc7Rp69eUtoMHSlyvnyIumwVZZDkdRF5k7JO52Lu5DhFghlm6c7M/L/x9TQ72iJSlVCGszWYJIdKJtdZAzbYf7VVspQpfcOS3E4ntNNPNIrhU1fmJpCQzyURZAYN8Jt62MISxWAfkGPSf4IKChrjqdfxZOmzoS3RZqmygq5S3FWlku+t3YsSjsfMKBk01L95FTeoX7HXGhftefPj1oOpWnnY4jF1zB/1a7LkSIWrEzDh0IvJeLbhc0BLi8JQkIdBc0MD7FNUm2iiZ3uzZtAaMRh66+GbXDR8EgtLplZGL/zffIRv7j85DWvcSSJJ1oasEgWGdjECiO9u69tKUT5JxPZi05I6hbTiniNlP1WUMrSUI3LWHkQKFFU+jiKFW8jE2WFXfrfNmAB0xaBvbdfA+AZmuK1OppYJiAtlF6pjhLEiNZLgL412BVt2nH/7ZWlAdcw6RnoGbYSBy+dDa2P/FiczmCKPsA+H2SpIEbhGLyrm8WK3bMexEnzjgHNUNPBhBkM9kAARnYmsa1jMOHRKe4zV5NcpYkyTPGSj6igGHAskD/f96Biaf0Rs6OLU3lkli8ksxipAQpSYmIaA0Q9/JMjCli2O52+ooRd+Q2dNWDBGnmqCF2G1UurHS9BQv1+0AQfgKUpDCdxE0a79O7nQweDzL++B0A0Pan70Tn5BRpTYpGfS1OOXssBt57k+i42nU5WgllKdJSc3KTEKFFjFuQ7w1lBTCZsOux53D40tn+NFRGGNPazCwUIsalhViTxDD8hFK6XgIA3K3F+/MYPG7YflqO004fxkfj4mgO3NBOdNwsXMcS6uuDDGy+REkK4p4Wqt6ElgJhnahxeRMnpHyKkVmjJqxbtkkp4vZJClae5gSarT/ugnY4ftb5KJs8A42duzZfI6hbJUXSnV8Ab0agEseybMBGrNLn1OD1qh6vTAqR7fjzAktP+tGSgPNMRiZgNGL3P+fj+HmX8seVo8/54d3tvMqRMoXR7VyFHbDt+TdQffJo/zmPwpokSccKNoZxa/uEe2RxAVsC3O1yxJakrm/9H1iw6PD5RwCADp996L9OpSUp2dYqkZJEaCLR1hSI04rd/XruVaRHSomiP0S1PSNIOlb1o1c2qtyu2OD1HeBuF6YsWueMQes6yDmlsogihflCh+DmUsncsxPDrr0EOVuU14e0WrwIWfv3Im+zeA+XUF+Do4VSHcj1B9Fkw+VGv0fuQveFL/CHOCuAR+Xkmpu0ql6TpLG3s6zYHbDk79f5/1Bwt+v53GPo/dRDoskeI2tJkihJXi8KLjwXaaXH+WhcHDZ+TVKBqF8LJ9bB1s3weUgeJkNr8dqUYJYXxcANXFoCZYOzDLJGo67uTD6pdQDioBicux0X5U2NJalu4BA4OnVG9YhTwJrN2L7gVWx5+W1RZbGCv+XaEvArSVLFZecjC/wfQPiNWP2KgjRkuLy7XWAehV8uxYi/nwNA4g4owChoB1klSRLYZdeDT8JnsWLb0/8XcK1IHnPofZI4N0JWUO/cfR2Xvo/Bt84KcBGWTkmUolR6cnJRctUNAABrZQVfQbLR7RDYV3q+PF+2TgPWThnC/zCXSKSmEyGhGwG+06G+hKqa20V/xhrtPOSUJH1yTBBtJwHRTwFJDUKVQy+Ljrlp0qheAda3hju//yb/N7cJqfJmsiwv55DbZiHj8CHk/7YSP24/ITs2GRU26lS7V5BWohXFst2iN9Dx0yWiY5amENZelaF5GZt/kmxSuSZJiJq+wYLlN8Jc++lPaOjrD0TAygRuMLhd6PrOQgBA6bRz+ONq3O2MMgvn237/JTJKDsLS1H+k1idxEJTQE7sAK17TZrK8nFotSYJF/MLJM+92pdWKJCejAK9EXkA8OQ7H3Y612vD717/y0dvkhRJYkmSsgoC/bbjnHAAOv/w6jk7+G1qxLK+8cZZF6XNqYNmQgRMAYOADzfsbufLl3SqNQkvSYTlLklhJOnL5NTh64RUhLX68kiSxOImCIQgsSc33Na0TcznR9ufv0OHzj3CkyfoLBI73cmPY9idewokzz+OtUSZnI0wOO5jMLP7jCCux8LGS9XpMWjpYmTVjtCaJiBliv/3g52OBXmtkUgk93e1EgRukk74I2lrvrzi6WIk0JSG+OJJJf7IF9VAbUjnoeclvxcANIerGpKclSSssiy7vvc7/tFRXitx6ZG9p+n/asSOyx/1/+38ZBRGugOYIXeGsy2kSN7z7JP/XSu4vPyueC+lu1wQ3aVVrSQpHWG7SLwq5zFuwmpUk4d8dl/mVP8ZqkzVrBliSPIFrNgbfdR16vvQU0o/7A0d4cvNE46NQSQrHkgTJGppg+znJuoRWC9yevF60+9q/jQo/WVahpISUUShDmtyan+Zjze52TdHtLOqUNNZiCWp6Lp84DQDgzm2lWEfu/DaifYs4dy+WbXY55OpFbvNZaShx6fgmVU6k/YfDKAgvbmlyE60bMFgxHUCdS2Szu12wwA2B7e6TWmoYBu2+XoaOH78Hg9cb8H7O/3VlQLru/DZgrTYwmZn8ui9r075w3DPns4n7hnRNkr1bTxhk9pLjysXLp1i65IKUpCRB2P09Xhb1TvGLoMHlhdsbfPKgmHaU5o8sy6LW4YHPx6K2UXlPAD1ocHnhZsIrP4dSNcgFaWCYwGOeMPOP5fS9ttGjq6ug3NohtWi6lhX3Uw/jQ53TAy/jC+hbDrcXTk9otyw1cP03GMI6iORZ0h5SOYRVV9AdWZZFvbP5pazUB3w+/zMr+qrJlY9lkbNlAz9xUpZL3TlpcT0yz5RJosQYGQaWmirUOT3/z953x0lyVPd/O03cnC/noJMuKyOhBAqAkETOYDDBmB9BJAuDLGGRwWQsLJuMMckIGYSEJCSUs053J92dLqe9zXlndmZ6pn9/dFd3VXV1mLQ7e+z385Futru6qrq6uvq9eu99H4Yns9C5d86Ac99Bu+96voD8GCtQpRYtNdspUUkKQqBiW0w8FfXqqSPDnuX00O52lpIU0oqWyuaLW/ModztG4Iu6LUn0bxL7oHi4QOYa2Vw1tOJb8LBq6PUNjBDHKEnF7goAkOKcwO/zIPn3XJkYh/zTnzLHTrnx44BhOIJrSEWX6ZPfSYEiQwvHtiXJjkkqvn0Rul/1Rjz7zR/g0Vvv9Xa3a2ljyRQs5T2rF+x+ESWJdzkDAImjEucfBb95wlsiCWSBO9zUPIfQJdfQJLwuCF7udqSbUi5n5+gyBJYkgmjvCaz/5Ptxyo2fQPs9tzN7R1Iuh3X/8lFX29m2Dvs3saAR0hry3udd7nasJUmZSkPpdxNZhKUAn204Oe1jsxxBH8oXes1F4MzlLWiIaZjI6Hh0v2mefsk6JyB1pv1B9/ZN4MigexGrNCap+yeopOK3u2cc6+ZzJmdBAw/vG2TGvxQY9v+KvS74ouMjaezqHkNjQsMZS935HWoN/BAXDMPe1Xl4/yBy1KbA+oWN6GyIIZcv4OF97neBtYaGH+AnDg1hXlMMp84X+62XimKtQF51+JWjLW/HhtNIZx3FsXdMLAjv7B5F31gGS9scIYUIkJH/uw1nvvn1GN5yFp766e99+1UKdh53u75pI0OuY5GhAQy3tOGpSbFiQN6FQjQGUEIU/9wfPTCEleOswkcYzUp1tyuZwtvhAA9XDuz6HjnR7XlNLqSAm7csOsW42z2yfxAvXt0OwzCgjo1CF8S6EBiG4RAwUEoSce/RRodNK6Es+yaWdYET+Nv+/Ef7dyESFU5Iva4BtPpEK0mTK9a4yvNwfVk5S1IxSvbGT/4jlAdYS6CamoScmbID60uzJEnUb/6kW0nKM+525vMhFpRKKUmQZfS/5GVmnSFjkojVK5XNI2r1g7D+xfp63E2MjwMUkQb/9ONHDnLtiS1JSt690ZZesBBP/PQ2ND31GAYueInwuiAUAixJy2524goZSxLnzkZISACg7oVd6KPcUjXBpsnk8lUYX+dYwnItbcCxI4gMmVYhJWNa5Xh3O/ApAqbSkHtOuOoP624328KU5ixJNYiwn9mRSfODMzxZxAelBAS5/3nBS0GqtOVqOFXd++8ecZv0K3kPfnVVkgL8+LB5H6Op0qx6lfG2C1+JX8kcZzXtGTWFEtqCFGQBCosTI1OB/SGYTre+YmKSjg2HYyzrGzOFj8ODzm48iW2I/OZXAIDmpx9zTQaRK1tQn8KAfOxzXfOQnr8QAJslngdtcfSjYTYMc67wlqpck7l5UKq7XbkIyvEkHL6pKWhDbvcXAlFM0qbFTa5jtiUpE26uALC9F+Z9/Yu44Ny1aH70Ac+yRtZZd+gdcmIpaHhuO7a867VmHypEnCHrulBhMSIRJsBfgoTM/Q+g97Ir8dznvukqz8NF3MApSX7zh36EDYP96KAUpIw1xwGg6/bfYes7XwOg1JgkH3C0/gUtAlBWN14p8iI3KAd8TA9Btq2dTX5M528i7na5LGAYiJ44zl8O2aK+J+A3R1TOHc/LkpQWUIOnlizH6JYzcfjd/48Zr2JgU4B7EDcsv/nr9m/6OfDECCReDAASh9lkt9owu2kMAAf+gbUskfxoy7QcFFmikslyFOCNbktS7NlnXPXzlq6TwoyEOSVp1kD0caS8YKavHzUY2yGymFW7l5Uch1KV0JMZpa6v9I6wV9xYLTM0VhJ0ryqxe5dfudL+LRJOwqDYodr8XpNaN1/f4AhIPgK0Qb1NYQRLklCSINfYZLZRKnFDoIUwwEWyGHc78uNf/9W3nM7FkyxtS6Ctzj02RDjSuPE97WPvw0Vbl2HBr37quoZg3je/AskwsPVdr8V5l2xB49OPuwtRigMjhFPKbMvjD5luZpVSknJZm6yBB59s1Tj7HOz4t1sYRcUb3AvF7aL7WZLoZ9zAKbf5ZJ3ttrT4RzdTFXqLal2NYouMb0wSVx+fl4ingc41sS6NlQDPDkeQbWlDPuGlJDnudur4GFSBu508zilJ/HnOUppausJVx5KWBG77yD9jcsly5nglxsFh6GMtVWReZCjLFkvcwM4xlbrP5MH9kNMpbH3b1Vh33f9DRKAk8ZtGJP6yIZvG+oWNTrxgQEySPDWF6FNPuOvXVCxuFT/T2Yw5JakGEVboIgJhLSoucygNnhTAFRDEqyXM0yxKxTRRqgtcWFQy9iosyotJKra8/wW01aZYHYmu2ha2KKf3mI+S5NetYixJ2sgQIsOmu13k0AFKSfK3HJNx4YUCUcu8WwqxJE03BbjB/esF5pmS5/KAt/UGEFGAi2eDKCZJTk2i60+3QplKY9VXb2SSm3oh1tONUz/1QUFHnOfGCH/czrWcThXnbgdg70c/49sfEeh1q9Kb3omjh7H6y/8SWE7hEoMWNM1WVqcoZc1L0QsLnulu8L0fYNvlXN/0OtZ6kJ1OJam1HZlOJxmtEXPmb4Ei+Yj2ip+rHBCTxCtJ42tPE9bTs2I1Hvi/+zF05osAAHqyDoPnXigsWwxsRc9DkU4vcZQ22u0wtXgZU462JEUG+rDo5/+F5qcexfzbfo1Ifx948MQP9jMeG4MEhwLczW7HKklKZgrqsaOu+g1VY2aZF7viTIeBFIs5JWkWg7gLTKcsWKOb5mVg5m/IzWhXSiXuQ7NpLRKyOJYSm0VdMxNKUqUQilK5CBKASnyYpAnH6jId7G+JQ44LiZzLBQoXdhsA5v/6Z6jbt8e5fiotbJsXPslOcdWSyXrdv+1OF2Bpon7bQshRU2A59tq3Cq/RQ8ckEQIF897n/e5/sPKbX7DPq5MTaBTlnBpyx41JonxWGSfnD+2qJBms66w2OlK0knT4nf+IHV/+d+YYIW3wVJKKY/32vNbr1Vr84+9DG3QHuNMPUeHjUgzDfg4k2SlgxigVC18K8AUL8ey3fmj/zVtIdC7Z7HRbkkY3bHEO0JYkzbEmx4+7BXUAkDhLEv9xVKj8QZOnbmByEYnw9H/9Gvc8cwR/ffB55OsbfMuGAblvhbeCWd0kZBTbvvMTxoI4svVsjK7fbP+tTjj3qU6Oo3GH4wKXOMK63wHA2Gmb2H7UWda6sTFIkmT3x+UGySlJUqEAZdj9zhuq6nZDFUzBWvW88MKcklSDYPz7fbYYyftTzUnHs4oFlg8h4hsev0vFjOgCVRryWl4+vOW72uk13RPa3W6WrcuhETaerRIKM60k+bmj+fapiLmSOLTf/j181asdS4efAG0A8qMPY90NH2MOR3tP8MUAw3ARQxBhUM6k0fz4Q2h55P7Q/bXrrSJcY1soAMdNq17vy64WXxTy4dsU4FNTqNvzPE799Iex+Gf/yZRp3Pak+8LDh12HhMxfNp01t1M9bx7ztzY2WpIlL8/FkBAChlgPa/UcX70OQHnfjbDXJg4fdB2j3wFVd8eHEtc3QpoAiHM/BcKnkxIkZDoca83k8lXMeb2ujvmbWFgrCa+YJCMSwRhFMFCgrFq0ux3ZROm75Ao8fNv96L769eY5LveZy5JkrV0jm87Ac7+4TdgHSZKcpyTLMCKRQGUqLIh1yKUkWdDGzf5nW1rZE5KEp//zV+i3CCNUymKmpNPouPt2++/kwf3MpQ/c/ZRJ1EBBT1qKsGVJUq1285x7HW9JAgBlwIvdzocsZJZiTkmaxSA7RdMp/52ksiaAk/veagWVVridsqR+5xoRTXuxfSgXpTYV5rqg+wjrbhd2PBhLkiA/SRgEpDhiED96CIAZYHzspq9RApJfTBKQ+P7NruON2592zSd1bBQyx2BF6KTV8TFs/btXY8vfvw7KBOu+42qzEq6wVt8CDE3MPUgSgP5+IJeDIUkY2XwmHv/F7cLrwyBPudt13iEWHhue3+4+SOX4IRCx3El2gkzW7aewajVw55323+pY8ZYkgKUgPvqxT9tMhURBnurowvZ/uwXP3PJLq0NU3yAVJdSFtczyAfU8FD6nk2HYmwGqyyJSHIK6OHbqRvv38OnnMOfySdaSpFfAgsLDy5IEAIVEEo/98g488dPbgDoqZxJZA/ScvYkyuWINUitWO/GEnAutV0zSxOpTUEjWwRNV+k7YlqQUqySRd1u16L9FY56vq7djqCIC5k+CxMF9zN+ZeQtcZWxr4dgYJMmZbzxJh1HnHiPR+zmXTHYO04aw31z7w3qybpOHxEyYdCtZOxubE1ymliCBi0kqlQJZdKwUdzvqN2NJqjkVuHKCtRfKSb4rAp1/pBgGNIJi2QYj1m7lkbe+B7kGirhhagqxY4eFE0QaHUX01v91HW/Yuc1dvyC4Odts7t7KlBsUz4AngjIxbiV0DCzqi2JcKA0Dtqtdrr0DhqZhjHZT8oCX8EzHe/BseVNd8wE4z4SBQEmiYyns/lrCKc/SJQHApZdiZNPpACx3uxIsJ3S9I6efZVs/iLtdPp5A32VX2sqTVKFdb79rExzdNA+FZzgzDDupKxGWS+5XUAFZxiO33ot9H7oOxzlXTd7dLu+nTJQIkZJE57UaP20TRrecydwHbYVM7n8BAJBavBSAs8EhB8RvkU2WQiQaYPWujinEUZIE60qh4Kms2EV8EhUTJDklSdgP2t0OkqOccRsckoAuXgRD1UK9R3MxSUXg/vvvx5VXXon58+dDkiTceuutzPl3vOMdkCSJ+e/yyy+fmc5OIxi2M3uHURS0Yf1TZfmPdf+rNWHz5IIBI5TSVFrdZV7vRSpRAXtJpeYVHd7gFZNUaYVJ6B5bbp0h6ikuJqm8/gCARCWR5Wm4jRAKabFDQ/J3ZNvaYRjOLvK6f/kozrvsLKz910+6rpEPHRLmH1Enxl0d0AR+9elFS1yuR4EC+8AAzr9kCza/+/X+5XzgpEkqcpT2mcLQFBfUXQpIMlF5Km27/BCQoPGIKMZmZMR1iA+OB+C423kkRiXCmTY2IiSIeOLnf/DsO19vLpZAttlUkggTIy9cuuInihCKw5ZUBVZI+r0UWpKIkuThjhUWfnmSyN+Tq07Bofd8yKW40u52w1vOEjLAlQuhIq24rRFMsm7K5a356ccAADnrOduuslyMnBdxQyEa9XzfqinGk/uW9Rwk/vmPjUGyOqw3iK13YRILh7H0M+52MqAR5cylJAG7rv8Sjr3+bfY7RTC++hSqvjqOuKG4d6pWMaNK0uTkJDZu3Ijvfve7nmUuv/xynDhxwv7vF7/4xTT2sLbhE640h1JQjCtYRZUXWisqtQ43anGBCu3aJZVqSaLc7WYxcUMYBN0dO36VJW4oJlkmAW/ZCnq+RCDPtrTBoNyQCBb+8ieua5RuMeuelOfpdg2hAFuIxTHw4kuYY4F04A89BHViHC2PPwSZiiMRIXBOF+FCCQB4wdxNn6qAEGuTVqQmEe3rZc4VqySJ4i1sdzuP2A4Sx6QKiBv6L3gpRi1Lkxdod59cLOGyJPH5X8rgbQi96SALhFX6CQpjkjj67VJRzhuvU+52u274SvmdEUDobqe4RVI6pZNIQSDjZStJ3OYHrwiRtasQjfq+b9X6etD3rTDJrmHH92Ubmz0tRn7530R4+vtimZlxtwPlbscpZxKA469/O3Zf/2Wm7wVVRXrRUqe+hsZZZyUKgxlVkq644grcdNNNuOaaazzLRKNRdHV12f81N1eeZaXmENbdzipXabcav67UotgpUgZqsZ9eOJmMc6XeSzGyo2/+D6ogrSSVa50La+niP8iLv/Y5nPHGl4nzxlQZQrroUvGlL0F9bqf9Z1BC16D+hIGtJLW2o2B4C9c0ZC/GKz3nmmMidxdDVV30x0oQiQBlNal/9qnAPorgWJICzjP7KYatJKWXOflcdn7h275teU0Fvb7BjtFI7tvNnEsvMZUkbXzMrSCLlCSRKxFht+MEXSJYkZgSk7iBVZIGLrzUo9cOaGtILh63LQxRax7xwmU5Ah1LH87Wk21pxZ5PfhaAN0sieY6ygN2OV+YAYNe/FK+o+N1e0K3nKXc7o4REtmEgIm4QWpLo8RXkiyKWt1yj+bwlzv2TX3bI+5yPeLutVVPWNyIRO37O9Z7s3QsASC1dzl9mwyv/Wz4SxeG3vZc59thv7sLQeReJyxNL3vg4pGzWtj65LUnOYND5s/KJJMN6mPO5bjaj5iOt7rvvPnR0dKC5uRkXX3wxbrrpJrS2tnqWz2QyyFAfrTEr+3Iul0OON21OM0j7Qf3I6Tp0y1f5yMAEoqqMuqhqH3PK5ZDLKchmnfK5XM7+LUP2bYuU03WFuc7V54JMlRXXSc6PpXQcGxxHQ0wT1kfqzOXMqafn2L6Xgpzu7rue05n6esemMKUXsKAxhoODKXTWR9EQ15Cz2s9bid1yuRyODKXcY831TdRmqfeQo8dAN2AYEvW3OW/zBcM+ls877ZBj42kdzx8fRkd91HlWssH0R9fFY+31nABgPDWFmGb6iefyBfc46zpkUPMjl0MOBaSzeRwbTmNRSxwxTUHfeAbpbJ65Pks9I75uRVLsMSbPhvyryJLLSkTmcJaax5lsjnrndGoOU+1SY+KHqUyWGb/BMWqOGBJ0qz+7jo9gbVc9IqoMZDJYdPM3AADzf/kjDG504kX6x9LQ9TyWtSZwaDCFxriKnJ539VHX857KBT8veGRzORwZGIdeKCDvc5+9o5NY1GwKLKIyuq7D+Pzn2Z33qRTzbAbHp5CeykBVZGacCEYm0lBliTnu9Q4RRAZNd7t0UxMUPQddsIvsuv7oMXFl2Sx2dY9AtyxKuq4DkxOuYnpeR5YT3ozUpGc/dx0fxorj3SA9U3fvgn7Gea5y5vpawPFhd5t0Gc91mKz1zHqpo3DsGGQAI62d9vFjL78Gp133/5jr81TiSntuidrpmofo/r226w3BZOc8FFQNsp6DPNCHrBWjBABTfQPgxU057R6zIz1D6ASQV9lvWS6XQ042kLUEc2VkGLDihnouuQLP3fBlM94k4D3NUwrHlBrBlKV02fcdiTLt5vMS877puv9aSIOeu4YhIZfLgahoBiTkouaMkNLub8meEyOIqQryeh4R3pJUKEDnlLltX/4eei5/pef9i943wBpXyVw7+Pef/u4K66QUtcmWFhRCjksx0AVCdEFR3N+YvP86kdVMWWOq3pw/8tAgN7+4eyXKgKZZ67+brl7XFRhg35tKIh9PQB4fBSbG7b7t7R3Fmm070AhgctFSz3vWOddIgmxrG1JUfikASDU0en8frHlmpFLIW7GGhiQhG0uY66MFeq3IU/NCTySRoRSjTDLJzDNdl6BL7u+TTsl/pSCsHB22niDUtJJ0+eWX41WvehWWLVuG/fv341Of+hSuuOIKPPLII1CoAD8aX/jCF3DjjTe6jv/5z39GwoNycrpx1113+Z4fzQJHJ8wFhOxLLqoz7GMEvUkDTVHg2CQwkjHPZQ4Y2Dlk/lZkYHyv9+4tKVcfMXCszvmbxuAeA6oE7BszzyU1AyfqXcWYa58CEFGArMf6ciJpoMX6DvSmgf600/dSMJIBjk2yfT8SN7Cb8log/UtqBiZz5u/TWgz0pICBKfPvU5qAP9xxF/aOuseB75uozVLvYSoP7LPa1BRAkQxM6ebfDREDR+vMXFjPD5vHogowuMtg7gtw5gqBJgOje5z+7BsFpvLusRY9d/vcM8CqRutDWwB2jbBlj8UNqDJw3BqLiX0GNBnYMyohlwdiqoGVDeI2DscM7LVeSb0A7KbqVmWgTjPseb2oDti2bRsA0/2C96Sr0wwcrwcmcsChcfOaI3EDndYcoMf4aNxAh3V8YAroSQXveE3uM3Bo3Bm/pygmZN418OGIgcV1QHRoCCSCcmhwCE896bYy1GkGJqz52JUw7L4cjhnYkwCeG5Y8LTNH4mb8Gpm/ovPk3Yqpzpzi8RTMdwEQP6dGNY+NFmnDwVM2YNmu7Rg4fJi5n23btuHIbgPzE8DRCWA0y9bzzFPAygYDL1Dv1nHqfnkouSwut1xRHj90FBgcwvnDw1jC950b0+XPPoNGAAVJhkwFqI0NDuKhRxxr3tG4gUV7dmMDgFwkAi2bxWDnfDz15FPI9Q/iFKrO/du345DP2L3sgUew2fp7eOcO4XPOHDDQPQkMZbznWuaA4bmukLV+SnfW4t6kgZcd70Y7gD3Hu7GXanfhWS/GaY/dj+fPMBNhkneH3PuuuPhZX75/r7Bvu070YkVdPepHhrD/oQfRQyW8XLBjN9YD+Mur34qxljZcfcvXURgddY3DyueexxkAJnI6c250r4GYAsTHJrASwOJf/QT3X/VGAED/ZAqP7vVniCOYv38PzrV+P/78bizuG8Am6vxgeoppN6EaSFnPdWiP2Qd+ffNCd8LACWvuyhKQ2mfgKutcLp/H/u4enAZgoq9XOB8IzuOUpHQ6jb7xCcynju3uPoH9PnU0RZ11ksb4XgMRS0zi597BmIEhj3WDoO/7P8bwZAETO5/3LVcq2iamwNOMZA3DNV70WAMAH5W+fd9+DE1MoWGgDy8CgCF2rd3Pjc/S3l7MB3Copwc7Hn8cOYGc0p0wAENi3ptK4lxVhQbghaefQs/giH1cffAxbAFwQFY9503ueDdOFRx/5NyLMTyRZtaux/cfgn7shKA00NzbjRcB0MfGcOjGG7ERwFQiiUefeIKR3Yb2GDhofVNPzekgdvYJScahsQkQm9dTBw6hPj1ir+lx1UBEdn8LaPmvHATJ0UFIpcLF/NW0kvSGN7zB/r1+/Xps2LABK1aswH333YdLLrlEeM11112Ha6+91v57bGwMixYtwqWXXooGj0C46UIul8Ndd92Fl770pdA8dgMAoGdsCs91szt5p3TVY1cP60O/bl4D5jXG8Fz3GHrGTLP+JWs7EN1tZluOKDLOX8Vy4xMYhoHoHnP3oL0uig0LG+3raGxe1ARNkdF4yPTzbUlEsHlxk6uc6FovrO2qx4ImU0o90D+Jg4OTdt9LQe/YFHZy47W0NYkV7U5gqKh/l6ztwN6+CRwZSiGv55E59AzOv+BCNHSzu72SJOHiNe3MsROjU3j+hJuitZR7GJ/S7fGNaQo0RcL4lLn70lEfxfoFjcgXDMRfMJ9XXVTFWctaPO+LIK4pOHeFY3V97OAQJjK6q59Bz46UzeULSOxlWa9WdtQhosj2WJy3ohVRTWHqpOckjcUtCazqMN17MnoByX1O3VFVQXNCQ8/YFPJ6HoP7nsGmTZugqAo0RUYuz3JJtyYj2LSoCYMTGWw7ZgadL2lJYKVV/0RGR+NBc4xXtCextNWcG4eHUtjX5727T3Du8lZsPz5qjx8N3rJlj/tOxz2trbERW0/f6rpWliTbUrSqow57rb6Qvsf39Htakpa2JmEYBg4PiRf7xc0JHBk2z9VFVWHfCcgzFj2n+YpuBxMb554P7NqOeY0N2Hr6VuT1PLZt24ZNmzahrSGOLYubmPWIxtnLWlB/0IkXWNVRh4OHepE4sNekI6Z2lmlShdNe9CIk4hG03e/+KJ6+cT3jvrXwd+YOzrHXvgWLf+XELDXXJZnxX9aaBB4zlaa+y6/CsWvegExbO7YuWY7O4R6mjbVLl6BV8OwIFt35a/v3+n3PY2zrFtOiRs2JS9Z24PFDQ/Z7LcIlazs815VT5zegqyGG8akcGg+Z7kTr5jWgwfqOLDvtNDRQfTyx7hbkHrwXvWe/GHhhr/3uAMDytiSWtSWFz3r8opeg/t67XceXbdkC6fetwMgQ1i9eiAVUW50/MsWIjtPWQz39bOCWryOu51zzvXPEjHOKNzUx585e1oJkVMWunYfsYy/+vRlH0TyvS/jeAOYakaF2+hPtjuvPlrPORF0zy8jWMG+eXZckSWiKaxhOmW59Wxc3IxlVXOubF9Z01mNPr/k9VmUJF6xuR66xGdroMMbOfTEWn2KKqs2RiLD/6tgotO7jrmSymRe9GM0qKxssP/U0NPnMv66GmPB9e9GKVtsLYE/POI6NOC6y9NrghWWtSfvbXBWcvhVPdLZhcslyXHjZWQAANRpzjZdI9mHOn346prrm2+65iq5j69Yt9nrCj09rwpQ9Fq5ejfiZZ2LK0pLOXtaCbL6AqVwBzTEZ3/vtPcx7U0nIjU3A8CBOW7KYfZf+1/wuta9c5TnvF+1/jvn7xOVXoeclVyB38eVY8NyzgJVT2ZAkbDz3HE/fwWivqYprqRQ2/uRHAID8/IU466wzkaK0pK2Lm/HUEXPNSba3A3t3mde1tmL+MocwZt1552HFojb7G9YY1xDXFNfcpOW/UhBWjg4C8TILQk0rSTyWL1+OtrY27Nu3z1NJikajiAoC2zRNK2tAK4mgvmhqHirnm6tqmuuYoqrQNA2KotrnNKqcqsqe7RiGQZVTmetcfVUk+5yiKsI6Rdd6gbRH7oHueynQNMF4UW149U/TNGhU+wYgHAdZdvdNVXXPOovuf97pn6LIUBQZZF1WFPM+pHyBKuPcm9+4q9yzMueJu59Bz84uKxdcZc3xk525pGnQNMX+W5LEY0quJXUXJPYZqqoMlXo2gDn3VEWFpsowwCpJ5HnL1LujUPWrzBg7xzWuDS9IimL2RyDjKrIESXIEYo2MO7UIR+AeOwBQFQm6lc9JUzX3O6kqnrmFVOthevZfdp5DNKLBRz73nU9a2vzoGbIM3aLIVrNZ97Ox+yweU4U7rqkazn7b1ah7YRe2f/0/0XfpK+xzUSvuJR+NQY1ETc8BQaxGLJ1GLuZ4CMiWj//4xq149twLMO+2X6PjL3dAznPzS1MhkQDuRBLjZ5oWFxWA0cjGvWrcvfIgboEAUL93N5bceRu0t78VhwYcIVTTNMiyivjoAApaBEZjg+u5mmPnsa6o5jdD0cHMEWnKci2PJ9nr6hsxeMXVtosWeXdIO17v5MBXvon609371EZDox2nEkml2eeYNsfcqG8ArHguJZ2CKiuMgKZaGxuGFmGv1zRomooCx5wFAEYk5jn285rjODbkCP7Z5avx/A1fRa6tHaqiotDKblgdfvcHmXXJnKcFqw8qIlq4tQAAM8cVRYKmaXj8N3eg9dbf4Oib34XGZ01Ts5qdEta54YaPo+Pu2zFkJXTtv/BSjJ26Ecfe8R4s/e7XmLJSLB6wzov7rVlrMfmtKo7VSg1xr0Fl6LWrVIy+iIuXUdxtimQfGlLCnPsytQ5oBQNGxFrT+O8IiXeLJaAoCtSCBE2V0VTnCO7EFYt+b0QodQwIpXpiaADj9LpEQkXiCc92eZUt32i+6wqA3LyF9vFCJApV9ZZHpDq30SCfrIOqqFAV572NUONvUMQNRjwBiapfTtQxZTVVhSoYP142KxXlyvRhr51VeZKOHTuGwcFBzOMydP8tQBQ4To5VOwdMpWuvNFFBJcMDZ4JEYbbwNpQyNrIs+VCHl1Z32HjQSj7LYpKg2hh08nVIHjTSilz67DUM/3ukrVvlvCNE8TDq6pwcHwLiBvJcPHN9CY7VvWDuSnb932+Y44T1iQR3FwxDGLCsUox7gMPAl08k0f/Sl6P3ZVeb9yBgEbPb4Fi2dC4nTBCTn9rLWp6WfutLwnLJpx/Hiy/YgBdftBHRPrH11pO4wc73wJYl7GmiYP9SoC9cJD6erLfZsNRJdldfmZy0ytTZQd9SoeBKwmvnp/GgMCbsdjT8csKICHu6X/sW9F90mdkfiuTJkCRMrnIckSSJXUeKZQJlrzUxtXgZDr7/o9Abm+x+ezEjdtxtJv1t6TPnzsTqdTj4/o8iX1ePAkcoEIawJKiPJV1f3uUloSCw2gT1g7Db0eNE0/a7KMDJPAxgiQvz+SiVnGD4TNMxdN5tv2aOO33znvcnrnodTrzi1dQ1zr3q9DsU0DcRi6JwraPZBWnihmhMSOMehNlG6DCjStLExAS2bdtm+30ePHjQ9G0/cgQTExP4+Mc/jkcffRSHDh3CPffcg6uuugorV67EZZddNpPdrjrCKj0ixqOK96VI2t5KtlUrmE72vEoOwXQtRX5dViTvmJpSIfsssnRbXm5qpXRHL0ZLIt2jlCQ5Kw4SVah7YZPfBiOoTFF99oFsCbtGMukIfyUkkzW47jDrHMdaRbLREwXGzJPkFmp4QZzkciKKDmGRkrgAbMOg2uA+9HwiTS+GMgLtBEs7rjc2Q/T2JZ950lQe0mnU79ourCtoDeS/DRJRkkIkmCwF3Ve9Dr2XvgKZrvmOksSROiiTjmJaiMVt4SsywrKMEeUqX8cqoeQVECkDpSoIAABKCJaCFiGpOOFNVJY+ZG8mhMhXAwAFa1ebzgdmnyuRXc5P8QtzpzMhzIrY7fj1fu9H/pn5m8x9WvmWKUZK/p0h73M+GrO/F8I7DbEIlzpCg+eZnlAxjo2T7psX8sk6PPclJ22ORClJ+Til+ASs/4amwXA9Y8l12xKjJDn9KkRj6HnZ1RjZdDoOvufDvm3NZsyokvTkk09i8+bN2LzZDHu99tprsXnzZlx//fVQFAXbt2/HK1/5SqxevRrvete7sHXrVjzwwANCd7qTCaL13G+NL5cCvDZVkyJQ6gonvEpwXZW/FaESh1a3CxWDi25VlkqanxJY5YpJjBqy/UKRSocf8j734BJcSQ+ppIaSwJIBmJY2u40KKTVOfZWZNbIlBBt19fZH2E/489rk8ZsHBq8kcVaegmEId355q4ZMWZIAwLCVJB9LEkfok+ctST4U4FI2A22AzR2keuRKostFe8TB1EHgH6mUtoSqClmSeJnp+c9/Czu+/p+AJFGWJNZ6p1qWRjJuhBZYG2Hz1WiW0kTTBtOYXLUWWc7V0fBRkoJkeH8lobwsckHX+lqSBGxqRDESKUl+Y+DbR0n8uxbxwsf/BQVFwa7Pfs11ju/74b9nmRvtDRZFgWERetFJWl3fpAlTyc8n62bsu0qUDd5yY+dwCvE+H377e5GPxXHwH5wYfHqzSQr6nkgSs3lgyDL2XvdZdzG635QSVojGUIgn8OTP/4D9H/onUiVd/UmBGY1JuvDCC313zu68885p7M3sQ1BujTDXFlt2tgjrYcHfj2hcqv6uc+NbrfEu1y1TdH2QqGESE5TVLAAwEUh+O5x0Hz3dvkroT1GGJNK90VHnmAfdKN0XvciBMgz/DxFdnzI5jpVf+xJOXP0GTK5cU1Q7tpKUrEMhan4kRcJf0Hvid3cuJYmz8hgGkG3vdF0XGWDd1nhLEkkwKvH5aODtbpdtbkU+FrcVQVFCUIKo5S6Vj0TxyP/dj/MuOwux7mPCCaNRiVhJglMeQXOT/l4ahYLjbhcNHwhd6nqWtxKM8tY7YknSE5aS1NCEWE+3rRQR2EpSo1hJKkRjeOC+Z3HhWavsXDalWlEAABLwwqc/j9U3fQoH3vsR1zl6HSlWoGOFQffFxJom2kzQBEo0fZ/8PZdlTfNAmPudThn3yDv+AUff9E5hTqai+hGNAqmU78ZGlMq/ZrchaCScu10xnXNALEW8lVrOBLvbEez9xI3Y9+FPeeex4k33AfjLUweBaNRF50+DcbcTKHKzzZUuDGZVTNLfCoqV4WrVTa1Y1OptiF78So45K9jX6CCUiLCWJKH11ONN8PugeVmfyh3WklzXqHxtskdMEn2PxVp+gpTeAlVfx4//E0t/+O8456oLih4MeZIE5tf5WpLIe1JSMlmZjUXgFRgDBgbOu9h1WeLwQbYPtiXJus5SkoQxScQCwilJRiSCh+54FH0veTkAoPnxh9H6VzHdbNSyDmXbO5DpNNmipHweCmdFAThLUq9YSZL7+zD/1z+z43x4MCNIza9KWZL8oFtuciqtJBUKlEXOVGiJpUgdHYEyOYn5v/1vaIP9nkoSvdFiRCLItjnCq1f8knmdPyQAx9/4d3jk1ntx8P0f9b1eClFfMfCyFABA4zNPuo7RiXBd7nZaqe521UWlBWJPYb+YZixrs0xtStHrjjI5acdTZlvbfL+31fwSe80PhViSQnpL+SX6DbQk0fXE43Zd/JDQz9ng3O1cbfr8Zdcxy2ScOSVpFoMISdM552bL/C6lnwbEC2Mxa3RNLQAzsKnj8v/2WWFYi1lALEZYdzvqd7luqDRKCUkCtUsosmTwoJWkUC6Yhv+HnLYkaSccobx+905RcU8olLtdUEC6H8pytyuYAnTfVa9lyiUO7Xf+yOchWwJQ3o5JsixJAhcnr5gkwLRapeebTFFtD92Lze9/K2LHjwjqIKQF9TA0zXYXU/r7XWUjlCWJWKB4tL7n77Duho9hzeeuY46L4k8lSlGtXEyS99slcrdT0mnbZUdPskpSw/PPYtWX/wXrrr8Wm97/1kB3O4Jsi5O2ohwriixJgCxjctUptrJMIKE8dyBasRNVQywFsq7bVmRtaACJg/uw6f+93VWetSSx98y7g4buY5lKTK0YBYpxjCSuiTSZAb3qRIZMJsp8LF4S6UA5faNBlCA5w1q8iGVYRKpQLALj8GhYJCdBl+QpBsGwitxsx5ySVIMQM9mJypn/Vij0wKdDdJs1pARYKMe7PMztCC0XFRwG3r1OZFmqSHtl1uHtvuZdsSLLJSsrpbgdMu5IzAnPP0KhXEuSF7sd3ZVS3O0AS4kRKAG00kVbshqfeaKodtRuU8EqJJP2DqjQkhTYYe5PWil0udtZVh5OQDzwhW9i70c/gwOWH37iyCHXNeZ1XEySy93R8HS3IyhwgooojojvZ7bVFPDVAbeSFO3rda7zsBTF7r8PADD/978Snmc2E1KmomrIMmOJAKoj4OpJN3EDuX9DklCwxjFnUXkv+fH37fto3LkN2qhpXQtUkig3KD93u8CYpCJilopVKETF6fro2I3IYD8kXcd5l56Bc648X1hfgbYkUZajoTPOdcXIhe6j1++Qt1pe1FblIOrv1GtfLy5szRcvd7uI7WrXBkhukgIa0+Jul80wO3DFuNtVEoaAfl9YjrIk5QUuvnxMUq0o2uVgTkmqQYSVKR0Xo9pTXGYtyiXBmIZHUW3K93JBz0dZCqfEB41bWP0hDLtdKfC1gni5J9Dudh7sdkwbtNIQ4hkbMKB2H8dFZ67E5ve+0XWeVpJUKpdP4/anA+sm6Ljj9+j6hklpbdTV2zucfrTYXj13PUNqt9fFbpf2sPJEIzj8zn/E8Bkmha467sR9EQIBQ1Vt4doO5C7C3Y6A0PR69VHUz5ylJCn9HMX3iROI9lNKUkqgJN10k7AfDASWpHw0VhVpROfGnowTHaOlpCiiDKsPx1/zFvs8rZyTBMG5JlYg47vOuNv5WpL879mXuEGSXDTexQxhGOKGya1nADBpnlvvv4exuvHQ6xvt3zRRw8iWs8J3iu/jSSCgAuKxnvjWd3HsNW/Bs9/6IXvCsm54ETfYShKxVhqkjRKDkkoEvQFDr6XE3W463GcZLF1i/+S/PfT3nCFuEMUkhVCsZ1vc0pySVCMoFAw8emAQuwTZ1gHghV53xmknT5KDXiq7cVYv4MG9AxiY8A5iDAK/ThgA9vWN4+H9A8jlS2fj2t8/gYf3sXUUDAOPHxzCc92jPleaONA/gXt39+HgwGRFPwZidzu2galcHnt8MoCX1WYFF+ZUJo+hSQ8LRhXBWDAk7zxJQTA8fvte42H1DEPo4IdirDxj6Rx2HBtlLUke7HZ0rXQbQxNZPLC339fNzzCAhl//AgDQ+sj9vn3SKIIDnuzAD+uud2I5JrSYswPqkyfJC7yiKaedZKtEmSHwsvKQJmyKZUrZILuwBqU0EAsL7253aCDlrYhZGDqb3fWXCgKXPa6fGcsKQitJdXueB+bPZ69LpeDCZz4j7AcAPN89hl0nxrD9mLM2Hj5mKr604GL3tYw1ce/PfouJFavxzH/8D3O8YMejOd8YdZJlEwSA8XUbhDmP4t3HAACpxUt929frnSSX5bjbFaX0lON653Ht2GVmcuTkgb2o27vLtw7aukbfcz5ZvksYj0p9L2dU1K2rw+4bv4r+S65gjwvc7ehVVhu1XD4ty0m5DKCljgFtKaJd7ogbc1mEJUVA/4//AE47Dfo3vx2qvEErSSKSjdml/4TCnJJUIxiYyGBiSsfx4fD5RxxLknNsxzFWwZjK5bHtyEhZfeN3Fg4NpJDK5NE9UnyuFMDs78H+SaSyeeZ+h1M5jKVzODESHO9woH8S+YKB/X0TwvOhheoQwjP/4u/zaLOYdplrPIT5oPrCKB9PHx4uoUflge6VH7sdM/bcOX7Mw7rehWK387neC8V62/WOTYVyt/OyfKWyeWRywY1KaYGwLQDt/sVTOPuB9juf0GK2oCznskIXP8B7XhoAFvzqJ1j3qQ9CyuUg0TFb3AATYYbPWUQo04lQTitrUt6M+zKohJQFP+KGAHc7fhKKFBveGpXpNBOda8ec/CeLfnaL/XvQUrzkEM+NdxHkvw1+OVX8rShWv1rc9y1JwPj5F+HR2+7H6OYzmHMOI5fTD3XM3NSjFRvA26UutWgpclTMEY3Vneazpp+Hb2B6oDsdcNqCRs9z7vrcR+tiHgTAIYTBfEcHANN64cVmSMAqSc49lxo3E48oVY1JWtxaWpxUaf0QPJeox3OJWkpSjsqTZABL/us7OPUT73fi4urZeSG618V1xX0pVMWspN5rzlAwVBUFa2OIWI+Qz9vrVKWSQwf2453vAnbsgERbkqjbjmkKYpqznuYbm5zfQksS+7tWXDbLwZySVCMoTbgm106f+1UlGcNcdZea26hK8UEE/GteSTcucSdEh2rXxY6fE/zwhFHmxHF43kpUmL5UPVYvCIySFOxuV8ojJnlygqCMOZsnQlcvD9ACuJ6sY/7m6WuDPoiGruOUGz+B+b//FTru+iMkSumQsqwSGbES8dLxKWYbVr+sGCCFUjYcJcmJ73DyJHHEGYbhGffkBREVOE/+kFqyHACg7d9nl6EViMPv+oB1XfAzCCrj5FQRBHmHkE3WdNWjqzGIocqBi5Ern8fam8z8KISxboklPHspSRNr1nn2Z3FrAhev7UDbvFb7WL5MCvD2+iga4pr7FBcv4TV3z1rWgtY6tzXLL6E1Qd5yG4wM9LvYDHuuuIr5O0cJn7QlSRfEI71knZsKn8dZy7xdGkX3WhdTcfHajlAC/tK2pK3QEmxe3BR4XSUR0xQ0J93PxRCw2xmGgVX/dhPm/fF/0XbvnwG4lXrR42yIAFsX+8fP0UO5sNmav/XsnF3QLCZhkMiGk7WO0m53fslkqw3yGTpzeQtetLKVmeu5LsciLoybmv06kQtzSlINYnriWsrHbDGt+tJ8VlrRK6FCxq0szOUVVQrLdDcQunIbzPlQMUlB54uM0wO4ZLJVfKc86w6hJPlZ08K0Kwvc3kSgY6KUoixJVKBuIsn50ovb9roPbffz9u/I0ABAKR18oHVEkMsEcHaVbXe7zJRt0ZJyRElyBD1DsdjtuPGXM1N2fEjY3XrbgpLPY97vf4X4kUOUJckcl9SSFQAA9YDDukesXcdf/SaMW0qCkk4FmicDlSTimhNIxesN/v01Y3PEV5N4tOTBfYgdO4yOu/6A5EFTGSRKEbmWFvqZOgIUUlmWIFHPwzeZrG9NjiIjexRkiRs8ykiScDzYHXOP8Wo3LUn1LzyP+l0so+Tzn/sm87dOuSdWwpLka0USnFJliUls7QdRsTBKY6nwqjkiok615otErSfyyIj9W7USyeqcO6hX//3YWXmYZIruejSvSuJsfKdCKUnlEDf0XXw5AKD7qtcFlpW4fwFHJiBrAX0uO49yGw545rMt9sgLc0rSrMb0bJUXQ9U82yG8Ox/Xr4q0aQDJF3ZBG+wXWGEq2E6515dQgWlZ8nC/oueVQF4sJibJoUimgkxDtBsWpcx7g8mTFGxJEvYrn0fjtieZjz7dp7DudrS7nzAexgO0wKYn6gBZtnf3eRrwoG+iun27/Tt+9DCUPidup/nJR5gBsJWkNl5JMv+lhUdiTSKWJCiOkuRFAU5boMLS7SrpNOp27cSiX/wQp37qg3jRFWe7XPZSS5YBALTDB20liLDBTaxcy7iS+SWpBYLdIv2CvKshoNAuQOdcdSEiQ4P2346SRP4Ws2XlI8HCn0HF4VQiNsMrzrScIQplSbKUJACIcZTvvBBMK/Z0bqhKMNuFARHuS02wW0152KtuRaSt2ex2FGHIiePO79ERAECugbMkldo3wZX8EdVL+SQxftZ7TFxX85EowMVoFoPnvvgdbP+3/8DuT3+hpOv9vnSFZseyRsaSRhj3utlGNBZsW53DtCOsQGbPtdk15yoO0XiV+h6KXuCi8jSU0Kay9wWcc81FMGQZ9+wQ+677UcDXEgy4+xXOkuRfKKy1zfD4Y0aGqsiYJNEYLPnB97DqG59D91Wvw/Of/5brWsaSZBhiiSKfZ5QEkfBtGIZQsKZjkuzcQ7E4lGxGSAMugjI+hnx9A+Rxh+wkceQA6j/rEBVEhofQ+affY/BFF0JvbHKzUPH9ikRhyDIkK5lpvq7evkdDoyxJFnEDH5NkW4CisdACyaqvfZZNpAo3ux2xfEm6DnV8DHpjk7N7XV/PWOLUVApZH0tBOZakcuC12tHKpDKVZpLCGtbcIdfyCWMJRLlVXPGHlLXJj7ghSBEMUmQqRdbgVU++TTx3g2DEqI2JEpUkNyTBLwciQd5rfGvFQiBUkgTudhEqR1ys16Tx17mYpLBWND/YVhk+ltGrbs59tWHnNgDAxOpTyupHPlmHvsteGaos6SvTZ7+PpeTYVUSxnDxj5MmAOUtSDaIU16JqwdUX6u9Sg/Km2xrlK1TzlhtBGddHvOwesVAfesBsx9p5rkHdxxPhkp6GiUli/5a4Y2GtmWFikkphuitJIaWJCfJ5oXtVkPK37PtfByDOm2OAJW7wSljLKwiynhNapkRglCRLeCWWC8WDBpy+j84/3YqLzl6NJbd8G6AUOnV0xLH8WFj/8ffhwnPXouPPf7AVOV5Jsl9FSXIx3JH7NChLEtmhlwoFZvwd5cbf/YvO38QrSHTbpC9GJGIzkpEgcdVSDvW6BtMSR3aQA6yAQUqSkiGJJ8twt+NK+gnABUFeFLsvnNtnXsC4B4SzDBl1jmJQLXa7cuV80bePX5fkSAQTy1cxx0Y2bsXTt/ySOZbnFEcjSlmSSk4k63+eX2uq6S5XLrzkDF8liVrfIgLSDD4myVtHCoizDPG19lSSuJgkkpphdNPpgXX6odxHSe7JUaDYund89WaceOVrcIJL7A24R0uYT6yG55oIc0rSLMZ0WRJKaab1gXtw3iVb0BJATVxLEFlBiq6jlOuZXRyDq0NgJSuhiUqgZGKNCpRh1AtfpTfY3W7awGVT96IBJxD11tC8hUTDMCCl6bgesbVKFA+lcgK411AVKPco4gZErCFh4qHWffojAIBV3/gco9CpE+OQR0eF12z4yN/bv90B1s67YjPcWe6DREkUxSTR5+lrPJntBNeLIGLI0y0rCmHocyxJ5r2Q/EM0w53wGQW425HxF8YkVUEO4RUfOUtvAuhWu2bDXsqNyJLEw0hSliTNu3zQLQafL821DGA21D3bkQAcevcHmWPbv/kDDJ17AXMs29zK/G1Q75yeKNHdzueGROcIM1uploCZWGrF7nZuCnBl3J1WhZ/LJQvu9KYxZ00l8HK3I8QNiqXQxbpNRsxJTrEuFqXcSjGX9F5xNZ77wnemPeHtTGFOSapBhF1viNBayvpUidw1fi/j5ve9GbGebmz5++DgQWE75SZ1LZkpL4zVo8JfBOqLK6dTVbO0TYfLnsEpeQaMULFB4jEV+8v5dZk+xxI3FG89KhuckiSKSzI8+khQ0NzMXHZ58IK2WEmiE3oSRYcnb/AaEkbYtfpXEOzWAvR64FEbxcSnTk4wAdUi5GNxYQJX+3ycZbgTKUkFlVaSKPKKIPpvC89++0e+5xOHDwAAMh1dTr+sHCy2kmQJaYTOnLRJK6q01Wj4jHNcx0RQbHa70pI6esFrXeeFIjq/y4F/+Chzzku5F5NMsA0aCTomyc/dzvNU4HkJvELgXVjsgh0MSfKPPSLglST6ezBdVNBKCZK111pbcXjFJAn6bNjJZJ01T2Q1H9uwpTJ9E4DvlqclybISytaGjRdZTTUh6plncnSP8p5lZ5fByBNzStIsRqXWpVoMpCuqSwFl/YVqg/vbDf5dr7/vbqz45heEeWJKUnAoNyB1cqKmYo0qsdBVhN2O/h3SfdKr2HSMb+z4EUjHjjHHRNYCw+M3gUhJoSFPOMqOFzkEabegqtAtVyZeAPdaA+gEqpMrVjN9cilJQZ9QijBCGx2GHGApEblsScx51t3Odt+jLUkUHbis62i9/24s/86XoVqU6HweJh6D51+MA+/9iOf5xNHDAICx9ZvtY7oV3Oy42xFLUiPzr2opUYCjtBa0iB3PE8RCKNt5kiqbTNYLBqewEwr43ktfgUkrjoI0WyhCSXK1EzImKRjhB6HY8Qrnnia5XCFF45JtZkkuck1OvAwfO1MqgixENnGDxzVMXRXpUflQFEFP7ITHVP60KXadeuw3d3kSi/CoxHukem30kLXY2rCJDJnJoctVkkrZIOGcWax6ROUC4vyKbrn2MUfcUIMIq7Q4jF5V7AwqvwtfS0oAjzB9W/l20zqWnr8I3a99S/mNTjoCqzoxjhzm+fbHyY9VG3DHdbHzpZSYJP4Yq0z4xCQxbVO/A3tQWaz/6Htdx2I93ZjwyB8DiMeJ3nnWRoaQo3adDQOQqfxHdAJFGsSSZGga9Lp6RIaH7DgZuy6PPhEFa++1n4Zu9Z24QAnd+wYG0PLLX2Dk0qtciUAlSnDhY1hECGKdIwoOcWeTdIu4QRCTZJ7PYfM/mO/r4LkXAoBnYlMa2Vb/Mpn2TugNlGBLLEkjw0A+b1uM9Hqzv5mOLmDXDsR6HcYzdZLELdXZ7nitD92HyRWrMXLGucJ27TxJZVCAi64LK2QRJZl2iSQylJdyw8ff0NfYoBRbvximoH6SeoXLT7kxSSGulyV3Dit6PmZa2xEd7EfP5WyQvRGJYt/2fTg+knYpppWAqO+eDGwhUc2cdJ7sdqIT1jumUN9Ufp2aoqy+dhsl9o3xrLH/5YgbRMocYCtJZH2IDPiT1dQCgi1JdNnyGCRrBXOWpBrBREYcdE0Q7T2BxP4Xpqk3DtyWFufvfMHA2FSIJJkltetGRs8HjpN9fYkB+cVYgloee0BYXyqrY3Aig0LBwGgqh0LBgGGYv/OCr4lEWQPUifGatOwBpSu3Ya4bD5hH2YL/ajuWzrnaCkhDY5YPLuKqNwwadzzjOrbkh99zHcvn/Tcg6LiUSH8fd9aAQsX1eOViIhamghZBzsoPIqJvnRS8W0TBSi9cbB+zLUkZgVL28Y9j2Sc/iFP+5WOuU5KAelxPJNH9SncAMAAUAtiTiItb4sgh1D/3rEPcQAuWsmyTL9AMf/XPPWvWEWLXdnzdBt/ze677V+bvPBWTRJM96HWmMjFlJWSMUgHldvLcljabRbDjL3fg9He8ihH4aBBLjoi4ISzKosEmSppAkfG2JIWISaI2EvzyJAXBz9rjIqwosm7mei+LiyS5FH3asvnwL/6I3/zjP+G4IJ9NoaMDuWl0uxKNlZcSGpQbr9LwejYiNzbDovYmmw4AIHEEMyIrUjW/uJ76J2XVl1OTUC2LEp/2oGiUEpMUciEIdHE9CW1Jc0pSDWAio+Ngv/MhFL2wW99+Dc5+9UugjQxR5aZfmKYFuX19E3j8wBAGJ8IxZRXXjvveHnhhAI/uH0Qqywpzga5aRUi4oqIMPSgl6MW6j7nKFgwDj+wfxDNHRvDXvf144tAQdveM4+hQGk8cGsK2oyOuayRKkFImJ8QB/JWw4JUwXwJZkgTuim4KcP92JzM6DvS7BUH6qhzl2SiqLl8wcGI0LcgzJbDOTPN7M7LpDACANjzkW87NJGlApZSZaH8ve34qw+TakT1ikoh/fkHTbAGBXkcAIJ3L45H9g4JrieLhCKue7nYSgB/9CAAw/7Zfu9n2BJThekMjei8X09UGWZKmukyL68pvfgFnve4ytDz8V7OvHKU3EUzp8YlYrm5hXFvG1633PT98+jlseza1b8a2ciEWswX+jKUkxXq7zWc8NspQnvOJWCMDvHIMq34fCnDfeJxwFpggOO07ig+p20u5KYTJk9TSgp1f/A52fOVmX/e8YIEtPIoN3A9TXAJrSTIkiZmbma752LP1HGFllRY1GTc6Qe2ql7UjJGiXMs8YnApD2I6lJMWo3EgSv5lTRA6ioDuh12zyGPnH6amsU0pS1LIi5aOxkhMIl4JiGSADlSB67+Ak0ZfmlKQawPAkK9zwwpI2MoTE0UOQc1lEKc5/x+1q+oQ+kcDbNy5IdFnmG+J3R2PpcNakktoV7ebTizGVAFNEuZzTHeICYiXoHknj2LCpXPHPGgCkSdaSFBxjZVh9rU2LEw+vbpL7GEkXZ430uuvukSnX/KyUS2o579ixN74DABC1BOGwkLMZyJT1g1eSFMrVDvCOSZIpRYck/dSoeBgAGE0FWaHcLlC8UqZwdSb37mb+lrjks4DpMjd43sU4/uo3MSQLgFhJogWOTOd85lzLI5aSxNdDhJEJd4xPrrXVdYxHIRrDnk/dhGOvfxu6r369uw6enSzquCPabo2NjjteptNU7uJHD2P1F6/HBeeuRfu9dwIwd5H5HEORYbfyCjgU4JUkbghatvf8k2M1I25CIsWHdrej477CWJIAoOfK16D3ZVeHKusFv80ZSaqcIuIlBEsSa+UzVC205FjO53N1p3+cnbA9azTC5H8ioL8/TXENi1oSWNNVj9OXNqOzIYZT5jf4XF1E3zw6ItKRDMv1s/Xhv6LzD/9rlguR7qB0dzv/70JnQwwxTcGarnosaI6zih2lJMWPHgIApBcsKlu7qKZuwnetrT7qe/5kwJySNAsQP3zQ/m3vTJaJUnkRwl5XiUzp5aBk17CgO+x1BFVRnpOSrDXjnLsdHVdTdG3FoYL8GCXV6VuPl3JVLvNhlQdVyuXsTYKRLWdictlKAA57EYE2MoRzXnauSQIigMwpFby7Ha8kSQEU4AVNg9bearU9LCzr6oNthRJZktj2NGoDBwAan32SrUvgbpdavAxQFBz+4jfxl2ePmdnmSb8F/pK0QErc1gjIDqxLSbIEJ5GSyrvbtdSJLSBH3/z32H39l9F/8eXuk1xgtmErkZQliVKSRqw8KE1PP4bFP7sFkmGg60+3ArAsSVzcmjYkVpIc4obSKcCLFWqOv+6t9m91zLw3xpJEYpKo+TI1f6H9W5hMtsw+eaGYOBm/JkXV0PPQ61oJEmNJ8mOqrBSSURWLW/0ZG0XjK1I4/O5LhDVd9VjUkkB9TMP6hY1IRsJbbCqGBkcxW//J9wMQWJIEqMQnQTQuKzrMNWlRSwKnzGtgB9VSkur0KZslM7V0RQV6UhpCWUe5MvMa/S3DJ4P73ZySVJNgX9nkof32bzrgutLCXstD92Hzu9+A2LHD3j0T0aGKdnQEVKf2uRB9CXNvcmoSGz/wdjS+9hqc+bpLsejn/1lye8jncdbXv4amb3/DvxylJKkCoa+UAFbakuRF+zsTrpVhEUTUENRz4TJakl+1KMaM/Bs8fs2PPoBN73kj4kfd87+Yd61u325IhgGjoQHP/Oz3tkuXNjzIBEot/J8fI3n4AJb9xzeF9Sice1p0gLUktf/sh8zfXu52DnFDhKKnHmHKeN2f427nCHiGh7udMswqXnHOHTX52MOu+kc3brUaMv/Z82lHYRS9C/ROLC18A078Fp/bSLfc16K9J1z15ZqCLUk0slw8Q44ibCAgyUDlbNZWJGglKb1kOSY2boEkGPRsa7tLSSKsVzxsdzePxK3VAL35pY6bSrqIjIG2JKWWLBdeXy6KsXS4ri2yLr+2vSwdksQpsEU1Ulnhkqdxdo2M5PpRZP2CYxW6h6KUtUbHipazNkfodWrfhz9VXNslfodCwVKS5MlJR0lasqz4Bl3th+900W6m1JjLsuA9Kqq22YE5JWkWIHHogP2btiQ5blflt2EYBra85w1offg+rPjuVzzLiYLhRYuVV+Bu6P6EEGo77/w/tN97J2J/vgMNz23Hms9/uuT2mrY/jSUPPoD2z99oCx9OXyjceaf9UxZZkkp4GBLDxJOZdva/hh3PYNVXbhBSDpf7oTMMQB4cwOovfAbJfXuEZcg6ndy7C6u+/C+mMgGg7Rc/xoJf/cRdp0db5se/9MHb+q7Xou2he7H2BjfpQDFoePYpAIBx5pmALNtsRbKuQxsbsct55TUi4C1JvJBf/zirdAS52xVUzVGSRvzjo5xr3ZakvOVexVuSVC7mSplgGfREmFhzqlmXNQm6X/0m5/o0qyRJEiuA0MK32Z6lJPGWJEuROfWfP+RqX29klZyg2c4rMBNr1rnKEEuSlM0KLUkAkOuax18GAEgvWuoKLPd0t/OjABdeEYxARipJsq19bQ/eC8CDuIE6ll7qCH7TmYCSbFhVwy2ZifGRSDtcGYl1hZQEKSNqBcJ1vkYk3qLkeJpl0vpNCGaev/FrruS+dhsl9k00tUIrHpS7XcwicZmav6jEnlDtl3odd6FoTtBGcwlun9WSk/LWMOYowGsQ/IuXOExbkirjbucCF1/T8vBfzd3ARZeXJLQzDFOGEW6lK7KdStCjknujd+Hrn9+B0c1niC+4/Xb7p9jdrnjQsRpyhlWSpoMC/Mw3XAHAFKL3f+SfPcsJSRAEj5Yv1fqJj6Dutt+h/d478NCfn2CuBYDYb3+NuuZFOPtVFwMAon09OPTlb2H5P18LAOi+5Ar/Brj+uPssFTVY0b6e4EI+qLNicQpbzISFRiSCfH09lPFxaMNDthBMB3FLuu4S7nllPdZ7AnV7nkfrA/eg9/JXQuMsDKKkiQAY4oa8JeSrnKuel3LpZ0ni3fsUTklSPfL85CNRO8u8yBLjdb3M+QTluRxHhNGKZhADgHyjdxu5+uLiJngl6djr3u4uRCXbtddrXkkSMFjl6hvQf8nliPawyrCXux2pO590B3pXU1gpRJ3nZ/5NKQJEYaDmS5pSZu1cVhRK7WvQdSImUa9riyduCC4vSRI7NoIY1lpBVaZLteVlUf31zpoQP34ULQ/dZ69TJEdcJUHPsKLH0Hpv5clJqDJZD5sq0q9qgXEzDdCr+U2t2Yo5JWkWIMHEJLnd7SoiLO/bZ//MNTRhy7vNAOW+V04Aiv80Eb0ItLuFMjnhEmiC4KeY2SwyIXfmwih59Lg27NzmrSSNOUqqks24hNtSFEqJyhkjpFWuEIL6ljy4z32w3EXOMFB32+8AmB+t2LHDmFq4xDl/991oftfbcTZ1ScNz25lxoK0vgI9AL0lFu3KKFD/Rbncxj1VNWRaN5hb7wkIsDmV8nHu+zuCqYyOunD0ud7veE9jw4XchceQg2u/9M9RBU0ma6lqAWM/xEMQNGgpWok5ewfeaG4RWmyVuELvbybyS5LGhk2tpg9Jjsk/lSdZ5wSKicO6sQblcZEsINVQ2FiLvo4jxyTqDnrNOCTED51+M3iuucpWh3RFtF8AGVhkT0Ttn2ztRiMbc7HYiS5JhIHHE/C6kFi11nQ4dkyR4wYOsx7zlSLRZRFsedepe9WTwd6BScpWvu12ZjUgev11lqIbIuzTj8BFu+Tw3wstF19eINMy/Z1ve8wZMzTPdcvm8bWFQUmLWsOeIu106BdUwz+j1xZNuuNoo8VFIYkdMrowDWZJOipijIMy529UgmGlqGJ6WpIo6EfQ7Qc2MW89UaUI7HRcQ7euBQvXbi3Wo2PsRubvZO98hayPlNGpnPUHFgLnACW58H0oibqBpnLNuBrBqwqD8J/VkaTttzOM02L9lztoR7eWsNPff765PVZlgW15Y9oyfQfHxUCKEZeDygpKynie1c2lQ1gWnnONOJqIHJ0oS2V2M9vfagnHTtids5YdQYQdRgBuaBiNOlCRWAfMaJ0JBzhI3iNnt1CHzHjJWrJA6Oe56WOOr12H4dEclJjmB6A87aYsPYlYkyfXsH/vNXa55y1uSCn5KErd5E7SRQFtIhs5+sVAisccnm3VcWDnhR2RJIux+elMzdn7xOxg437SsRgbdMUmRwQGT5EWWkV60xHW+mqKL6/2gBo0Iy7QiZcSieObm/8buf/48Jtae6qqvdNfAgH4GPMty5PpwyWRLb6CaOodQMfaJqyq5nQrdQ1HKWmcX9Je/nDkWO2HGRuarQCYV5Mrpq0TYMUkTtlxHcqnVAoKUYfF56rfHvc8WVl6COSWpBuB2EXJ+R/t6GIGGUZIqOdmooGt6Z1CamipJ8KfjFRb97D9x0dmrsezmrwPwYy0rrg1VENjNuyiFrosaVxJE6epXoQBwcSKuXVSve/NrnFYIOEsSecaM9cOvrmIxMmL/1It0PQoDnvHMxTAmoGUuqCrzHLXxUVcZL3iNDavH+Y+g0JJUxOQkyo9B5buwGc8oJYmec1v/7tWuekgOpKn5C1FQVSHbW76h0d6d52OE7HqoZLK2JYmzUonur/2uP9oU5LRyQJQYvj3FinPKLFps3d84JG73fN+Hr2OszISRjv6cPv6L29F72ZXY8bXvs/chS65nN37Keuz70HXsvXB5UPKcZYbtNM/AVcTb5SUF0hTgHkqSLkoYKTt96bnyNTj6pncCgB2jR4NsnKXnLxTukJe8mxzCRYZ/P7qveYO7DO2eGY1j8PyLccy6n0ohsJ9FEDf4ISjuxKsfNWJcARB8v0J2u4C5UBIhTwnwHF+P8tn3/oPweLmbX2FRCnEDiV2sxjc4NEIp/vRvd/ziyWhZmlOSahC0IMBbNVjiBuvfEpQl1yWUkqRSgqtXnEMQpJxz3aJf/hgAsOLbXyKtF98/AYiCMvnOv4dhRRQWS8tN2gllSaKU1YIlXPGKWknsdtPlbic6eMxhIBP5zNNLXuhbowpGOIYzngYbhw+7L1dUZhx4ty1PS5IksCSF7DRtEcwL8s4AQHzvHpx38WYssOazF+w5SMWKFCjBmYB2I4wO9kPK5XDGG1+GU6/7gFkPCcyPJ5Dp6BK2pbe12y5rC371U5x3yVbUP/cse29UTJKRMIP8ZV5JEtS96Of/5fQ/RDJZxbISpi0LULTvBJPnCTDZ22hWNz3htiRNnHIadvzbLS5Lkpe7Hc/u5iJuKCKDfZj3d9+HrsPoqRtxnCKZYNqPEmKLjKMwc0pStkVgSeIUNpJ/SeRu57BheVEGhxNWShHkU4uX2r8fvOsJm2KdbpVW3IxpZN+jkScbTDPSenkWsmqKmuFdMWcpPDwiSmFWDE6m7i4bWlFgLEmmuz9v2a418JsD/J2GoxGfXTNrTkmqQdCCHW/VqAYFuAEAQ467D5NoskR3O6/4CMDHksTkBwq+OSLYGsk6O/EksboVbZWiBPFYT7fttseAYqEjwfeu2I6S3O0o4oYilNJKPH9p0BHAvALtffvg+ttgxkDlLEkuOuOnn3bXqaqMRU0rgqwkjJVSVIbJGyS783sYAFa/762I9Z7AKZ/9pG8f7DlRl3QYKIklyUf5a33oXjRufxrzbvuNWdZSZPLxOKa6Fgjbyjc12yxOTdueQKznOE77pw8wZSQqmawRS7J9JPcnGBNaSaETptLuZDTUbvNZp1auAQBEBC6EU/MXMo0ZtlUp+MMpy253O8DN7sa72+nzxGMnQph36tB7PoQnfnWnd5wlTQFO1gwuaFxoSeKUpGyLldNqaNDVMcJ4mvagDK6mm9T+D14HPZ7Asde/zcXGZedJoqyFxe7ghxWigoTRasYk8T0p5nAtgoy5S+gt4yaqLQyL6pckwEiK80RVJXdjOd9goiSlUna82kxaksI8LXqfKmhuVDJh80xijrhhhlAoGDgwMAFVlrG/nxVOjw87u7zt9/wJADC5fBWSB/YylqThyWxRVqRcvoBDA5PobIwhxgU305YkWkkq1ZLk5foDeK8rL/R6C+mi+yRWnEFDRVc8DjU16RL+ukfSSGWDCR5oQVwyDEQG+pCxhSurbSs2Jh+LQ6+rR3Sw35UgM8zj2Ns7Dk2RoVvuU8sZS5KYfpxxF7MaGUn7U0gTHB1KYVGLR4JB2pVToCTpecP3+v19E2hOsnTvR4acMVEHWKVo/v/+DwDgwPs/hqF9R4BDh1x1GorKzDt1bAwIIedKcBM3iJTW/nGzbsMwcKDfnEO0ksRbWQBAGRlG/NAB13ERhO52MfMD3XH3H9Hw/LM48P6PucY7fuyI/Xvhf/8AXX/4LQBYwfzNwrYKyaTrw8rHyclUMlkiQPAxSSIQC9TeD/8zY53xSiZLFOK0pSSJkGtpE74kYeQp1UNJKnCWP97dTl8gnjwD513kOlYJF2YSfxY/dhj1e54DAPQUWMUt19bhuu7QO/+R+TtrKaZKNuMiv3GST7I06GFQruw6sfZU/PXRF1zjTINJnBognFZLlhalq6BaRaVEOK/+lxeTVNlBYWNF/M8H9aHmDQEeLHa04l4N2Ipmke52BIYk2TGa5aCaIT/0nJal2WcVKgVzStIM4ehwCocG3K5hNKRcDq0P3QcAOPLWd+OUGz/h2n0eSeVCb2bs7Z1A90gahwdTePFqbieTsiSpdKLJqanA3RIJQKS/Fy2PPYiel10DyLKvRcTrJc7phcAyNIhClIklkLcC0mkB1zAMPN8dzgrBj2us9wSlJFmwFKJCPG4LpnyCzzDP4vAg9dwNAyszLAV4WGw/Gi5WZ0/PONrrxYKKQQnUojxJ5PquxpjnMxmedITlVDaPvjHnHsjzKGgRyLksYj3Hsfx7X8PoaZs82YYMrbSYJFEyWS+MT+UwNmW6F3bc8XtEBxw3QJEC0fzH39u/M61trvM0yLwsUDuaxAVr/q2/NNtfe5rrWXfc/Uf799rPOUkP87G4Tc7Ao5BIuBja6GQWTU89iq7/My1T+UTSdk2T9RykXI6KNXIPnP3sEpylxhI2Ou7+oz3gyuQEFMtlNbVytbCvIy+6AAAgGW7pNaIEOzV4CZ3Eimz3j3O3y82bL7xu+7d+6DpWEfnCUpJoJbjfYJWkZIej9I6t24CdX/ouUstWMmUKiSTy8TiUdBqRoUGkKSUpZrmxpmimSAqlCugRVUYqG3ytV7JwsrvM7NqHeLalIOgW5zV552QKowx3NRaX04mvcTrFx0RUQSqTR0dDsLVEkiQ0JTQcobw4JeocjflNcRwd8pdTPNsp6SpBPcUa6rzc7TzcqAGgrU48bkH30JTQMDjBbhbR17hidiQJ9kzh3FD1uno2EZEAi1sTODJY2vMIgp4Pfifqos57L1KQ6HXH6xWj65gNmF29PYkwmQm2bqhjI7b//ti6DeYxLkFjvohtg4mMOE+DnJoE/vxn528qjkAKSYSw8R/fhsbnnkX82BEcfPcHhUHmBGFc0lwWAcElhEUsH0+gwLnbeV3j1Y7G5Y2J9hwHcDpb2HKdKcTiGF+3AY07t6FhxzPou+yVVJviRj0plnka5RItd0HwDGJmLEneyT/9gqBp5PLscycsdekFi5CkYr2i/X2eeSsKfEzSWDglCfCOSeLnXKEApLN5ND/6IDZ89L3MOZ7UAADkUacPaQHlMnO9HZPk3B+/ixk/dsS21OSjMSiZKTQ/8YiwvkIshkyHl5KUdOUaMqwPlTyVxulvu9o+Pn7KekgJR3Fr2LkNEyvXIF/fAMMAkvv2INfYjGx7h3Uf1vsVY62INHNl07NPAZAQ67M2C+rr7esJ+i+8FN2veiOmzr/AqsB9Hys76tCU0LD7hPccXNqWxOFBN1mLy5LECfA8LfDE8lV4+r9+LSToCDvPfSFwL6N3iDcsamSsHNnmVqSWrxJWlW1uRTx9DNrwINJULBDZ0PBiw1JKUJJOW9CI9rooxtLBVNULW+I4NuRtjWTc7QLiLCq9G72mqx6qIqGj3lsoXtKaxGjAfZ4yj4yt/5wQ9f7M5S32pl9BUVyxeeXivFVteHCvY6U/fUkLRlJZT2GfR0d9DF2NGfSMmt93oesagFUddWhOaDg2ksaQpQzYZYM2Tyv0WIt2+fPIi+ZljY9pChY2h4+bWzvPnM8RVYaeN2wlqejb5QbILx7pnBWtyOgFNCc0pLN52xtiukDar485a6sscKdTKH+8AslRaKGrMYZ5jTE0xsvPbzmdmItJqmFolkUn19Bo5+cgFo+oZj46w0Dp25+GAWV8DCvf+hpIVJ4kBplgly4DQKMVLL7wFz8MFPRLSk5L/SavHXFrKsQTVExSSnhNEIi1IttsxhrFqISOdn+Ju10igdGNWwEAjTu3sf0s8t5kji3Py5JUrhuQBElcB6UkKZNuAdRpP1w7rqzz1v1NWbTQBIVoFNqYh5VPlplxUdPe/XK1H7qcWbJ+907XuUh/r+sYbaH0oto2KzYcam+KuMHgBXKjYFvL9n70M759zUdjnvkzComkHZNkw/r41j+3nTk8unErEI3ZJCdnvOVKrPvMRwAAyrGjOOeqC/DiCzfY5cm7RKy0IhDF137v6usBRWWIHjLtnei/5ArbXWyqy23ZiSgyFjZ7t0PKiOCyJHF53WRJwjM3/9z++8TVr0fWgwijEqYkkYVUp1wv25Ls+Yk16zzrIi53PA24ba1MiMdMCcgpRUCX6mqMQZbdjFUixDWxq50tP0ei2P6172PnF7+DfIDl1a9PxZaLqLcrUT8AAIrpSURBVDIWtSQwrzHuOwYxzV/0iUeU0GNIQK+vDTF38uVKIsaNf0SV0dEQcyVcJqAVDfKMaO8CrzuVZQkdDTFoARaOmYDnPE0ksPNL38Xht7ObX16ubO310aIUdVOpSriUcLuKEpVDv1ySyaiKlmQEkiR5eoVUGvSQkPbZZLLutYKefgXDYM4vbI6jNaQSX0uovZk/BxvEupFraLSFJDWdgqTr9qJXDFEAvYgbMHDax96Li85ejbonH/O8xqQAD6hXd3bJtJEh33ikZTd/PZyFJ0QhIijoiaQtyClTlJIUog5Shiifk4vNQGiNdjkkIO52sbjNNqZSFgazvsAmGbgsSXxMkqC+UuQ4zwSsKdqSFEDcUIRljoAoF2kuwFvOZqF6uNHJ2QwzDn7KGw0/dzvP44K4iuhgP9ru+zNzjFaShKQepFw2Y1tRC9RH2eCsC1I+byvEI1vOwuhpmzzr1BuaPBWVQiKBHB/sK5nLeuMOlhQjvXAJJFlilIrOu0wXv+gzT7nqJhY1XgnpvexK+zeJd7LHxxLaaaUgvcCkBCeP4NC7P4gTL38Vjv3oF8J78oLs8Xx5ixBvSZIkYPD8S+y/s4JErva1RfXIA1G3UJynFGbSp2e//SP0XHE1Dr7vI55V5SwFg2e4I/GYXvNCVWYmHoa+su/yq9Bz5WuE9NIVQRn1BrkjFrOOe8fumMfzkeLc9oDpD3h3mNncx/jf041i2pas8j2veDX2fuJGNodaKTfhYWETt13eIPGbOyXXU5FaxAiaE/S7kOeoQmcrPfickjRDCKPcqBaBgt7YxLhVqBNj9odHGh7BmS97EVZ95Yai+9B1x22BZYKIG7SRIaxe6ggdsq5j8/vE1LiASQMexqXF7W7nvobe6SaxFqVbkkwlKU0SYYoEeComybZcuaiUi1uiFD7vUol5noLgSW3MWJKKZ7fjwT8n4q7JW5LUiXFbMeXdceRMhnW3E+TDEsHTWibsJ7lIvHAv/95X2T7RliQBVToBQxySTDrufpySpE6M25sJhWgUk6vWetaZa2q28wnxKCQStpWZgLjbxY8fZY6TODp6PHVLyKaTChMqeDsmiafYjsfRffXrzbosGnN73lplC5TwTsgFyHufT9bhuS9/D+OXvkx4T17wjEkKoAAn1x165z9iZPOZ6L3iKs82KuFuxz9rgBWAyG30X3w5dn71Zt9gbWJJWnf9tXZsGQzDJufwUpLKIQ0Ic20xAs9Mx3aLHmk54+PZjtfxKhMGFAvRnVdjPKotFFeq/lIYae0+iBQFn3759dgI+QxmVmGliRsk33utiOtyDWBOSaphOJakJhiaZgvm6vi4/bZFfn8rkgf3YcmPbq5KH9Rnt6Hp6leg8SmxtWnJD77nyq/TuN1N61wuRK+bQu2mZtpNy078yCGzvBE+JknSdduKQiwePJEDADsmKR+L23EQYSw/fpAzae7v4nyNO+68DZve+0ZhwkkangsWxc6npiY9KaFCu9txfxO3uSzH5qVMjtuxRvrixew1mSk7lsksW7q7nROT5FHe44vT8Nx2bHrvG7H6C6YrnJR2nrPk426nWbTXerKOsVLxLljayLBtRSxEIpjqFMccAZaSRAnDtO+6EY25LSPWPblyUknuT1rGategYsnIe+XEJLFKiCTBJosgmwsKZUkyADt3E+AoSeV+M72EgwJHAV7w2JHd99HP4Mmf3SaMRSKoxHdd5G6X5ggWwso50f4++3fHXX+ENjSALe96rR3jonsoz145pXiIhbwyILzYR2gU7kaHbaoca1nJlwr6YcFj7uz84ndhyDL2XHdT+DqnQRAOasJrfEO7Q1YsJqm69VcKtjWuxvpVKoLer6AlJu/LLjl7MKck1TDsmCQrYzwxHSuTE/bOT4EKUtRG3HlJykXdFz+H6L334Iy3XYUlt3zbff6F5z2vzbR1INPeWVK7xbDb5RNJjG7YAgBo3PakfT7sToZCkWFMCSxJdi1ESYonXXmZXGVDwhWTxFnu7Dw7Ho1suPY9aHvwXiz/9pd92xEQipng+j/v97/0rsPr7gwDy773NbTd+2fXcyP3l4/GMHaqE++ijY7aSYb1RawAaVqSqJikVDgLVzHsdnYxztf+hY9db/9ue/BeLP7ZLYh1H+VikrwtSbEekwabj7vhY5JMt1RLSYrGPPMgAUCWU5IYpUjXXVY6W0nic1JZp/ovvNT528rPQRO0nPIvH8WSW76NxNFDANzWCgkSchYZAtlMsOcxsepQgeq8u50dt1LkyyJJHnmSeOIGjd25L8bdqxJ7n0ZjI5NA9aHbH6ZYBItzZ+t+1Rvs35HBAaz41pfQ8tiD9rGChyWp2HgaGpW2KtSi0FhMn0pVnEkTw2efh788dRBH3/L3pVVUAQS7SQnOBYxRORaYaqHi1OlVKmvj5S+nKqjBF8UHckAiJNPdbnbdkwhzSlINg7iyEHcakpRPzmbsD5lBfQwTIfO4mBcWv8Ct+sbnkNy3h2pvP9oe+Iv9N1FUCPRkHR699V488vv7mOOhlBeuiJDdLu0QKYxsPgMA0LTtSUSo3dcwILvh2WjMJm7QuFgjAMCEKaznk0kfS1K4cU0c2Iuu//uNy70uTP4aEZIHPYg3SL+8PmlcnqdTPy2Oj/D7ILY++Bes+O5XsOkDb/N0tyvEYnjqv36DgRddBADo/NOtdhl9PqtQKJkMoywqId3tRP306jfpp8EpSVMLFqP30lcwxyL9fVxMkrclKWopSZnO+cxY8Ne03X+PE7ukRZDxoPgGAL2Rdbej41skXYehqtApyw1RfPhgf+ssdnzl3/HsN/4LACBb8YQylaS6889/wKpvfM5pj3Nng+SsSbYliczjRAKGwbodFqy+k/e+HOuBCLxlyM0SFb7ySuRJkiIRpN/4FgCmFS4jIokI2aXey16J52/8GgDTMkiovwFz3nhRcZejJJWViFZwY1ULSSpjHsmCoPNy++G3RnqlO/Css6rCpegZ1a4wW6ziQ9/L8dea7+HQmS+qaJ9EbZGfRfX2f//X/hnW3S4IlVjDwsKvyyeLu90cBfgMIcz84S1JRBiQsxkYZHJOOcJk/NhhjG7iaKu92k+VJozTFOSnv/lK5pyeSCIfiUIhO+TxBHJNLcg1tdhl8pFoSDe4AGGXYhHLJ5LItndidMMWNG5/Gu333I7civeG1gOJ1WiKolMWxiRZgmQ+kUTeehZKZsp0UbOEbU+3Lu7MuVeeD8Chds+2tCIyNOhKhusHmkCAV9Z4hIlJ8oPfWMao2Bcvd7tCNIp8fQMGL7gEbQ/diyjlCjZ1xtlo+OF/OtdkpxjLhloR4gaPExKrJOUam1wU39GBPsh0wl8BcUNy7y5kW9oQ6zVZEae65oG2ZyhDrDskHctWiEYxxefkovvU1GzPN4DNQUPmwPj6zWh+7CGzbkvxjQxw7nbk+kTSvkfbkiRyLyXleXc7OPFNxCXYvh9LoRLGkVXClU1QiaFpKKiqHSvGMwFOh9WAbU/CxGc/h0OL12By1VrG2lO0HCTLGD7jHACmkpRe6LimernaAeHd7cRNVlbB8hNyy1PISkclrWWebmm1q3cAYF/HYhTO6b6vcprb/8F/wuiGLRg6+8WeZfze+eJII0roKR2vFjYmaZoU2qDuyJz7Nl+eJ26oYT3cF3OWpBqGZluSTMHdVpIyGceFpNTAe5GlJASIdQsAIgL3PpoemXbTOfr6twMAJlatLY2djXfjoljESDvja08z+2UJpKHyMRUMRHt7AJiWpFw9UZIcodFumyhJyToUqNwxtIJSrJDV8LxJ05xpM90S5VwWEs0OSGJqDPqQ+UdkwLGYEeU11n1UyL7muasjyAlU7E3Iecf9zO1uZwX/W3NXT7ppTseveQ3zt5JKMRa1sJYkCZL7iY+MCMuScrwlKdfQhILG5nGI9p5g3CKJYkGQOLAX51x9Ec6/aBOilpKU6ZwHA854qEKrjolCJIrJ5eIErIA7JglUrJPebrre7b3+ixg4/2LzdDoFKZez1w8a9q63ZYGwSRrGvfMTudztJMl5TywlyR6fRAIGHGIBGmTelsLMadfhcQmtyPFUusUIxBVzIaqvR/dr3+K5aVWMoJNtMRnu1NQka6HzoWYPr+hU3/JTi7JRNfo0WzbORe6ukv2v5DpWbjvVQhglrhCNoe+yV0K3Npqnoz+lbgqkliyvcI+qiyBW+GJyeNYy5pSkGoZqW5KaAQB54m6XyTgvImVJKsZVSxLkqAljkiY7x140yBIjzTuBMP0vNX1v5Vw2JDW3zzmw7jxEiLPZuywFJ8w7uuiGf8KmD7zNvD4Sde2QMyDudokkEwdBWwVKNXXTsVthlQIS/wKY9N1Lb/kWznvpGTj9ra90lfVSkqSUW5gVWaVogd9VB0UBz7dDCBhIDFeGI3Dou/hyl6KiTKWRfH6H/bc6lYZUCJeMkR7/zj/+DonOduA73/GeC9yJXGMTDJVVkuJHD0Oa8rYktTz6gHk8n7c3EWjrKcAyro1sPpPtg6IAsozH//uPru4dfM+HkWtqYdztpHwe2//tP9Dzytdg6K3vAgCkVqzG8//6dbO6dIrZMOm75Ao89es7zWutY0QRlC2FT57wVpJ0jmJcgkPMQNYc3pIkSp5pc4JUQXiiE8ry7nbFNFcRS5LfuRLuPV9Xj7xlPYxSObzyAhY9grIsSRWiALePFVldpXfKRYpvkBJZjLJcaoxdLSHIpY2JaapJtddEKT2r1HOTuH/DYuKPd6LniqvwwidvDFW+VmLBJEi+86bg6b4yuzCnJE0zMnngL3v67UzXfiBxMcQFjLjZKJm08yLS+WREVgELD+4dwPgUFXAucK858tb3eF6ftRQ1zaIlp60YNrgXRqEEcFsoy+VCveKkzLNHR/DUYdZiZRgUs100Zu+sk91tbWwEfWMZPHt0JLCdjh/fYv/ORaK2gKVMpV2sfcSSlIknAUWxE2bSVoZSlwW9odEWhGiiglQ2jwf3DggzbMetwHoAkNNptDx0HwCgccczbkWH69jIP98ArF8P7N3rqlc0j3yVP0qBOT7AWjMddztTiOVjbwrRGA4NpLDzi9/BxMo1dkxY46MPMuVe9e9fwTmvv8LXrZB3tzv1ug+YP/7f/8OeHlYJIOWkPPuM9Ua3Janrj79lyD3kXBbR3hM475KteMmpXVj7uU/Z54hFT0/W4fEDzrztu/ELmFi1Fju+/O+etM1jG7ei/4KX2H8ff/WbsP9D/2T2l3LL0Jtb0HfZK7H7y9+1CQIkSbIVKckwbCtvQdWw/Vs/xPC6jez9W+8MuX8/SxL/XkuSY7khsUjk356chEzOn9aI1HZihLLOhZSkvWYhbVXhLUnT726HQEmpKMVBkmx3TJrWnZ+7NMpxmat0XiNfmuAyGLAqHaRfadQK+56rbutfWtiuRnOVUqY8LUYzpKzR8y7oOYV5joWLL8LOr34fOZ/8bUz5GtE9gtYJw6h9l9MwmFOSphknUuGtDba7nR2T5FiS7N0+SkAXubgQTOXYnV2RJYlPeMhcv9CixrYUt2U3m7vW6QWLcOAfrkU+GsPej17PXMO4hlgKhZTLhhZECgUD/eMZDE/mMJlhBQKigDHUyBzjViobzvpAkItGoVNjQBQx+3lRxA2Aw6qlFOtuJ9hlzyeSdr2tD96Hze9+PZJ7dwEwn92hAbd1iSbqiIwOo+WJh+2/iQshQcEAI2E2ff5GYOdOyLt3u+rlGfeCQFuS3MlxibudOXd5FjdiAei58jV49Pd/Rf/FVwjbWPvUI2jctQMtD/3Vux9gP/x0brGGZ93JUgF3zqN8IuliR4sODiDK5Rw6/+LNiPUcd9WnWnOEt2bkVq/Fo7feh96XX+NiY6NBxxt5UVWn1q4THqepujXLvY/Pr0Q+8MRaJllMffKEo9ySTRkvSJDsGCmitJI5k1bN/u/46s0oqBp2fNWdmsBPuF3T5Z11HgBWtHvki6LGTa9j8w4VI0xtWdIcWCbIzcQ/T4pk/VscCI06DT5WjEZEkZGIKkhGVMSUYmkEi+wcfako+WaVBKVylbkFTXHIMtDV6J/s1Wv0FrcmIEnAsjbv72Yp8Hs/VnQ4c3tRi/ntWxqifVGVjLud5C7HKAMlTAq/5z6/yXvuuuuZuZiv4vYyrHe7aMtpcSjFW6U5GYFSZIJpr9Lzm+JQZAmLWhLCmKR1883v7oaF7HdktipMc0rSNCMfcn5Hu48hecDc5c/Z7HYOcYM94abCWZJcmHQrVHRQsOucReOrjY0ChoH2e+8wm5+3AAc+8Anc9+geTJxyGnMN7TZGdsLNBJph3O38jcpOIllnsU10mIkXVZGrXAjkIlEYWgQFS4B0ub1Zu+0kYNp+HpSbYxhTuMidTk/W2QLtKTd+HK0P/xVrPvfPwuvJGpk4vN+zjWhvN/N3ENPMxPJVTv9EliQA6h23Y/O7Xoult3yL+cLSMUlylmVxkygKcMDc5aezoOcp4XZJawKt7f4COrFk0mjY8QxWfeUGyONjzIc/1+y4vK27/loAQEQlBBtWfAwXXwRJQkHAGMbflxcI4YefNePI27wttrRilOeUpPE1pwIA+l/9RgCsC6QEAIpiX7PkR/9u1pEQW62IkiTrOdDJSQFg30c+jX0fNq1j+//x465rTUuStUEwxbrbkf73XnE17n1iH3qvuNp9vbBHJojg54X6mIaL13bgJes6ccZS5/lKlGuv39hrqvcnL6rJaElGcN6qNs8yGxY14sLVHZ7n+fa8oAZpWhxSS1a4jk1S76wI5yxvxVnLmrG8wbuMqK/TQQHuy74XsnmRtawYYT6mKbhwdQdOW+C/5nhhdWc9LlrTgWR0evivLl7bwShka7rqcfHaDtSFaJ9PAgrwxA3Fx6YVI6s3JzU0xB0L/br5DVjObXgEbZDUOkp9a4q1iAaNu+j01iXNuGBVOEtVENbNb8AFq9sR0xThuz2/KY6L13ago8F/82G2YI7dbpoRdmFZ9bXP2r9tdruI25JEs4AVRR8tEPqyza048pa/x+KfmUxjPS+7Bl23/w75aAyTy8wPsjo6jFj3UUStnert3/yBeV8CilPWkkTc7YqwJNEUytTbaMBgciTZ5YlLoA9Tlx9ylrVDT9YhMjpsx3UYgDle999vtmkJ+URBoy1JYdxHRMxf+USCUR74ekWIHzvieY6wrBHwQz7VtYCxhDz9g9/ixReaTHsiS5JhAA2vuQYA0ProAxg858UYP20TADBEE4wlKZ+343fomJFMRxdUi7KcPi7LEiQfKwvAsisSnPkG0/o01FSHg+/+mH2ctuYQBj5eAHS5VMKdZ6cYkFxlfnExI2eci/E1p6J+z3Ou6+k5wMcCPfnj30EbHYa6bAUwpTMPldwWmTMdfzE3Mdw5jkwwimChYCv6+z50nUmbaxjov+hS+73n67DzhFlzhViU6E0LL9rjcmVwIhxrKrXTTVlnC7EEQLn80e35yeZKyI6FcWXzFNYlUkeopmyMcxtQAHDiqtf590HyjxnwvK7oK4Lqc9eoyJKb/apIlBN3RVCOW2Lg9RUeSFFbYfsv2vEvFWGv54vxXeXnZrHPQlRakmbOYmFb40JYktljxaFUl+Cix9dnIIPqIudnqfGIwZySNM0oBGUxnkqjftdONG5/2j6WazKFf+KyFO3rgbJ3N9CxlLUkFUEfDQHxghGJYnTDVgCmkrTnun/F0FnnYXL5KtRZ+ZESRw6i6w8mt//YqRtcAerpBYtsv/nhs86zj9vxO0XEJHnTOQPaiGlRyNNWiUYf+m4ROLc3XTX7mE8kgNFhVpn5+c+dy3hL0lSRliRL+crH4vYOvJzNInaCdd+aWLlGeL1RMIAnnkDisHderGgPZ0kqsJmSpBzrFpdta0dq4WIkjh0RWyS522p65glbSaLnHR0zRFvMGOsRJbgXoqzbhRGgJEX7WDdCmqBA278fyX17EBnox+hZ57DPT5ZNi4njkG8eFihJfEwSwdjWs9Dw1GP+/bM2D1xKEvfaj68VK0njp6x3fq9bz5zL1zcgX9+AYvZbeUsSz24HmNYkYkkaO3WjLWlMrlwrrpSyJMm5LKRC3t6g8XIRrAZohTdCvzuuGKpihYPiyvLrVDUsSb1XXA3IMtTxMYyvORXa2AgGqKTAlUQ5sT5egmuYY8Wi0havWkKlb01EvBDktlXJPtQyqYXfNzuQ0IL5LbkOhrFsFjvOtZR/qJZJPCqFOSVpmhG0ebbunz+Erjtus//uvvr1dlAyUZKW/uC7wA++i547H4NEsdvJxbjbiZQkVUVqyTKnSHMrul/zZgAOq1LTtifRtO1JAEBq8TJXHU//12+w7Ptfh56sw8H3ftip2xI8pWw4S5JhsIsBvaAbABp2bgMAjK924jMKREkK6W5njI+zi5zlskMUL4XOz/PEE/ZPPWFZkshuOu1u56PYEaiWYJ9raobSY16rToy7LGCGrECE1gfuAf7hLRCL8ia0ETfZBQ2X+5gk2TEOwpgkzkS25oufwcjmMzB+2iZGGaLrJfdpqCpjnWFcyiilyDAMIEhJ6j0BdWzUtLJIEtZ95iPO9ZKEs151MeR8Hrs+/02olGueOjlhJlddYCb2JMNBu9vp1ntmeChJk+tOQ92zTwkVKx5BCU35XEwEY+s3279H128RlrHjipjAa/HHym1Jsq6llCRJ120lyYtUgq+Djn9Ss1mo1vW8NdTr+kqAdtnKdi1A7MhBZBYvdefqCttcCd1SFRk5nX03fCmASZ+KtCQZmoaeV7y6yN6VhooTN4iUpArMgdAJc2dIpqwlHY6h9iYbJUWMSyn3Um1ijZoj7pim7tSOilQcauxphcackjTNCFqYaAUJAI685d3270KEFSCT+19g8twUE5PkisWwMH7qRhx+x/uQbW1nVsacIM/AVNd817H0oiV4/qZvuI4XNMtVMJeFEcInzYDBjBWtXBqGgQbL0ja20REkDUJsETJ+BBx5hUKSUVqCHs0yh3bHn3dirRkbQgTKoix4cCwsdDJIngYbAJSs2N1u/q2/DGyDJCIm4HefyBgVzjsPz135JgCggvEFMUkCF8G2++82lSTGkkRR0hMGwmQdM5dol6wCRWNcMOBSkugkoaTNzvN+j+5XvQm7b/gKOu/8P/tcZM8um3q67oVdrjHQhgYgLWTZ9Wh3O2J18bIk6Q2NpgJlXZNpbWeS4jJlOWWB/54ffsf7kDi0H/2XsEQVE2vW4cD7PoJcYzN0y4LMoxjZwEvpoWnOpVzOdrcrxIMDqiWJVXS1bNaxjvokOKWvrwRod6t9X/kOWn/2Q/R/5rNuy07Iz3MpgrsiSRCtpEH3GNa1r1SU6hJlHiu9b6LPW7H1he17JdztwqCGNu5LRilD5ZkkN/T1xbZXmfKVtG6UUlO1Ke8DiRsqTGnuW6ZIq9lsxJySNM3wUw9EyWBpymQ+L4acz9uB8UCRMUkeeY4gSdj78Rtch0XJ2DKdbiXJC0TwlAwDhoDdTQR6p5z5bTiWLdqaZdgufaUqSeaYEEHPYbcDYLHpjf7jh+yVgVic1n/8fRhftx6ppStCfVCJhSqfrMOuz3wRC3/5Exx69wcxfOa52HCtE9RPKxxe0JN1tsWGBnFHJGC6ZRh27FD2579A74T5bIiALFS2J9xKEokDYZSknNuSVOAUBlrAZqxKBcPlbpdrakGUopsn1raFv/4pMp3zkG1ptZMHx/bsssvFjxyylav0vAWInziOyMgQ8sQKQwgPKCWJWNK8YpLy9Y0oaBH7Pcu2tgmVJEOWfRN9AiZl9XNf+q77hCThwP/7pO+1tsegQRFQeHyf3Ox21rVUQlopr9tW6LwPYxrTviwjH41ByUzhrDtvRbPFHpgPZUmqDOid5LEtZ6LntK1oTkYAjtUytMIQIqaAh0j4DHN1aCtIFRA4HtNhSapAG9PJpFcKyulKxa0kVHUytway7Qb/JihGeTRQ8WklhDluxWkJxSrBkscfpT6y4t3tKldXtVFz1r4SMMduN83weyFFMSZ0zA+dKwUwWdVo4oamZx7H4h9+L1xHvJQkr+IiWuAiPvS04CmFEP5hcIsBN252PhqK5tl26SsUQjEoGCOsW55isbQ57naU8mEpNvROO20t2PLO11jdFD9g+qhtYUkkcfwN78Bjv/sLMl3z0XcZmwTWi4rboC18HtYGXkliSDB03Un6SynehmLumWy49j1Y9u//Zh+PHz6I+ssudrUhWWNMqOoBKybJMLDmc5/Cmn81c/wUOEpmWhCn3e0KnLtdQYsILZgEK77zZU/XyuQ+k9o8H4nayrw2MuyasrSVilhdROx2gEkxT7upZanEuBkqx0U+nnDHxXjeRfEQuct41e/pPkex+Mm67hChhFGSrA4QBffcP/2vfU4PYUmqhrSUN8QbKkD43c6SuuWhAHjucts0wdMnPBTbUuXzJIU7NofqQTTvS05KWqWHV6lXYsaIG7h/hWUq0reTwLQ5izCjStL999+PK6+8EvPnz4ckSbj11luZ84Zh4Prrr8e8efMQj8fxkpe8BHsFyS9PFkR7WEayp2/5JfNW8QKhMpVmYpIAYPVXPxtuaySsS5oFQkNOY+C8S0JfX6AVvBBtG2AFe9bdjlaSHAGcjbMIoQQODjJ/Kla+H+J2xVB1W5YkJmklJRASNjnvmCTnBHHjE8VvHHnzu+zffM4h+ziVl8grUN4dk0RRdtPjTylJLY85CVxXfOfLdh3r/uVaKPv2udoglqSIRVYAmNav+NHDWPTfP0Djc8+afeQEZ5rRjiZuMDh3u6mueUz+GxG84oNiRw8DMC2gRJHURoYdBUNAAZ63Y5LEliS9sYlRUA+//X0ATPp0en6L8iBVVigOX5dfjJFNAz41ZbMQhopJspoX3adfrjX7+ipIWc764H4BQ7vblcQEJ7kEn4orYiWgvESmle2lsDqfJmpBgToZXOxoMAyP0yT10W2GGc9quWVOF6bLsllLlqRaewbVwIwqSZOTk9i4cSO++12B2wmAL3/5y/jWt76Fm2++GY899hiSySQuu+wyTBWZ7LLWEes+iiX/9R20/fUu5niWy8DMs58p6ZQwgeziH3+fYRkTwhKK0vMXhuojn3vkodsfQZoieQgCo8CEdIejUp+w7na5rO0SxlqSHEFVDmMpO3aM+XPvxtMBALkGU6iO9vU6bRMliWILEwmEXswz9GG/+I29n7jRzk3Du9tJ2Szm//a/Ubd7h33M6/nx+YQMw+mDTDPbUUrS0Te8g7mGJGCNDIjjblAgSpJzXs5mERkaYIv5WJLomKR8gbUkZTrneZIoeKFguZERS5ne1GwrSeroCPshMwzM+/2v7D9JTh/PmKT6RqgUmcfQuRfgoT89isd/eYenCyFBNSxJADWvrGOD57yYKesXI0Rc7hq3O4l2Q8UkkbICq9N0xiTRYEleSmvPdrcron+y5KbDnU2CQyn5cUpoRXBkFg3SDKDSoyMxv33c7TzjkErYQDgJiBuKYrqchjaAMHmSKqPhz6Z1rJqYUSXpiiuuwE033YRrrrnGdc4wDHzjG9/Apz/9aVx11VXYsGEDfvKTn6C7u9tlcZrtWHvjJ7Dq327Cwt/8jDnOK0kTHCWvnE5DGWYtBgCw+is3YOEvfuTfqKVEDL7oIjzz7z/Do3/2pzbm35hiFCRyPaEBz0wEx04ZBpDK6czfBOP9jgJAx0DQArUUSkkyqcp7L30Fnvm3/8DTF15u1m9RL9M07MTdLqVQFgOBQOi1PNELl2oTGgiuV1WMnWrlKyKKbj6Pxm1PYtnNX8e6669FgsqPRNMAj566EU//pyn0ayPDkChLFL37ZOc1UhSAUl73c7Ew9btNimo3U5tVT74AKZsxEwxbkLNTiHI5mrJx9j5pCwSjMBkGQAnpU53z7cS+YdF36SuYv2lLUtMzjzHxPIk7b7efxeipG3HkLX9vnvNoM9/QgCyVoBayjPTipSgkkowlSaQ8VBL0mzicylrHzKM7/u0WpqyXOybgxIyd9k8fAGC6cQZZ7gB/SxJhfpxuEEupWPALh1JkAkmSXAQCErwFuNkgeExHH2fDOBAEBsp7oJbiMei+ONb0oGuq1x+g9HENwnSOuog1sNrP3Y8CfLo3H4ppr5beh2JQs8QNBw8eRE9PD17ykpfYxxobG3HWWWfhkUcewRve8AbhdZlMBhlqB37MCs7P5XLIFRmHU2mQ9vM6G1ic3LtbWD7V0ADkHUVh/9+9D3lVQcsTj6D18YcgpSegcLEnBG13344Db/17z74ULDe9vCKj90UXwupY2FuBXkRZu01NM9ntMunA6zPZLHb1OIlDs7mcfc3gcdPCk4/FkJMlu9+64QSjFzJp6Hn/jDKFI0cgAxhZtx7dF14GY9s25PU8Bq38P/XPb4eeyyKvRFCYnIQMYBiq3Q+do+jOZ6agR2XhvUkFyf4oSJarYC4WF5bNETeozBT0vI6V3/0KVn7/m65yx65+PQ69+k0Y2HQ6Ou+9Ewff9l4UYjFkm1sQGR5C3TOPY/TUTSjE49b45WEYBjTL+mhEo8hR46rX1+O+Pz+OCy890+xnahJ6XkfOIxhfHeqHbBFo2Pc5PsZYWwAgHY0x96lTgvhUQ6N9ToEGnVLa0p1diFD1G7Jsx0HRoBnwJhcuQUHVIFtudNmGRkxZikL7X+/G8f4+6JE65HI5NP75T3YdJy67EjoMIK8jpzh7R8ObTkezRXk/Vd+AwbPOw0KLXZC+pzztbheJMOckSYKe10t6Z0TI5xXnmeXJMbM/ejKJkdM2ommn6epIjy8A6Lp3P/LxBPRCMKlKXjfnuCh+KROLwgi4T9JXGvTa7NU/0fpNysZkBdl8HrouQdfz0PPOPKHvOScZ0D2IY1RJNb8T+YJnH4x8nnln8nkJRqHA1JnTdRgFSViHIinOd6CQr5qgqOs5SIYs/Oboum4f13XnXsixgs/9E+So62gUBPM8L5hzug5Xu3bduXDvCv0c7Lbyhqs+891jn7mXLEDqkyVn7ETvrt9cJOeD7oM8E14ekCEL39Ny5Bf6GZDnLxl51zNg3pWcDtly56DnSd66XpEMZKy+B41nTjcZHen2ZLDzTPeYU6LnTD8bd9ng+UtDRkEwB93jYZ/Tc8jlJFefc7kccpLBPPdcLgcUnO+JWR87Zroe4n2j+icbPuUNCQXDrUj5jZfdN8G5IMWGHmvDkFzjmNfZscjJ5a93pI1y5fmw19esktTTYyaN7OzsZI53dnba50T4whe+gBtvvNF1/M9//jMSiWB/++pDwrZt25gjp8sKaHHj4CkbsH/9Fjz1DFsOAB7fej4uOnAA5wIYPHgQyzyUpImJCTz15FPCcwCw5IUXcAqAnsEh33I0LorFEbXc3LyuaYwYyOSBqbz75XqxLEMFsOuZbRjoc1vAaHQnDJxIScK/O44ewgUA0pEY04+mqIH1qgpF17Hz6acx3tLOV8tgy/Yd6ACwa3IKz1nPZNu2bVByWbwYgJLNYMdDDwF1CZzW3Y1mAC8cO469VpvxY0exmqpvx8MPQW1MYjLnv7B0HD6MZQCOjI4Jx3HhwUM4E0BubAwTN39bqCABwM8vfzV0Mke2ng889zwAYMXiFVg1PISz3vlaDLd14t+/8O84kJAxnJUAA2g9cQwXAMjJMu644068MMr2N3r5NTjnjt+h79hRPPXkU1iS09EmaH/BH/4XT8xbwhxbf8PH8dilLAFFz0SKuc/owCBWWr+fPH4C45Y1ZLLJQP/u3SCRbnszOlam0mi1/t523iXYfD/rkgoA6XgSv33/J3HWfbfjj+vPwLsa/huNlsvfiZyOvy5YAZKWd9efbseBBSswMd6N1/z8x3YdR7pP2H1sP3YI51rH97V2YuT170RdagwPHjsB+eIrccWxY9h+3iXYT93TukwOTdbvsZzO3K8kAcfiBnpSldlJq48YGM+ydcUUw37nTsnqdl929w/iBaovJ5IGuifNcpdz9WYUNdRaUKcZmMhJqF+0HC+ira0Annx2h8dVDuKqgbTO9j9zwPl47hxyj9PyBgO3C3Inj+eAkQxQpwHHJyXEVQPZvIQ89S0e2mPg4LhZpyoDuoDTpU4zMJkEDm8zra7PD7v70BI1kDnA9jGpGdALEjKUnNu/20xafGjcXYcqA2MvmJ17flgKzJsHCSXFaaf2GSC6viSB+eacSBposfYp+tJAX9rsJ/0MetNm07JkjpcmA5k8MJQxyx5PiOfz5D4DA5YBfGDKPH80bthtEMRUA1O6u10AmNKBfWPidyWuGojIQFMUuP2A8/xHrfchogDDu9n69oxKyFnPpzFioNm6VgTyXFUZGLee074x2H0l4PtMX0vOZ/LAXm5t5ZMPt8UMHHz+Gbv/AKDI5pgdmwxuMywmc7DfgcMxA3sT5jzvTgF1qjMe3SlgyHpuk/sMqNYcOpECBq3j/bsNNESAsSwwmAGaI8HjGVPMdyJFPXP+PeurM3B0wv3cMwcMDGVgr1v0WPBrhaheL8QUA1EFSCWBvR7F77rrLlcbQ3sMJC1ng7EscMTq8/heAxEFzHOn30MAeGFUssk3yT3kC8CuEf/+0s8+bwDdk2DmDIFsfuJdFnVy/UgGzLzyW3fDzDe675Jk3i+NgSnY68ToXgMxcerHknDXXW5ZoBikUuFSt9SsklQqrrvuOlx77bX232NjY1i0aBEuvfRSNDQ0+FxZfeRyOez85d3YtGkTFNWZLZHGRuCEGR+jx+LY88vbAQBbPeppf+KvAIBFigTFY1e0c7APW0/3qgFYvu0vZl0LFviWo6F3zkPUYuDzuuaStR149tgoBibcpANyIgFMjOO9n/l/uOe+Z5FraRXUYGJVRx329k0I/26WzJ0JqbmZ6ce8xhikaBTQdWxcdwrSC1kBnkebtWs+/4yzoG3ahG3btpnPRpFt68Tpq1dCWbQQTZalYOlp69Fgtbngsb8w9Z2+ehViy5ZgJO2/Q9H1a9NNqWPVauE4NiTMFTguAVf/4FvCOvR4AhvPPVd4rm7zFuBZM/lt80AvzlmyEC1rluPEqCm91O8xVXKtrg6XX34Z6vezBBYdj9wDAJjX0oKtp29Fw/wFgIfsfPUtX3cdO/2+O5m/WxYvYe5z0WP32r/XXHghDC2ClkQEmxc3YarDYYxrP+NM1B0/ZP+dOG0DYClJmZY2REnsU1MTOt78Ngz9/buwLp2DNH8hYJ1rXLESqy67HBPfW4m6g/uwZcVyNJ+2FWf/6CGmj0u6OlGw+phsdZgcFy5ZhMEPfxpZTcFZEpDK5nHkwgvRBPb9TLS2AhanTLy1jblfWZKwvD2JfX1uqvZS0FEfRd84+37VRVVMZMz3ItHWBrxgHl+89XTUb3X6srarHrspCy2N1MYtTL8jioxs3q1RtNVFMTCRQWbZYuCPv2HOieZzV0MMPWNOjGRjXMMo945cstZ57tHdfeBBnxehfzyD7cdH0RjXkMrmkaP6ffqSZjx52NxMiqgysgIt6cWr2qBR0kw8oA+kjy2JCLL5gj32ALBxYSMUWcLTR0ZcdURVBeetNNe9hn2D9k68F2RJ8nWv8QK5n1wuh7vuuov55qztqseCJnMNODyYwr7+Cdf9eeEe67759Zng/JVtiKgycvkC7t9rvoMr2pPY389alxtiGsamcsJ2JzI6Gg+KN9Ha66LYsNDNtEr6lYgoOGc5+11p2j+ItKUlBd0jea4RVcb5K82toccPDWF8it1lF9VDz9tL1nZgMqOjgbuPTYuasO3oCADTgjS6/xlc/bKX4v79zmZnRJGxsqMOz59gU1SEeT5eGEvn8IT1DixtTWJFuzh2cF/fBA4PmcIj/U7s7Z3AkWHz+KaFjWitC3bLBZwxqYuqUGXJ/jaSe9k4nMILveY8Wr+gETuOj7rqIGUfPTCEyazOHOPXCnJc9P7y8BsH8t689KUvRZR6NgCwdXEzmqxv9OBEBtuOmX1+0YpWxDSFee78utJ8YBCpLDsXc/kCEnvZOF4eomd/j+AeNUVGvmC41gz6+ue6x+z12G/dDTPfdKrvsiThojXsxnT3SNr2CDprWQvqouWrHPSz0YqMWaYxxqWA8ULNKkldXV0AgN7eXsyb5+QK6u3txaZNmzyvi0ajiEbdL7CmaWUNaCWhqApUxRl6mmSgkEgw54SwYmHivaZFLR+L20QGE8tXoe7AXkSHBhDJZj3ztSiWECFFosHtWXjui9/B6W+7Ggfe/1HPazRNg6aqUBX3x59mMjvtC592xU/QUFWVaYP+O0LoiuvqXWWgRQBMQssXkAu4L2nIXMgKLW22AEGeTT5RB3lsBNF0GlBUSNaug5Sss9tUONklMjWFxqcex6pvfQ27P/NFpBcvFbarWXUZyXrhOEokSW02Y8ZZifIWKYrnMzAaWDfDxOgIFMUZP81yTZOiUWia5q7HcodT8zpURbWT7Prh8f/5E+b/7hdY+MufQOFY+Yw4O6c1Kp+XEjPvVdVUaJrGsBXm5i8CKDe2zIJFzrmWVltJ0ptaoCoqZFmBqhjIdXYBO81yeescIR6JpCahKiqMRYvZW7aOA4BMM+61tJpjoCiQJUBVxDt+Bp0UNx5n7leRJeudqMxyq6ma6/3SVBWq9ZgMOs6rpc3zPeLRd8XVXFkZBUFmt4hmvt+Fjnk4/opXYcEfTArwvpe8XFg336Y5FuzLQ6/NojqC1m5NK1jPSYWsACoVbhuJOHNcUWSohvueNE1jhJmgPpDzqqYCsmGPPSmnSJLHWMh2PVFNRd7w30GW5VDZDFyIaBpU6n7ob46qqnYf6GcT5vtol1UF6wbI+i8DcsG3rKapUHOGsF2tIB47AIhGxN9x+94UxXVeVVWoBSnUPTr1OM9JVVSo3A64Xx/I+Yjhvo9YRDQWmuu9iwjW5XLkFy3v9C+iqZ510e8K/U6omkrN+fCylPPeqVAVyX7vyfX03PBaI0lZRVWg5tljXmMUZq2l3wMviL6PGjV+qlZgx0tTmOfOv4eqNQ50XyXqXfHrh6v/HuuLVCi41gxm7fJ450uZb7JiON9N2X1NNJJnxkLTKqdylCvTh722ZvMkLVu2DF1dXbjnnnvsY2NjY3jsscdwzjnnzGDPKg+akjnvQelMg9D0xnpMtjs6ODtfVw/dOh/t83ZLNCxB1vDICSPC2IYtuPfxvTj0ng/5lvNyY6Wpn5ufeNi3Dn7zlP6bUFVPdS1g24Xk5EoKEuwNw6YAFwW3E2HdTtRqKTY0RTJPEqBOTuCUN1yJ1ofvw8qv3+TZtJ0nySPWhyiTkeEhO3kqj76XvMyzfoOrN8IlPLWpxaNRYaA7Idgg5BeEQGLihs+i/4KXuMr3XvoKjK3fjJEtZwn7U+A2LdRJsSUDgEkmYSHTOd/uCwBMdTnJi+n3hBwnrks5Kn9R1sqzRMgnFKvtAkeaQSjlAZbdLrN8JcKAJvFwkR9IlQ2oFSfndA7SBCZ0njW+HI9sq8ip0g2ZqoMml9n+jf8UlndRZE9z/C7dnFcMUKldkiXJlVfIJG4Ql6eb51nxxP2aXcHOTkJe9zGmXIn1yzMQ/F3JqDE+ifB03Q77PLwbVWiCB4/rS0Go2LuARir9LlQ8X2+J9VWa0GCm6OtF7c5k0uxKYUaVpImJCWzbts32lz548CC2bduGI0eOQJIkfPjDH8ZNN92E2267DTt27MDb3vY2zJ8/H1dfffVMdrvikClKbC/LDw0SME1YxJgcRoaBzDxTeYj1dHvWQfLDFMseZoRhv/JYzGjBNjI0iPiRQ97tcH/T5uO2v94NADhx1evcF2okQaZ5f01PPYqWB+91FVNSk7YSIFKS7ISyqUmzL0RJonbpx09Zj4f+9ChSC02rRMef/2CfSx5w5/OSshnM/+1/I3nA9IXKe8TI5QWWUIID7/sInvzx77D7+i95luGVL57C21bKPdohQrZsK0mmUlXomu8koaUwvs5k4xtdv0VYH0+JPXTW+WY/KSY7MmOMFkeoz7a0MgJ/lkosSzPIkWSxZI7k2iklyXo38klLSRq3lCEuaFOhlCSa3S67bIV5LIBYNdviKBg8u125n4kw31C6THLfHvu3XzJeHno968YUpt0+Wmn2YnRzjUDlP5xOgl3DtXgwCmSl24X7tv2EHrr9k0GACIOi89/4nJuuMauWnMkredMlgEkeyg+PMOP7tzFri0epSlwlx3O6n01QeyfDGjej7nZPPvkkLrroIvtvEkv09re/HT/60Y/wiU98ApOTk3jPe96DkZERnHfeebjjjjsQE1DPzmbQSUMHz70gsDzZFZeteCS9noq1KhQw1TkPyQN7XVTMDCwhsdg8NOWAT9K59e1X45E/PIjkgb0YO20TI23wPrX0X5Eh0wI0uXSFZxtSLgfk8zj9bVcDAP76wE7kKEGWJErNR2OmYsqzL1mKhjoxbm6RWIxteS6PTHrxUmRb25E4dgRLf/g9+3j8yCHzOuqeFv76p1jz+U87bXhQa3tZmACTsn10y5me5wG3laRx25MYNt5h/01bkoTXE2ucpbwrWdOSZESjQt+f1CIz9iu9cLHrHOCmiu694ioUYjGMnbrRPkY+4lJbO578ya2mZUaWGSWeFuLHT1mP5qceBQBkOkxyF1tJ6nDIXnRLSSKWQWViwro3VkmaXOFQcND9zS1dCoHHmQv03ApjDS4GfLB3kPIydtom1O1/AalFS4t6v3P14WI2aUFv+PRz8D8fvh7zL3FbGL1Qjd1zW8n2Oed7fYmdkqTSrw1lFanC7rSIDnq6UWq7SglaRS0lhg1rSaq4lSNk3bR1s5IWjjCPYLZZTXk4VlSf+6jyLdYay/acklQmLrzwQl8zrCRJ+OxnP4vPfvaz09ir6iKamnCt2mRn/8SVr8H+D14XWMfwWeehUFcH2RL46DiO9OJlds6WmIeSJOVywKjpxlWsJSkMPF1NuBOxvh5s+btXo/G5Z/Hst3+E/osdvi2Xu12+ADk1iUI0BnXcDJQU5oAhVhA9B21sxD4c7e/jlKRh7zoA5BOOu52UzdrKQV5g6RMlD1WyGSiTE0wS3qYnHmHKpBd4KBXJOmz/2vex4aPvBWC6Fe7+zBcQ7ekOVJAAwOCUr4W/+RmGP/8lAKYrm52k1tOSZM4f3pJkxGKYouKCCHJNVqC0orjOAYLxkWX0X3IFc4ieGSNbz7Z/0655mbZ2PPWD36B+104ce91bsfhnt1jtm9Yn4m6ntztKUo5zt1OHLZKKrHlvqUVL0H3NG3H0re+2r8nX1eO5z38L+VgMUl0DQJEOeCFDuZ3x7oWVdqcQfYTpI/s/dB1SS5bjGJccOAh6A2dJ8kosyR3ev2ErmpYs9/yYTPeHm7f5Me1XWGCWJQkS3x68x47+3p3Mu/bBilipSmmgT1bNQDQHZsJdEGCfgZ8Qr3j0r9xu15KiWklU4r5qTbEpBsLE5hQUOWgdqH3UbEzSyQjp/vvxsQ+8Gau//jn2uKUk7fvgPwkTjPLQGxqhb9xs/51P1uOpH/wGPZe/Ei/80786lqa0IOAfwIYP/R3U/7sNQHExSeVC5KrV+NyzAID5v/1v5jivPM9/9SvwoivOQXL/C3Y9eiOr4EgSYEQcS5JG0aMTy5Hz97BVR5Owr7blYXICEjWOokShtHLHtsG2meFiqDKd8+CFvsuvwsP/9wD6XvJybPvuTzBw4aU4HlLoLQgsUcqAw54TGbBYbDrE7DUF293OnJeOUhXDvg9eh54rrsbkMidWR68PyEdVhGWFX0gjg06/DS2C4bPOw5F3vA+FRBLPfvtH6H7la9Hz8mvMdsi86HTuy1aSLHe7tu9/B8r4mG0lGzttMw6998OuPp646nXou+yVlBuXf7+zjJJUYUsSJ9QEfWwynfNw6L0f9pzbBNu+/WPmb52zJHm1U6yg53JHK+rqyqJS2ehp8OPhNzyMu91slRp8EPaOSrYkzfIxE8WviVDpu5QDlVarHCURVrIPYd67mYxVLBX0fZH6ZnKKSpCmVSEN2rSY7e8rMKckTSvkT34SALD8Rzc7Bw3DZgMLE+9DkG93hDK9vh7DZ52HnV/7D2Tb2m1LksyxjAFA/c5taLdiegA2/qJS8Hwv/KyGnPsTXzLx8AOIDvThlM+aY5irbxAreKoTT0MrSUTYXv2Fz+Circuw+is3AACmPBQV4vKmTk5AsZQkQ1WF7kteJAoal8NK4QkLZP/XL7V8FbZ/878wsfZU33I8eHc7AJAJAQUoC+OiRcKPl4u4wZpHhVgMelMzdn71ZkYxpN0Gn/32jzCxfBW6X/lap74Q7rFecyYy5E2N2n/x5Xj+C9+2FVeiWLOWJFORphXW5KH9lLtpZTYJaNID/n5FcSvlQFRX2O8ifenAxZfh0N+93/6bV+48Bbgy76UamddJnYZR2u5uqT0y3e34usLVFvD6l4XQyso0qKzFPm6/8rPJfSeIYAVwK00zjTBCbSnv79+CxaV0l90av7EyQL+vs9WaOKckTScE7kgSTdoQibjOe8GgrABkl9w+Z7tLZcGjftdO5u9CBSkZCbw/vM5bkqEEWcCt0DExGBT7X9MzjwPwdpMjxA2SrnNKkklesPhnt0CZSqNu724AQGqZmL2MxCQpkxOQLcpxL1INmtkMcMgdeCWJ/vvAP1yLaqFQ57YkSROOkmTHqi1cKLzecFmSrJikGEVzTbmU5an513/x5Xj0/x7A8JlODqcwMTpec8ZPSeJBwqVy8xYgvXI1xtZtsN0dT1zzBqctXQdCEpfYliT4L/KpJcvt37ETx4V1lIwQQnipHyAm/q1KH2uXJawqbZgwYLjGgm6/0h9qCZLbsibB+yap9meTwF8OREJgqXcehhGQRzWsh6WC7/10zQD6EfiNobfFqbyehotJmh1g1jNaThGUne6ZV2v6Fr3G5WepljSnJE0nBLz2NP13MUpSgQ5O52JQiCWArptAs+J5CKbVkkQh08a6esmcJYkmbiCU2TRyjW4liXa3k3NZxnrgJWynFi8THieKpzo5AX3cVDAKXmx0nHsbEZhppUiZGEfHX+4AAOz4ys048IFPCOuqBAwqz89Uh5lvbHJgxD4W67VYDxcudCX1BEQU4JYCS7saUgQOukApIzFdgDtGpxgceJ+pTD594WWhr5E1FTv/9AAe/58/2ZNxbP1mm+hDzmYwPGI+0yBig7A77XpTMwZeYbr9+dGzVwulJBwFTPp2AIz7pI0KfXCnkwI8lfFPzlrp77TIGuTvbketa7Um0VQAjkXPf6BL3T0PGrNqWMYqOWdc3Z8mf7vw1k1aSfKITyqh/VAU4LMc4XhYqvvO19qKQitJhcLsnANzStI0gnbt4V2ZAEF+Fb+6KHe7PCekFiLeliSVy7tTqCC7XUwTB+7boBZKPvZK4vpKC31qyp3ZfWq+2ApC3O0kXYc2yrnbiZjZBEpSIqLY/VMmJ+xEvaJ4JMAd15VetBQA0HHP7faxZf/xTfs3TRdNo1LuN/lmR4EkcU8K7W7Xfcz8sWgRnjvuzsPkogAn7naURUjKO8KoKAaHVtzDxOiQD4zK7XIee9M78cDv/oI73vzewDoIZEmCpKouyy15fnI2C8nK3B7WkhQG+//tZjz8x4cwcMFL2TogMYlKi4VLrhK524X8/vDXplasxkN3PIbHf3ln6P4UI+90NLjXtGoICn7PiT63uFW80cFf317P9rspIZ4nLYmIOyYpoD/2tcngTbFSrU1h521DvDoxqfSYaIIEzKXOgPqYuL+JiPmui+bbvEZz/anzuLbS8J+LwVbVrsbKs/eGnQ/xoG94ifBaMhpizntFj02j9b7x72FYdDZMDwMyfV+k//RaX85GCBmD5hDrBEHHNN13KQiUD2sUM8pu9zcHSrpIHNoHOZu1A74LqspIyUGZ1gvznMSaOufuZdNg85Ykw0CrIGdQGHQ1xjAwkYGeN+9hdWc9mpMaHjvgWGu2LGky26XWhfb6KPrHTSFbYpQkVrFTJ1lFKF/wtyTt+dTnXMcA1pJEB/233307jr/mza7yvNsfAGxY1ARjQbvdL8VytzMSYiXJVacVn9L55z9gp67DkCQs/tG/U22KCRNkSUKhAgZ6o7ERT/z8DyhoGlZ+4wsAADU1iagmIzeRcpSkVauAQff1BcpdU8pmnfuPx+2vAsmzZf7h/hDQz5enAPeDqshoiGsYIxYuScLkitUwhp8KXYfXd4nePCBKeZAlSaZ3xoM+eIqClICWXpKAjhI/9gRnLW9h3jUe5ezUpi0K90pj3fwGdNRHcXCAfX9nws3s7BWtyOoFNCc0NMQ07Dw+6lv+1PkNGJrMoikRwUgq6xJUzlvVhvEpHe31UQxOujejvECv6a11UWxc1IRnj464yp0yvwH1MRXbj/r3s1w0JSLYvLgJ8UhlBRhZlnDGshbAEFs5fRUJDxVqy5JmJKNikeX0pS0YSWXRVud+z5a31aEhphUlbJbzPhUjF4uKrmyvw8CkO564HITtUkSVcfrSZpdLXtlGT4/lszGh2fNvKue8HOvmNWAyo4faSBBh3fwGNCc17D5hxgF3Ncbs57+r29wYDGvNPHtFK44MptA9IibC4qGQuY/S3EMJ1nTVYyqbDzUGDXENS1sTaKuL4tCAW16aSZy9ohU5vTBrlaQ5S9J0YmTE/nnO1RfhrNddhqYnzVwvvBWpPuYvvOnnv9j+XdDYa72IGzr/+Ds0PL+dORYbHca8pmAhtqMhigi1Q9LREGUm/YLmOBIRKx6IWpIb4uL74ON4eEVIp5UkK0dRprUd+z/wCTx82/3ICpQbCZJNAS7pOhJUstrI6DDOfKPbDSonsOqosoT6zlarbcqSFA9mHgSAI1QwvDoxhq7bf2fntDr+6jchReXkYdut3Os4uul0jJ+6ETplEauPaYgfPQzJMExLjwe7HbF4Srkc6vc8B1nXkW9qZhRzOacLryXQKUthIRpOuSRo9ti1LxfE7U8bHoKsV96S5OeeUs7HEgDqPIRDglJFukTU58NVpr7e2RCDqsiuMayGkhRknaqLqmhJRiBJEjpF1i2uk6oio6Mhhohq/stbAmOaYu9yu9ntwtvKvHbKG+Mas8teTbTWRe21u1zQ990Y19CY0MQEBiXYkvyERfKcRO+ZLEvCZ1gL4McmEVEgy1LFra3FuDc2JSK+c68UhckvLozMP7paxXpmaonPTJElxpq0sDmOBU1xRoYJi7qoirZ68dzz0qUb4xoaPWSfsFCk8GOgKZLn/J9p1EXVojYoag21t2qcxJAG3dv28277NQC3khQ01aX6ejz7rR+i++rXo/+lrPBP6uLjfBb8L0uzDQDy1FSoBTkoNwtzXPIoQ1uSOBdBlVOSaEsSsTJlW9tx8B+u9VQyAErA13OIHzngWQ4w8zZlm1vE/a93YpIIlXoYS1JB05BetMS27qljY0gc2m+f33XDVz2vrYbwSJRRJTUJCUDiyEEAQGrJMs+vHW1Jatj+NAAge/oZTPkg6xBNJhImJomZM2VuW3oZfchmwrrrr0XshGlNC6LAJ9UYCA4Ar1aIiSRJbN4ZQZnQ7nZFCF+V8yBn25xpwoKK563iY64qUaf1b6mkAyczY1atg7xjtfQIaqgrJaPYexCVn2nq+VqYE7XQh9mEOXe76YQg8L/tIdP9jSdtCJrIsgT0X3KFKyknQOW54dztsi2t9u/RDVsg6Tp6X/MmNCMYkgTXquOVL0UKUYaP75HTKUa6JW59gGNl4q1PQlCkFYnDB32L5mNxzwSoRElSJsZtS5LhwW5Hg+Sa0RsaoaYmoY6N2HFgB9/zYd/AI1Xgu18K6CF3qMwnIUmAMma672SbW0WXAnBc0OLHj2Lt5/8ZAKCvXsMIbEfe8T60PnQfeq58jbAOmgbbkIPN7LTwXq4M7UViQL9jHXeb8WLENdWzX2W6zvifKLNeCqUSN/gpTeXGWnvVXBUlaQY//K7cNxKmn9aqCNSCjDSbBLWZYMer9PiUTdtfZvt+oQN2G5L4dyVQrmVO9UggVc25MZvekZMZc0rSNGJi2w70n/0irNj5tOucrPMsY/5viN9L78ResO52en2j/fvom96JnitfA02VXYuTSDgKel8Zym6Pwns+9Tmc/tZX4uA/fBTxYZZtTs7nIeWydq6ofL6A1V+8HjAKGF+3wey/IEmqC5aAv+aLnwksWoiLLUMSJKDBVHbU1KQdk+NFAU4jZ42xXt8A9HRDGx+DZikmuYYGv0srJjzSc0OnLEmyJNmEIX6shiIyD51jI8w1t+Lx39zlWUeuqQXjq0+BZBhMDqFQ/S/XkmTW4jouYo8sBCZTluhKS0LlXWfcx0rtXlgmtnJAt6HI05GZx7v9KrXA/SVVIJdUedfXEop94rP+3iXyT+3cSCUti9OSW6sCbVSWel58/G+AtC80Zv1764E5d7tphAEDD77itcJz42tPY/4OnHB+wo2laDQ/8QgW/Oon9nEi7APAyNazwrdlN0m5/Eh+17HlCMY2bMG9T+zHwfd9RLi6qKlJLPrpLWi/649QDx/E4p/+Bxb/7D8R7TEpq/MeFNx0W0YRdNO5hibPemxL0uQEmp942Gx/njjxLACMXG0+1wPv/xgA05IEAOrYKFRLSaKVVBF4ZrdKgMRcLf7ZLYi+sNtWxv1YDQsC60rBI37JE7KMx35zNx77zd2haPuYPB5lDoNhGGJ3OwF7ZEUtSTP4kagGxW6lqmQsy1VytfNV9qosyAgtSX+jCP0tOYnH6GS8tdnovlmGCOXCTLsIz2HmMKckTSMMAzi2eh3+evtD2PGl79nHp7oW4Nlv/oApG/iC+xSgBeBTbvwE1NERALCF9YPv+TCm5i8qqu/CXZkSFk6iwEnULjURyuf/9r+x5oufwcYPvwt1zzrWtvjxIwDcjHjC+jlrT67e23oz6RPbRJQkbXwMbfeZFpPR173Js/jxb3wPD992P3pffo3ZV0sBU8fHbHc7ojh5oWKWJKqa0fWb7d9L3v46M5Eq/C1JIsY3vb2jeGFTUYQxP0G5ZbxcNMPCMx2D4AaCLEkViS+xKqnch9ZdT6kU4H5ueuXqFqLHWI2NgJnGbBQgpxV/o8NTzrT4Gx0yG0Kyjxl8z7zW7jlDkoOTdRmcU5KmEeSFSi9cgpEzzrGP911yOQpcvE3QguB3lme7I0lVibA+fgpntQpF3MD/7X0NI/B6LC4MHbil2Mz/31/Yxxqfftz+nThsEjDkmkJET3HWpoyVTFWE/osuFfcNsN3tAMcVMuujVElaxCSUsG4+bylErQ/+xR7/XICSVCn2JXr8x9ett39Hjh5B8sBeAMVbkvKt7YKSpSFICSp3sfVKWifl3Yx8gclkCQV4BXLGl2pFCdNyqa5xfrECXtapYtui17JyFWDPNqpSaziIHmu5/SHr68nqzlNLrmiVRlnC/GwYltnQR3DfEeICWeKzoYkbpisp6sn8jswmzClJ0wj6g8ckFC3Bd9bvZedjLyID/QAAbWwEgFtYD7NuBJWhBSfB2uRCtsuhkyZudEmKBa5u3277d+IQUZLcTHSufiRZJUlvaMKz3/4Rso2OgnX8VW/E3ms/jRNXv0FYhyRJQCJh5gUi9STrUIiGp7HMN5pKVuddf0SdpZjoPlYtoDoxSYVYHM9876f233UvPA/AXzkQuttRCWrL7p9wvku+54uBAfG8I7TfNIKSKRfTE69uk8OVYkgSIUxgtAj5qlqSzPul77pS5CS1BDcF+Ax1pAYg9jgQlZuGzlQKJ6miOofwoL/N9JpZrJvzbJr2xeJkVermlKRpBP1C0UKqJBDegj4ifqd5ATg6aCpJttsXJayHndb8C+CbDJCmK/Yo1/fO9+HEK16NZ7/5AyFrXcJSLAAgOtAHAMg1NgX0EQDvbtfQgP6LL0fPK15lH9v9mS/i8Ls+EHQTMDqcXEw0M6BHcQbZBW53Rr3OX0mqlivS4AUvRe9lVwIA6vbtAeBPfa03NiFLKaTZllbkFi+pmKwg3HmvYEySlwuZ6D3zczs0++Ls6Je6q0/eh0qlwarkRrXvrmgVhENZKp/UQIRacnmbI24IRq3fXzlTX+L+LamOGhug6e5NZdyc/Tefi4s3nX5LUrVwsioz1cKckjSN8Hq1JMO9DRw0kX1jkrgAdW1oAMjnEbGUpayP61Ql1mbWkuThy5tM4rkvfRf9L3kZ8gKWuejggOtYjrIGecHg3O3yVr6eo29+F8ZXn4IdX73ZjovyAumx0eGMU6651VdIdilJy1Ywfw+eeyHSCxf7tluNmCSC1JLlAAB1wsxAXtAiuPv5Xs8KRjdusf/c8083wTAM7O+bqEj/glyuynXJMpnkBR9IF4NksCWpGHj12o5JqjHBB2DzkfGoFrvdyQbejbKSj3l2i2PemBPUZi9mahmrleWTTnR/0rrDljLWNfJ8Ko05JWkawb9QR978LujxBA7/3T+6ygbnSQrvbhcd7EdkaACyrsOQZWQpOueCYYSb2xLbJ/4aLwpwr27SckU+BLU2EC4miVeSEgf3AQDSS5bjsd/di94rrg6sg/SZsSQ1tzD32FbPJ/9lbzS7fLn9+5Hf34dnbvkf75xMFirnbudGetES5u+gJKqTK9favwsBiWOLhdD9JuC8CG31Uciye9zWzRNb7JKC4Q+yJNF9KT0XkYm1XWa/uhrN8VzUEm7ee9VHY2lbiBxiFkj7AHDGMm8XVtHtruxgyVO8drwbqGzz9LtRiqJ4ynx/CywAxDX3w01EFMQjCqKq+zO3oDk4MXRYdLjWguKwrN18dis6/IlpwrgqaqrMjL0I7fXhGUBF18oy0NkYDT1/Rb1ebF07v8n/OazqNMdkTVe9b7lawOpOs4+nesxXci/knhc3e49fNeTNtvooFEVyzddiUWrfVnaY4xNmraqUJa0+piKqyaiPWknmy6i2rT4KVZGY96ezIQZZdssDlUBQX+n3L2jtoLG0zbyOXwPJ/AWA9Qv946dFOEl1pLk8SdMJfmf2hU99Dns/dn2gZaNY8Lvj2sgwYhaNdqa9kxGQDVQmJokpS8eXUMfb66PoH89Y9Tlnck3+rmxOOf+YJEmCi7jh2Bve4SqnKhKTrNYTnY4ymaOSry5vT2J5ex329U3g0MCkuK9LlpvMaYaB1OJlwW2hOkHty9uTONA/iamuBcxxUdwRDTpurRCJwoCzq33m8hYMjGdwoF9875IEnL60BU8cHBKfFyynrAIebhximowLV3egfyKDHcdGAZgfxeZkBEeGHLr71Z31WNgchyy5n3mQsmgrzEbpShJBY0LDxWs7IMsS1s1rgCxLOGr1s7MhhlPnNyCVy+PR/YNF1dvVGENdNPxSftqCRluRlGUJC5rjOD6cdpXjb3fLkma0JCPY3TNmH7twVRtOPG+4yjUnKCUpxKaJHxYECNKAqSh3NcbQMzoFANi4qAltdRGrTXejp8xrgKbInu9vMdAUGacvbcaTh4bt9ug5fO7KVjyyf9Bz13lFex2WtSYxknZbOmm8eFU7/rLbdD2OqDKyesFqz3lW569s8x3j9QsbyyKI2bioCYWCAVmWsKarHqs66nB8JI09PeNF1ROPKPa7wIPuf3t9FIuaE1Wjjq8kFrcmzHXG6is9785c3oKGmPlOrJvfgJUddZCMPPYKa6oONlHPrljQz0Qt0W+4Ma55PnNXeyW14MaZy8zNzUrMH9H4RVTzGzQT85O8f0Bx95eIqMLnQOZvsfWd7JizJE0jRB9JLwUpMCapCHc7OTNl5xqaoggTzD6FE/z45kLv9DCxJmLlKb1goeflT/zk9/bvqU7vPEUENAX4s9/8AbqvcZMzBFlsbEazdkdJyja32EouuQ/ZR/iTolE8ePfTePCep0MrwZVSkkR02vzYBSkHOpVDKh+LMXM3yBogSf5xReLLnYNh12cJEmQuOano2UqStejn3EJoEJkG64serl+i9gnIx4f/CBkwP76ie+ffUf7dK2raSE4/SB/CWjBJMbo7oo+pLLF9pMtUi90OYO+D9MFvnaqWHMBXGyYOy8tlj372XuPIzy+/e67E8DP9oOaRd5vi8+GE5eD6awmebK7c3xGBdZMpX6VbrsRYlhNbOd3PUpLY+VOum6dwvSviniodaxbm/fO6rpL1ncyYU5KmEcXsQwfGJPmcL8TYnVcllUK034w/ybazlNjmNzjEx6qIl9vLKiAS3gFg+PRz7d+9L325/XuqowujW8/CI7fei8f/+4/QQ7nbOfc+fsppgS5uvnVR7nZ0TFKQuxhgCmzZ9g5k2zvdhT1QubXJPeYZXjkOcDPTKQr0QtR0z6pUwtKg2wwrSPuxZgmtF2efzZTNtHdiZNMZ/m2E6omJ2eqeXu60c22g8CQv9G+pevEorOJQWx/6UtIsVLLu2YpaeIylvtc10PWKgQ5dLNWSVC4qPZ4n83szE6i1NbdSmHO3m04UIWSWY0nik5YqU2nIGdMNJZ9gFajQSSgD/va8zqMgfXzgokvxwsdvwMSadYgdO4LOu/4IAMhY1o/JVaeEbY1htwsb6+SJTjG7XZjFtZQd82rsspO+5pN1KMTjkNOmW1UQYUG+kXK3i8ZAiwqS5L8gmuxexd1LWS5ZkucfVn3WsRtuwIAcQ9tXPgcAppUxQImuzCMpYoNBULbaylfFpx1XHz2vq2lJojcZpnszlI/JdN1mkf0pirjnJJNN5oTX2kOeMqNPx7tVtWVibmrNoUjMKUnTiGKYIwOVpCLalafSkC1XI1EsSqUXJD+CB7tPnFR85B3vAwC0PnCPfTjTOZ+/rKjG8zFxLEPYj7DRTrHbNbX6viz8GJay2VYpM7eXwpHdcjpiDz0AIIQlqd5Rkoi7XejpG3AbonpYa0NIS5LvOcldrq4OA9d+AifaF6L5iYdx8D0fCtFG+c+k4u9XZaureI38NJ4u5YVJPTDN0hA9p4OohyuNWpf7ar1/cwhGnnI1PlktBnMoDyfrrJhzt5tGVHJHOGhH9ulbfmn/VtJpyFmTMKEgEI4rvpFchtsLHTM11RUcg+QH3u2waHCWJD93O34US7MkUbWV8VB49yaCifc6LIpBliTaGlmIxsy5S+4/0BW0vDlVrCDt5dLpdaz35ddg9w1fQSGEpXG65YFqtzcdyoPrnZd8zlW0XXGbtYBi1wM7JsnrPFO2xm72ZEAFPtblreG19Uz9UgVUA9Wa0zP9qsx0+9XEyXpvc0rSNKKYmI5yF8mhcy/A09//BQBASacgWZakSjHp8S8E424C8W8m4NvjjUovXobUwsUoKAqGzjq/6H4VNmxEev5CjGzc6mnOCfsyG5SSpNfVF8VuVk23oiB4Kql1DvVqkCWpUOfQgRabS6iUDxwT6F9OTJLgHP0uFRtWVYnHWHYVXJ+rafmtSH3c314kA5XGdLUjQtDaXs3+1LpsUpayUOs39zeCcpk95zCH2Yo5d7tpRCWXmTAfDxKTY7rbZQGIBV63m0pwT8MyKNG/DS6uRYRCNIZH/vAQ5Kk08gHMY8J2IxE8fPsjMMogbLDR3Gz/nJq3AHHuQ8G62LCXluJWVI3dM0ZJTThKUkELYLdrdujW9fpGy93OvONKuoKKril2GNj55n9x0UpSRdztpsN6U8a1leuGWZ/rXSheAS4FjCW2aq2I4TetSiGr+FvWDZjvRA2MxIzoBzN/2wxKtSRJUuXGr9IbVrWugNd6//5WMKckTSMqudhKFq2sX52FuOlupgTEJFUabDyIeBffT1gyNA35Iq0X/PX+/QsJWcZfH9gJSddRSCTt3bQw7HalCIP8Al7qfPH8ENCWpKB5oGn46/07IBmAEYm4cnz5ti+Vt8CHH7twsR/TtZPt9bzCVFHMsy5HcBS7I1b2a8z3b9pikhi3y5mVMCqxaeLfgHdbtYZi5+vJYrSY6TlYSeRLTaRdQSVpDrWNWtjQqAbmlKQaRZj1NWgBIsQFSjoFKWtakoyIgLihpB6GBFX5dJjsK/1dyrW02b9HUjmrjeBGZtbdjvpNC45JJyt3IUQS1WyrQ1yRyRVKzhPEQzQNymG3C9odZKxpRdpzp/spit6RYvtcLIq9R76LrhAk/m+PTZNKg253JtnthCjaOmpdEOLRn6zCCVD7CmBYhH2DybOstfsulGpJCumZMofZj1qbs5XCXEzSNKJSeWYIvD6Oiajpakbc7bSxUaiTEwCKjy8hCEo4GdWcqeTtbkf/rvzCWe131O/x8YpTKex2lVpkPIkMkg5RQVBMEj+3+sczTJ1+XU1Eit97odsrJyZJeK4sS1L4i1WvRJIhqohp4d1DpysmiZ/DpbIvSlQ9klTcux+UdJPGTCZB9Hr2BKW8E+Z14nlBvy/FjNFM5bgpBl5Jx6cTcWrc4x7PoBgEJeCuZFvVQFQtrV9e81eEIBmjmDXSCzNt3Sum9ZN582M2Yc6SNI3Qi9iNmdcYw0RGR2Ncw8H+SXEhj3fo1PmNeOLgkO1uBwBdf7oVQGkU4Evbkp4L1KbFTegZncKyNseVy0s+rbSSWDK4+1UUCXre/L2yo85d3v9y4bGIImN5exKHBiddFhhNlZHT/c0y5mJe/ngxSipFxiDl9dDXhUVjQkNMVbCqsy7QarhhYSP29U0glc0X35AF0sUg6ueyiBuKKNsQ1xCPKDgymPJsnwd5f5a3m+9PIqJiSWsCEVXG3t4Jz+s2LGzE9mOjvv1prYtAkiQM0AquoJyof50NMSxojuPpw8MAgLqYioZYuA0W35gkWUIhH/4hbFnSHLos69Y3vQJGczKChS1xJC1liB/TtV312CtJWNgcjnGTXL1hYRP29U1gcas3E2NbXQT1MRUNce/ns6azHpkC0JKsvrs1j2IfRUSVsaw9CQmAqkyvUnfm8hYcHkgx34FT5zdgb+8Euhpj6B2bwvym8KypqzrrkNULSEb9Ra3Tlzbj6FAaqzqDvz8zgdVdZr/Czl+CMPOXoD6mYXFrAjEPhWxVRz0Mw5SNCDYvbsIzR0aK6tPfEjobYljSVma+yJA4WVW6OSVpGlGMu1l9TMOWxaaA4KUkiSZlPKIgau0sivIEFYTudv7T209xaKuLoq2OY8xjLEmlC6jVAn+/8xpjONRvutItoj6AXh/3sB/95e11UGTJJexqsoQFbUkcGmCfK5/bR5GlkgJmvd3tnMWSxKh51uF7Tny2IaZhTZepiKV9lB8DBjoaYohHFDx2YEjQ59JB6gmiBS+2PhGWtSfRXh/F49Y9AMDqznpIAA5zipIXRO/Pqk5zDMm8Eb03HQ0xAN5KkqpI2Ly4Gfv6xjEwHqorDNYvbMRUznmGazrrfUqz4BUUftOkmHWgLkC4ZNuZ2c/02i5vopmYpmD9wkbP816IR4KvkyQJp8zzJ7lZ2ByHVkac53RjRfvMKAsNMc013vSza68vjh12SWsyuBCApkQETQnn21xrAmdUrd78pbHaZ52JqDJOW8DW1crLHgGotXGtNkp5ZnNgUfu295MI+QrFdBAEmY4L0RjG129mjgUG7FdgFREm8kRxyXQr0bZnGZ+d7lCxYFYbDO05f53krrvoflXAfYipk3K1kSy2Q+/rvNuu1Ca9l3tF6GSyVrmg0mUpXQFXi6ymfP9r3Vd7OinAp43drsbHPAiBDJIV2lSoBGa6/TnMYQ41gJN0IZhTkqYR+UpFvlsQyZgSqA+oJGH7r/8E45OftM+LKcAr2i3PmKRqEzeUWjsrXJUYd8GtEL4BuBIQprdBcQ7h+iX+HWRJCqxX0LUwFO80vATmiliSPCopegoGCqvuApUOjQnTZx+VtiJ98I3/cpX1VhKrGjbkYUH1QjVXo+lU0ma7QjiHOUwXZtO7Mpv6ejJjTkmaRpRqSSrrZVEUSCtX2n8G0WNXAqxg7vxVdSUpZPWiqBVxOS9LR4g2bGFdXDhMX0vddWeVVHEd42tPK6luP4R+vFY5Wgn0tcp5gNoLoI4Jnm4ZL5CfUC9BPHOqHRxcnvugaHzK6IyoDb/6peopJ5Vysaw0Sln2ZjrAfA4zi7nnP4fZhpl2d64W5mKSphGlJmTzQhghWgKABsdfvRApzoe3XDDEATUSk8Sj2N1tsWAsLiO29oVTvoLYfrzAEhmwxx+6/WHEjx7G2IYtJdXN11kO6Puj83BUQkDwckeqNKuiqKv8Y6t1eafieZL83Fmr+CGtJRe0asNrI6oWUevzfw5/O5jpjZS5d2H2YU5JmkZUOiFb6PeNVpKmw5LksRLQlqSqKUyhrDxsoWrESZA2vOoOc/ulKklsP6jfANJLliO9ZHmZdZZuHfOqpxQro6gbQcfK6aPwvOCj6yYuqLQSEr6+mREEqv9+BWEm85TNYQ7lYm72Fo+5V35mcbKO/5y73TSivIRswhNhLmaUJBFxQzXdbdiYpMq240bpSmgxx0XjXkwdnmW5iku2JPnUGRbVTmDKo5R3w477EigqlUpgKsH//ThZPwxAsBtj6Hoq0Jdi2zmZnwvAWYtr/F5r3dI1h5MDxbjBzwbMoq6e1JhTkqYRxeRJCgPhx0cSCIiMu51ISaqiCwzVl2rnSSq1+qpYkux/w1td+G6UStzAx4B41e8Lv8S5EN9XWMVKVKpUK6vdIfun+J3wa9u36hIeAc9KWEsf5pnoykwkeZ2L6ZjDHP62MKeMz6EamFOSphElExcUa+ngwbjb+VOAV2KZ8WK3m46YpOmQjcKQAziuV+I6wigUJRM3zJDfdSnkCwSlED/6Wem85mAp8Lte9IyqHZNUTHUVa5pRNMt7kau1WTKnGNUm5h5L8ZgbsxJQ5JjNzHpx8j7Yk/XO5pSkaUSplqQivL7cZTh3O5GmMl2Tu1YowCsnNFNkA3wZeMckhX2elYhJKhV+Y1mNb0s5cyMoYJ8+VqyAHpgnSbAJUO0dTW9a+Qq3E7LSOYHOjWoPSSU3AeYwh5MBc6/BzOJk3aSaU5KmEaXGJM1vijN/xzQFgHhSSpDcH816J4u1nM0EttecDEg4GwAv4WpRSwKA2f+WMtsoFYmo4jrWEBeTWQQpM3SGdK9CXutGi8e1TQmzL/Ma44hp3q9nRJWFv/k26ebJvPFCfczhcfGzYpW7GNLtKIpZVznzQRSL4tXDtmIztEuApoifQ1MiwjHnmXBZkir8+a6Luvl2khExBw8/N2YayahStWi3RMR/fvNo8njvKwH6/QnrNhsvov8NseoT8IQF/T7PYQ5zKB5ELmmtc76Ds0XpIOtWR/30MidPF+ZWt2nEivYkDiYMnLm0GQVJQV1UxXPdYxiezPpet7K9Dk1xDU2JCEZSWVs49yYAcGAYABTn45tranaX5+rZsLARf93z/9u78yApyvMP4N+e6Tl3Z3b2XhZ2l2vlFpAVsoomERTReMdEJAjGaGkgSvTnQVleZankMhg1qEnEGEWMKTGGQilEgxI55FQEEZVDgeVa9mZ353h/f+zObPdcOzM7M907+/1UUUBPH2+/T0/P+/Tb/fbxWHYpJpMG58HrE8ixmeCym5BjM8EiG7Hf2ozGVg8AYGBBFvafaI573WPLXNjxbR2Ajn3t7rRSVZGHHd/Vqabl2EwYV+ZCw974mm8F2RaMLXMh2yKj7rQ6htHek2Q0SChyWjG2TEL96XbsP9ESmHdsmQunmttRkG2BQMew8d8c76iX/rk2lObY4PH58N2p0zje2JHwThqch6+PNeNw3emO9QRtz1//0ZKkc4bmw2Q0BOJukICzB+Wh4bQbe2oa46qXjjKE7vfZA/PQ2OZGoeJkWj04Hw2tbhRGSF6MRgkeb/RtqXvcOnvwFNOUMRiQa4NslPD5oYYY9qLDuDIX6lrcyLLIsJoMqG1uDyT6ymH9/b1UoaO7xbypqKqH5KPV7YUjTAM5yyLjrIpcbD1wSjW9X44NPh/w5dHYYnhWRS5MxsQLPKLUGXb694bko93jgz0omfN/f5LBajJiQkUu5BjLn59twbhyV8QEsycMBglnD8oDBCBHSLKDxVL+c4bmo6XdC69P4NvajmlaN6YcVhPGl7sinl96R1NPX/h8TfxieiWKTqu1qiIPdS3tsMhGnGyq1bo4cakamIv6FnfcFyB7CyZJaVTqsqHA2vGjYuocirsw29JtkmTobFQDCPwNROnpCHMm2PWXpZC+/RbNlSO6LWekK+cxC+rJUDbqihxd5S90WAJJUrHTEjFJMskGuD3hH1opjOPqRZHTEvHKen6WGWE6mcJS1q9/+/Wng55J6vw7XAPZ34AvdFjQ6vaqljEZDaoYl7psgSSpyGFBTmdP06HOhAgALLIRRU5LIEkKFq5RHSy48SrQkTzG08Dv7k42h1UOlN/PajJGTd5i+eELN4/y6r26p0lCkcOKzxF7kuSwmlR1qKyrcKULfSYpOb/MWRYZWVESinC9cUaDhH4ua8xJknIdsRZbOVukhCfbIgNhvqrxfH9jEW8veCp/2HMS6Knqrvx2swy7WcbRhtZEi5US+RnaQKLeQ68JUCzMcsfvfkOrW+uixK2j/RFfL35vwiRJY6n4YqtvAepouTZccBGaOhOS0PmTW4hE9ikZz9/E+kB5rFuK1LiN68H5cD1JiQ7IEOtLOZMYzngGj+iu/hMZ5SyWZ4jUx07H/KoXmIbc/ha77nZf9UxSYJoUcZ7eKuaEKYb59PpS6d4ktO9Uv7Tu6eqNWGWpoXUPXTxx5SGgD/q6YZ0A9KxBIknhpyc6nHRPRfuBVH6WjGG4u2t8pfIEGdIQD7xMNnTeSAlhXO9Uipojhb/VLBHxbL8no9v1hPLY9t/9ZlT1JKUy7l3r7hq4Qa0vvdi07+wpEemJ1gkQZSYmSToUe5sqUmM79PJ2tKv4mdSGS8dVy3C5WPBWu263Cy1PpEZzd2WP9mmy99rf4O8NDXxlvfmfEVLdbheSwMax7rhq1v9MknqqhoMUAgjuWU6t3nC8ZATlLc06r3KdF48yRCznWX5XKF5MknQoFUPvRutJCn5mo6cSWUMyTl7d9iTFuY1Is8dyC1i49/X4KR/MTkXvVzJ/CPT+oxLMnyRFvyiQmp0K9CQF326XYT990Y7Z3na8ZIJMO76IiPSCSZIOJfLAdCRdwxJrdLudJltNrbBtxJDnXiTV30qJ9iwkclwkWv/+54viaYAp6yVZcY+358PfgE/W7aXxfG26nklKfB2pkGhSmNDFjrjOSkRESRLnCStVL7WmzKLrJOnhhx+GJEmqP8OHD9e6WCnXkyvdkZaMOixuEpMyIPbyqxvzSXgmKU2Nr3Dn1uDy+6sg7Oh2ccQ3kWeSkim+0e1SU/+Rjqdwm/O/lNYQ5Xa7VIn4TJLG99ulc+taJ4R9hfq5Qw0LEgO9l48yQyxtCK0PxXi2z++NPuh+dLtRo0bhvffeC/xflnVf5LiEfVg/5mW7n9PfcEt0RLVExLqlZDep03VhKJ5kLFxClIyR/EKTsuQN1gCg61m2uEa3S4E4V+rtPAiUx3tPEvD4nkhK7XuS9CrDd48o7dhAjl8m1BlHgtQf3WccsiyjpKRE62KkVawN09hubInhGQ0dNHPSeW7o8XDG4XqS4ujxiasnKcb5lL046mfMYt5U+O1rf2jExdf5TJJRRz1Jevh++cXT25fIDzaHAE8//Rxd4bHhR+kQy1HGY5Hipfskae/evSgtLYXVakV1dTWeeOIJlJeXR5y/ra0NbW1tgf83NHS8NNLtdsPt1vZFXf7tK8vh9Xjg8arfX+Q1iJjK6vWGLuvxdqzfP90oGeF2uyF83pB5A8t4uuY3wKBaXllej2J70crn8ajni5SgKbcbvE0lAwzweMO/TFa5nMfjQXt75PV4PJ6O+T3ekP0LFxshRNh1tbndcLvVL0/zBMXR4/HAjY4yB69D+Lxd2wuqg5Aye32Kzz1wuzvq0hsUC7di+8H175aEYn3h60YZ445yiZBpynmD9xcAPG5D134pyh28jVj4lxVCgtfT8W+vx6uax+1xh5Sx3S11lq9r++3tbiDoJcKR6iGkHB4PhC/6D6s6PqF14/V6Ejr3hPsOhvvcf1yrlhFSYJryOHZ7PHC7g+rCHf4Y9Pq6lvO4PfAf8sHHF9AVG4/bA4MI/10N7EuY5ePZbwK8yvOGJ/LxFe68poWenAsyVbTYKM9fwfOTmr+evF6p2zpSntP85+twUvW9CXfuVG9X/Tue0DYy/PyZrNjEurwkdPz02jvvvIOmpiYMGzYMR44cwSOPPIJDhw5h586dcDgcYZd5+OGH8cgjj4RMX7p0Kex2e6qLHLfaNuBws7oRNtAhkB3Dy9q/bQLq2zuWLbIJHDstYZBDIMsE7KztmC4bgOEugZOtwJGW8I29CofAgcbOgQYkYFSuCCwPAKPzOg6RrxqAVo+kmhaOEMCX9RIMElCZE3m+Y6eBY6c71jfCJVDbBhw9rS5jWbaAUQL2N0qBffTLswqU2rv2NccsUGgFvmoIv58ui8CALGBfI9DcmWzkWgT6Z0UsIr6qB1q9XeszSsAZro4yKTW5O8roN9wlAu3ybxqAdp8Eq1GgxSNhWI6AsfOzE61ATUvkOvUJYNepjs/9sQWANi+wt14KlF+5/UEOgX2d/67MEbAo8jllXHPMAg1uCS5zVx34PzcZgWGdsfumAWjxqI8H5fHkMAs0tksY4hSwdV52EaIjDm2deU0/u0C+NXwdh+MvhyR1dtyFOYxK7AIFnes8dho41iphsEPALndtHwCGOkVID4eyHpSMBsBsEPD4uj9+g9flj4UQwK46KdBjUp4t4DR3u5qI6wXCHxuHm4HaNkkVY39clNsUAvi88xgKd27x+oAv6iVkyQIDFadV5bE31Clg7Yyt/9jLswiUBh17I1xdx3YkNS3AidbIx7z/nFiWLZCTQL31Be3ejuNboCM2Fp2/8F55LBfaBIptGhamF/D4gC/q1OeoaL+5fdnR08Dx0xIGOzvO/dEoz2nx/iYlw/5GoMkd/ff+y3oJxhh/e8I51QYc4vmzWy0tLbj++utRX18Pp9MZcT5dJ0nB6urqUFFRgSeffBI33XRT2HnC9SSVlZXhxIkTUSsiHdxuN1avXo0LL7wQJlNHS+Vw3WnsrmkMzJNtkTFpUF5M6/v8cANqGloBAFOGF8HnE4FemzVfHAMAmGUDzhtagCP1rdh1pCHsesaVubD92zoAwOhSJ4qd1sDy/nUDwKb9tWhs9aimReI/rKJ1b+8/2YyvjzcDAL5fWQDZaIDPJ/DBl8dDtu2/jcr/2ch+TvTLsar2tdhhRUW+HZv214bd3gCXDcNKHNh6sA6nWtpV6w8XG+V+CNFxy6KyjpVqm9uxrbMOAeD8ygKYOluLQoiIyx+sbcHeY02qsih5fQL/7dznCeW5cNm7yqZc18nm9kAMqypysfnAKQBA9eA82M1dvxzKuJbn2jGkMEtVHv/nVpMR5w7JD5R/3Vcn0d7ZmzdleBEO1Z3GF53H7fcG5cFmMobUS3DdxcNfDoPU0ZO0ddt2jBs3Dka5qzU4tCgbFXldFz6C6zbaMaisB6UfnlGoSqhiuT3Dv64SpxWjSjvOMa1uL/739UkAwLgBOcjPtnS7nmhljPR9C3c8hpvmX9e4Mhfys0J/OcMtozz2Jg7Mg8Mqh8zvdruxfOVquIaMh1E24gdnFHb7zN3eo004eKol7v0iNW+YW0uDRTqvpZv/+BvTPwdFjvi/C5koWmzaPT589NUJ1bTufnP7sljPF8r2xbBiBwbkhs/WU/W92fFdPU40dbRPI8UzlrZTdzL5/Jms2DQ0NKCgoKDbJEn3t9spuVwunHHGGfjqq68izmOxWGCxhJ6ETSaTpj8SSsqyyCYPZGNXGMxxlFOW5cCywcv4pxuNBphMJljNXtV2VOVRrMdiNsNkMqnmDZTVKMPfRk1GXcqySVV+uTOp8E+TJIQkLP7PlPXknybLMkwmOeJ+Wswdy3TUmy/sfiR6nJhNIiSOcneX1BE9hgBg9AnF53LEssmyL6guu/5tMnWVS1lG2STDYlE3mAN1aTSqtmUyyfChq85k2d0VC7MJFnNyTyX+dRsUVWiUjerjUo5cH7GuP1hwfcSzLllRHp9kUNSPOaFyhvsOJipwPMRRZ7EeewJdsTGbTN3+OMum6Mc8xSaemtP69y/ceZs6hI2NwRdyjmK99ZyyDSHHcC5M9vem4/feG1g3Ja6nsYl1WV0PAR6sqakJX3/9Nfr166d1UZImXbl+tKuNyisWyXq/TLxiuWrS3TzdjTqXyoc2Q9+No91VHFVPSJQjLFoJ0zWcenei9XP3lj5wPV3QS0WVKePA56KJiChT6DpJ+r//+z+sXbsW+/fvx8cff4yrrroKRqMRM2bM0LpouhBPgyTWYaf11EUbbyNYiOiNwGQMvR1t20rJ2lJvaHTqafQ2LamSBeV7bPpQ/XD0KCLSK56fKF66vt3uu+++w4wZM3Dy5EkUFhZi8uTJ2LBhAwoLC7Uumi7E0vjy398afQjwLlr1JMUrkZ6OdL4rSkvp3ss+Uq3dinhMsn5UeksPIJFWeMog0gddJ0nLli3Tugi6Fk/jNFryo1xPKntbogm31Wj7l0hDy5DCftPg4iQrcejpla9EF++uftN1RU6I3pOERbrtrJdcdwgRa70z5yEi6l4v/Sno03R9ux1FF9OLGzv/jvYCU5+ilaNVkhSvcA2z7hpr/n1LRaM7eJDIdHfrqxvosW27tyQfkeitcR6pPJlwi0cm7AMRkR97tCkWTJJ6sZiedeg8EURLfnyKs0VvviWtu9HsoyWKPeVL8ISbihN1MvaSvx/xUx5/yhjo6RuViuMt7mcHeXT1WYw9EfUmTJI01pOfjGTdbudTtPDTOXCDqlGZpM1Ga7ClMknS049/KnYz6ih5esoCNBS5JymtxSAiIqIkYJKU4fyN92i3y3h7Yb9zuF6jWG+3o+7F847pVI/e1luiFqnKeuvodrzFjoiI+jImSTpjNcUeEqv/za49FC55kI0d0yxxlKcnwjXIbObI+2cK86JWq2wM6TEzy13zmYypa/QlepuiSY69fpOf5EVenz3JL4dNhVTGMxGRvruJDhjiP/6TGfdER6+MdnzHu8peeE2GksSUytFzMkgq73qgDlrc/WE1JafNRumj/5ZQH1LosGBYiSPm+Qfk2tDQ6kahwxJxHmWDZHg/B7440hi63WwLSl02uOxdbyCuGpiHfcebMbgwK+byJMvEwXk4cKIFQ4pCtz2y1Im6FjeKFPs8vtyFI/WtGFqUDbNsQEW+He1eH3w+YHBhFk40taHd44PDmro3XOdnWzAgz4bDdadRWRR7DPs5rahraUdeljniPGcUO9Dq8UYtv/KE35Oei7MH5eHgyRYMLcqOOl8qbpWMV2mOLeFlzxyQg0+/q09KOfzHnzLustGAwYVZEAAsCV7MGFfmwjfHmzGwwN7jMg4rcaCl3YvcKMdZOEOLsuHx+aJesHCYgP4uG/IciceDMtuwEgea2z1xH399lcEgYUhRNprbPBACKM/v+TmAtDe4MAturw8lOVati0IxYpKkI2P658T1TJDBIGF0/5yY5x+Qaw+bJEmShJGlTtW0bIuMMQNiX3cyOa2miNsuddlQ6lI3xvKzLcjP7kqaKovVSUqWRX2Yp6pNP7zEieElzu5nVDAYJIwqjV7PPfmBjDeBybFFrns9GVKU3aPn54qcVgDJSZKCjz+/wYXRE83uZCXxO1iWl9gxNLCg+4skkgQML3HAZErdRQjq3RI9/vqyQTF896h3MRkNcbXZSHvs+9ZYqq/I89YWSgXVkOMp3hafjcksPCcREVFvwCRJR9gYpHTSywtvE9pm2rdIRESZghdrKBZMkogyjDJn6a0jq3WH1xOIiIgolZgkaYxXM9IvI3vsUnwcRauyDKxNIiIi6uOYJBH1UT1JbjIxued7tNJDTy9eJiIiioRJEsUsI3tgqMe0OCxScRshkyQior6Bl2ooFkySKGYiE7sPMlw6EphUJ8/pSl2YJKUHTyNERNQbMEkizbCtlBrpaIRqfctUKvIyvuWeiIiI/JgkUcwy5Xa7zNgLtURSlkyJZ7KwJ4mIiIj8mCRpLFVX/QsdFgBASY5VNd1qMvZ4nT1ZB6VGlkWOe5kcmynh7aW6t8p/rBU7rShxdhzDDmvXPjqtiZc9kmKnJenrpFD52WYAHMadiIj0Lf6WFfUKo0qdqG1uR362uuF3VoULtc3tKMi2oKHVHVdjsyLPjiyzETn25DdQqWeyLTLOqsiFRVZf9whuh54zNB+1ze2wmozIyzKnr4BxUh6/HrcbZdkC48tcgMGI0+3epByDkysLcKKpDQBgNhoCiRmlVonTCqNBSkmiS0QUCz5jTbFgkpShZKMBRU5ryHS7WYbd3BH2eHuEDAYp7DpJH/xJz+l2b8R5lPGPR3CyleqfF+Xx6zNIyDEDJqMBJlNi5Q/HajJiQK49Keui2EmShCIHzyNERKRvvN2OiIiIiIhIgUkSUQbj4AxERERE8WOSpDGth1Lui5g39Bzv5yYiot6Kv2AUCyZJRERERERECkySSDPsjEi9VHWaMXRERESUyZgkaYyJAiUbb+EkIiIi6hkmSUQUNyb3RETUW/E3jGLBJIn6HCllN6ERERERUSZgkqQxXswgIiIiItIXJkkaK3VZYTAAxU6+gT5dBhVmAQDK8uwalyQ1bCYjrCYj7BYjDIbk9JqN6OcEAAwpyu6cwvSeiIh6l5IcKyQJGJBr07oo1AvIWhegr7PIRvzgjKKkNWape9kWGRcMz9w6lyQJ5w7NT+o6c7PMGV1nRESU+Ub3z8HIfk7+llFMmCTpAL+s6ZfpdS6l4I25yjrjQ69ERNQbZfrvPyUPb7cjIiIiIiJSYJJERHFjRxIRERFlMiZJRERERERECkySiIiIiIiIFJgkEVHcOHADERERZTImSURERERERApMkogoboJDNxAREVEGY5JEGmJDm4iIiIj0h0kSacZsNGpdBEqQ2chTBxEREWUuWesCUN81INeGhlY3Ch0WrYtCcarIz0JLuxdFTsaOiIiIMg+TJNKMwSBhdP8crYtBCTAydkRERJTBeM8MERERERGRApMkIiIiIiIiBSZJRERERERECkySiIiIiIiIFJgkERERERERKfSKJOnZZ5/FwIEDYbVaMWnSJGzatEnrIhERERERUYbSfZL0+uuv484778RDDz2ErVu3YuzYsZg2bRqOHTumddGIiIiIiCgD6T5JevLJJ3HzzTfjxhtvxMiRI/Hcc8/BbrfjxRdf1LpoRERERESUgXT9Mtn29nZs2bIFCxYsCEwzGAyYOnUq1q9fH3aZtrY2tLW1Bf7f0NAAAHC73XC73aktcDf829e6HBSKsdEvxka/GBt9Y3z0i7HRL8ZGv5IVm1iXl4QQokdbSqHDhw+jf//++Pjjj1FdXR2Yfs8992Dt2rXYuHFjyDIPP/wwHnnkkZDpS5cuhd1uT2l5iYiIiIhIv1paWnD99dejvr4eTqcz4ny67klKxIIFC3DnnXcG/t/Q0ICysjJcdNFFUSsiHdxuN1avXo0LL7wQJpNJ07KQGmOjX4yNfjE2+sb46Bdjo1+MjX4lKzb+u8y6o+skqaCgAEajEUePHlVNP3r0KEpKSsIuY7FYYLFYQqabTCbdHOx6KgupMTb6xdjoF2Ojb4yPfjE2+sXY6FdPYxPrsroeuMFsNmPChAlYs2ZNYJrP58OaNWtUt98REREREREli657kgDgzjvvxOzZs1FVVYWJEydi0aJFaG5uxo033qh10YiIiIiIKAPpPkn66U9/iuPHj+PBBx9ETU0Nxo0bh3fffRfFxcVaF42IiIiIiDKQ7pMkAJg3bx7mzZundTGIiIiIiKgP0PUzSUREREREROnGJImIiIiIiEihV9xu1xP+d+XGOiZ6KrndbrS0tKChoYHDSuoMY6NfjI1+MTb6xvjoF2OjX4yNfiUrNv6cwJ8jRJLxSVJjYyMAoKysTOOSEBERERGRHjQ2NiInJyfi55LoLo3q5Xw+Hw4fPgyHwwFJkjQtS0NDA8rKyvDtt9/C6XRqWhZSY2z0i7HRL8ZG3xgf/WJs9Iux0a9kxUYIgcbGRpSWlsJgiPzkUcb3JBkMBgwYMEDrYqg4nU5+8XSKsdEvxka/GBt9Y3z0i7HRL8ZGv5IRm2g9SH4cuIGIiIiIiEiBSRIREREREZECk6Q0slgseOihh2CxWLQuCgVhbPSLsdEvxkbfGB/9Ymz0i7HRr3THJuMHbiAiIiIiIooHe5KIiIiIiIgUmCQREREREREpMEkiIiIiIiJSYJJERERERESkwCQpTZ599lkMHDgQVqsVkyZNwqZNm7QuUsZ74okncPbZZ8PhcKCoqAhXXnkl9uzZo5qntbUVc+fORX5+PrKzs3HNNdfg6NGjqnkOHjyISy+9FHa7HUVFRbj77rvh8XjSuSsZb+HChZAkCfPnzw9MY2y0c+jQIfzsZz9Dfn4+bDYbxowZg82bNwc+F0LgwQcfRL9+/WCz2TB16lTs3btXtY7a2lrMnDkTTqcTLpcLN910E5qamtK9KxnF6/XigQcewKBBg2Cz2TBkyBA8+uijUI6/xNikz4cffojLLrsMpaWlkCQJb731lurzZMXi008/xXnnnQer1YqysjL89re/TfWu9XrRYuN2u3HvvfdizJgxyMrKQmlpKW644QYcPnxYtQ7GJjW6+94o3XrrrZAkCYsWLVJNT1tsBKXcsmXLhNlsFi+++KL4/PPPxc033yxcLpc4evSo1kXLaNOmTRNLliwRO3fuFNu3bxeXXHKJKC8vF01NTYF5br31VlFWVibWrFkjNm/eLL73ve+Jc845J/C5x+MRo0ePFlOnThXbtm0TK1euFAUFBWLBggVa7FJG2rRpkxg4cKA488wzxR133BGYzthoo7a2VlRUVIg5c+aIjRs3im+++UasWrVKfPXVV4F5Fi5cKHJycsRbb70lduzYIS6//HIxaNAgcfr06cA8F198sRg7dqzYsGGD+Oijj8TQoUPFjBkztNiljPHYY4+J/Px8sWLFCrFv3z7xxhtviOzsbPHUU08F5mFs0mflypXi/vvvF2+++aYAIJYvX676PBmxqK+vF8XFxWLmzJli586d4rXXXhM2m008//zz6drNXilabOrq6sTUqVPF66+/Lr744guxfv16MXHiRDFhwgTVOhib1Ojue+P35ptvirFjx4rS0lLxxz/+UfVZumLDJCkNJk6cKObOnRv4v9frFaWlpeKJJ57QsFR9z7FjxwQAsXbtWiFEx4nSZDKJN954IzDP7t27BQCxfv16IUTHl9lgMIiamprAPIsXLxZOp1O0tbWldwcyUGNjo6isrBSrV68W3//+9wNJEmOjnXvvvVdMnjw54uc+n0+UlJSI3/3ud4FpdXV1wmKxiNdee00IIcSuXbsEAPHJJ58E5nnnnXeEJEni0KFDqSt8hrv00kvFz3/+c9W0q6++WsycOVMIwdhoKbixl6xY/PnPfxa5ubmqc9q9994rhg0bluI9yhzRGuJ+mzZtEgDEgQMHhBCMTbpEis13330n+vfvL3bu3CkqKipUSVI6Y8Pb7VKsvb0dW7ZswdSpUwPTDAYDpk6divXr12tYsr6nvr4eAJCXlwcA2LJlC9xutyo2w4cPR3l5eSA269evx5gxY1BcXByYZ9q0aWhoaMDnn3+extJnprlz5+LSSy9VxQBgbLT09ttvo6qqCtdeey2Kioowfvx4/OUvfwl8vm/fPtTU1Khik5OTg0mTJqli43K5UFVVFZhn6tSpMBgM2LhxY/p2JsOcc845WLNmDb788ksAwI4dO7Bu3TpMnz4dAGOjJ8mKxfr163H++efDbDYH5pk2bRr27NmDU6dOpWlvMl99fT0kSYLL5QLA2GjJ5/Nh1qxZuPvuuzFq1KiQz9MZGyZJKXbixAl4vV5VQw4AiouLUVNTo1Gp+h6fz4f58+fj3HPPxejRowEANTU1MJvNgZOinzI2NTU1YWPn/4wSt2zZMmzduhVPPPFEyGeMjXa++eYbLF68GJWVlVi1ahVuu+023H777fj73/8OoKtuo53TampqUFRUpPpclmXk5eUxNj1w33334brrrsPw4cNhMpkwfvx4zJ8/HzNnzgTA2OhJsmLB81zqtba24t5778WMGTPgdDoBMDZa+s1vfgNZlnH77beH/TydsZHjKThRbzV37lzs3LkT69at07ooBODbb7/FHXfcgdWrV8NqtWpdHFLw+XyoqqrC448/DgAYP348du7cieeeew6zZ8/WuHR92z//+U+8+uqrWLp0KUaNGoXt27dj/vz5KC0tZWyIEuB2u/GTn/wEQggsXrxY6+L0eVu2bMFTTz2FrVu3QpIkrYvDnqRUKygogNFoDBmV6+jRoygpKdGoVH3LvHnzsGLFCnzwwQcYMGBAYHpJSQna29tRV1enml8Zm5KSkrCx839GidmyZQuOHTuGs846C7IsQ5ZlrF27Fn/6058gyzKKi4sZG43069cPI0eOVE0bMWIEDh48CKCrbqOd00pKSnDs2DHV5x6PB7W1tYxND9x9992B3qQxY8Zg1qxZ+PWvfx3ojWVs9CNZseB5LnX8CdKBAwewevXqQC8SwNho5aOPPsKxY8dQXl4eaBscOHAAd911FwYOHAggvbFhkpRiZrMZEyZMwJo1awLTfD4f1qxZg+rqag1LlvmEEJg3bx6WL1+O999/H4MGDVJ9PmHCBJhMJlVs9uzZg4MHDwZiU11djc8++0z1hfSfTIMbkhS7KVOm4LPPPsP27dsDf6qqqjBz5szAvxkbbZx77rkhQ+V/+eWXqKioAAAMGjQIJSUlqtg0NDRg48aNqtjU1dVhy5YtgXnef/99+Hw+TJo0KQ17kZlaWlpgMKh/to1GI3w+HwDGRk+SFYvq6mp8+OGHcLvdgXlWr16NYcOGITc3N017k3n8CdLevXvx3nvvIT8/X/U5Y6ONWbNm4dNPP1W1DUpLS3H33Xdj1apVANIcm7iGeaCELFu2TFgsFvHSSy+JXbt2iVtuuUW4XC7VqFyUfLfddpvIyckR//3vf8WRI0cCf1paWgLz3HrrraK8vFy8//77YvPmzaK6ulpUV1cHPvcPM33RRReJ7du3i3fffVcUFhZymOkUUI5uJwRjo5VNmzYJWZbFY489Jvbu3SteffVVYbfbxSuvvBKYZ+HChcLlcol///vf4tNPPxVXXHFF2KGNx48fLzZu3CjWrVsnKisrOcx0D82ePVv0798/MAT4m2++KQoKCsQ999wTmIexSZ/Gxkaxbds2sW3bNgFAPPnkk2Lbtm2BEdKSEYu6ujpRXFwsZs2aJXbu3CmWLVsm7HY7h5nuRrTYtLe3i8svv1wMGDBAbN++XdU+UI6GxtikRnffm2DBo9sJkb7YMElKk6efflqUl5cLs9ksJk6cKDZs2KB1kTIegLB/lixZEpjn9OnT4pe//KXIzc0VdrtdXHXVVeLIkSOq9ezfv19Mnz5d2Gw2UVBQIO666y7hdrvTvDeZLzhJYmy085///EeMHj1aWCwWMXz4cPHCCy+oPvf5fOKBBx4QxcXFwmKxiClTpog9e/ao5jl58qSYMWOGyM7OFk6nU9x4442isbExnbuRcRoaGsQdd9whysvLhdVqFYMHDxb333+/qmHH2KTPBx98EPY3Zvbs2UKI5MVix44dYvLkycJisYj+/fuLhQsXpmsXe61osdm3b1/E9sEHH3wQWAdjkxrdfW+ChUuS0hUbSQjFq7qJiIiIiIj6OD6TREREREREpMAkiYiIiIiISIFJEhERERERkQKTJCIiIiIiIgUmSURERERERApMkoiIiIiIiBSYJBERERERESkwSSIiIiIiIlJgkkRERL3W/v37IUkStm/fnrJtzJkzB1deeWXg/z/4wQ8wf/78lG2PiIi0xySJiIg0M2fOHEiSFPLn4osvjmn5srIyHDlyBKNHj05xSbu8+eabePTRR9O2PSIiSj9Z6wIQEVHfdvHFF2PJkiWqaRaLJaZljUYjSkpKUlGsiPLy8tK6PSIiSj/2JBERkaYsFgtKSkpUf3JzcwEAkiRh8eLFmD59Omw2GwYPHox//etfgWWDb7c7deoUZs6cicLCQthsNlRWVqoSsM8++wwXXHABbDYb8vPzccstt6CpqSnwudfrxZ133gmXy4X8/Hzcc889EEKoyht8u92pU6dwww03IDc3F3a7HdOnT8fevXtTUFNERJQuTJKIiEjXHnjgAVxzzTXYsWMHZs6cieuuuw67d++OOO+uXbvwzjvvYPfu3Vi8eDEKCgoAAM3NzZg2bRpyc3PxySef4I033sB7772HefPmBZb/wx/+gJdeegkvvvgi1q1bh9raWixfvjxq+ebMmYPNmzfj7bffxvr16yGEwCWXXAK32528SiAiorRikkRERJpasWIFsrOzVX8ef/zxwOfXXnstfvGLX+CMM87Ao48+iqqqKjz99NNh13Xw4EGMHz8eVVVVGDhwIKZOnYrLLrsMALB06VK0trbi5ZdfxujRo3HBBRfgmWeewT/+8Q8cPXoUALBo0SIsWLAAV199NUaMGIHnnnsOOTk5Ecu+d+9evP322/jrX/+K8847D2PHjsWrr76KQ4cO4a233kpeJRERUVrxmSQiItLUD3/4QyxevFg1TfncT3V1teqz6urqiKPZ3XbbbbjmmmuwdetWXHTRRbjyyitxzjnnAAB2796NsWPHIisrKzD/ueeeC5/Phz179sBqteLIkSOYNGlS4HNZllFVVRVyy53f7t27Icuyapn8/HwMGzYsYm8XERHpH5MkIiLSVFZWFoYOHZqUdU2fPh0HDhzAypUrsXr1akyZMgVz587F73//+6Ssn4iI+gbebkdERLq2YcOGkP+PGDEi4vyFhYWYPXs2XnnlFSxatAgvvPACAGDEiBHYsWMHmpubA/P+73//g8FgwLBhw5CTk4N+/fph48aNgc89Hg+2bNkScVsjRoyAx+NRLXPy5Ens2bMHI0eOjHtfiYhIH9iTREREmmpra0NNTY1qmizLgQEX3njjDVRVVWHy5Ml49dVXsWnTJvztb38Lu64HH3wQEyZMwKhRo9DW1oYVK1YEEqqZM2fioYcewuzZs/Hwww/j+PHj+NWvfoVZs2ahuLgYAHDHHXdg4cKFqKysxPDhw/Hkk0+irq4uYtkrKytxxRVX4Oabb8bzzz8Ph8OB++67D/3798cVV1yRhNohIiItsCeJiIg09e6776Jfv36qP5MnTw58/sgjj2DZsmU488wz8fLLL+O1116L2EtjNpuxYMECnHnmmTj//PNhNBqxbNkyAIDdbseqVatQW1uLs88+Gz/+8Y8xZcoUPPPMM4Hl77rrLsyaNQuzZ89GdXU1HA4HrrrqqqjlX7JkCSZMmIAf/ehHqK6uhhACK1euhMlkSkLtEBGRFiQR6WlUIiIijUmShOXLl+PKK6/UuihERNSHsCeJiIiIiIhIgUkSERERERGRAgduICIi3eId4UREpAX2JBERERERESkwSSIiIiIiIlJgkkRERERERKTAJImIiIiIiEiBSRIREREREZECkyQiIiIiIiIFJklEREREREQKTJKIiIiIiIgU/h+g8MarAvWk/AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Leer los logs guardados\n",
        "with open(log_filename) as f:\n",
        "    log_data = json.load(f)\n",
        "\n",
        "# Extraer rewards y episodios\n",
        "episode_rewards = log_data['episode_reward']\n",
        "episodes = list(range(1, len(episode_rewards) + 1))  # Episodios desde 1\n",
        "\n",
        "# (Opcional) Suavizar la curva con media móvil\n",
        "def moving_average(data, window_size=10):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "smoothed_rewards = moving_average(episode_rewards, window_size=10)\n",
        "\n",
        "# Graficar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(episodes, episode_rewards, alpha=0.3, label='Reward por episodio')\n",
        "plt.plot(episodes[:len(smoothed_rewards)], smoothed_rewards, color='red', label='Media móvil (10)')\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Reward')\n",
        "plt.title('Evolución del reward durante el entrenamiento')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7n7MJ-Pv1L6"
      },
      "source": [
        "¿Reducir learning_rate de 0.00025 a 0.0001 mejorará la recompensa promedio y reducirá el tiempo de entrenamiento? En las siguientes lineas de código pro la idea sería estudiar el impacto del learning rate. Cambiar a 0.0001 podría mejorar la estabilidad del aprendizaje, especialmente en entornos visuales como Atari (SpaceInvaders), donde:\n",
        "\n",
        "La señal de recompensa con un learning rate de 0.00025 puede ser ruidosa\n",
        "\n",
        "El agente necesita consolidar políticas más lentamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIrmHJGhyZWZ",
        "outputId": "ff51d129-0484-410c-8525-b9d11affe164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 1000000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    420/1000000: episode: 1, duration: 1.756s, episode steps: 420, steps per second: 239, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1131/1000000: episode: 2, duration: 2.788s, episode steps: 711, steps per second: 255, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1941/1000000: episode: 3, duration: 3.229s, episode steps: 810, steps per second: 251, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2809/1000000: episode: 4, duration: 3.582s, episode steps: 868, steps per second: 242, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3622/1000000: episode: 5, duration: 3.821s, episode steps: 813, steps per second: 213, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4418/1000000: episode: 6, duration: 3.370s, episode steps: 796, steps per second: 236, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5351/1000000: episode: 7, duration: 3.763s, episode steps: 933, steps per second: 248, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6180/1000000: episode: 8, duration: 3.422s, episode steps: 829, steps per second: 242, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6860/1000000: episode: 9, duration: 2.763s, episode steps: 680, steps per second: 246, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7412/1000000: episode: 10, duration: 2.255s, episode steps: 552, steps per second: 245, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8803/1000000: episode: 11, duration: 5.614s, episode steps: 1391, steps per second: 248, episode reward: 12.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9332/1000000: episode: 12, duration: 2.147s, episode steps: 529, steps per second: 246, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9799/1000000: episode: 13, duration: 1.892s, episode steps: 467, steps per second: 247, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10754/1000000: episode: 14, duration: 4.007s, episode steps: 955, steps per second: 238, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11344/1000000: episode: 15, duration: 2.372s, episode steps: 590, steps per second: 249, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11728/1000000: episode: 16, duration: 1.533s, episode steps: 384, steps per second: 250, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13075/1000000: episode: 17, duration: 5.401s, episode steps: 1347, steps per second: 249, episode reward: 13.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13648/1000000: episode: 18, duration: 2.428s, episode steps: 573, steps per second: 236, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14328/1000000: episode: 19, duration: 2.812s, episode steps: 680, steps per second: 242, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14918/1000000: episode: 20, duration: 2.464s, episode steps: 590, steps per second: 239, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15322/1000000: episode: 21, duration: 1.644s, episode steps: 404, steps per second: 246, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15947/1000000: episode: 22, duration: 2.582s, episode steps: 625, steps per second: 242, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17096/1000000: episode: 23, duration: 4.795s, episode steps: 1149, steps per second: 240, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18470/1000000: episode: 24, duration: 5.541s, episode steps: 1374, steps per second: 248, episode reward: 23.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19014/1000000: episode: 25, duration: 2.181s, episode steps: 544, steps per second: 249, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19718/1000000: episode: 26, duration: 2.881s, episode steps: 704, steps per second: 244, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20439/1000000: episode: 27, duration: 2.879s, episode steps: 721, steps per second: 250, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21225/1000000: episode: 28, duration: 3.125s, episode steps: 786, steps per second: 252, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22032/1000000: episode: 29, duration: 3.214s, episode steps: 807, steps per second: 251, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22843/1000000: episode: 30, duration: 3.404s, episode steps: 811, steps per second: 238, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23357/1000000: episode: 31, duration: 2.064s, episode steps: 514, steps per second: 249, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23933/1000000: episode: 32, duration: 2.315s, episode steps: 576, steps per second: 249, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24891/1000000: episode: 33, duration: 3.783s, episode steps: 958, steps per second: 253, episode reward:  7.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25417/1000000: episode: 34, duration: 2.218s, episode steps: 526, steps per second: 237, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26207/1000000: episode: 35, duration: 3.178s, episode steps: 790, steps per second: 249, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26809/1000000: episode: 36, duration: 2.394s, episode steps: 602, steps per second: 251, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27629/1000000: episode: 37, duration: 3.265s, episode steps: 820, steps per second: 251, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28511/1000000: episode: 38, duration: 3.604s, episode steps: 882, steps per second: 245, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29256/1000000: episode: 39, duration: 3.009s, episode steps: 745, steps per second: 248, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29932/1000000: episode: 40, duration: 2.690s, episode steps: 676, steps per second: 251, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30631/1000000: episode: 41, duration: 2.777s, episode steps: 699, steps per second: 252, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31517/1000000: episode: 42, duration: 3.630s, episode steps: 886, steps per second: 244, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32196/1000000: episode: 43, duration: 2.792s, episode steps: 679, steps per second: 243, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33026/1000000: episode: 44, duration: 3.264s, episode steps: 830, steps per second: 254, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33620/1000000: episode: 45, duration: 2.351s, episode steps: 594, steps per second: 253, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34765/1000000: episode: 46, duration: 4.635s, episode steps: 1145, steps per second: 247, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35721/1000000: episode: 47, duration: 3.794s, episode steps: 956, steps per second: 252, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36432/1000000: episode: 48, duration: 2.814s, episode steps: 711, steps per second: 253, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37165/1000000: episode: 49, duration: 2.933s, episode steps: 733, steps per second: 250, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37917/1000000: episode: 50, duration: 3.068s, episode steps: 752, steps per second: 245, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38558/1000000: episode: 51, duration: 2.609s, episode steps: 641, steps per second: 246, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39210/1000000: episode: 52, duration: 2.667s, episode steps: 652, steps per second: 244, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39835/1000000: episode: 53, duration: 2.483s, episode steps: 625, steps per second: 252, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40458/1000000: episode: 54, duration: 2.516s, episode steps: 623, steps per second: 248, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40852/1000000: episode: 55, duration: 1.622s, episode steps: 394, steps per second: 243, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41712/1000000: episode: 56, duration: 3.376s, episode steps: 860, steps per second: 255, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42232/1000000: episode: 57, duration: 2.064s, episode steps: 520, steps per second: 252, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42895/1000000: episode: 58, duration: 2.668s, episode steps: 663, steps per second: 249, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44064/1000000: episode: 59, duration: 4.857s, episode steps: 1169, steps per second: 241, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44705/1000000: episode: 60, duration: 2.637s, episode steps: 641, steps per second: 243, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45291/1000000: episode: 61, duration: 2.367s, episode steps: 586, steps per second: 248, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45824/1000000: episode: 62, duration: 2.161s, episode steps: 533, steps per second: 247, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46451/1000000: episode: 63, duration: 2.637s, episode steps: 627, steps per second: 238, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47051/1000000: episode: 64, duration: 2.595s, episode steps: 600, steps per second: 231, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47992/1000000: episode: 65, duration: 3.766s, episode steps: 941, steps per second: 250, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48599/1000000: episode: 66, duration: 2.502s, episode steps: 607, steps per second: 243, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49108/1000000: episode: 67, duration: 2.052s, episode steps: 509, steps per second: 248, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49771/1000000: episode: 68, duration: 2.722s, episode steps: 663, steps per second: 244, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  50339/1000000: episode: 69, duration: 11.267s, episode steps: 568, steps per second:  50, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.006348, mae: 0.046631, mean_q: 0.076942, mean_eps: 0.954847\n",
            "  51058/1000000: episode: 70, duration: 21.226s, episode steps: 719, steps per second:  34, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006464, mae: 0.047347, mean_q: 0.070326, mean_eps: 0.954372\n",
            "  51854/1000000: episode: 71, duration: 23.415s, episode steps: 796, steps per second:  34, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.006974, mae: 0.049637, mean_q: 0.071917, mean_eps: 0.953690\n",
            "  52443/1000000: episode: 72, duration: 17.187s, episode steps: 589, steps per second:  34, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.006759, mae: 0.049468, mean_q: 0.069238, mean_eps: 0.953067\n",
            "  53635/1000000: episode: 73, duration: 34.760s, episode steps: 1192, steps per second:  34, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.006796, mae: 0.049284, mean_q: 0.069610, mean_eps: 0.952266\n",
            "  54386/1000000: episode: 74, duration: 21.999s, episode steps: 751, steps per second:  34, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.007527, mae: 0.050740, mean_q: 0.070449, mean_eps: 0.951391\n",
            "  54949/1000000: episode: 75, duration: 16.548s, episode steps: 563, steps per second:  34, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.006564, mae: 0.050405, mean_q: 0.068116, mean_eps: 0.950799\n",
            "  55444/1000000: episode: 76, duration: 14.572s, episode steps: 495, steps per second:  34, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.005405, mae: 0.045432, mean_q: 0.061816, mean_eps: 0.950324\n",
            "  56569/1000000: episode: 77, duration: 33.143s, episode steps: 1125, steps per second:  34, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.005482, mae: 0.046491, mean_q: 0.062664, mean_eps: 0.949595\n",
            "  57100/1000000: episode: 78, duration: 15.583s, episode steps: 531, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.006115, mae: 0.048227, mean_q: 0.065557, mean_eps: 0.948849\n",
            "  57610/1000000: episode: 79, duration: 15.034s, episode steps: 510, steps per second:  34, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007653, mae: 0.050186, mean_q: 0.071577, mean_eps: 0.948381\n",
            "  58166/1000000: episode: 80, duration: 16.228s, episode steps: 556, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.006721, mae: 0.050477, mean_q: 0.067468, mean_eps: 0.947901\n",
            "  59033/1000000: episode: 81, duration: 25.506s, episode steps: 867, steps per second:  34, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.005487, mae: 0.047255, mean_q: 0.063284, mean_eps: 0.947260\n",
            "  59474/1000000: episode: 82, duration: 12.960s, episode steps: 441, steps per second:  34, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.005856, mae: 0.047330, mean_q: 0.064012, mean_eps: 0.946671\n",
            "  59871/1000000: episode: 83, duration: 11.613s, episode steps: 397, steps per second:  34, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.005150, mae: 0.044550, mean_q: 0.058384, mean_eps: 0.946295\n",
            "  60488/1000000: episode: 84, duration: 18.227s, episode steps: 617, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.006852, mae: 0.063895, mean_q: 0.083719, mean_eps: 0.945840\n",
            "  61152/1000000: episode: 85, duration: 19.626s, episode steps: 664, steps per second:  34, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.006439, mae: 0.068149, mean_q: 0.090680, mean_eps: 0.945264\n",
            "  61819/1000000: episode: 86, duration: 19.493s, episode steps: 667, steps per second:  34, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006748, mae: 0.067948, mean_q: 0.093217, mean_eps: 0.944664\n",
            "  62356/1000000: episode: 87, duration: 15.946s, episode steps: 537, steps per second:  34, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.007858, mae: 0.071386, mean_q: 0.094595, mean_eps: 0.944123\n",
            "  63150/1000000: episode: 88, duration: 23.484s, episode steps: 794, steps per second:  34, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.006219, mae: 0.067513, mean_q: 0.091767, mean_eps: 0.943523\n",
            "  64138/1000000: episode: 89, duration: 29.311s, episode steps: 988, steps per second:  34, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.007644, mae: 0.071040, mean_q: 0.096226, mean_eps: 0.942720\n",
            "  64560/1000000: episode: 90, duration: 12.478s, episode steps: 422, steps per second:  34, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.006192, mae: 0.067856, mean_q: 0.090988, mean_eps: 0.942087\n",
            "  65352/1000000: episode: 91, duration: 23.460s, episode steps: 792, steps per second:  34, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.005436, mae: 0.065879, mean_q: 0.088513, mean_eps: 0.941541\n",
            "  65835/1000000: episode: 92, duration: 14.285s, episode steps: 483, steps per second:  34, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.003715, mae: 0.061700, mean_q: 0.081963, mean_eps: 0.940967\n",
            "  66949/1000000: episode: 93, duration: 33.098s, episode steps: 1114, steps per second:  34, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006200, mae: 0.067984, mean_q: 0.091374, mean_eps: 0.940247\n",
            "  67715/1000000: episode: 94, duration: 22.523s, episode steps: 766, steps per second:  34, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.005247, mae: 0.065681, mean_q: 0.087477, mean_eps: 0.939401\n",
            "  68300/1000000: episode: 95, duration: 17.235s, episode steps: 585, steps per second:  34, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.006973, mae: 0.070399, mean_q: 0.093079, mean_eps: 0.938795\n",
            "  68940/1000000: episode: 96, duration: 18.809s, episode steps: 640, steps per second:  34, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.006390, mae: 0.067192, mean_q: 0.088927, mean_eps: 0.938244\n",
            "  69581/1000000: episode: 97, duration: 18.785s, episode steps: 641, steps per second:  34, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.006301, mae: 0.068526, mean_q: 0.091562, mean_eps: 0.937666\n",
            "  70357/1000000: episode: 98, duration: 22.872s, episode steps: 776, steps per second:  34, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006773, mae: 0.079225, mean_q: 0.104844, mean_eps: 0.937027\n",
            "  70852/1000000: episode: 99, duration: 14.573s, episode steps: 495, steps per second:  34, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.007382, mae: 0.092352, mean_q: 0.121783, mean_eps: 0.936456\n",
            "  71251/1000000: episode: 100, duration: 11.770s, episode steps: 399, steps per second:  34, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.007513, mae: 0.092316, mean_q: 0.125293, mean_eps: 0.936055\n",
            "  72021/1000000: episode: 101, duration: 22.674s, episode steps: 770, steps per second:  34, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.005491, mae: 0.090055, mean_q: 0.119884, mean_eps: 0.935528\n",
            "  72529/1000000: episode: 102, duration: 14.988s, episode steps: 508, steps per second:  34, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.006646, mae: 0.091836, mean_q: 0.123060, mean_eps: 0.934952\n",
            "  73138/1000000: episode: 103, duration: 17.990s, episode steps: 609, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.005367, mae: 0.087811, mean_q: 0.118348, mean_eps: 0.934449\n",
            "  73875/1000000: episode: 104, duration: 21.439s, episode steps: 737, steps per second:  34, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.006186, mae: 0.091404, mean_q: 0.118778, mean_eps: 0.933845\n",
            "  74729/1000000: episode: 105, duration: 25.162s, episode steps: 854, steps per second:  34, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.005402, mae: 0.088503, mean_q: 0.117410, mean_eps: 0.933128\n",
            "  75688/1000000: episode: 106, duration: 28.335s, episode steps: 959, steps per second:  34, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007102, mae: 0.092785, mean_q: 0.123430, mean_eps: 0.932313\n",
            "  76482/1000000: episode: 107, duration: 23.504s, episode steps: 794, steps per second:  34, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.007466, mae: 0.093447, mean_q: 0.122600, mean_eps: 0.931524\n",
            "  77017/1000000: episode: 108, duration: 15.943s, episode steps: 535, steps per second:  34, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006178, mae: 0.090875, mean_q: 0.120716, mean_eps: 0.930925\n",
            "  77507/1000000: episode: 109, duration: 14.418s, episode steps: 490, steps per second:  34, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.006707, mae: 0.090751, mean_q: 0.118931, mean_eps: 0.930464\n",
            "  78052/1000000: episode: 110, duration: 16.197s, episode steps: 545, steps per second:  34, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.005989, mae: 0.089749, mean_q: 0.118437, mean_eps: 0.930000\n",
            "  78655/1000000: episode: 111, duration: 17.670s, episode steps: 603, steps per second:  34, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.007122, mae: 0.092107, mean_q: 0.121722, mean_eps: 0.929483\n",
            "  79058/1000000: episode: 112, duration: 11.900s, episode steps: 403, steps per second:  34, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.006820, mae: 0.092287, mean_q: 0.121751, mean_eps: 0.929030\n",
            "  79793/1000000: episode: 113, duration: 21.606s, episode steps: 735, steps per second:  34, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.006537, mae: 0.091815, mean_q: 0.121120, mean_eps: 0.928517\n",
            "  80306/1000000: episode: 114, duration: 14.923s, episode steps: 513, steps per second:  34, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.006953, mae: 0.105690, mean_q: 0.138891, mean_eps: 0.927955\n",
            "  80825/1000000: episode: 115, duration: 15.203s, episode steps: 519, steps per second:  34, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.005916, mae: 0.116085, mean_q: 0.153473, mean_eps: 0.927491\n",
            "  81371/1000000: episode: 116, duration: 16.074s, episode steps: 546, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.006721, mae: 0.116628, mean_q: 0.153619, mean_eps: 0.927012\n",
            "  82291/1000000: episode: 117, duration: 26.984s, episode steps: 920, steps per second:  34, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.007355, mae: 0.119996, mean_q: 0.156794, mean_eps: 0.926353\n",
            "  83267/1000000: episode: 118, duration: 29.016s, episode steps: 976, steps per second:  34, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.005234, mae: 0.114236, mean_q: 0.150782, mean_eps: 0.925500\n",
            "  83779/1000000: episode: 119, duration: 15.239s, episode steps: 512, steps per second:  34, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.005354, mae: 0.115364, mean_q: 0.152734, mean_eps: 0.924830\n",
            "  84466/1000000: episode: 120, duration: 20.456s, episode steps: 687, steps per second:  34, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.007617, mae: 0.118819, mean_q: 0.154379, mean_eps: 0.924290\n",
            "  85089/1000000: episode: 121, duration: 18.810s, episode steps: 623, steps per second:  33, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.007021, mae: 0.118731, mean_q: 0.155048, mean_eps: 0.923700\n",
            "  85848/1000000: episode: 122, duration: 22.401s, episode steps: 759, steps per second:  34, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006896, mae: 0.117774, mean_q: 0.155648, mean_eps: 0.923079\n",
            "  86686/1000000: episode: 123, duration: 24.633s, episode steps: 838, steps per second:  34, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.006053, mae: 0.115796, mean_q: 0.151779, mean_eps: 0.922361\n",
            "  87488/1000000: episode: 124, duration: 23.676s, episode steps: 802, steps per second:  34, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.006132, mae: 0.116444, mean_q: 0.152391, mean_eps: 0.921623\n",
            "  88168/1000000: episode: 125, duration: 20.213s, episode steps: 680, steps per second:  34, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.006786, mae: 0.118795, mean_q: 0.155312, mean_eps: 0.920957\n",
            "  88667/1000000: episode: 126, duration: 14.674s, episode steps: 499, steps per second:  34, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.007456, mae: 0.120093, mean_q: 0.155370, mean_eps: 0.920426\n",
            "  90024/1000000: episode: 127, duration: 40.017s, episode steps: 1357, steps per second:  34, episode reward: 22.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.005753, mae: 0.115559, mean_q: 0.152334, mean_eps: 0.919590\n",
            "  90661/1000000: episode: 128, duration: 18.797s, episode steps: 637, steps per second:  34, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.008658, mae: 0.140728, mean_q: 0.182891, mean_eps: 0.918692\n",
            "  91200/1000000: episode: 129, duration: 16.086s, episode steps: 539, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.709 [0.000, 5.000],  loss: 0.007187, mae: 0.140115, mean_q: 0.184944, mean_eps: 0.918163\n",
            "  91807/1000000: episode: 130, duration: 17.969s, episode steps: 607, steps per second:  34, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.006590, mae: 0.138285, mean_q: 0.181408, mean_eps: 0.917648\n",
            "  92209/1000000: episode: 131, duration: 11.987s, episode steps: 402, steps per second:  34, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.006263, mae: 0.138382, mean_q: 0.180523, mean_eps: 0.917193\n",
            "  92790/1000000: episode: 132, duration: 16.978s, episode steps: 581, steps per second:  34, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.006572, mae: 0.137085, mean_q: 0.178285, mean_eps: 0.916750\n",
            "  93988/1000000: episode: 133, duration: 35.160s, episode steps: 1198, steps per second:  34, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.004787, mae: 0.134433, mean_q: 0.173120, mean_eps: 0.915951\n",
            "  94825/1000000: episode: 134, duration: 24.684s, episode steps: 837, steps per second:  34, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.007023, mae: 0.138424, mean_q: 0.178631, mean_eps: 0.915035\n",
            "  95429/1000000: episode: 135, duration: 17.912s, episode steps: 604, steps per second:  34, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.007863, mae: 0.140705, mean_q: 0.181669, mean_eps: 0.914385\n",
            "  96019/1000000: episode: 136, duration: 17.286s, episode steps: 590, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.007141, mae: 0.140311, mean_q: 0.181612, mean_eps: 0.913848\n",
            "  96463/1000000: episode: 137, duration: 12.977s, episode steps: 444, steps per second:  34, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.006073, mae: 0.136999, mean_q: 0.178792, mean_eps: 0.913384\n",
            "  96920/1000000: episode: 138, duration: 13.343s, episode steps: 457, steps per second:  34, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.007554, mae: 0.142554, mean_q: 0.184680, mean_eps: 0.912979\n",
            "  97524/1000000: episode: 139, duration: 17.804s, episode steps: 604, steps per second:  34, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.704 [0.000, 5.000],  loss: 0.006768, mae: 0.139384, mean_q: 0.180235, mean_eps: 0.912502\n",
            "  98255/1000000: episode: 140, duration: 21.729s, episode steps: 731, steps per second:  34, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007190, mae: 0.139819, mean_q: 0.181289, mean_eps: 0.911901\n",
            "  98724/1000000: episode: 141, duration: 13.773s, episode steps: 469, steps per second:  34, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006495, mae: 0.137177, mean_q: 0.179139, mean_eps: 0.911361\n",
            "  99242/1000000: episode: 142, duration: 15.271s, episode steps: 518, steps per second:  34, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.005081, mae: 0.133787, mean_q: 0.174455, mean_eps: 0.910916\n",
            " 100195/1000000: episode: 143, duration: 27.824s, episode steps: 953, steps per second:  34, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.005877, mae: 0.140983, mean_q: 0.183497, mean_eps: 0.910254\n",
            " 100862/1000000: episode: 144, duration: 19.498s, episode steps: 667, steps per second:  34, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.006594, mae: 0.163159, mean_q: 0.211698, mean_eps: 0.909525\n",
            " 101556/1000000: episode: 145, duration: 20.444s, episode steps: 694, steps per second:  34, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.006888, mae: 0.165543, mean_q: 0.213864, mean_eps: 0.908913\n",
            " 102206/1000000: episode: 146, duration: 19.136s, episode steps: 650, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.007087, mae: 0.166453, mean_q: 0.213623, mean_eps: 0.908308\n",
            " 102861/1000000: episode: 147, duration: 19.265s, episode steps: 655, steps per second:  34, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.007058, mae: 0.165337, mean_q: 0.213078, mean_eps: 0.907719\n",
            " 103534/1000000: episode: 148, duration: 19.716s, episode steps: 673, steps per second:  34, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.006624, mae: 0.164168, mean_q: 0.213564, mean_eps: 0.907122\n",
            " 104050/1000000: episode: 149, duration: 15.148s, episode steps: 516, steps per second:  34, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.312 [0.000, 5.000],  loss: 0.006997, mae: 0.167240, mean_q: 0.217390, mean_eps: 0.906587\n",
            " 104728/1000000: episode: 150, duration: 19.885s, episode steps: 678, steps per second:  34, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.006644, mae: 0.166387, mean_q: 0.214688, mean_eps: 0.906051\n",
            " 105507/1000000: episode: 151, duration: 22.990s, episode steps: 779, steps per second:  34, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.005701, mae: 0.160298, mean_q: 0.206960, mean_eps: 0.905396\n",
            " 106551/1000000: episode: 152, duration: 31.068s, episode steps: 1044, steps per second:  34, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.006813, mae: 0.164639, mean_q: 0.212527, mean_eps: 0.904575\n",
            " 107533/1000000: episode: 153, duration: 29.181s, episode steps: 982, steps per second:  34, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.005666, mae: 0.163743, mean_q: 0.210936, mean_eps: 0.903662\n",
            " 107927/1000000: episode: 154, duration: 11.843s, episode steps: 394, steps per second:  33, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.007054, mae: 0.166044, mean_q: 0.212569, mean_eps: 0.903043\n",
            " 108550/1000000: episode: 155, duration: 18.866s, episode steps: 623, steps per second:  33, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.007131, mae: 0.166158, mean_q: 0.213253, mean_eps: 0.902586\n",
            " 109302/1000000: episode: 156, duration: 22.711s, episode steps: 752, steps per second:  33, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.006625, mae: 0.165041, mean_q: 0.212572, mean_eps: 0.901967\n",
            " 110134/1000000: episode: 157, duration: 25.346s, episode steps: 832, steps per second:  33, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.006668, mae: 0.168083, mean_q: 0.215827, mean_eps: 0.901254\n",
            " 110815/1000000: episode: 158, duration: 20.475s, episode steps: 681, steps per second:  33, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007126, mae: 0.190540, mean_q: 0.244652, mean_eps: 0.900573\n",
            " 111219/1000000: episode: 159, duration: 12.121s, episode steps: 404, steps per second:  33, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.005050, mae: 0.183695, mean_q: 0.237381, mean_eps: 0.900086\n",
            " 111713/1000000: episode: 160, duration: 14.995s, episode steps: 494, steps per second:  33, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.006637, mae: 0.190138, mean_q: 0.242519, mean_eps: 0.899681\n",
            " 112104/1000000: episode: 161, duration: 11.840s, episode steps: 391, steps per second:  33, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.006296, mae: 0.188029, mean_q: 0.241903, mean_eps: 0.899283\n",
            " 112788/1000000: episode: 162, duration: 20.726s, episode steps: 684, steps per second:  33, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006998, mae: 0.189113, mean_q: 0.243917, mean_eps: 0.898800\n",
            " 113271/1000000: episode: 163, duration: 14.702s, episode steps: 483, steps per second:  33, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.006602, mae: 0.188262, mean_q: 0.241516, mean_eps: 0.898275\n",
            " 113642/1000000: episode: 164, duration: 11.642s, episode steps: 371, steps per second:  32, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.005923, mae: 0.185195, mean_q: 0.237494, mean_eps: 0.897890\n",
            " 114209/1000000: episode: 165, duration: 17.773s, episode steps: 567, steps per second:  32, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.007643, mae: 0.192253, mean_q: 0.245400, mean_eps: 0.897467\n",
            " 115094/1000000: episode: 166, duration: 26.950s, episode steps: 885, steps per second:  33, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.006033, mae: 0.186804, mean_q: 0.238791, mean_eps: 0.896813\n",
            " 115731/1000000: episode: 167, duration: 19.625s, episode steps: 637, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.005782, mae: 0.185156, mean_q: 0.236676, mean_eps: 0.896129\n",
            " 116338/1000000: episode: 168, duration: 18.574s, episode steps: 607, steps per second:  33, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.007346, mae: 0.188962, mean_q: 0.240259, mean_eps: 0.895569\n",
            " 116695/1000000: episode: 169, duration: 10.999s, episode steps: 357, steps per second:  32, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.009192, mae: 0.195512, mean_q: 0.250453, mean_eps: 0.895136\n",
            " 117179/1000000: episode: 170, duration: 14.720s, episode steps: 484, steps per second:  33, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.005625, mae: 0.186856, mean_q: 0.238154, mean_eps: 0.894758\n",
            " 117600/1000000: episode: 171, duration: 12.855s, episode steps: 421, steps per second:  33, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.006472, mae: 0.188911, mean_q: 0.240432, mean_eps: 0.894351\n",
            " 118027/1000000: episode: 172, duration: 12.876s, episode steps: 427, steps per second:  33, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.004996, mae: 0.184844, mean_q: 0.238993, mean_eps: 0.893969\n",
            " 118726/1000000: episode: 173, duration: 21.064s, episode steps: 699, steps per second:  33, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.007065, mae: 0.190503, mean_q: 0.244037, mean_eps: 0.893462\n",
            " 119713/1000000: episode: 174, duration: 29.928s, episode steps: 987, steps per second:  33, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.006490, mae: 0.189671, mean_q: 0.244477, mean_eps: 0.892702\n",
            " 120616/1000000: episode: 175, duration: 27.613s, episode steps: 903, steps per second:  33, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.006469, mae: 0.211323, mean_q: 0.270577, mean_eps: 0.891852\n",
            " 121405/1000000: episode: 176, duration: 23.849s, episode steps: 789, steps per second:  33, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.007046, mae: 0.221245, mean_q: 0.282660, mean_eps: 0.891091\n",
            " 122053/1000000: episode: 177, duration: 19.681s, episode steps: 648, steps per second:  33, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006376, mae: 0.223537, mean_q: 0.285977, mean_eps: 0.890443\n",
            " 122661/1000000: episode: 178, duration: 18.427s, episode steps: 608, steps per second:  33, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.006870, mae: 0.222807, mean_q: 0.283824, mean_eps: 0.889878\n",
            " 123052/1000000: episode: 179, duration: 11.776s, episode steps: 391, steps per second:  33, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.005809, mae: 0.220680, mean_q: 0.282726, mean_eps: 0.889430\n",
            " 123698/1000000: episode: 180, duration: 19.700s, episode steps: 646, steps per second:  33, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.006826, mae: 0.220827, mean_q: 0.283310, mean_eps: 0.888963\n",
            " 124594/1000000: episode: 181, duration: 26.911s, episode steps: 896, steps per second:  33, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.006935, mae: 0.223917, mean_q: 0.288461, mean_eps: 0.888269\n",
            " 124981/1000000: episode: 182, duration: 11.614s, episode steps: 387, steps per second:  33, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.006397, mae: 0.219514, mean_q: 0.281370, mean_eps: 0.887691\n",
            " 126488/1000000: episode: 183, duration: 44.955s, episode steps: 1507, steps per second:  34, episode reward: 19.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.007145, mae: 0.221811, mean_q: 0.284161, mean_eps: 0.886839\n",
            " 127374/1000000: episode: 184, duration: 26.660s, episode steps: 886, steps per second:  33, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.006585, mae: 0.222315, mean_q: 0.283466, mean_eps: 0.885763\n",
            " 127853/1000000: episode: 185, duration: 14.396s, episode steps: 479, steps per second:  33, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.006022, mae: 0.220629, mean_q: 0.282323, mean_eps: 0.885147\n",
            " 128461/1000000: episode: 186, duration: 18.083s, episode steps: 608, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.005850, mae: 0.218547, mean_q: 0.279121, mean_eps: 0.884658\n",
            " 129109/1000000: episode: 187, duration: 19.676s, episode steps: 648, steps per second:  33, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.006746, mae: 0.222465, mean_q: 0.283035, mean_eps: 0.884093\n",
            " 129504/1000000: episode: 188, duration: 11.983s, episode steps: 395, steps per second:  33, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.007174, mae: 0.220969, mean_q: 0.282361, mean_eps: 0.883625\n",
            " 130268/1000000: episode: 189, duration: 23.057s, episode steps: 764, steps per second:  33, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.007121, mae: 0.234334, mean_q: 0.297273, mean_eps: 0.883104\n",
            " 130806/1000000: episode: 190, duration: 16.234s, episode steps: 538, steps per second:  33, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.007665, mae: 0.255188, mean_q: 0.322733, mean_eps: 0.882518\n",
            " 131341/1000000: episode: 191, duration: 15.947s, episode steps: 535, steps per second:  34, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.007479, mae: 0.256461, mean_q: 0.325706, mean_eps: 0.882033\n",
            " 131730/1000000: episode: 192, duration: 11.757s, episode steps: 389, steps per second:  33, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.008093, mae: 0.259499, mean_q: 0.331239, mean_eps: 0.881618\n",
            " 132340/1000000: episode: 193, duration: 18.391s, episode steps: 610, steps per second:  33, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.007227, mae: 0.253283, mean_q: 0.322583, mean_eps: 0.881169\n",
            " 132849/1000000: episode: 194, duration: 15.389s, episode steps: 509, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.007201, mae: 0.252751, mean_q: 0.321469, mean_eps: 0.880665\n",
            " 133796/1000000: episode: 195, duration: 28.466s, episode steps: 947, steps per second:  33, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.005967, mae: 0.251933, mean_q: 0.318813, mean_eps: 0.880010\n",
            " 134414/1000000: episode: 196, duration: 18.701s, episode steps: 618, steps per second:  33, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.007652, mae: 0.257638, mean_q: 0.325153, mean_eps: 0.879306\n",
            " 135740/1000000: episode: 197, duration: 39.814s, episode steps: 1326, steps per second:  33, episode reward: 26.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.006336, mae: 0.255211, mean_q: 0.323263, mean_eps: 0.878432\n",
            " 136318/1000000: episode: 198, duration: 17.556s, episode steps: 578, steps per second:  33, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.005953, mae: 0.253944, mean_q: 0.318968, mean_eps: 0.877575\n",
            " 137115/1000000: episode: 199, duration: 23.986s, episode steps: 797, steps per second:  33, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006902, mae: 0.255961, mean_q: 0.323934, mean_eps: 0.876956\n",
            " 137621/1000000: episode: 200, duration: 15.254s, episode steps: 506, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.005801, mae: 0.253693, mean_q: 0.321866, mean_eps: 0.876369\n",
            " 138331/1000000: episode: 201, duration: 21.420s, episode steps: 710, steps per second:  33, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.006296, mae: 0.251896, mean_q: 0.317156, mean_eps: 0.875822\n",
            " 138836/1000000: episode: 202, duration: 15.328s, episode steps: 505, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.005182, mae: 0.247194, mean_q: 0.312109, mean_eps: 0.875276\n",
            " 139169/1000000: episode: 203, duration: 10.196s, episode steps: 333, steps per second:  33, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.006034, mae: 0.256523, mean_q: 0.324658, mean_eps: 0.874898\n",
            " 139851/1000000: episode: 204, duration: 20.544s, episode steps: 682, steps per second:  33, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006162, mae: 0.254704, mean_q: 0.323291, mean_eps: 0.874441\n",
            " 140611/1000000: episode: 205, duration: 22.999s, episode steps: 760, steps per second:  33, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007133, mae: 0.274958, mean_q: 0.348191, mean_eps: 0.873793\n",
            " 141322/1000000: episode: 206, duration: 21.335s, episode steps: 711, steps per second:  33, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.007013, mae: 0.279353, mean_q: 0.352932, mean_eps: 0.873131\n",
            " 142238/1000000: episode: 207, duration: 27.308s, episode steps: 916, steps per second:  34, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.006468, mae: 0.278919, mean_q: 0.353083, mean_eps: 0.872398\n",
            " 142926/1000000: episode: 208, duration: 20.578s, episode steps: 688, steps per second:  33, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.006937, mae: 0.275735, mean_q: 0.349057, mean_eps: 0.871676\n",
            " 143351/1000000: episode: 209, duration: 12.857s, episode steps: 425, steps per second:  33, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.008844, mae: 0.289990, mean_q: 0.363053, mean_eps: 0.871176\n",
            " 144107/1000000: episode: 210, duration: 22.847s, episode steps: 756, steps per second:  33, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.006641, mae: 0.277354, mean_q: 0.349691, mean_eps: 0.870645\n",
            " 144617/1000000: episode: 211, duration: 15.271s, episode steps: 510, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.007312, mae: 0.278469, mean_q: 0.353357, mean_eps: 0.870074\n",
            " 145447/1000000: episode: 212, duration: 25.110s, episode steps: 830, steps per second:  33, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.005969, mae: 0.277037, mean_q: 0.352160, mean_eps: 0.869471\n",
            " 146035/1000000: episode: 213, duration: 17.835s, episode steps: 588, steps per second:  33, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.007713, mae: 0.279233, mean_q: 0.351505, mean_eps: 0.868834\n",
            " 146889/1000000: episode: 214, duration: 25.703s, episode steps: 854, steps per second:  33, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.007408, mae: 0.280445, mean_q: 0.354703, mean_eps: 0.868184\n",
            " 147712/1000000: episode: 215, duration: 24.768s, episode steps: 823, steps per second:  33, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007812, mae: 0.282576, mean_q: 0.356890, mean_eps: 0.867430\n",
            " 148324/1000000: episode: 216, duration: 18.660s, episode steps: 612, steps per second:  33, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.006979, mae: 0.282464, mean_q: 0.356856, mean_eps: 0.866786\n",
            " 148805/1000000: episode: 217, duration: 14.700s, episode steps: 481, steps per second:  33, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.006526, mae: 0.278882, mean_q: 0.352478, mean_eps: 0.866292\n",
            " 149602/1000000: episode: 218, duration: 23.971s, episode steps: 797, steps per second:  33, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.005997, mae: 0.277383, mean_q: 0.349564, mean_eps: 0.865716\n",
            " 150200/1000000: episode: 219, duration: 18.056s, episode steps: 598, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.007694, mae: 0.293832, mean_q: 0.372289, mean_eps: 0.865090\n",
            " 150871/1000000: episode: 220, duration: 20.140s, episode steps: 671, steps per second:  33, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.006218, mae: 0.315874, mean_q: 0.401626, mean_eps: 0.864519\n",
            " 151771/1000000: episode: 221, duration: 26.737s, episode steps: 900, steps per second:  34, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.006670, mae: 0.313059, mean_q: 0.393779, mean_eps: 0.863812\n",
            " 152922/1000000: episode: 222, duration: 34.171s, episode steps: 1151, steps per second:  34, episode reward: 25.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.006976, mae: 0.317028, mean_q: 0.398394, mean_eps: 0.862889\n",
            " 153614/1000000: episode: 223, duration: 20.601s, episode steps: 692, steps per second:  34, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.006617, mae: 0.318969, mean_q: 0.399447, mean_eps: 0.862059\n",
            " 154205/1000000: episode: 224, duration: 17.814s, episode steps: 591, steps per second:  33, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.007825, mae: 0.317958, mean_q: 0.398102, mean_eps: 0.861481\n",
            " 154872/1000000: episode: 225, duration: 19.917s, episode steps: 667, steps per second:  33, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.007536, mae: 0.317389, mean_q: 0.397908, mean_eps: 0.860916\n",
            " 155622/1000000: episode: 226, duration: 22.674s, episode steps: 750, steps per second:  33, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006150, mae: 0.314748, mean_q: 0.394707, mean_eps: 0.860279\n",
            " 156009/1000000: episode: 227, duration: 11.731s, episode steps: 387, steps per second:  33, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.006364, mae: 0.318430, mean_q: 0.398625, mean_eps: 0.859766\n",
            " 157052/1000000: episode: 228, duration: 31.185s, episode steps: 1043, steps per second:  33, episode reward:  7.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.006862, mae: 0.319348, mean_q: 0.401193, mean_eps: 0.859123\n",
            " 157688/1000000: episode: 229, duration: 19.192s, episode steps: 636, steps per second:  33, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.008028, mae: 0.323654, mean_q: 0.405518, mean_eps: 0.858369\n",
            " 158068/1000000: episode: 230, duration: 11.623s, episode steps: 380, steps per second:  33, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.703 [0.000, 5.000],  loss: 0.005961, mae: 0.314676, mean_q: 0.395245, mean_eps: 0.857912\n",
            " 158746/1000000: episode: 231, duration: 20.445s, episode steps: 678, steps per second:  33, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.005549, mae: 0.315537, mean_q: 0.395190, mean_eps: 0.857435\n",
            " 159363/1000000: episode: 232, duration: 18.624s, episode steps: 617, steps per second:  33, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.007359, mae: 0.321921, mean_q: 0.403745, mean_eps: 0.856851\n",
            " 159993/1000000: episode: 233, duration: 19.332s, episode steps: 630, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.006392, mae: 0.312942, mean_q: 0.393826, mean_eps: 0.856290\n",
            " 160669/1000000: episode: 234, duration: 20.524s, episode steps: 676, steps per second:  33, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006713, mae: 0.329624, mean_q: 0.414231, mean_eps: 0.855701\n",
            " 161223/1000000: episode: 235, duration: 16.652s, episode steps: 554, steps per second:  33, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.007723, mae: 0.335249, mean_q: 0.421130, mean_eps: 0.855149\n",
            " 161690/1000000: episode: 236, duration: 14.123s, episode steps: 467, steps per second:  33, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.007538, mae: 0.327922, mean_q: 0.411439, mean_eps: 0.854690\n",
            " 162052/1000000: episode: 237, duration: 11.020s, episode steps: 362, steps per second:  33, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.007155, mae: 0.329535, mean_q: 0.414618, mean_eps: 0.854317\n",
            " 162856/1000000: episode: 238, duration: 24.345s, episode steps: 804, steps per second:  33, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.007313, mae: 0.332106, mean_q: 0.417582, mean_eps: 0.853793\n",
            " 163665/1000000: episode: 239, duration: 24.655s, episode steps: 809, steps per second:  33, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.007004, mae: 0.329363, mean_q: 0.411808, mean_eps: 0.853066\n",
            " 164317/1000000: episode: 240, duration: 19.730s, episode steps: 652, steps per second:  33, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.007068, mae: 0.331743, mean_q: 0.415851, mean_eps: 0.852407\n",
            " 164756/1000000: episode: 241, duration: 13.276s, episode steps: 439, steps per second:  33, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.006834, mae: 0.325957, mean_q: 0.407076, mean_eps: 0.851918\n",
            " 165319/1000000: episode: 242, duration: 17.014s, episode steps: 563, steps per second:  33, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006664, mae: 0.327831, mean_q: 0.410391, mean_eps: 0.851468\n",
            " 166354/1000000: episode: 243, duration: 31.372s, episode steps: 1035, steps per second:  33, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006407, mae: 0.329004, mean_q: 0.411223, mean_eps: 0.850748\n",
            " 167010/1000000: episode: 244, duration: 19.910s, episode steps: 656, steps per second:  33, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.007368, mae: 0.329155, mean_q: 0.413369, mean_eps: 0.849986\n",
            " 167707/1000000: episode: 245, duration: 20.910s, episode steps: 697, steps per second:  33, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.006431, mae: 0.327596, mean_q: 0.411362, mean_eps: 0.849378\n",
            " 168338/1000000: episode: 246, duration: 19.299s, episode steps: 631, steps per second:  33, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.006623, mae: 0.331069, mean_q: 0.414237, mean_eps: 0.848780\n",
            " 169113/1000000: episode: 247, duration: 23.686s, episode steps: 775, steps per second:  33, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006981, mae: 0.327860, mean_q: 0.410290, mean_eps: 0.848147\n",
            " 169511/1000000: episode: 248, duration: 12.034s, episode steps: 398, steps per second:  33, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007033, mae: 0.336570, mean_q: 0.421572, mean_eps: 0.847619\n",
            " 170156/1000000: episode: 249, duration: 19.797s, episode steps: 645, steps per second:  33, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.006141, mae: 0.335478, mean_q: 0.419107, mean_eps: 0.847151\n",
            " 170524/1000000: episode: 250, duration: 11.347s, episode steps: 368, steps per second:  32, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.007420, mae: 0.363389, mean_q: 0.454330, mean_eps: 0.846696\n",
            " 171328/1000000: episode: 251, duration: 24.392s, episode steps: 804, steps per second:  33, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.008494, mae: 0.364600, mean_q: 0.455592, mean_eps: 0.846168\n",
            " 171832/1000000: episode: 252, duration: 15.471s, episode steps: 504, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.007350, mae: 0.366396, mean_q: 0.456964, mean_eps: 0.845580\n",
            " 172921/1000000: episode: 253, duration: 32.991s, episode steps: 1089, steps per second:  33, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.006848, mae: 0.362814, mean_q: 0.452857, mean_eps: 0.844862\n",
            " 174055/1000000: episode: 254, duration: 34.520s, episode steps: 1134, steps per second:  33, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.007753, mae: 0.364310, mean_q: 0.455255, mean_eps: 0.843861\n",
            " 174793/1000000: episode: 255, duration: 22.412s, episode steps: 738, steps per second:  33, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.007351, mae: 0.365967, mean_q: 0.456324, mean_eps: 0.843018\n",
            " 175489/1000000: episode: 256, duration: 21.065s, episode steps: 696, steps per second:  33, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.007566, mae: 0.362435, mean_q: 0.451717, mean_eps: 0.842372\n",
            " 176232/1000000: episode: 257, duration: 22.327s, episode steps: 743, steps per second:  33, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.007967, mae: 0.367168, mean_q: 0.457416, mean_eps: 0.841726\n",
            " 176972/1000000: episode: 258, duration: 22.434s, episode steps: 740, steps per second:  33, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.006285, mae: 0.359354, mean_q: 0.448443, mean_eps: 0.841060\n",
            " 178037/1000000: episode: 259, duration: 32.136s, episode steps: 1065, steps per second:  33, episode reward:  9.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.007054, mae: 0.363642, mean_q: 0.453360, mean_eps: 0.840246\n",
            " 178719/1000000: episode: 260, duration: 20.387s, episode steps: 682, steps per second:  33, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.007769, mae: 0.368809, mean_q: 0.460649, mean_eps: 0.839460\n",
            " 179249/1000000: episode: 261, duration: 15.937s, episode steps: 530, steps per second:  33, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.006253, mae: 0.360063, mean_q: 0.450241, mean_eps: 0.838914\n",
            " 179861/1000000: episode: 262, duration: 18.730s, episode steps: 612, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.006780, mae: 0.356738, mean_q: 0.444336, mean_eps: 0.838400\n",
            " 181067/1000000: episode: 263, duration: 36.866s, episode steps: 1206, steps per second:  33, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.007850, mae: 0.383136, mean_q: 0.477404, mean_eps: 0.837582\n",
            " 181593/1000000: episode: 264, duration: 16.127s, episode steps: 526, steps per second:  33, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.006085, mae: 0.381614, mean_q: 0.476245, mean_eps: 0.836803\n",
            " 182003/1000000: episode: 265, duration: 12.662s, episode steps: 410, steps per second:  32, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.007128, mae: 0.388041, mean_q: 0.483985, mean_eps: 0.836382\n",
            " 182463/1000000: episode: 266, duration: 14.115s, episode steps: 460, steps per second:  33, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: 0.006499, mae: 0.381287, mean_q: 0.475039, mean_eps: 0.835991\n",
            " 183118/1000000: episode: 267, duration: 20.127s, episode steps: 655, steps per second:  33, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.007823, mae: 0.387278, mean_q: 0.483908, mean_eps: 0.835489\n",
            " 183850/1000000: episode: 268, duration: 22.261s, episode steps: 732, steps per second:  33, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.007377, mae: 0.385033, mean_q: 0.480147, mean_eps: 0.834864\n",
            " 184516/1000000: episode: 269, duration: 20.045s, episode steps: 666, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.006678, mae: 0.383302, mean_q: 0.476693, mean_eps: 0.834236\n",
            " 184920/1000000: episode: 270, duration: 12.387s, episode steps: 404, steps per second:  33, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006138, mae: 0.386844, mean_q: 0.482290, mean_eps: 0.833756\n",
            " 185588/1000000: episode: 271, duration: 20.607s, episode steps: 668, steps per second:  32, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.006965, mae: 0.386953, mean_q: 0.481461, mean_eps: 0.833273\n",
            " 186246/1000000: episode: 272, duration: 20.202s, episode steps: 658, steps per second:  33, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.008314, mae: 0.390140, mean_q: 0.485101, mean_eps: 0.832676\n",
            " 186935/1000000: episode: 273, duration: 20.888s, episode steps: 689, steps per second:  33, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.006368, mae: 0.387976, mean_q: 0.483398, mean_eps: 0.832069\n",
            " 187289/1000000: episode: 274, duration: 10.821s, episode steps: 354, steps per second:  33, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007375, mae: 0.383543, mean_q: 0.476695, mean_eps: 0.831599\n",
            " 187931/1000000: episode: 275, duration: 19.483s, episode steps: 642, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.008705, mae: 0.388808, mean_q: 0.484055, mean_eps: 0.831151\n",
            " 188590/1000000: episode: 276, duration: 20.082s, episode steps: 659, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.007490, mae: 0.387471, mean_q: 0.482247, mean_eps: 0.830566\n",
            " 189634/1000000: episode: 277, duration: 31.716s, episode steps: 1044, steps per second:  33, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006555, mae: 0.382757, mean_q: 0.475596, mean_eps: 0.829799\n",
            " 190025/1000000: episode: 278, duration: 11.917s, episode steps: 391, steps per second:  33, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.007377, mae: 0.389657, mean_q: 0.483992, mean_eps: 0.829153\n",
            " 191421/1000000: episode: 279, duration: 43.360s, episode steps: 1396, steps per second:  32, episode reward: 28.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.007292, mae: 0.407478, mean_q: 0.508342, mean_eps: 0.828348\n",
            " 191900/1000000: episode: 280, duration: 14.600s, episode steps: 479, steps per second:  33, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.006223, mae: 0.406428, mean_q: 0.505760, mean_eps: 0.827506\n",
            " 192592/1000000: episode: 281, duration: 21.300s, episode steps: 692, steps per second:  32, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.007687, mae: 0.407179, mean_q: 0.506029, mean_eps: 0.826980\n",
            " 193864/1000000: episode: 282, duration: 38.827s, episode steps: 1272, steps per second:  33, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.007472, mae: 0.404935, mean_q: 0.503716, mean_eps: 0.826097\n",
            " 194519/1000000: episode: 283, duration: 19.949s, episode steps: 655, steps per second:  33, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.006411, mae: 0.405438, mean_q: 0.504230, mean_eps: 0.825229\n",
            " 195319/1000000: episode: 284, duration: 24.219s, episode steps: 800, steps per second:  33, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.008033, mae: 0.413039, mean_q: 0.512671, mean_eps: 0.824574\n",
            " 196748/1000000: episode: 285, duration: 43.739s, episode steps: 1429, steps per second:  33, episode reward: 12.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.007704, mae: 0.408563, mean_q: 0.506413, mean_eps: 0.823571\n",
            " 197175/1000000: episode: 286, duration: 13.010s, episode steps: 427, steps per second:  33, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.714 [0.000, 5.000],  loss: 0.007290, mae: 0.403367, mean_q: 0.501574, mean_eps: 0.822736\n",
            " 197690/1000000: episode: 287, duration: 15.685s, episode steps: 515, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.007317, mae: 0.402418, mean_q: 0.498386, mean_eps: 0.822311\n",
            " 198259/1000000: episode: 288, duration: 17.273s, episode steps: 569, steps per second:  33, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.007287, mae: 0.406073, mean_q: 0.504593, mean_eps: 0.821823\n",
            " 198773/1000000: episode: 289, duration: 15.791s, episode steps: 514, steps per second:  33, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.006489, mae: 0.410040, mean_q: 0.509359, mean_eps: 0.821336\n",
            " 200096/1000000: episode: 290, duration: 41.492s, episode steps: 1323, steps per second:  32, episode reward: 23.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006895, mae: 0.404302, mean_q: 0.501493, mean_eps: 0.820509\n",
            " 200654/1000000: episode: 291, duration: 18.054s, episode steps: 558, steps per second:  31, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.007023, mae: 0.426477, mean_q: 0.528899, mean_eps: 0.819663\n",
            " 201405/1000000: episode: 292, duration: 23.356s, episode steps: 751, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.007193, mae: 0.432370, mean_q: 0.536263, mean_eps: 0.819073\n",
            " 201772/1000000: episode: 293, duration: 11.292s, episode steps: 367, steps per second:  33, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.008265, mae: 0.448361, mean_q: 0.555278, mean_eps: 0.818571\n",
            " 202440/1000000: episode: 294, duration: 20.736s, episode steps: 668, steps per second:  32, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.006604, mae: 0.432956, mean_q: 0.536521, mean_eps: 0.818106\n",
            " 203164/1000000: episode: 295, duration: 22.385s, episode steps: 724, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.006564, mae: 0.433228, mean_q: 0.536479, mean_eps: 0.817480\n",
            " 203836/1000000: episode: 296, duration: 20.714s, episode steps: 672, steps per second:  32, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.007709, mae: 0.425006, mean_q: 0.525752, mean_eps: 0.816852\n",
            " 204451/1000000: episode: 297, duration: 18.991s, episode steps: 615, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.008038, mae: 0.435738, mean_q: 0.540108, mean_eps: 0.816272\n",
            " 205281/1000000: episode: 298, duration: 25.635s, episode steps: 830, steps per second:  32, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.007888, mae: 0.436996, mean_q: 0.539220, mean_eps: 0.815621\n",
            " 205685/1000000: episode: 299, duration: 12.954s, episode steps: 404, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.007374, mae: 0.433351, mean_q: 0.537025, mean_eps: 0.815064\n",
            " 206468/1000000: episode: 300, duration: 24.367s, episode steps: 783, steps per second:  32, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.007255, mae: 0.431401, mean_q: 0.532555, mean_eps: 0.814532\n",
            " 207455/1000000: episode: 301, duration: 30.773s, episode steps: 987, steps per second:  32, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.006784, mae: 0.430103, mean_q: 0.532094, mean_eps: 0.813736\n",
            " 208010/1000000: episode: 302, duration: 17.022s, episode steps: 555, steps per second:  33, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.006960, mae: 0.428753, mean_q: 0.530837, mean_eps: 0.813041\n",
            " 208499/1000000: episode: 303, duration: 14.985s, episode steps: 489, steps per second:  33, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.008038, mae: 0.430511, mean_q: 0.532537, mean_eps: 0.812571\n",
            " 209027/1000000: episode: 304, duration: 16.376s, episode steps: 528, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.006038, mae: 0.426512, mean_q: 0.527616, mean_eps: 0.812114\n",
            " 209653/1000000: episode: 305, duration: 19.850s, episode steps: 626, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.009391, mae: 0.431243, mean_q: 0.533681, mean_eps: 0.811594\n",
            " 210432/1000000: episode: 306, duration: 24.304s, episode steps: 779, steps per second:  32, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.007638, mae: 0.446839, mean_q: 0.553652, mean_eps: 0.810962\n",
            " 211065/1000000: episode: 307, duration: 19.922s, episode steps: 633, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.007604, mae: 0.452057, mean_q: 0.560878, mean_eps: 0.810327\n",
            " 211721/1000000: episode: 308, duration: 20.880s, episode steps: 656, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.007867, mae: 0.458149, mean_q: 0.568403, mean_eps: 0.809745\n",
            " 212388/1000000: episode: 309, duration: 20.969s, episode steps: 667, steps per second:  32, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.007712, mae: 0.457870, mean_q: 0.570535, mean_eps: 0.809151\n",
            " 213098/1000000: episode: 310, duration: 22.375s, episode steps: 710, steps per second:  32, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.007277, mae: 0.458033, mean_q: 0.567477, mean_eps: 0.808532\n",
            " 213754/1000000: episode: 311, duration: 20.706s, episode steps: 656, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.006601, mae: 0.445758, mean_q: 0.552991, mean_eps: 0.807917\n",
            " 214638/1000000: episode: 312, duration: 27.736s, episode steps: 884, steps per second:  32, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.007004, mae: 0.453393, mean_q: 0.560702, mean_eps: 0.807224\n",
            " 215289/1000000: episode: 313, duration: 20.375s, episode steps: 651, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007376, mae: 0.452040, mean_q: 0.559086, mean_eps: 0.806532\n",
            " 216241/1000000: episode: 314, duration: 29.744s, episode steps: 952, steps per second:  32, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.007831, mae: 0.455103, mean_q: 0.563112, mean_eps: 0.805811\n",
            " 217474/1000000: episode: 315, duration: 38.350s, episode steps: 1233, steps per second:  32, episode reward: 21.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.007896, mae: 0.460360, mean_q: 0.571877, mean_eps: 0.804828\n",
            " 218041/1000000: episode: 316, duration: 17.856s, episode steps: 567, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.734 [0.000, 5.000],  loss: 0.007024, mae: 0.453082, mean_q: 0.560573, mean_eps: 0.804018\n",
            " 218587/1000000: episode: 317, duration: 16.802s, episode steps: 546, steps per second:  32, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.008516, mae: 0.454521, mean_q: 0.562351, mean_eps: 0.803517\n",
            " 219098/1000000: episode: 318, duration: 15.812s, episode steps: 511, steps per second:  32, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006683, mae: 0.457872, mean_q: 0.566124, mean_eps: 0.803042\n",
            " 219441/1000000: episode: 319, duration: 10.678s, episode steps: 343, steps per second:  32, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007209, mae: 0.454687, mean_q: 0.562181, mean_eps: 0.802657\n",
            " 219818/1000000: episode: 320, duration: 11.723s, episode steps: 377, steps per second:  32, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.782 [0.000, 5.000],  loss: 0.006320, mae: 0.444917, mean_q: 0.551499, mean_eps: 0.802333\n",
            " 220589/1000000: episode: 321, duration: 24.135s, episode steps: 771, steps per second:  32, episode reward: 21.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.007864, mae: 0.468112, mean_q: 0.577791, mean_eps: 0.801816\n",
            " 221295/1000000: episode: 322, duration: 21.988s, episode steps: 706, steps per second:  32, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006739, mae: 0.483916, mean_q: 0.600624, mean_eps: 0.801152\n",
            " 222378/1000000: episode: 323, duration: 33.807s, episode steps: 1083, steps per second:  32, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.007616, mae: 0.486679, mean_q: 0.603077, mean_eps: 0.800348\n",
            " 223210/1000000: episode: 324, duration: 25.935s, episode steps: 832, steps per second:  32, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.007804, mae: 0.487106, mean_q: 0.604297, mean_eps: 0.799485\n",
            " 223929/1000000: episode: 325, duration: 22.509s, episode steps: 719, steps per second:  32, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.008305, mae: 0.488716, mean_q: 0.603670, mean_eps: 0.798787\n",
            " 224542/1000000: episode: 326, duration: 18.931s, episode steps: 613, steps per second:  32, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.008798, mae: 0.493134, mean_q: 0.609716, mean_eps: 0.798188\n",
            " 224918/1000000: episode: 327, duration: 11.753s, episode steps: 376, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006722, mae: 0.482840, mean_q: 0.597562, mean_eps: 0.797743\n",
            " 225862/1000000: episode: 328, duration: 29.488s, episode steps: 944, steps per second:  32, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.007200, mae: 0.484002, mean_q: 0.598444, mean_eps: 0.797149\n",
            " 226346/1000000: episode: 329, duration: 15.154s, episode steps: 484, steps per second:  32, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.008942, mae: 0.490113, mean_q: 0.605762, mean_eps: 0.796506\n",
            " 226978/1000000: episode: 330, duration: 19.673s, episode steps: 632, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.007465, mae: 0.487002, mean_q: 0.602718, mean_eps: 0.796004\n",
            " 227584/1000000: episode: 331, duration: 19.109s, episode steps: 606, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.008657, mae: 0.486844, mean_q: 0.601270, mean_eps: 0.795448\n",
            " 228471/1000000: episode: 332, duration: 27.686s, episode steps: 887, steps per second:  32, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.008087, mae: 0.487330, mean_q: 0.602999, mean_eps: 0.794777\n",
            " 229081/1000000: episode: 333, duration: 18.978s, episode steps: 610, steps per second:  32, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.008173, mae: 0.486701, mean_q: 0.600828, mean_eps: 0.794102\n",
            " 230131/1000000: episode: 334, duration: 32.585s, episode steps: 1050, steps per second:  32, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.007760, mae: 0.491266, mean_q: 0.608547, mean_eps: 0.793355\n",
            " 230802/1000000: episode: 335, duration: 20.831s, episode steps: 671, steps per second:  32, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.009164, mae: 0.509040, mean_q: 0.630627, mean_eps: 0.792581\n",
            " 231514/1000000: episode: 336, duration: 22.211s, episode steps: 712, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.008077, mae: 0.511772, mean_q: 0.633200, mean_eps: 0.791958\n",
            " 232214/1000000: episode: 337, duration: 22.100s, episode steps: 700, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.008497, mae: 0.517750, mean_q: 0.638940, mean_eps: 0.791322\n",
            " 233005/1000000: episode: 338, duration: 24.800s, episode steps: 791, steps per second:  32, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.008524, mae: 0.517513, mean_q: 0.640236, mean_eps: 0.790651\n",
            " 233513/1000000: episode: 339, duration: 15.885s, episode steps: 508, steps per second:  32, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.007614, mae: 0.518443, mean_q: 0.642521, mean_eps: 0.790066\n",
            " 234450/1000000: episode: 340, duration: 29.720s, episode steps: 937, steps per second:  32, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.007412, mae: 0.508567, mean_q: 0.629171, mean_eps: 0.789416\n",
            " 234891/1000000: episode: 341, duration: 13.957s, episode steps: 441, steps per second:  32, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.008481, mae: 0.505087, mean_q: 0.626444, mean_eps: 0.788797\n",
            " 235603/1000000: episode: 342, duration: 22.931s, episode steps: 712, steps per second:  31, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.007501, mae: 0.507431, mean_q: 0.628727, mean_eps: 0.788279\n",
            " 236108/1000000: episode: 343, duration: 15.869s, episode steps: 505, steps per second:  32, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.006633, mae: 0.504093, mean_q: 0.622585, mean_eps: 0.787731\n",
            " 237065/1000000: episode: 344, duration: 30.007s, episode steps: 957, steps per second:  32, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.007930, mae: 0.518575, mean_q: 0.640513, mean_eps: 0.787073\n",
            " 238286/1000000: episode: 345, duration: 38.087s, episode steps: 1221, steps per second:  32, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.007959, mae: 0.511503, mean_q: 0.631535, mean_eps: 0.786092\n",
            " 238667/1000000: episode: 346, duration: 11.889s, episode steps: 381, steps per second:  32, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.010882, mae: 0.516502, mean_q: 0.638882, mean_eps: 0.785372\n",
            " 239344/1000000: episode: 347, duration: 21.275s, episode steps: 677, steps per second:  32, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.258 [0.000, 5.000],  loss: 0.006997, mae: 0.515442, mean_q: 0.636657, mean_eps: 0.784896\n",
            " 239876/1000000: episode: 348, duration: 16.734s, episode steps: 532, steps per second:  32, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.007968, mae: 0.512555, mean_q: 0.634508, mean_eps: 0.784353\n",
            " 240520/1000000: episode: 349, duration: 20.148s, episode steps: 644, steps per second:  32, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.008341, mae: 0.548644, mean_q: 0.678080, mean_eps: 0.783824\n",
            " 241074/1000000: episode: 350, duration: 17.387s, episode steps: 554, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.006596, mae: 0.547273, mean_q: 0.677486, mean_eps: 0.783284\n",
            " 241687/1000000: episode: 351, duration: 19.099s, episode steps: 613, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.008765, mae: 0.553276, mean_q: 0.684786, mean_eps: 0.782758\n",
            " 242219/1000000: episode: 352, duration: 16.895s, episode steps: 532, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.008402, mae: 0.552426, mean_q: 0.682756, mean_eps: 0.782243\n",
            " 242600/1000000: episode: 353, duration: 12.075s, episode steps: 381, steps per second:  32, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.007727, mae: 0.546024, mean_q: 0.674671, mean_eps: 0.781833\n",
            " 243300/1000000: episode: 354, duration: 22.156s, episode steps: 700, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.007198, mae: 0.540730, mean_q: 0.669341, mean_eps: 0.781347\n",
            " 243883/1000000: episode: 355, duration: 18.305s, episode steps: 583, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.007271, mae: 0.556573, mean_q: 0.687903, mean_eps: 0.780769\n",
            " 244375/1000000: episode: 356, duration: 15.274s, episode steps: 492, steps per second:  32, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.007068, mae: 0.544751, mean_q: 0.673124, mean_eps: 0.780285\n",
            " 244976/1000000: episode: 357, duration: 18.938s, episode steps: 601, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.008133, mae: 0.545374, mean_q: 0.674434, mean_eps: 0.779793\n",
            " 245739/1000000: episode: 358, duration: 23.993s, episode steps: 763, steps per second:  32, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.007836, mae: 0.549476, mean_q: 0.677947, mean_eps: 0.779180\n",
            " 246374/1000000: episode: 359, duration: 19.951s, episode steps: 635, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.007588, mae: 0.552840, mean_q: 0.681461, mean_eps: 0.778550\n",
            " 246896/1000000: episode: 360, duration: 16.547s, episode steps: 522, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.008513, mae: 0.550292, mean_q: 0.680388, mean_eps: 0.778029\n",
            " 247536/1000000: episode: 361, duration: 20.451s, episode steps: 640, steps per second:  31, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.691 [0.000, 5.000],  loss: 0.008617, mae: 0.565772, mean_q: 0.697929, mean_eps: 0.777507\n",
            " 248109/1000000: episode: 362, duration: 18.219s, episode steps: 573, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.009254, mae: 0.548397, mean_q: 0.675980, mean_eps: 0.776960\n",
            " 248756/1000000: episode: 363, duration: 20.404s, episode steps: 647, steps per second:  32, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.007343, mae: 0.549104, mean_q: 0.678720, mean_eps: 0.776411\n",
            " 249401/1000000: episode: 364, duration: 20.187s, episode steps: 645, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.007938, mae: 0.549325, mean_q: 0.677513, mean_eps: 0.775830\n",
            " 250481/1000000: episode: 365, duration: 33.923s, episode steps: 1080, steps per second:  32, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.007576, mae: 0.556264, mean_q: 0.686892, mean_eps: 0.775052\n",
            " 250990/1000000: episode: 366, duration: 15.909s, episode steps: 509, steps per second:  32, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.009376, mae: 0.585772, mean_q: 0.723509, mean_eps: 0.774338\n",
            " 251790/1000000: episode: 367, duration: 25.127s, episode steps: 800, steps per second:  32, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.007630, mae: 0.567239, mean_q: 0.700862, mean_eps: 0.773749\n",
            " 252137/1000000: episode: 368, duration: 10.823s, episode steps: 347, steps per second:  32, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.009334, mae: 0.566940, mean_q: 0.699141, mean_eps: 0.773232\n",
            " 252611/1000000: episode: 369, duration: 14.889s, episode steps: 474, steps per second:  32, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.008989, mae: 0.567942, mean_q: 0.703856, mean_eps: 0.772863\n",
            " 253639/1000000: episode: 370, duration: 32.247s, episode steps: 1028, steps per second:  32, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.008243, mae: 0.577631, mean_q: 0.713093, mean_eps: 0.772188\n",
            " 254040/1000000: episode: 371, duration: 12.601s, episode steps: 401, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.008467, mae: 0.578443, mean_q: 0.714468, mean_eps: 0.771546\n",
            " 254584/1000000: episode: 372, duration: 17.322s, episode steps: 544, steps per second:  31, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.008053, mae: 0.561206, mean_q: 0.695336, mean_eps: 0.771121\n",
            " 255268/1000000: episode: 373, duration: 21.478s, episode steps: 684, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.007084, mae: 0.568032, mean_q: 0.701180, mean_eps: 0.770568\n",
            " 256161/1000000: episode: 374, duration: 28.110s, episode steps: 893, steps per second:  32, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.008248, mae: 0.572061, mean_q: 0.706520, mean_eps: 0.769857\n",
            " 256535/1000000: episode: 375, duration: 11.674s, episode steps: 374, steps per second:  32, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.008343, mae: 0.575129, mean_q: 0.709485, mean_eps: 0.769287\n",
            " 257628/1000000: episode: 376, duration: 34.228s, episode steps: 1093, steps per second:  32, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.007679, mae: 0.568565, mean_q: 0.701929, mean_eps: 0.768628\n",
            " 258289/1000000: episode: 377, duration: 20.815s, episode steps: 661, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.008071, mae: 0.570032, mean_q: 0.703657, mean_eps: 0.767838\n",
            " 259125/1000000: episode: 378, duration: 26.045s, episode steps: 836, steps per second:  32, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.008464, mae: 0.572669, mean_q: 0.706231, mean_eps: 0.767163\n",
            " 259998/1000000: episode: 379, duration: 27.631s, episode steps: 873, steps per second:  32, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.007719, mae: 0.570658, mean_q: 0.705248, mean_eps: 0.766394\n",
            " 261131/1000000: episode: 380, duration: 35.756s, episode steps: 1133, steps per second:  32, episode reward: 25.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.008304, mae: 0.589888, mean_q: 0.728829, mean_eps: 0.765492\n",
            " 261856/1000000: episode: 381, duration: 22.988s, episode steps: 725, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.009823, mae: 0.592228, mean_q: 0.730171, mean_eps: 0.764657\n",
            " 262516/1000000: episode: 382, duration: 20.678s, episode steps: 660, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.008533, mae: 0.586771, mean_q: 0.724171, mean_eps: 0.764034\n",
            " 263793/1000000: episode: 383, duration: 40.155s, episode steps: 1277, steps per second:  32, episode reward: 10.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.009644, mae: 0.596007, mean_q: 0.736233, mean_eps: 0.763161\n",
            " 264139/1000000: episode: 384, duration: 10.838s, episode steps: 346, steps per second:  32, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.007794, mae: 0.590839, mean_q: 0.730605, mean_eps: 0.762431\n",
            " 264948/1000000: episode: 385, duration: 25.390s, episode steps: 809, steps per second:  32, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.008213, mae: 0.593124, mean_q: 0.733854, mean_eps: 0.761912\n",
            " 265445/1000000: episode: 386, duration: 15.597s, episode steps: 497, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.008168, mae: 0.595257, mean_q: 0.734890, mean_eps: 0.761324\n",
            " 265935/1000000: episode: 387, duration: 15.280s, episode steps: 490, steps per second:  32, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007889, mae: 0.598017, mean_q: 0.737917, mean_eps: 0.760879\n",
            " 266345/1000000: episode: 388, duration: 12.929s, episode steps: 410, steps per second:  32, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.008693, mae: 0.592927, mean_q: 0.731217, mean_eps: 0.760474\n",
            " 266864/1000000: episode: 389, duration: 16.255s, episode steps: 519, steps per second:  32, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.007632, mae: 0.600925, mean_q: 0.742696, mean_eps: 0.760056\n",
            " 267504/1000000: episode: 390, duration: 20.150s, episode steps: 640, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.009556, mae: 0.591319, mean_q: 0.728611, mean_eps: 0.759536\n",
            " 268058/1000000: episode: 391, duration: 17.462s, episode steps: 554, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.008992, mae: 0.591120, mean_q: 0.727174, mean_eps: 0.758998\n",
            " 269124/1000000: episode: 392, duration: 33.556s, episode steps: 1066, steps per second:  32, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.008448, mae: 0.586825, mean_q: 0.723167, mean_eps: 0.758269\n",
            " 269499/1000000: episode: 393, duration: 11.823s, episode steps: 375, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.008175, mae: 0.616021, mean_q: 0.759225, mean_eps: 0.757621\n",
            " 270432/1000000: episode: 394, duration: 29.484s, episode steps: 933, steps per second:  32, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.008191, mae: 0.597737, mean_q: 0.735979, mean_eps: 0.757032\n",
            " 271672/1000000: episode: 395, duration: 39.236s, episode steps: 1240, steps per second:  32, episode reward: 11.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.008345, mae: 0.612726, mean_q: 0.756554, mean_eps: 0.756055\n",
            " 272299/1000000: episode: 396, duration: 19.730s, episode steps: 627, steps per second:  32, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.009004, mae: 0.606022, mean_q: 0.748823, mean_eps: 0.755214\n",
            " 272845/1000000: episode: 397, duration: 17.296s, episode steps: 546, steps per second:  32, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.007728, mae: 0.611955, mean_q: 0.754924, mean_eps: 0.754685\n",
            " 273578/1000000: episode: 398, duration: 23.262s, episode steps: 733, steps per second:  32, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.008670, mae: 0.615798, mean_q: 0.759793, mean_eps: 0.754109\n",
            " 274197/1000000: episode: 399, duration: 19.457s, episode steps: 619, steps per second:  32, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.008722, mae: 0.607073, mean_q: 0.751680, mean_eps: 0.753501\n",
            " 274881/1000000: episode: 400, duration: 21.743s, episode steps: 684, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.009231, mae: 0.612082, mean_q: 0.755041, mean_eps: 0.752914\n",
            " 275267/1000000: episode: 401, duration: 12.377s, episode steps: 386, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.008303, mae: 0.603866, mean_q: 0.743544, mean_eps: 0.752433\n",
            " 275861/1000000: episode: 402, duration: 19.045s, episode steps: 594, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.008240, mae: 0.606769, mean_q: 0.746687, mean_eps: 0.751992\n",
            " 276549/1000000: episode: 403, duration: 21.941s, episode steps: 688, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.009723, mae: 0.621527, mean_q: 0.765112, mean_eps: 0.751415\n",
            " 278021/1000000: episode: 404, duration: 46.534s, episode steps: 1472, steps per second:  32, episode reward: 30.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.008262, mae: 0.607732, mean_q: 0.749322, mean_eps: 0.750443\n",
            " 278801/1000000: episode: 405, duration: 24.806s, episode steps: 780, steps per second:  31, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.008714, mae: 0.612155, mean_q: 0.754691, mean_eps: 0.749429\n",
            " 279407/1000000: episode: 406, duration: 19.122s, episode steps: 606, steps per second:  32, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007111, mae: 0.604170, mean_q: 0.745638, mean_eps: 0.748806\n",
            " 280301/1000000: episode: 407, duration: 28.534s, episode steps: 894, steps per second:  31, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.008814, mae: 0.618100, mean_q: 0.761092, mean_eps: 0.748131\n",
            " 280994/1000000: episode: 408, duration: 22.014s, episode steps: 693, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.009448, mae: 0.632883, mean_q: 0.779671, mean_eps: 0.747417\n",
            " 282071/1000000: episode: 409, duration: 34.361s, episode steps: 1077, steps per second:  31, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.008419, mae: 0.631870, mean_q: 0.780321, mean_eps: 0.746621\n",
            " 282771/1000000: episode: 410, duration: 22.317s, episode steps: 700, steps per second:  31, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.008587, mae: 0.632036, mean_q: 0.779376, mean_eps: 0.745822\n",
            " 283544/1000000: episode: 411, duration: 24.601s, episode steps: 773, steps per second:  31, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.009382, mae: 0.631677, mean_q: 0.778961, mean_eps: 0.745160\n",
            " 284285/1000000: episode: 412, duration: 23.506s, episode steps: 741, steps per second:  32, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.009270, mae: 0.639418, mean_q: 0.788023, mean_eps: 0.744477\n",
            " 284916/1000000: episode: 413, duration: 19.927s, episode steps: 631, steps per second:  32, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.010458, mae: 0.636944, mean_q: 0.784218, mean_eps: 0.743860\n",
            " 285780/1000000: episode: 414, duration: 27.350s, episode steps: 864, steps per second:  32, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.008939, mae: 0.629485, mean_q: 0.775394, mean_eps: 0.743189\n",
            " 286497/1000000: episode: 415, duration: 22.683s, episode steps: 717, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.009108, mae: 0.627815, mean_q: 0.772969, mean_eps: 0.742476\n",
            " 287473/1000000: episode: 416, duration: 30.853s, episode steps: 976, steps per second:  32, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.008651, mae: 0.633777, mean_q: 0.781588, mean_eps: 0.741713\n",
            " 288089/1000000: episode: 417, duration: 19.387s, episode steps: 616, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.008927, mae: 0.640278, mean_q: 0.791569, mean_eps: 0.740996\n",
            " 288911/1000000: episode: 418, duration: 25.996s, episode steps: 822, steps per second:  32, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.008563, mae: 0.639730, mean_q: 0.789423, mean_eps: 0.740350\n",
            " 289551/1000000: episode: 419, duration: 20.330s, episode steps: 640, steps per second:  31, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.008941, mae: 0.631707, mean_q: 0.779810, mean_eps: 0.739693\n",
            " 290530/1000000: episode: 420, duration: 30.755s, episode steps: 979, steps per second:  32, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.009231, mae: 0.637433, mean_q: 0.786216, mean_eps: 0.738964\n",
            " 291069/1000000: episode: 421, duration: 17.026s, episode steps: 539, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.009503, mae: 0.652172, mean_q: 0.803636, mean_eps: 0.738280\n",
            " 291884/1000000: episode: 422, duration: 25.835s, episode steps: 815, steps per second:  32, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.009809, mae: 0.655201, mean_q: 0.807686, mean_eps: 0.737672\n",
            " 292512/1000000: episode: 423, duration: 19.836s, episode steps: 628, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.008420, mae: 0.655638, mean_q: 0.807749, mean_eps: 0.737024\n",
            " 293892/1000000: episode: 424, duration: 43.300s, episode steps: 1380, steps per second:  32, episode reward: 25.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.009435, mae: 0.653421, mean_q: 0.805062, mean_eps: 0.736120\n",
            " 294543/1000000: episode: 425, duration: 20.600s, episode steps: 651, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.008788, mae: 0.650966, mean_q: 0.802533, mean_eps: 0.735206\n",
            " 294933/1000000: episode: 426, duration: 12.382s, episode steps: 390, steps per second:  31, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.009660, mae: 0.666476, mean_q: 0.820789, mean_eps: 0.734736\n",
            " 295964/1000000: episode: 427, duration: 32.381s, episode steps: 1031, steps per second:  32, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.009425, mae: 0.650841, mean_q: 0.802518, mean_eps: 0.734097\n",
            " 296655/1000000: episode: 428, duration: 21.855s, episode steps: 691, steps per second:  32, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.010120, mae: 0.661038, mean_q: 0.814693, mean_eps: 0.733323\n",
            " 297231/1000000: episode: 429, duration: 18.209s, episode steps: 576, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.009202, mae: 0.658184, mean_q: 0.810491, mean_eps: 0.732752\n",
            " 297679/1000000: episode: 430, duration: 14.134s, episode steps: 448, steps per second:  32, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.009450, mae: 0.650993, mean_q: 0.801483, mean_eps: 0.732291\n",
            " 298212/1000000: episode: 431, duration: 16.760s, episode steps: 533, steps per second:  32, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.009026, mae: 0.650688, mean_q: 0.801013, mean_eps: 0.731850\n",
            " 298671/1000000: episode: 432, duration: 14.431s, episode steps: 459, steps per second:  32, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.009462, mae: 0.654243, mean_q: 0.804133, mean_eps: 0.731404\n",
            " 299377/1000000: episode: 433, duration: 22.378s, episode steps: 706, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.008873, mae: 0.648578, mean_q: 0.797944, mean_eps: 0.730878\n",
            " 300192/1000000: episode: 434, duration: 25.652s, episode steps: 815, steps per second:  32, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.009996, mae: 0.660828, mean_q: 0.813155, mean_eps: 0.730194\n",
            " 300887/1000000: episode: 435, duration: 22.148s, episode steps: 695, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.009856, mae: 0.672123, mean_q: 0.828484, mean_eps: 0.729516\n",
            " 301381/1000000: episode: 436, duration: 15.735s, episode steps: 494, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.009636, mae: 0.673808, mean_q: 0.830128, mean_eps: 0.728979\n",
            " 302093/1000000: episode: 437, duration: 22.724s, episode steps: 712, steps per second:  31, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.008491, mae: 0.672805, mean_q: 0.829852, mean_eps: 0.728436\n",
            " 302906/1000000: episode: 438, duration: 25.735s, episode steps: 813, steps per second:  32, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.008482, mae: 0.677966, mean_q: 0.833591, mean_eps: 0.727750\n",
            " 303424/1000000: episode: 439, duration: 16.483s, episode steps: 518, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.009858, mae: 0.674453, mean_q: 0.829589, mean_eps: 0.727152\n",
            " 303990/1000000: episode: 440, duration: 18.135s, episode steps: 566, steps per second:  31, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.008383, mae: 0.665102, mean_q: 0.819064, mean_eps: 0.726665\n",
            " 304762/1000000: episode: 441, duration: 24.630s, episode steps: 772, steps per second:  31, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.008470, mae: 0.662453, mean_q: 0.816481, mean_eps: 0.726062\n",
            " 305994/1000000: episode: 442, duration: 39.145s, episode steps: 1232, steps per second:  31, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.009108, mae: 0.669856, mean_q: 0.824424, mean_eps: 0.725160\n",
            " 307137/1000000: episode: 443, duration: 36.148s, episode steps: 1143, steps per second:  32, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.008959, mae: 0.674050, mean_q: 0.830077, mean_eps: 0.724091\n",
            " 307789/1000000: episode: 444, duration: 20.884s, episode steps: 652, steps per second:  31, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.008424, mae: 0.675942, mean_q: 0.831876, mean_eps: 0.723282\n",
            " 308481/1000000: episode: 445, duration: 22.142s, episode steps: 692, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.009841, mae: 0.668476, mean_q: 0.822602, mean_eps: 0.722678\n",
            " 309310/1000000: episode: 446, duration: 26.569s, episode steps: 829, steps per second:  31, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.007975, mae: 0.662354, mean_q: 0.813828, mean_eps: 0.721994\n",
            " 309977/1000000: episode: 447, duration: 21.498s, episode steps: 667, steps per second:  31, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.008647, mae: 0.673251, mean_q: 0.828519, mean_eps: 0.721320\n",
            " 310392/1000000: episode: 448, duration: 13.418s, episode steps: 415, steps per second:  31, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.009243, mae: 0.714353, mean_q: 0.879471, mean_eps: 0.720834\n",
            " 311213/1000000: episode: 449, duration: 26.544s, episode steps: 821, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.008449, mae: 0.711710, mean_q: 0.876347, mean_eps: 0.720278\n",
            " 311842/1000000: episode: 450, duration: 20.459s, episode steps: 629, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.010407, mae: 0.716279, mean_q: 0.881311, mean_eps: 0.719625\n",
            " 312588/1000000: episode: 451, duration: 24.202s, episode steps: 746, steps per second:  31, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.009815, mae: 0.702683, mean_q: 0.864757, mean_eps: 0.719007\n",
            " 313254/1000000: episode: 452, duration: 21.904s, episode steps: 666, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: 0.008981, mae: 0.718941, mean_q: 0.886499, mean_eps: 0.718372\n",
            " 313639/1000000: episode: 453, duration: 12.284s, episode steps: 385, steps per second:  31, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.008391, mae: 0.713664, mean_q: 0.876898, mean_eps: 0.717899\n",
            " 314069/1000000: episode: 454, duration: 14.137s, episode steps: 430, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.009773, mae: 0.704547, mean_q: 0.865428, mean_eps: 0.717531\n",
            " 314725/1000000: episode: 455, duration: 21.408s, episode steps: 656, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.009843, mae: 0.724982, mean_q: 0.890196, mean_eps: 0.717042\n",
            " 315445/1000000: episode: 456, duration: 23.219s, episode steps: 720, steps per second:  31, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.007489, mae: 0.709094, mean_q: 0.871266, mean_eps: 0.716423\n",
            " 316511/1000000: episode: 457, duration: 34.378s, episode steps: 1066, steps per second:  31, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: 0.010020, mae: 0.720267, mean_q: 0.884969, mean_eps: 0.715620\n",
            " 317606/1000000: episode: 458, duration: 35.513s, episode steps: 1095, steps per second:  31, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.009626, mae: 0.706508, mean_q: 0.867149, mean_eps: 0.714648\n",
            " 318052/1000000: episode: 459, duration: 14.721s, episode steps: 446, steps per second:  30, episode reward: 10.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.008873, mae: 0.713809, mean_q: 0.878381, mean_eps: 0.713955\n",
            " 318602/1000000: episode: 460, duration: 18.189s, episode steps: 550, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.009828, mae: 0.707782, mean_q: 0.869592, mean_eps: 0.713507\n",
            " 319512/1000000: episode: 461, duration: 29.741s, episode steps: 910, steps per second:  31, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.010702, mae: 0.719719, mean_q: 0.885931, mean_eps: 0.712850\n",
            " 320268/1000000: episode: 462, duration: 24.784s, episode steps: 756, steps per second:  31, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.009403, mae: 0.728743, mean_q: 0.895088, mean_eps: 0.712101\n",
            " 321280/1000000: episode: 463, duration: 32.707s, episode steps: 1012, steps per second:  31, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: 0.010164, mae: 0.751858, mean_q: 0.925130, mean_eps: 0.711305\n",
            " 322006/1000000: episode: 464, duration: 23.499s, episode steps: 726, steps per second:  31, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.009048, mae: 0.750350, mean_q: 0.923369, mean_eps: 0.710522\n",
            " 322576/1000000: episode: 465, duration: 18.346s, episode steps: 570, steps per second:  31, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.009393, mae: 0.750078, mean_q: 0.923779, mean_eps: 0.709939\n",
            " 323257/1000000: episode: 466, duration: 21.789s, episode steps: 681, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.009807, mae: 0.754305, mean_q: 0.926473, mean_eps: 0.709376\n",
            " 323952/1000000: episode: 467, duration: 22.174s, episode steps: 695, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: 0.009872, mae: 0.761482, mean_q: 0.939001, mean_eps: 0.708756\n",
            " 324346/1000000: episode: 468, duration: 12.624s, episode steps: 394, steps per second:  31, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.009528, mae: 0.755269, mean_q: 0.928804, mean_eps: 0.708267\n",
            " 325279/1000000: episode: 469, duration: 29.852s, episode steps: 933, steps per second:  31, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.009336, mae: 0.743726, mean_q: 0.914449, mean_eps: 0.707669\n",
            " 325979/1000000: episode: 470, duration: 22.490s, episode steps: 700, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.009159, mae: 0.761104, mean_q: 0.935914, mean_eps: 0.706935\n",
            " 326705/1000000: episode: 471, duration: 23.908s, episode steps: 726, steps per second:  30, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.009389, mae: 0.753282, mean_q: 0.926516, mean_eps: 0.706292\n",
            " 327207/1000000: episode: 472, duration: 16.593s, episode steps: 502, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.010044, mae: 0.758268, mean_q: 0.930855, mean_eps: 0.705740\n",
            " 327762/1000000: episode: 473, duration: 18.748s, episode steps: 555, steps per second:  30, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: 0.010552, mae: 0.761430, mean_q: 0.937249, mean_eps: 0.705264\n",
            " 328211/1000000: episode: 474, duration: 14.847s, episode steps: 449, steps per second:  30, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.216 [0.000, 5.000],  loss: 0.009362, mae: 0.754338, mean_q: 0.927285, mean_eps: 0.704813\n",
            " 329185/1000000: episode: 475, duration: 32.080s, episode steps: 974, steps per second:  30, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.009139, mae: 0.761509, mean_q: 0.934933, mean_eps: 0.704172\n",
            " 329575/1000000: episode: 476, duration: 12.696s, episode steps: 390, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.009944, mae: 0.765930, mean_q: 0.942608, mean_eps: 0.703558\n",
            " 330877/1000000: episode: 477, duration: 43.425s, episode steps: 1302, steps per second:  30, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.010495, mae: 0.782892, mean_q: 0.961206, mean_eps: 0.702797\n",
            " 331312/1000000: episode: 478, duration: 14.512s, episode steps: 435, steps per second:  30, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.008367, mae: 0.790622, mean_q: 0.972051, mean_eps: 0.702015\n",
            " 331959/1000000: episode: 479, duration: 21.724s, episode steps: 647, steps per second:  30, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.009709, mae: 0.790539, mean_q: 0.971136, mean_eps: 0.701529\n",
            " 332514/1000000: episode: 480, duration: 18.474s, episode steps: 555, steps per second:  30, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.009849, mae: 0.783918, mean_q: 0.963658, mean_eps: 0.700988\n",
            " 333502/1000000: episode: 481, duration: 32.476s, episode steps: 988, steps per second:  30, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.009823, mae: 0.788814, mean_q: 0.970238, mean_eps: 0.700293\n",
            " 334485/1000000: episode: 482, duration: 32.155s, episode steps: 983, steps per second:  31, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.009484, mae: 0.780641, mean_q: 0.959489, mean_eps: 0.699405\n",
            " 335324/1000000: episode: 483, duration: 27.637s, episode steps: 839, steps per second:  30, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.010643, mae: 0.786018, mean_q: 0.965178, mean_eps: 0.698586\n",
            " 336354/1000000: episode: 484, duration: 33.974s, episode steps: 1030, steps per second:  30, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.010198, mae: 0.797339, mean_q: 0.979257, mean_eps: 0.697746\n",
            " 337452/1000000: episode: 485, duration: 36.377s, episode steps: 1098, steps per second:  30, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.010025, mae: 0.788675, mean_q: 0.969556, mean_eps: 0.696788\n",
            " 338090/1000000: episode: 486, duration: 21.028s, episode steps: 638, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.008888, mae: 0.793565, mean_q: 0.973472, mean_eps: 0.696007\n",
            " 338957/1000000: episode: 487, duration: 28.434s, episode steps: 867, steps per second:  30, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.009430, mae: 0.784135, mean_q: 0.963677, mean_eps: 0.695328\n",
            " 339580/1000000: episode: 488, duration: 20.215s, episode steps: 623, steps per second:  31, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.008947, mae: 0.782353, mean_q: 0.960343, mean_eps: 0.694659\n",
            " 340101/1000000: episode: 489, duration: 17.148s, episode steps: 521, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.009488, mae: 0.800904, mean_q: 0.984807, mean_eps: 0.694144\n",
            " 340724/1000000: episode: 490, duration: 20.301s, episode steps: 623, steps per second:  31, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.010717, mae: 0.827648, mean_q: 1.018801, mean_eps: 0.693629\n",
            " 341339/1000000: episode: 491, duration: 20.027s, episode steps: 615, steps per second:  31, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.009153, mae: 0.826427, mean_q: 1.014426, mean_eps: 0.693073\n",
            " 341969/1000000: episode: 492, duration: 20.634s, episode steps: 630, steps per second:  31, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.010542, mae: 0.839655, mean_q: 1.031502, mean_eps: 0.692511\n",
            " 342734/1000000: episode: 493, duration: 24.906s, episode steps: 765, steps per second:  31, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.009981, mae: 0.831443, mean_q: 1.020335, mean_eps: 0.691883\n",
            " 343479/1000000: episode: 494, duration: 24.408s, episode steps: 745, steps per second:  31, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.011397, mae: 0.839425, mean_q: 1.031490, mean_eps: 0.691205\n",
            " 343966/1000000: episode: 495, duration: 16.080s, episode steps: 487, steps per second:  30, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.010239, mae: 0.822880, mean_q: 1.011691, mean_eps: 0.690650\n",
            " 344504/1000000: episode: 496, duration: 17.730s, episode steps: 538, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.010983, mae: 0.841627, mean_q: 1.033593, mean_eps: 0.690189\n",
            " 345078/1000000: episode: 497, duration: 18.811s, episode steps: 574, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.009118, mae: 0.830957, mean_q: 1.020123, mean_eps: 0.689689\n",
            " 345589/1000000: episode: 498, duration: 16.792s, episode steps: 511, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.010176, mae: 0.830895, mean_q: 1.020731, mean_eps: 0.689199\n",
            " 346247/1000000: episode: 499, duration: 21.550s, episode steps: 658, steps per second:  31, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.010395, mae: 0.831457, mean_q: 1.019928, mean_eps: 0.688674\n",
            " 347070/1000000: episode: 500, duration: 27.023s, episode steps: 823, steps per second:  30, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.009471, mae: 0.829713, mean_q: 1.017022, mean_eps: 0.688008\n",
            " 347667/1000000: episode: 501, duration: 19.440s, episode steps: 597, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.010706, mae: 0.836678, mean_q: 1.027074, mean_eps: 0.687369\n",
            " 348420/1000000: episode: 502, duration: 24.799s, episode steps: 753, steps per second:  30, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.009789, mae: 0.830082, mean_q: 1.018326, mean_eps: 0.686762\n",
            " 349066/1000000: episode: 503, duration: 21.292s, episode steps: 646, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.010185, mae: 0.829355, mean_q: 1.017724, mean_eps: 0.686132\n",
            " 349720/1000000: episode: 504, duration: 21.479s, episode steps: 654, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.009465, mae: 0.828090, mean_q: 1.016380, mean_eps: 0.685547\n",
            " 350443/1000000: episode: 505, duration: 23.670s, episode steps: 723, steps per second:  31, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.750 [0.000, 5.000],  loss: 0.009644, mae: 0.851964, mean_q: 1.047379, mean_eps: 0.684928\n",
            " 351083/1000000: episode: 506, duration: 20.998s, episode steps: 640, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.011160, mae: 0.846040, mean_q: 1.039557, mean_eps: 0.684314\n",
            " 352133/1000000: episode: 507, duration: 34.458s, episode steps: 1050, steps per second:  30, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.010216, mae: 0.849328, mean_q: 1.045055, mean_eps: 0.683553\n",
            " 352811/1000000: episode: 508, duration: 22.000s, episode steps: 678, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.009559, mae: 0.848798, mean_q: 1.043658, mean_eps: 0.682775\n",
            " 353902/1000000: episode: 509, duration: 35.873s, episode steps: 1091, steps per second:  30, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.010609, mae: 0.853822, mean_q: 1.048228, mean_eps: 0.681980\n",
            " 354590/1000000: episode: 510, duration: 22.439s, episode steps: 688, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.010737, mae: 0.849001, mean_q: 1.041813, mean_eps: 0.681179\n",
            " 355080/1000000: episode: 511, duration: 16.214s, episode steps: 490, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.010867, mae: 0.859535, mean_q: 1.056354, mean_eps: 0.680649\n",
            " 355724/1000000: episode: 512, duration: 21.513s, episode steps: 644, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.010117, mae: 0.847358, mean_q: 1.040882, mean_eps: 0.680140\n",
            " 356711/1000000: episode: 513, duration: 32.446s, episode steps: 987, steps per second:  30, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.009726, mae: 0.855500, mean_q: 1.051249, mean_eps: 0.679406\n",
            " 357721/1000000: episode: 514, duration: 33.384s, episode steps: 1010, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.011288, mae: 0.860522, mean_q: 1.055608, mean_eps: 0.678506\n",
            " 358681/1000000: episode: 515, duration: 31.730s, episode steps: 960, steps per second:  30, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.010575, mae: 0.858982, mean_q: 1.054928, mean_eps: 0.677618\n",
            " 359419/1000000: episode: 516, duration: 24.099s, episode steps: 738, steps per second:  31, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.011173, mae: 0.859977, mean_q: 1.055050, mean_eps: 0.676855\n",
            " 360318/1000000: episode: 517, duration: 29.360s, episode steps: 899, steps per second:  31, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.009892, mae: 0.870843, mean_q: 1.069614, mean_eps: 0.676119\n",
            " 360712/1000000: episode: 518, duration: 12.944s, episode steps: 394, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.777 [0.000, 5.000],  loss: 0.010897, mae: 0.907510, mean_q: 1.115170, mean_eps: 0.675537\n",
            " 361462/1000000: episode: 519, duration: 24.601s, episode steps: 750, steps per second:  30, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.010887, mae: 0.907767, mean_q: 1.114500, mean_eps: 0.675023\n",
            " 362462/1000000: episode: 520, duration: 32.607s, episode steps: 1000, steps per second:  31, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.010636, mae: 0.895402, mean_q: 1.097929, mean_eps: 0.674234\n",
            " 363123/1000000: episode: 521, duration: 21.699s, episode steps: 661, steps per second:  30, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.009611, mae: 0.889872, mean_q: 1.093512, mean_eps: 0.673487\n",
            " 363640/1000000: episode: 522, duration: 16.983s, episode steps: 517, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.009685, mae: 0.891520, mean_q: 1.093359, mean_eps: 0.672958\n",
            " 364317/1000000: episode: 523, duration: 22.320s, episode steps: 677, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.010125, mae: 0.899854, mean_q: 1.103509, mean_eps: 0.672420\n",
            " 365196/1000000: episode: 524, duration: 28.822s, episode steps: 879, steps per second:  30, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.010017, mae: 0.890060, mean_q: 1.091571, mean_eps: 0.671720\n",
            " 365714/1000000: episode: 525, duration: 16.966s, episode steps: 518, steps per second:  31, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.009918, mae: 0.901362, mean_q: 1.105692, mean_eps: 0.671091\n",
            " 366258/1000000: episode: 526, duration: 17.859s, episode steps: 544, steps per second:  30, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.011672, mae: 0.902935, mean_q: 1.106904, mean_eps: 0.670613\n",
            " 367017/1000000: episode: 527, duration: 24.821s, episode steps: 759, steps per second:  31, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.010417, mae: 0.898972, mean_q: 1.101792, mean_eps: 0.670026\n",
            " 368319/1000000: episode: 528, duration: 42.652s, episode steps: 1302, steps per second:  31, episode reward: 31.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.010291, mae: 0.901495, mean_q: 1.103262, mean_eps: 0.669099\n",
            " 369239/1000000: episode: 529, duration: 30.249s, episode steps: 920, steps per second:  30, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.010378, mae: 0.902071, mean_q: 1.105741, mean_eps: 0.668100\n",
            " 370007/1000000: episode: 530, duration: 25.182s, episode steps: 768, steps per second:  30, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.009762, mae: 0.904166, mean_q: 1.108727, mean_eps: 0.667340\n",
            " 370677/1000000: episode: 531, duration: 21.893s, episode steps: 670, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.010153, mae: 0.913755, mean_q: 1.121091, mean_eps: 0.666692\n",
            " 371157/1000000: episode: 532, duration: 15.821s, episode steps: 480, steps per second:  30, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.011486, mae: 0.937020, mean_q: 1.147048, mean_eps: 0.666174\n",
            " 371977/1000000: episode: 533, duration: 26.624s, episode steps: 820, steps per second:  31, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.009474, mae: 0.924269, mean_q: 1.132212, mean_eps: 0.665589\n",
            " 372954/1000000: episode: 534, duration: 31.807s, episode steps: 977, steps per second:  31, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.010618, mae: 0.924538, mean_q: 1.133342, mean_eps: 0.664781\n",
            " 373630/1000000: episode: 535, duration: 22.264s, episode steps: 676, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.010816, mae: 0.930836, mean_q: 1.140117, mean_eps: 0.664037\n",
            " 374890/1000000: episode: 536, duration: 41.263s, episode steps: 1260, steps per second:  31, episode reward: 32.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.010294, mae: 0.926641, mean_q: 1.135188, mean_eps: 0.663166\n",
            " 375577/1000000: episode: 537, duration: 22.478s, episode steps: 687, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.010978, mae: 0.927832, mean_q: 1.136923, mean_eps: 0.662289\n",
            " 376959/1000000: episode: 538, duration: 45.450s, episode steps: 1382, steps per second:  30, episode reward: 31.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.010147, mae: 0.923738, mean_q: 1.132054, mean_eps: 0.661359\n",
            " 377616/1000000: episode: 539, duration: 21.733s, episode steps: 657, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.010544, mae: 0.924656, mean_q: 1.132571, mean_eps: 0.660443\n",
            " 378601/1000000: episode: 540, duration: 32.644s, episode steps: 985, steps per second:  30, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.009689, mae: 0.918232, mean_q: 1.125082, mean_eps: 0.659703\n",
            " 378992/1000000: episode: 541, duration: 12.887s, episode steps: 391, steps per second:  30, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.012180, mae: 0.926274, mean_q: 1.133545, mean_eps: 0.659084\n",
            " 379516/1000000: episode: 542, duration: 17.511s, episode steps: 524, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.011293, mae: 0.926363, mean_q: 1.135463, mean_eps: 0.658673\n",
            " 380398/1000000: episode: 543, duration: 29.127s, episode steps: 882, steps per second:  30, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.009046, mae: 0.933065, mean_q: 1.143909, mean_eps: 0.658040\n",
            " 380791/1000000: episode: 544, duration: 13.045s, episode steps: 393, steps per second:  30, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.011592, mae: 0.949654, mean_q: 1.162605, mean_eps: 0.657465\n",
            " 381185/1000000: episode: 545, duration: 13.175s, episode steps: 394, steps per second:  30, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.010226, mae: 0.940712, mean_q: 1.151000, mean_eps: 0.657111\n",
            " 381919/1000000: episode: 546, duration: 24.165s, episode steps: 734, steps per second:  30, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.009705, mae: 0.954788, mean_q: 1.168985, mean_eps: 0.656603\n",
            " 382580/1000000: episode: 547, duration: 21.909s, episode steps: 661, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.118 [0.000, 5.000],  loss: 0.011261, mae: 0.957826, mean_q: 1.173298, mean_eps: 0.655977\n",
            " 383084/1000000: episode: 548, duration: 16.801s, episode steps: 504, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.009514, mae: 0.948870, mean_q: 1.162389, mean_eps: 0.655453\n",
            " 383778/1000000: episode: 549, duration: 23.081s, episode steps: 694, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.010315, mae: 0.956737, mean_q: 1.170184, mean_eps: 0.654913\n",
            " 384307/1000000: episode: 550, duration: 17.553s, episode steps: 529, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.011200, mae: 0.945106, mean_q: 1.157165, mean_eps: 0.654362\n",
            " 384894/1000000: episode: 551, duration: 19.419s, episode steps: 587, steps per second:  30, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.695 [0.000, 5.000],  loss: 0.010037, mae: 0.948750, mean_q: 1.162593, mean_eps: 0.653860\n",
            " 385615/1000000: episode: 552, duration: 23.910s, episode steps: 721, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.010372, mae: 0.953096, mean_q: 1.167870, mean_eps: 0.653271\n",
            " 386291/1000000: episode: 553, duration: 22.379s, episode steps: 676, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.009695, mae: 0.956603, mean_q: 1.172460, mean_eps: 0.652643\n",
            " 386916/1000000: episode: 554, duration: 20.551s, episode steps: 625, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.010160, mae: 0.949568, mean_q: 1.163926, mean_eps: 0.652058\n",
            " 387807/1000000: episode: 555, duration: 29.391s, episode steps: 891, steps per second:  30, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.009595, mae: 0.955244, mean_q: 1.170060, mean_eps: 0.651376\n",
            " 388443/1000000: episode: 556, duration: 20.978s, episode steps: 636, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.009835, mae: 0.948336, mean_q: 1.161678, mean_eps: 0.650688\n",
            " 388864/1000000: episode: 557, duration: 13.948s, episode steps: 421, steps per second:  30, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.010048, mae: 0.949357, mean_q: 1.162273, mean_eps: 0.650213\n",
            " 389898/1000000: episode: 558, duration: 34.098s, episode steps: 1034, steps per second:  30, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.009855, mae: 0.946284, mean_q: 1.158994, mean_eps: 0.649558\n",
            " 390844/1000000: episode: 559, duration: 31.279s, episode steps: 946, steps per second:  30, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.010513, mae: 0.970224, mean_q: 1.188642, mean_eps: 0.648667\n",
            " 392341/1000000: episode: 560, duration: 49.506s, episode steps: 1497, steps per second:  30, episode reward: 35.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.009496, mae: 0.982190, mean_q: 1.204666, mean_eps: 0.647567\n",
            " 392899/1000000: episode: 561, duration: 18.441s, episode steps: 558, steps per second:  30, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.158 [0.000, 5.000],  loss: 0.011074, mae: 0.977073, mean_q: 1.195450, mean_eps: 0.646642\n",
            " 393567/1000000: episode: 562, duration: 22.198s, episode steps: 668, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.834 [0.000, 5.000],  loss: 0.010406, mae: 0.977793, mean_q: 1.199350, mean_eps: 0.646091\n",
            " 394659/1000000: episode: 563, duration: 36.270s, episode steps: 1092, steps per second:  30, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.010884, mae: 0.988444, mean_q: 1.210898, mean_eps: 0.645299\n",
            " 395345/1000000: episode: 564, duration: 22.777s, episode steps: 686, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.010059, mae: 0.961543, mean_q: 1.180876, mean_eps: 0.644498\n",
            " 396053/1000000: episode: 565, duration: 23.710s, episode steps: 708, steps per second:  30, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.011368, mae: 0.979592, mean_q: 1.199016, mean_eps: 0.643870\n",
            " 396841/1000000: episode: 566, duration: 26.033s, episode steps: 788, steps per second:  30, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.011403, mae: 0.975957, mean_q: 1.195876, mean_eps: 0.643197\n",
            " 397643/1000000: episode: 567, duration: 26.709s, episode steps: 802, steps per second:  30, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.010192, mae: 0.980541, mean_q: 1.200509, mean_eps: 0.642482\n",
            " 398682/1000000: episode: 568, duration: 34.456s, episode steps: 1039, steps per second:  30, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.174 [0.000, 5.000],  loss: 0.010208, mae: 0.973946, mean_q: 1.194422, mean_eps: 0.641654\n",
            " 399547/1000000: episode: 569, duration: 28.937s, episode steps: 865, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.010206, mae: 0.977381, mean_q: 1.197272, mean_eps: 0.640797\n",
            " 400089/1000000: episode: 570, duration: 18.267s, episode steps: 542, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.009978, mae: 0.975862, mean_q: 1.195427, mean_eps: 0.640164\n",
            " 400610/1000000: episode: 571, duration: 17.550s, episode steps: 521, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: 0.011043, mae: 1.022914, mean_q: 1.251348, mean_eps: 0.639685\n",
            " 401122/1000000: episode: 572, duration: 17.006s, episode steps: 512, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.011032, mae: 1.007421, mean_q: 1.234348, mean_eps: 0.639221\n",
            " 401513/1000000: episode: 573, duration: 13.230s, episode steps: 391, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: 0.010024, mae: 1.017384, mean_q: 1.244818, mean_eps: 0.638814\n",
            " 401997/1000000: episode: 574, duration: 16.203s, episode steps: 484, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.010236, mae: 1.008153, mean_q: 1.235477, mean_eps: 0.638420\n",
            " 402587/1000000: episode: 575, duration: 19.639s, episode steps: 590, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: 0.010232, mae: 1.009493, mean_q: 1.236673, mean_eps: 0.637937\n",
            " 403274/1000000: episode: 576, duration: 23.126s, episode steps: 687, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.010670, mae: 1.012775, mean_q: 1.238706, mean_eps: 0.637363\n",
            " 403759/1000000: episode: 577, duration: 16.072s, episode steps: 485, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.011260, mae: 1.019928, mean_q: 1.248772, mean_eps: 0.636836\n",
            " 404415/1000000: episode: 578, duration: 22.028s, episode steps: 656, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.009890, mae: 1.010169, mean_q: 1.236316, mean_eps: 0.636323\n",
            " 405024/1000000: episode: 579, duration: 20.635s, episode steps: 609, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.011931, mae: 1.010432, mean_q: 1.238238, mean_eps: 0.635754\n",
            " 405638/1000000: episode: 580, duration: 20.533s, episode steps: 614, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.009727, mae: 1.012951, mean_q: 1.239527, mean_eps: 0.635203\n",
            " 406468/1000000: episode: 581, duration: 27.669s, episode steps: 830, steps per second:  30, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.010812, mae: 1.021829, mean_q: 1.248590, mean_eps: 0.634553\n",
            " 407291/1000000: episode: 582, duration: 27.060s, episode steps: 823, steps per second:  30, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.010237, mae: 1.010003, mean_q: 1.236779, mean_eps: 0.633810\n",
            " 408079/1000000: episode: 583, duration: 26.108s, episode steps: 788, steps per second:  30, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.010425, mae: 1.018032, mean_q: 1.245402, mean_eps: 0.633084\n",
            " 408760/1000000: episode: 584, duration: 22.902s, episode steps: 681, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.009762, mae: 1.007452, mean_q: 1.232528, mean_eps: 0.632424\n",
            " 409362/1000000: episode: 585, duration: 20.323s, episode steps: 602, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.011141, mae: 1.018619, mean_q: 1.245126, mean_eps: 0.631846\n",
            " 410055/1000000: episode: 586, duration: 23.137s, episode steps: 693, steps per second:  30, episode reward: 18.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: 0.009941, mae: 1.018225, mean_q: 1.247062, mean_eps: 0.631263\n",
            " 410951/1000000: episode: 587, duration: 29.653s, episode steps: 896, steps per second:  30, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.010219, mae: 1.050176, mean_q: 1.285555, mean_eps: 0.630548\n",
            " 411347/1000000: episode: 588, duration: 13.118s, episode steps: 396, steps per second:  30, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.010094, mae: 1.042205, mean_q: 1.275157, mean_eps: 0.629967\n",
            " 412225/1000000: episode: 589, duration: 29.496s, episode steps: 878, steps per second:  30, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.010013, mae: 1.048379, mean_q: 1.283605, mean_eps: 0.629393\n",
            " 413081/1000000: episode: 590, duration: 28.350s, episode steps: 856, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.009826, mae: 1.045381, mean_q: 1.278563, mean_eps: 0.628611\n",
            " 413885/1000000: episode: 591, duration: 26.627s, episode steps: 804, steps per second:  30, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.011184, mae: 1.050891, mean_q: 1.284569, mean_eps: 0.627864\n",
            " 415188/1000000: episode: 592, duration: 43.520s, episode steps: 1303, steps per second:  30, episode reward: 26.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.134 [0.000, 5.000],  loss: 0.010243, mae: 1.054634, mean_q: 1.289704, mean_eps: 0.626918\n",
            " 416129/1000000: episode: 593, duration: 31.214s, episode steps: 941, steps per second:  30, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.202 [0.000, 5.000],  loss: 0.010739, mae: 1.049399, mean_q: 1.282669, mean_eps: 0.625908\n",
            " 416956/1000000: episode: 594, duration: 27.447s, episode steps: 827, steps per second:  30, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.010368, mae: 1.054258, mean_q: 1.289281, mean_eps: 0.625112\n",
            " 418152/1000000: episode: 595, duration: 40.031s, episode steps: 1196, steps per second:  30, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.010165, mae: 1.049519, mean_q: 1.284363, mean_eps: 0.624203\n",
            " 418537/1000000: episode: 596, duration: 13.528s, episode steps: 385, steps per second:  28, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.138 [0.000, 5.000],  loss: 0.011383, mae: 1.054226, mean_q: 1.290928, mean_eps: 0.623490\n",
            " 419195/1000000: episode: 597, duration: 22.370s, episode steps: 658, steps per second:  29, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.011263, mae: 1.046747, mean_q: 1.279669, mean_eps: 0.623021\n",
            " 420419/1000000: episode: 598, duration: 41.554s, episode steps: 1224, steps per second:  29, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.011806, mae: 1.070288, mean_q: 1.309729, mean_eps: 0.622175\n",
            " 420892/1000000: episode: 599, duration: 16.006s, episode steps: 473, steps per second:  30, episode reward: 12.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.010003, mae: 1.104772, mean_q: 1.353091, mean_eps: 0.621411\n",
            " 421322/1000000: episode: 600, duration: 14.635s, episode steps: 430, steps per second:  29, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.012730, mae: 1.122894, mean_q: 1.373323, mean_eps: 0.621005\n",
            " 421928/1000000: episode: 601, duration: 20.391s, episode steps: 606, steps per second:  30, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.010300, mae: 1.119230, mean_q: 1.369876, mean_eps: 0.620538\n",
            " 422425/1000000: episode: 602, duration: 16.906s, episode steps: 497, steps per second:  29, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.010237, mae: 1.107795, mean_q: 1.354256, mean_eps: 0.620042\n",
            " 423673/1000000: episode: 603, duration: 41.899s, episode steps: 1248, steps per second:  30, episode reward: 18.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.011437, mae: 1.106118, mean_q: 1.352438, mean_eps: 0.619255\n",
            " 424401/1000000: episode: 604, duration: 24.497s, episode steps: 728, steps per second:  30, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.011492, mae: 1.128454, mean_q: 1.380278, mean_eps: 0.618366\n",
            " 424786/1000000: episode: 605, duration: 12.939s, episode steps: 385, steps per second:  30, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.039 [0.000, 5.000],  loss: 0.013531, mae: 1.128632, mean_q: 1.382447, mean_eps: 0.617865\n",
            " 425554/1000000: episode: 606, duration: 27.184s, episode steps: 768, steps per second:  28, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.010729, mae: 1.103051, mean_q: 1.349502, mean_eps: 0.617347\n",
            " 426080/1000000: episode: 607, duration: 18.564s, episode steps: 526, steps per second:  28, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.011980, mae: 1.117958, mean_q: 1.368007, mean_eps: 0.616766\n",
            " 426621/1000000: episode: 608, duration: 19.179s, episode steps: 541, steps per second:  28, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.011794, mae: 1.118942, mean_q: 1.369046, mean_eps: 0.616285\n",
            " 427334/1000000: episode: 609, duration: 25.122s, episode steps: 713, steps per second:  28, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.012161, mae: 1.123359, mean_q: 1.375480, mean_eps: 0.615720\n",
            " 428139/1000000: episode: 610, duration: 28.270s, episode steps: 805, steps per second:  28, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.010657, mae: 1.119274, mean_q: 1.368902, mean_eps: 0.615038\n",
            " 428513/1000000: episode: 611, duration: 13.355s, episode steps: 374, steps per second:  28, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.888 [0.000, 5.000],  loss: 0.010750, mae: 1.117069, mean_q: 1.366206, mean_eps: 0.614507\n",
            " 428978/1000000: episode: 612, duration: 16.890s, episode steps: 465, steps per second:  28, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.011056, mae: 1.116273, mean_q: 1.366019, mean_eps: 0.614129\n",
            " 429962/1000000: episode: 613, duration: 34.560s, episode steps: 984, steps per second:  28, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.010374, mae: 1.111965, mean_q: 1.360936, mean_eps: 0.613477\n",
            " 430823/1000000: episode: 614, duration: 30.025s, episode steps: 861, steps per second:  29, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.010959, mae: 1.130703, mean_q: 1.384322, mean_eps: 0.612647\n",
            " 431382/1000000: episode: 615, duration: 19.838s, episode steps: 559, steps per second:  28, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.012207, mae: 1.131924, mean_q: 1.387375, mean_eps: 0.612008\n",
            " 432138/1000000: episode: 616, duration: 26.777s, episode steps: 756, steps per second:  28, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.861 [0.000, 5.000],  loss: 0.012178, mae: 1.139228, mean_q: 1.396134, mean_eps: 0.611416\n",
            " 433290/1000000: episode: 617, duration: 40.626s, episode steps: 1152, steps per second:  28, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.010907, mae: 1.145876, mean_q: 1.402214, mean_eps: 0.610557\n",
            " 433661/1000000: episode: 618, duration: 12.986s, episode steps: 371, steps per second:  29, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.011213, mae: 1.151516, mean_q: 1.408512, mean_eps: 0.609872\n",
            " 434292/1000000: episode: 619, duration: 22.317s, episode steps: 631, steps per second:  28, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.011560, mae: 1.147249, mean_q: 1.403977, mean_eps: 0.609422\n",
            " 434952/1000000: episode: 620, duration: 23.183s, episode steps: 660, steps per second:  28, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.011911, mae: 1.139562, mean_q: 1.393193, mean_eps: 0.608842\n",
            " 435344/1000000: episode: 621, duration: 13.889s, episode steps: 392, steps per second:  28, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.012053, mae: 1.131848, mean_q: 1.383206, mean_eps: 0.608369\n",
            " 436240/1000000: episode: 622, duration: 31.532s, episode steps: 896, steps per second:  28, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.011215, mae: 1.145568, mean_q: 1.400370, mean_eps: 0.607789\n",
            " 437822/1000000: episode: 623, duration: 53.442s, episode steps: 1582, steps per second:  30, episode reward: 31.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.011623, mae: 1.141771, mean_q: 1.395388, mean_eps: 0.606673\n",
            " 438378/1000000: episode: 624, duration: 18.458s, episode steps: 556, steps per second:  30, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.011027, mae: 1.148260, mean_q: 1.402572, mean_eps: 0.605710\n",
            " 438800/1000000: episode: 625, duration: 14.395s, episode steps: 422, steps per second:  29, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.013441, mae: 1.132392, mean_q: 1.384593, mean_eps: 0.605271\n",
            " 439464/1000000: episode: 626, duration: 23.016s, episode steps: 664, steps per second:  29, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.009559, mae: 1.137001, mean_q: 1.392352, mean_eps: 0.604783\n",
            " 440449/1000000: episode: 627, duration: 33.638s, episode steps: 985, steps per second:  29, episode reward: 26.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.010896, mae: 1.144850, mean_q: 1.401013, mean_eps: 0.604040\n",
            " 440896/1000000: episode: 628, duration: 15.327s, episode steps: 447, steps per second:  29, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.011179, mae: 1.142579, mean_q: 1.397106, mean_eps: 0.603395\n",
            " 441968/1000000: episode: 629, duration: 36.737s, episode steps: 1072, steps per second:  29, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.010854, mae: 1.144249, mean_q: 1.398616, mean_eps: 0.602713\n",
            " 442655/1000000: episode: 630, duration: 23.392s, episode steps: 687, steps per second:  29, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.012497, mae: 1.161653, mean_q: 1.421918, mean_eps: 0.601921\n",
            " 443601/1000000: episode: 631, duration: 32.185s, episode steps: 946, steps per second:  29, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.011146, mae: 1.135784, mean_q: 1.388782, mean_eps: 0.601185\n",
            " 444618/1000000: episode: 632, duration: 34.359s, episode steps: 1017, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.011383, mae: 1.149815, mean_q: 1.405253, mean_eps: 0.600301\n",
            " 445307/1000000: episode: 633, duration: 23.202s, episode steps: 689, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.139 [0.000, 5.000],  loss: 0.012746, mae: 1.162330, mean_q: 1.419946, mean_eps: 0.599534\n",
            " 446620/1000000: episode: 634, duration: 44.149s, episode steps: 1313, steps per second:  30, episode reward: 33.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.010940, mae: 1.151469, mean_q: 1.407184, mean_eps: 0.598634\n",
            " 447631/1000000: episode: 635, duration: 34.287s, episode steps: 1011, steps per second:  29, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.010963, mae: 1.144131, mean_q: 1.395540, mean_eps: 0.597588\n",
            " 448693/1000000: episode: 636, duration: 36.164s, episode steps: 1062, steps per second:  29, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.011486, mae: 1.145056, mean_q: 1.398603, mean_eps: 0.596654\n",
            " 449503/1000000: episode: 637, duration: 27.202s, episode steps: 810, steps per second:  30, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.012175, mae: 1.145735, mean_q: 1.398621, mean_eps: 0.595812\n",
            " 450512/1000000: episode: 638, duration: 34.287s, episode steps: 1009, steps per second:  29, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.010867, mae: 1.172541, mean_q: 1.434425, mean_eps: 0.594995\n",
            " 450894/1000000: episode: 639, duration: 13.063s, episode steps: 382, steps per second:  29, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.009920, mae: 1.189867, mean_q: 1.457028, mean_eps: 0.594368\n",
            " 451789/1000000: episode: 640, duration: 30.238s, episode steps: 895, steps per second:  30, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.010839, mae: 1.182887, mean_q: 1.446917, mean_eps: 0.593792\n",
            " 452557/1000000: episode: 641, duration: 25.991s, episode steps: 768, steps per second:  30, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.012443, mae: 1.180785, mean_q: 1.441815, mean_eps: 0.593043\n",
            " 453257/1000000: episode: 642, duration: 23.765s, episode steps: 700, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.012514, mae: 1.192792, mean_q: 1.458273, mean_eps: 0.592383\n",
            " 453728/1000000: episode: 643, duration: 16.021s, episode steps: 471, steps per second:  29, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.013326, mae: 1.186316, mean_q: 1.448856, mean_eps: 0.591857\n",
            " 454224/1000000: episode: 644, duration: 16.987s, episode steps: 496, steps per second:  29, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: 0.011414, mae: 1.175623, mean_q: 1.436921, mean_eps: 0.591423\n",
            " 454669/1000000: episode: 645, duration: 15.254s, episode steps: 445, steps per second:  29, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.010195, mae: 1.187840, mean_q: 1.450546, mean_eps: 0.590999\n",
            " 455469/1000000: episode: 646, duration: 27.221s, episode steps: 800, steps per second:  29, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: 0.011049, mae: 1.189192, mean_q: 1.453098, mean_eps: 0.590437\n",
            " 456540/1000000: episode: 647, duration: 36.322s, episode steps: 1071, steps per second:  29, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.012472, mae: 1.187038, mean_q: 1.450365, mean_eps: 0.589596\n",
            " 457280/1000000: episode: 648, duration: 25.239s, episode steps: 740, steps per second:  29, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.013658, mae: 1.205182, mean_q: 1.471090, mean_eps: 0.588783\n",
            " 458117/1000000: episode: 649, duration: 28.403s, episode steps: 837, steps per second:  29, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.011967, mae: 1.193766, mean_q: 1.457301, mean_eps: 0.588072\n",
            " 458730/1000000: episode: 650, duration: 20.720s, episode steps: 613, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.011176, mae: 1.191430, mean_q: 1.454776, mean_eps: 0.587418\n",
            " 459950/1000000: episode: 651, duration: 41.548s, episode steps: 1220, steps per second:  29, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.011533, mae: 1.188394, mean_q: 1.450787, mean_eps: 0.586594\n",
            " 461033/1000000: episode: 652, duration: 37.029s, episode steps: 1083, steps per second:  29, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.011633, mae: 1.250945, mean_q: 1.528012, mean_eps: 0.585557\n",
            " 462025/1000000: episode: 653, duration: 33.830s, episode steps: 992, steps per second:  29, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.012518, mae: 1.249450, mean_q: 1.524302, mean_eps: 0.584623\n",
            " 462567/1000000: episode: 654, duration: 18.518s, episode steps: 542, steps per second:  29, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.011890, mae: 1.243681, mean_q: 1.516723, mean_eps: 0.583934\n",
            " 463365/1000000: episode: 655, duration: 27.154s, episode steps: 798, steps per second:  29, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.012870, mae: 1.239122, mean_q: 1.512402, mean_eps: 0.583331\n",
            " 463911/1000000: episode: 656, duration: 18.629s, episode steps: 546, steps per second:  29, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.009 [0.000, 5.000],  loss: 0.011450, mae: 1.244029, mean_q: 1.519848, mean_eps: 0.582726\n",
            " 464309/1000000: episode: 657, duration: 13.754s, episode steps: 398, steps per second:  29, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.010114, mae: 1.229337, mean_q: 1.503369, mean_eps: 0.582301\n",
            " 464942/1000000: episode: 658, duration: 21.586s, episode steps: 633, steps per second:  29, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.010080, mae: 1.237490, mean_q: 1.512968, mean_eps: 0.581837\n",
            " 465344/1000000: episode: 659, duration: 13.819s, episode steps: 402, steps per second:  29, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: 0.010936, mae: 1.211119, mean_q: 1.479407, mean_eps: 0.581372\n",
            " 466553/1000000: episode: 660, duration: 41.548s, episode steps: 1209, steps per second:  29, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.011767, mae: 1.248093, mean_q: 1.523378, mean_eps: 0.580647\n",
            " 467078/1000000: episode: 661, duration: 17.953s, episode steps: 525, steps per second:  29, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.011332, mae: 1.257973, mean_q: 1.536906, mean_eps: 0.579866\n",
            " 467570/1000000: episode: 662, duration: 16.810s, episode steps: 492, steps per second:  29, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.009339, mae: 1.229063, mean_q: 1.502815, mean_eps: 0.579408\n",
            " 468375/1000000: episode: 663, duration: 27.481s, episode steps: 805, steps per second:  29, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.012791, mae: 1.241707, mean_q: 1.517090, mean_eps: 0.578825\n",
            " 468836/1000000: episode: 664, duration: 15.754s, episode steps: 461, steps per second:  29, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.012819, mae: 1.255099, mean_q: 1.532587, mean_eps: 0.578256\n",
            " 469550/1000000: episode: 665, duration: 24.717s, episode steps: 714, steps per second:  29, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.864 [0.000, 5.000],  loss: 0.012286, mae: 1.245882, mean_q: 1.520630, mean_eps: 0.577727\n",
            " 469937/1000000: episode: 666, duration: 13.398s, episode steps: 387, steps per second:  29, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: 0.011208, mae: 1.244618, mean_q: 1.518224, mean_eps: 0.577230\n",
            " 470864/1000000: episode: 667, duration: 31.599s, episode steps: 927, steps per second:  29, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.012073, mae: 1.279132, mean_q: 1.562052, mean_eps: 0.576640\n",
            " 471534/1000000: episode: 668, duration: 23.109s, episode steps: 670, steps per second:  29, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.140 [0.000, 5.000],  loss: 0.011212, mae: 1.285263, mean_q: 1.569487, mean_eps: 0.575922\n",
            " 472508/1000000: episode: 669, duration: 33.386s, episode steps: 974, steps per second:  29, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.013112, mae: 1.293706, mean_q: 1.578944, mean_eps: 0.575182\n",
            " 473758/1000000: episode: 670, duration: 42.835s, episode steps: 1250, steps per second:  29, episode reward: 29.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.012683, mae: 1.289163, mean_q: 1.574361, mean_eps: 0.574181\n",
            " 474151/1000000: episode: 671, duration: 13.484s, episode steps: 393, steps per second:  29, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.011850, mae: 1.270443, mean_q: 1.548052, mean_eps: 0.573441\n",
            " 474893/1000000: episode: 672, duration: 25.567s, episode steps: 742, steps per second:  29, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.011415, mae: 1.289456, mean_q: 1.573847, mean_eps: 0.572930\n",
            " 475770/1000000: episode: 673, duration: 30.204s, episode steps: 877, steps per second:  29, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.012322, mae: 1.280337, mean_q: 1.562172, mean_eps: 0.572201\n",
            " 476373/1000000: episode: 674, duration: 20.883s, episode steps: 603, steps per second:  29, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.012 [0.000, 5.000],  loss: 0.011296, mae: 1.292853, mean_q: 1.578942, mean_eps: 0.571535\n",
            " 476976/1000000: episode: 675, duration: 20.811s, episode steps: 603, steps per second:  29, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.013832, mae: 1.287284, mean_q: 1.572647, mean_eps: 0.570993\n",
            " 478079/1000000: episode: 676, duration: 39.715s, episode steps: 1103, steps per second:  28, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.012991, mae: 1.287504, mean_q: 1.572456, mean_eps: 0.570227\n",
            " 478780/1000000: episode: 677, duration: 24.905s, episode steps: 701, steps per second:  28, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.012343, mae: 1.285172, mean_q: 1.568919, mean_eps: 0.569415\n",
            " 479577/1000000: episode: 678, duration: 27.943s, episode steps: 797, steps per second:  29, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.011874, mae: 1.279592, mean_q: 1.562460, mean_eps: 0.568740\n",
            " 480237/1000000: episode: 679, duration: 23.219s, episode steps: 660, steps per second:  28, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.010044, mae: 1.286672, mean_q: 1.570883, mean_eps: 0.568083\n",
            " 480888/1000000: episode: 680, duration: 22.607s, episode steps: 651, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.011805, mae: 1.321428, mean_q: 1.612978, mean_eps: 0.567494\n",
            " 481685/1000000: episode: 681, duration: 27.634s, episode steps: 797, steps per second:  29, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.011389, mae: 1.304233, mean_q: 1.591264, mean_eps: 0.566843\n",
            " 482431/1000000: episode: 682, duration: 25.806s, episode steps: 746, steps per second:  29, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.011749, mae: 1.320938, mean_q: 1.613221, mean_eps: 0.566148\n",
            " 483232/1000000: episode: 683, duration: 28.019s, episode steps: 801, steps per second:  29, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.012575, mae: 1.326234, mean_q: 1.619865, mean_eps: 0.565453\n",
            " 483633/1000000: episode: 684, duration: 14.221s, episode steps: 401, steps per second:  28, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.865 [0.000, 5.000],  loss: 0.013821, mae: 1.322412, mean_q: 1.613980, mean_eps: 0.564911\n",
            " 484260/1000000: episode: 685, duration: 21.923s, episode steps: 627, steps per second:  29, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.011852, mae: 1.296198, mean_q: 1.581759, mean_eps: 0.564449\n",
            " 485216/1000000: episode: 686, duration: 33.676s, episode steps: 956, steps per second:  28, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.012869, mae: 1.310654, mean_q: 1.599926, mean_eps: 0.563738\n",
            " 486120/1000000: episode: 687, duration: 31.705s, episode steps: 904, steps per second:  29, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.011671, mae: 1.322511, mean_q: 1.612747, mean_eps: 0.562901\n",
            " 486595/1000000: episode: 688, duration: 16.724s, episode steps: 475, steps per second:  28, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.010003, mae: 1.320280, mean_q: 1.611188, mean_eps: 0.562280\n",
            " 487244/1000000: episode: 689, duration: 22.881s, episode steps: 649, steps per second:  28, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.011899, mae: 1.316467, mean_q: 1.606554, mean_eps: 0.561774\n",
            " 487626/1000000: episode: 690, duration: 13.349s, episode steps: 382, steps per second:  29, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.000 [0.000, 5.000],  loss: 0.012959, mae: 1.315933, mean_q: 1.605248, mean_eps: 0.561309\n",
            " 488015/1000000: episode: 691, duration: 13.589s, episode steps: 389, steps per second:  29, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.126 [0.000, 5.000],  loss: 0.011981, mae: 1.321442, mean_q: 1.612917, mean_eps: 0.560962\n",
            " 488415/1000000: episode: 692, duration: 14.033s, episode steps: 400, steps per second:  29, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.011165, mae: 1.287662, mean_q: 1.570075, mean_eps: 0.560607\n",
            " 489383/1000000: episode: 693, duration: 33.924s, episode steps: 968, steps per second:  29, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.011824, mae: 1.307142, mean_q: 1.596696, mean_eps: 0.559992\n",
            " 490154/1000000: episode: 694, duration: 27.016s, episode steps: 771, steps per second:  29, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.011833, mae: 1.322361, mean_q: 1.613308, mean_eps: 0.559209\n",
            " 490748/1000000: episode: 695, duration: 20.875s, episode steps: 594, steps per second:  28, episode reward: 15.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.011547, mae: 1.341163, mean_q: 1.637170, mean_eps: 0.558595\n",
            " 491293/1000000: episode: 696, duration: 19.019s, episode steps: 545, steps per second:  29, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.011209, mae: 1.357211, mean_q: 1.656695, mean_eps: 0.558082\n",
            " 492742/1000000: episode: 697, duration: 50.398s, episode steps: 1449, steps per second:  29, episode reward: 33.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.011579, mae: 1.342193, mean_q: 1.636267, mean_eps: 0.557184\n",
            " 493699/1000000: episode: 698, duration: 33.587s, episode steps: 957, steps per second:  28, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.011853, mae: 1.345686, mean_q: 1.639639, mean_eps: 0.556102\n",
            " 494191/1000000: episode: 699, duration: 17.255s, episode steps: 492, steps per second:  29, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.011735, mae: 1.338842, mean_q: 1.632796, mean_eps: 0.555450\n",
            " 495180/1000000: episode: 700, duration: 34.699s, episode steps: 989, steps per second:  29, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.011970, mae: 1.351103, mean_q: 1.647314, mean_eps: 0.554784\n",
            " 495794/1000000: episode: 701, duration: 21.976s, episode steps: 614, steps per second:  28, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.011720, mae: 1.324680, mean_q: 1.614315, mean_eps: 0.554063\n",
            " 496490/1000000: episode: 702, duration: 24.988s, episode steps: 696, steps per second:  28, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.013051, mae: 1.345825, mean_q: 1.642908, mean_eps: 0.553472\n",
            " 497468/1000000: episode: 703, duration: 34.755s, episode steps: 978, steps per second:  28, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.013219, mae: 1.356191, mean_q: 1.654344, mean_eps: 0.552720\n",
            " 498169/1000000: episode: 704, duration: 24.986s, episode steps: 701, steps per second:  28, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.012081, mae: 1.345889, mean_q: 1.643748, mean_eps: 0.551964\n",
            " 498920/1000000: episode: 705, duration: 26.759s, episode steps: 751, steps per second:  28, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.011166, mae: 1.346237, mean_q: 1.641665, mean_eps: 0.551310\n",
            " 499824/1000000: episode: 706, duration: 32.561s, episode steps: 904, steps per second:  28, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.011911, mae: 1.349470, mean_q: 1.645372, mean_eps: 0.550567\n",
            " 500775/1000000: episode: 707, duration: 33.885s, episode steps: 951, steps per second:  28, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.043 [0.000, 5.000],  loss: 0.012050, mae: 1.383471, mean_q: 1.689375, mean_eps: 0.549732\n",
            " 501455/1000000: episode: 708, duration: 24.289s, episode steps: 680, steps per second:  28, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.012752, mae: 1.377245, mean_q: 1.681051, mean_eps: 0.548997\n",
            " 502271/1000000: episode: 709, duration: 29.249s, episode steps: 816, steps per second:  28, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.012885, mae: 1.402571, mean_q: 1.711377, mean_eps: 0.548324\n",
            " 502937/1000000: episode: 710, duration: 23.610s, episode steps: 666, steps per second:  28, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.012366, mae: 1.397970, mean_q: 1.705479, mean_eps: 0.547656\n",
            " 503888/1000000: episode: 711, duration: 33.611s, episode steps: 951, steps per second:  28, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.013042, mae: 1.389475, mean_q: 1.696730, mean_eps: 0.546929\n",
            " 504409/1000000: episode: 712, duration: 18.618s, episode steps: 521, steps per second:  28, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.012790, mae: 1.405271, mean_q: 1.713112, mean_eps: 0.546267\n",
            " 505517/1000000: episode: 713, duration: 39.449s, episode steps: 1108, steps per second:  28, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.012303, mae: 1.389062, mean_q: 1.694817, mean_eps: 0.545532\n",
            " 506243/1000000: episode: 714, duration: 25.486s, episode steps: 726, steps per second:  28, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.013095, mae: 1.385323, mean_q: 1.690323, mean_eps: 0.544708\n",
            " 507060/1000000: episode: 715, duration: 28.931s, episode steps: 817, steps per second:  28, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.963 [0.000, 5.000],  loss: 0.013374, mae: 1.384485, mean_q: 1.688242, mean_eps: 0.544015\n",
            " 508007/1000000: episode: 716, duration: 33.689s, episode steps: 947, steps per second:  28, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.011475, mae: 1.389060, mean_q: 1.694804, mean_eps: 0.543221\n",
            " 508736/1000000: episode: 717, duration: 25.917s, episode steps: 729, steps per second:  28, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.013046, mae: 1.379647, mean_q: 1.684205, mean_eps: 0.542467\n",
            " 509233/1000000: episode: 718, duration: 17.938s, episode steps: 497, steps per second:  28, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.012206, mae: 1.388163, mean_q: 1.694401, mean_eps: 0.541914\n",
            " 510017/1000000: episode: 719, duration: 27.810s, episode steps: 784, steps per second:  28, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.012019, mae: 1.373465, mean_q: 1.675759, mean_eps: 0.541337\n",
            " 511024/1000000: episode: 720, duration: 35.831s, episode steps: 1007, steps per second:  28, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: 0.011964, mae: 1.416925, mean_q: 1.728217, mean_eps: 0.540532\n",
            " 511602/1000000: episode: 721, duration: 20.607s, episode steps: 578, steps per second:  28, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.013330, mae: 1.439426, mean_q: 1.754674, mean_eps: 0.539819\n",
            " 512847/1000000: episode: 722, duration: 44.445s, episode steps: 1245, steps per second:  28, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.012654, mae: 1.425411, mean_q: 1.739338, mean_eps: 0.538998\n",
            " 513301/1000000: episode: 723, duration: 16.338s, episode steps: 454, steps per second:  28, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.306 [0.000, 5.000],  loss: 0.010733, mae: 1.417049, mean_q: 1.728232, mean_eps: 0.538233\n",
            " 513986/1000000: episode: 724, duration: 24.404s, episode steps: 685, steps per second:  28, episode reward: 17.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.013040, mae: 1.432140, mean_q: 1.746396, mean_eps: 0.537720\n",
            " 514967/1000000: episode: 725, duration: 35.005s, episode steps: 981, steps per second:  28, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.013696, mae: 1.430629, mean_q: 1.747361, mean_eps: 0.536972\n",
            " 515606/1000000: episode: 726, duration: 23.110s, episode steps: 639, steps per second:  28, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.011753, mae: 1.416248, mean_q: 1.728172, mean_eps: 0.536243\n",
            " 516375/1000000: episode: 727, duration: 28.050s, episode steps: 769, steps per second:  27, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.013452, mae: 1.420913, mean_q: 1.732948, mean_eps: 0.535609\n",
            " 517223/1000000: episode: 728, duration: 30.669s, episode steps: 848, steps per second:  28, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.235 [0.000, 5.000],  loss: 0.011827, mae: 1.428788, mean_q: 1.742421, mean_eps: 0.534882\n",
            " 517832/1000000: episode: 729, duration: 21.966s, episode steps: 609, steps per second:  28, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.012390, mae: 1.425980, mean_q: 1.738565, mean_eps: 0.534227\n",
            " 519048/1000000: episode: 730, duration: 43.518s, episode steps: 1216, steps per second:  28, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.013187, mae: 1.424448, mean_q: 1.737150, mean_eps: 0.533406\n",
            " 520011/1000000: episode: 731, duration: 33.871s, episode steps: 963, steps per second:  28, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.234 [0.000, 5.000],  loss: 0.012679, mae: 1.434545, mean_q: 1.750293, mean_eps: 0.532425\n",
            " 520513/1000000: episode: 732, duration: 17.910s, episode steps: 502, steps per second:  28, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.012075, mae: 1.491533, mean_q: 1.822148, mean_eps: 0.531764\n",
            " 521328/1000000: episode: 733, duration: 28.646s, episode steps: 815, steps per second:  28, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.013171, mae: 1.465927, mean_q: 1.788825, mean_eps: 0.531172\n",
            " 521863/1000000: episode: 734, duration: 18.919s, episode steps: 535, steps per second:  28, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: 0.011794, mae: 1.470457, mean_q: 1.795824, mean_eps: 0.530565\n",
            " 522593/1000000: episode: 735, duration: 25.496s, episode steps: 730, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.012674, mae: 1.473648, mean_q: 1.798555, mean_eps: 0.529995\n",
            " 523414/1000000: episode: 736, duration: 28.516s, episode steps: 821, steps per second:  29, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.713 [0.000, 5.000],  loss: 0.012413, mae: 1.481125, mean_q: 1.808289, mean_eps: 0.529296\n",
            " 523921/1000000: episode: 737, duration: 17.928s, episode steps: 507, steps per second:  28, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.013836, mae: 1.492770, mean_q: 1.821968, mean_eps: 0.528699\n",
            " 524622/1000000: episode: 738, duration: 24.679s, episode steps: 701, steps per second:  28, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.013064, mae: 1.475377, mean_q: 1.799131, mean_eps: 0.528155\n",
            " 525956/1000000: episode: 739, duration: 46.825s, episode steps: 1334, steps per second:  28, episode reward: 28.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.012393, mae: 1.479192, mean_q: 1.804111, mean_eps: 0.527241\n",
            " 526727/1000000: episode: 740, duration: 27.144s, episode steps: 771, steps per second:  28, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.013551, mae: 1.470725, mean_q: 1.793229, mean_eps: 0.526294\n",
            " 527372/1000000: episode: 741, duration: 23.021s, episode steps: 645, steps per second:  28, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.011925, mae: 1.474437, mean_q: 1.798193, mean_eps: 0.525657\n",
            " 528048/1000000: episode: 742, duration: 25.594s, episode steps: 676, steps per second:  26, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.014360, mae: 1.461729, mean_q: 1.780192, mean_eps: 0.525063\n",
            " 528944/1000000: episode: 743, duration: 32.186s, episode steps: 896, steps per second:  28, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.011835, mae: 1.468482, mean_q: 1.789918, mean_eps: 0.524355\n",
            " 529483/1000000: episode: 744, duration: 19.133s, episode steps: 539, steps per second:  28, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: 0.012350, mae: 1.466173, mean_q: 1.788033, mean_eps: 0.523709\n",
            " 530049/1000000: episode: 745, duration: 21.050s, episode steps: 566, steps per second:  27, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.013063, mae: 1.477155, mean_q: 1.801098, mean_eps: 0.523211\n",
            " 530730/1000000: episode: 746, duration: 25.182s, episode steps: 681, steps per second:  27, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.010897, mae: 1.527515, mean_q: 1.862035, mean_eps: 0.522649\n",
            " 531567/1000000: episode: 747, duration: 30.707s, episode steps: 837, steps per second:  27, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.013659, mae: 1.523697, mean_q: 1.860564, mean_eps: 0.521967\n",
            " 532480/1000000: episode: 748, duration: 33.903s, episode steps: 913, steps per second:  27, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.012282, mae: 1.521829, mean_q: 1.855412, mean_eps: 0.521180\n",
            " 533102/1000000: episode: 749, duration: 23.107s, episode steps: 622, steps per second:  27, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.012481, mae: 1.525486, mean_q: 1.859048, mean_eps: 0.520489\n",
            " 533767/1000000: episode: 750, duration: 24.528s, episode steps: 665, steps per second:  27, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.013130, mae: 1.537965, mean_q: 1.872202, mean_eps: 0.519909\n",
            " 534495/1000000: episode: 751, duration: 26.642s, episode steps: 728, steps per second:  27, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.013426, mae: 1.535340, mean_q: 1.870797, mean_eps: 0.519283\n",
            " 535225/1000000: episode: 752, duration: 26.713s, episode steps: 730, steps per second:  27, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.012597, mae: 1.523233, mean_q: 1.857955, mean_eps: 0.518626\n",
            " 536160/1000000: episode: 753, duration: 33.117s, episode steps: 935, steps per second:  28, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.012670, mae: 1.518651, mean_q: 1.850475, mean_eps: 0.517877\n",
            " 536745/1000000: episode: 754, duration: 20.857s, episode steps: 585, steps per second:  28, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.012818, mae: 1.531754, mean_q: 1.870114, mean_eps: 0.517193\n",
            " 537611/1000000: episode: 755, duration: 30.578s, episode steps: 866, steps per second:  28, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.707 [0.000, 5.000],  loss: 0.012760, mae: 1.532106, mean_q: 1.870183, mean_eps: 0.516540\n",
            " 538137/1000000: episode: 756, duration: 18.552s, episode steps: 526, steps per second:  28, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.012869, mae: 1.527158, mean_q: 1.862252, mean_eps: 0.515913\n",
            " 538982/1000000: episode: 757, duration: 29.956s, episode steps: 845, steps per second:  28, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.012344, mae: 1.523472, mean_q: 1.858179, mean_eps: 0.515296\n",
            " 539589/1000000: episode: 758, duration: 21.683s, episode steps: 607, steps per second:  28, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.013414, mae: 1.535593, mean_q: 1.871125, mean_eps: 0.514643\n",
            " 540362/1000000: episode: 759, duration: 27.532s, episode steps: 773, steps per second:  28, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.012662, mae: 1.556047, mean_q: 1.898694, mean_eps: 0.514022\n",
            " 541117/1000000: episode: 760, duration: 27.220s, episode steps: 755, steps per second:  28, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.012769, mae: 1.568842, mean_q: 1.913236, mean_eps: 0.513334\n",
            " 541738/1000000: episode: 761, duration: 22.009s, episode steps: 621, steps per second:  28, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.013146, mae: 1.576134, mean_q: 1.919593, mean_eps: 0.512715\n",
            " 542479/1000000: episode: 762, duration: 26.497s, episode steps: 741, steps per second:  28, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.011734, mae: 1.565881, mean_q: 1.910537, mean_eps: 0.512103\n",
            " 543353/1000000: episode: 763, duration: 31.245s, episode steps: 874, steps per second:  28, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.011804, mae: 1.566445, mean_q: 1.908054, mean_eps: 0.511376\n",
            " 543945/1000000: episode: 764, duration: 21.187s, episode steps: 592, steps per second:  28, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.142 [0.000, 5.000],  loss: 0.012317, mae: 1.570556, mean_q: 1.913699, mean_eps: 0.510715\n",
            " 544920/1000000: episode: 765, duration: 34.909s, episode steps: 975, steps per second:  28, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.013651, mae: 1.568794, mean_q: 1.910894, mean_eps: 0.510011\n",
            " 545666/1000000: episode: 766, duration: 26.510s, episode steps: 746, steps per second:  28, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: 0.013561, mae: 1.573807, mean_q: 1.919742, mean_eps: 0.509237\n",
            " 546264/1000000: episode: 767, duration: 21.571s, episode steps: 598, steps per second:  28, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.806 [0.000, 5.000],  loss: 0.012193, mae: 1.558608, mean_q: 1.899126, mean_eps: 0.508632\n",
            " 547100/1000000: episode: 768, duration: 29.928s, episode steps: 836, steps per second:  28, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.013569, mae: 1.577802, mean_q: 1.920712, mean_eps: 0.507988\n",
            " 548354/1000000: episode: 769, duration: 45.083s, episode steps: 1254, steps per second:  28, episode reward: 28.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.014183, mae: 1.562438, mean_q: 1.902019, mean_eps: 0.507047\n",
            " 549359/1000000: episode: 770, duration: 36.157s, episode steps: 1005, steps per second:  28, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.012006, mae: 1.578028, mean_q: 1.920979, mean_eps: 0.506030\n",
            " 550276/1000000: episode: 771, duration: 33.386s, episode steps: 917, steps per second:  27, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.012908, mae: 1.586534, mean_q: 1.931748, mean_eps: 0.505166\n",
            " 550735/1000000: episode: 772, duration: 16.567s, episode steps: 459, steps per second:  28, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.012476, mae: 1.629215, mean_q: 1.987332, mean_eps: 0.504546\n",
            " 551514/1000000: episode: 773, duration: 28.322s, episode steps: 779, steps per second:  28, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.012371, mae: 1.627172, mean_q: 1.980013, mean_eps: 0.503988\n",
            " 552559/1000000: episode: 774, duration: 37.657s, episode steps: 1045, steps per second:  28, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.013668, mae: 1.619997, mean_q: 1.971753, mean_eps: 0.503168\n",
            " 553206/1000000: episode: 775, duration: 23.452s, episode steps: 647, steps per second:  28, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.014355, mae: 1.624421, mean_q: 1.979111, mean_eps: 0.502406\n",
            " 554011/1000000: episode: 776, duration: 29.005s, episode steps: 805, steps per second:  28, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.245 [0.000, 5.000],  loss: 0.013598, mae: 1.621901, mean_q: 1.974434, mean_eps: 0.501753\n",
            " 554754/1000000: episode: 777, duration: 26.814s, episode steps: 743, steps per second:  28, episode reward: 20.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.012600, mae: 1.645821, mean_q: 2.004396, mean_eps: 0.501056\n",
            " 555150/1000000: episode: 778, duration: 14.262s, episode steps: 396, steps per second:  28, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.096 [0.000, 5.000],  loss: 0.012179, mae: 1.597970, mean_q: 1.948156, mean_eps: 0.500543\n",
            " 555805/1000000: episode: 779, duration: 23.722s, episode steps: 655, steps per second:  28, episode reward: 17.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.012294, mae: 1.631362, mean_q: 1.988768, mean_eps: 0.500070\n",
            " 556534/1000000: episode: 780, duration: 26.305s, episode steps: 729, steps per second:  28, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.012847, mae: 1.611628, mean_q: 1.962457, mean_eps: 0.499447\n",
            " 557694/1000000: episode: 781, duration: 42.048s, episode steps: 1160, steps per second:  28, episode reward: 29.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.014290, mae: 1.613443, mean_q: 1.964920, mean_eps: 0.498597\n",
            " 558396/1000000: episode: 782, duration: 25.284s, episode steps: 702, steps per second:  28, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.013942, mae: 1.625309, mean_q: 1.977846, mean_eps: 0.497760\n",
            " 559308/1000000: episode: 783, duration: 32.909s, episode steps: 912, steps per second:  28, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.755 [0.000, 5.000],  loss: 0.013506, mae: 1.626567, mean_q: 1.979126, mean_eps: 0.497035\n",
            " 559945/1000000: episode: 784, duration: 23.104s, episode steps: 637, steps per second:  28, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.160 [0.000, 5.000],  loss: 0.014095, mae: 1.638495, mean_q: 1.996067, mean_eps: 0.496337\n",
            " 561038/1000000: episode: 785, duration: 39.363s, episode steps: 1093, steps per second:  28, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.014488, mae: 1.653133, mean_q: 2.012502, mean_eps: 0.495557\n",
            " 561839/1000000: episode: 786, duration: 28.823s, episode steps: 801, steps per second:  28, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.013742, mae: 1.662602, mean_q: 2.024334, mean_eps: 0.494706\n",
            " 562358/1000000: episode: 787, duration: 18.973s, episode steps: 519, steps per second:  27, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.012969, mae: 1.645608, mean_q: 2.001855, mean_eps: 0.494112\n",
            " 563199/1000000: episode: 788, duration: 30.283s, episode steps: 841, steps per second:  28, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.012657, mae: 1.659114, mean_q: 2.019265, mean_eps: 0.493500\n",
            " 563958/1000000: episode: 789, duration: 27.283s, episode steps: 759, steps per second:  28, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.014746, mae: 1.672488, mean_q: 2.036652, mean_eps: 0.492780\n",
            " 564655/1000000: episode: 790, duration: 25.304s, episode steps: 697, steps per second:  28, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.139 [0.000, 5.000],  loss: 0.013011, mae: 1.633480, mean_q: 1.988091, mean_eps: 0.492125\n",
            " 565192/1000000: episode: 791, duration: 19.779s, episode steps: 537, steps per second:  27, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.013308, mae: 1.670917, mean_q: 2.033980, mean_eps: 0.491570\n",
            " 565698/1000000: episode: 792, duration: 18.442s, episode steps: 506, steps per second:  27, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.013553, mae: 1.653747, mean_q: 2.014298, mean_eps: 0.491100\n",
            " 566442/1000000: episode: 793, duration: 27.348s, episode steps: 744, steps per second:  27, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.013164, mae: 1.654327, mean_q: 2.014158, mean_eps: 0.490537\n",
            " 567600/1000000: episode: 794, duration: 42.379s, episode steps: 1158, steps per second:  27, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.013824, mae: 1.644306, mean_q: 2.003444, mean_eps: 0.489682\n",
            " 568459/1000000: episode: 795, duration: 31.619s, episode steps: 859, steps per second:  27, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.016382, mae: 1.645413, mean_q: 2.002737, mean_eps: 0.488775\n",
            " 569143/1000000: episode: 796, duration: 24.954s, episode steps: 684, steps per second:  27, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.015313, mae: 1.648624, mean_q: 2.007068, mean_eps: 0.488080\n",
            " 569834/1000000: episode: 797, duration: 24.926s, episode steps: 691, steps per second:  28, episode reward: 18.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.014144, mae: 1.657960, mean_q: 2.020432, mean_eps: 0.487461\n",
            " 570644/1000000: episode: 798, duration: 29.346s, episode steps: 810, steps per second:  28, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.188 [0.000, 5.000],  loss: 0.012524, mae: 1.671871, mean_q: 2.036164, mean_eps: 0.486786\n",
            " 571258/1000000: episode: 799, duration: 22.903s, episode steps: 614, steps per second:  27, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.013029, mae: 1.688037, mean_q: 2.054418, mean_eps: 0.486145\n",
            " 572134/1000000: episode: 800, duration: 31.860s, episode steps: 876, steps per second:  27, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.013107, mae: 1.673667, mean_q: 2.036843, mean_eps: 0.485474\n",
            " 572935/1000000: episode: 801, duration: 28.879s, episode steps: 801, steps per second:  28, episode reward: 24.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.013588, mae: 1.681302, mean_q: 2.046011, mean_eps: 0.484719\n",
            " 574533/1000000: episode: 802, duration: 57.510s, episode steps: 1598, steps per second:  28, episode reward: 36.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.014472, mae: 1.693830, mean_q: 2.061894, mean_eps: 0.483639\n",
            " 575400/1000000: episode: 803, duration: 31.136s, episode steps: 867, steps per second:  28, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.014706, mae: 1.703911, mean_q: 2.073034, mean_eps: 0.482531\n",
            " 575899/1000000: episode: 804, duration: 17.986s, episode steps: 499, steps per second:  28, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.012483, mae: 1.667946, mean_q: 2.031211, mean_eps: 0.481917\n",
            " 576711/1000000: episode: 805, duration: 29.207s, episode steps: 812, steps per second:  28, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.142 [0.000, 5.000],  loss: 0.013679, mae: 1.708014, mean_q: 2.079671, mean_eps: 0.481326\n",
            " 577559/1000000: episode: 806, duration: 30.814s, episode steps: 848, steps per second:  28, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.014559, mae: 1.699006, mean_q: 2.067722, mean_eps: 0.480579\n",
            " 578168/1000000: episode: 807, duration: 23.454s, episode steps: 609, steps per second:  26, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.014936, mae: 1.697429, mean_q: 2.065114, mean_eps: 0.479924\n",
            " 579090/1000000: episode: 808, duration: 35.123s, episode steps: 922, steps per second:  26, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.014038, mae: 1.701113, mean_q: 2.071594, mean_eps: 0.479235\n",
            " 579592/1000000: episode: 809, duration: 19.101s, episode steps: 502, steps per second:  26, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.014031, mae: 1.686336, mean_q: 2.052189, mean_eps: 0.478594\n",
            " 580151/1000000: episode: 810, duration: 21.277s, episode steps: 559, steps per second:  26, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.012824, mae: 1.716052, mean_q: 2.091223, mean_eps: 0.478117\n",
            " 581251/1000000: episode: 811, duration: 41.509s, episode steps: 1100, steps per second:  27, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.079 [0.000, 5.000],  loss: 0.013723, mae: 1.741343, mean_q: 2.120477, mean_eps: 0.477370\n",
            " 581927/1000000: episode: 812, duration: 25.620s, episode steps: 676, steps per second:  26, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.013680, mae: 1.729682, mean_q: 2.104593, mean_eps: 0.476571\n",
            " 582652/1000000: episode: 813, duration: 27.627s, episode steps: 725, steps per second:  26, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.014292, mae: 1.721485, mean_q: 2.093865, mean_eps: 0.475941\n",
            " 583559/1000000: episode: 814, duration: 34.466s, episode steps: 907, steps per second:  26, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.014238, mae: 1.729223, mean_q: 2.102990, mean_eps: 0.475206\n",
            " 584175/1000000: episode: 815, duration: 23.492s, episode steps: 616, steps per second:  26, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: 0.014137, mae: 1.734310, mean_q: 2.110268, mean_eps: 0.474521\n",
            " 585147/1000000: episode: 816, duration: 36.711s, episode steps: 972, steps per second:  26, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.015153, mae: 1.733409, mean_q: 2.108447, mean_eps: 0.473806\n",
            " 585654/1000000: episode: 817, duration: 19.279s, episode steps: 507, steps per second:  26, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.012802, mae: 1.735501, mean_q: 2.112080, mean_eps: 0.473140\n",
            " 586151/1000000: episode: 818, duration: 18.901s, episode steps: 497, steps per second:  26, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.011909, mae: 1.711597, mean_q: 2.082634, mean_eps: 0.472688\n",
            " 586685/1000000: episode: 819, duration: 20.372s, episode steps: 534, steps per second:  26, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.014382, mae: 1.727027, mean_q: 2.101782, mean_eps: 0.472224\n",
            " 588251/1000000: episode: 820, duration: 59.726s, episode steps: 1566, steps per second:  26, episode reward: 20.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: 0.014866, mae: 1.726766, mean_q: 2.102430, mean_eps: 0.471279\n",
            " 588962/1000000: episode: 821, duration: 26.737s, episode steps: 711, steps per second:  27, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.016737, mae: 1.714886, mean_q: 2.085113, mean_eps: 0.470255\n",
            " 589765/1000000: episode: 822, duration: 29.092s, episode steps: 803, steps per second:  28, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.014286, mae: 1.739365, mean_q: 2.115902, mean_eps: 0.469572\n",
            " 590321/1000000: episode: 823, duration: 20.155s, episode steps: 556, steps per second:  28, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.013780, mae: 1.742927, mean_q: 2.122619, mean_eps: 0.468960\n",
            " 591197/1000000: episode: 824, duration: 33.585s, episode steps: 876, steps per second:  26, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.012597, mae: 1.773056, mean_q: 2.158416, mean_eps: 0.468316\n",
            " 592697/1000000: episode: 825, duration: 57.877s, episode steps: 1500, steps per second:  26, episode reward: 32.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.013993, mae: 1.772477, mean_q: 2.157762, mean_eps: 0.467247\n",
            " 593414/1000000: episode: 826, duration: 27.287s, episode steps: 717, steps per second:  26, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.014257, mae: 1.766438, mean_q: 2.147925, mean_eps: 0.466250\n",
            " 593960/1000000: episode: 827, duration: 20.995s, episode steps: 546, steps per second:  26, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.172 [0.000, 5.000],  loss: 0.016098, mae: 1.785983, mean_q: 2.171381, mean_eps: 0.465683\n",
            " 594640/1000000: episode: 828, duration: 26.159s, episode steps: 680, steps per second:  26, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.013771, mae: 1.767692, mean_q: 2.151907, mean_eps: 0.465132\n",
            " 595032/1000000: episode: 829, duration: 15.219s, episode steps: 392, steps per second:  26, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.115 [0.000, 5.000],  loss: 0.013003, mae: 1.760838, mean_q: 2.142618, mean_eps: 0.464649\n",
            " 595777/1000000: episode: 830, duration: 28.537s, episode steps: 745, steps per second:  26, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.779 [0.000, 5.000],  loss: 0.013086, mae: 1.749011, mean_q: 2.129327, mean_eps: 0.464136\n",
            " 596407/1000000: episode: 831, duration: 24.217s, episode steps: 630, steps per second:  26, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.015374, mae: 1.776947, mean_q: 2.163348, mean_eps: 0.463517\n",
            " 597845/1000000: episode: 832, duration: 55.266s, episode steps: 1438, steps per second:  26, episode reward: 34.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.258 [0.000, 5.000],  loss: 0.014195, mae: 1.765278, mean_q: 2.146888, mean_eps: 0.462587\n",
            " 598468/1000000: episode: 833, duration: 24.254s, episode steps: 623, steps per second:  26, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: 0.012522, mae: 1.772477, mean_q: 2.156732, mean_eps: 0.461660\n",
            " 599651/1000000: episode: 834, duration: 45.760s, episode steps: 1183, steps per second:  26, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.016130, mae: 1.778577, mean_q: 2.163286, mean_eps: 0.460848\n",
            " 600885/1000000: episode: 835, duration: 47.657s, episode steps: 1234, steps per second:  26, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.013941, mae: 1.784008, mean_q: 2.171664, mean_eps: 0.459759\n",
            " 601794/1000000: episode: 836, duration: 34.092s, episode steps: 909, steps per second:  27, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: 0.014675, mae: 1.798339, mean_q: 2.188434, mean_eps: 0.458794\n",
            " 602429/1000000: episode: 837, duration: 23.123s, episode steps: 635, steps per second:  27, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.013908, mae: 1.790131, mean_q: 2.177070, mean_eps: 0.458099\n",
            " 602926/1000000: episode: 838, duration: 18.358s, episode steps: 497, steps per second:  27, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.151 [0.000, 5.000],  loss: 0.012827, mae: 1.785895, mean_q: 2.170298, mean_eps: 0.457590\n",
            " 603383/1000000: episode: 839, duration: 16.985s, episode steps: 457, steps per second:  27, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.046 [0.000, 5.000],  loss: 0.013386, mae: 1.807698, mean_q: 2.198604, mean_eps: 0.457161\n",
            " 604570/1000000: episode: 840, duration: 44.151s, episode steps: 1187, steps per second:  27, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.100 [0.000, 5.000],  loss: 0.015300, mae: 1.794287, mean_q: 2.181677, mean_eps: 0.456422\n",
            " 605261/1000000: episode: 841, duration: 25.285s, episode steps: 691, steps per second:  27, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.130 [0.000, 5.000],  loss: 0.013858, mae: 1.805371, mean_q: 2.196064, mean_eps: 0.455576\n",
            " 605648/1000000: episode: 842, duration: 14.263s, episode steps: 387, steps per second:  27, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.015334, mae: 1.798376, mean_q: 2.190869, mean_eps: 0.455091\n",
            " 606596/1000000: episode: 843, duration: 34.709s, episode steps: 948, steps per second:  27, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.013225, mae: 1.803944, mean_q: 2.195886, mean_eps: 0.454492\n",
            " 607104/1000000: episode: 844, duration: 18.700s, episode steps: 508, steps per second:  27, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.012735, mae: 1.801692, mean_q: 2.193472, mean_eps: 0.453837\n",
            " 607719/1000000: episode: 845, duration: 22.739s, episode steps: 615, steps per second:  27, episode reward: 16.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.972 [0.000, 5.000],  loss: 0.014160, mae: 1.802303, mean_q: 2.191284, mean_eps: 0.453331\n",
            " 608324/1000000: episode: 846, duration: 22.346s, episode steps: 605, steps per second:  27, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.013657, mae: 1.803183, mean_q: 2.193297, mean_eps: 0.452782\n",
            " 609040/1000000: episode: 847, duration: 26.228s, episode steps: 716, steps per second:  27, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.131 [0.000, 5.000],  loss: 0.014103, mae: 1.808768, mean_q: 2.200019, mean_eps: 0.452188\n",
            " 609837/1000000: episode: 848, duration: 29.217s, episode steps: 797, steps per second:  27, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.014392, mae: 1.793352, mean_q: 2.180749, mean_eps: 0.451506\n",
            " 610526/1000000: episode: 849, duration: 25.184s, episode steps: 689, steps per second:  27, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.174 [0.000, 5.000],  loss: 0.014469, mae: 1.858840, mean_q: 2.259527, mean_eps: 0.450836\n",
            " 611388/1000000: episode: 850, duration: 31.851s, episode steps: 862, steps per second:  27, episode reward: 22.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.015449, mae: 1.877338, mean_q: 2.282901, mean_eps: 0.450140\n",
            " 612063/1000000: episode: 851, duration: 24.692s, episode steps: 675, steps per second:  27, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.014473, mae: 1.897467, mean_q: 2.306758, mean_eps: 0.449448\n",
            " 612976/1000000: episode: 852, duration: 33.458s, episode steps: 913, steps per second:  27, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.013666, mae: 1.874670, mean_q: 2.278589, mean_eps: 0.448734\n",
            " 613817/1000000: episode: 853, duration: 31.049s, episode steps: 841, steps per second:  27, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: 0.013783, mae: 1.885293, mean_q: 2.291467, mean_eps: 0.447944\n",
            " 614390/1000000: episode: 854, duration: 21.236s, episode steps: 573, steps per second:  27, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.017513, mae: 1.888520, mean_q: 2.293883, mean_eps: 0.447306\n",
            " 614867/1000000: episode: 855, duration: 17.570s, episode steps: 477, steps per second:  27, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.014376, mae: 1.875575, mean_q: 2.279143, mean_eps: 0.446835\n",
            " 615753/1000000: episode: 856, duration: 32.616s, episode steps: 886, steps per second:  27, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.113 [0.000, 5.000],  loss: 0.013752, mae: 1.879109, mean_q: 2.283042, mean_eps: 0.446221\n",
            " 616284/1000000: episode: 857, duration: 19.637s, episode steps: 531, steps per second:  27, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.151 [0.000, 5.000],  loss: 0.014013, mae: 1.885920, mean_q: 2.291490, mean_eps: 0.445584\n",
            " 616858/1000000: episode: 858, duration: 21.432s, episode steps: 574, steps per second:  27, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.015539, mae: 1.899285, mean_q: 2.308416, mean_eps: 0.445087\n",
            " 617397/1000000: episode: 859, duration: 19.927s, episode steps: 539, steps per second:  27, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.015602, mae: 1.885918, mean_q: 2.293679, mean_eps: 0.444585\n",
            " 618059/1000000: episode: 860, duration: 24.251s, episode steps: 662, steps per second:  27, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.159 [0.000, 5.000],  loss: 0.015194, mae: 1.895096, mean_q: 2.303216, mean_eps: 0.444045\n",
            " 618723/1000000: episode: 861, duration: 24.431s, episode steps: 664, steps per second:  27, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.014649, mae: 1.894088, mean_q: 2.301718, mean_eps: 0.443449\n",
            " 619524/1000000: episode: 862, duration: 29.597s, episode steps: 801, steps per second:  27, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.016191, mae: 1.868101, mean_q: 2.268626, mean_eps: 0.442790\n",
            " 619992/1000000: episode: 863, duration: 17.533s, episode steps: 468, steps per second:  27, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.013222, mae: 1.849750, mean_q: 2.248410, mean_eps: 0.442220\n",
            " 620643/1000000: episode: 864, duration: 23.943s, episode steps: 651, steps per second:  27, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.143 [0.000, 5.000],  loss: 0.016177, mae: 1.918766, mean_q: 2.332656, mean_eps: 0.441716\n",
            " 621537/1000000: episode: 865, duration: 32.840s, episode steps: 894, steps per second:  27, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.013292, mae: 1.893235, mean_q: 2.301798, mean_eps: 0.441019\n",
            " 621998/1000000: episode: 866, duration: 16.992s, episode steps: 461, steps per second:  27, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.106 [0.000, 5.000],  loss: 0.016193, mae: 1.919826, mean_q: 2.332936, mean_eps: 0.440409\n",
            " 623072/1000000: episode: 867, duration: 39.968s, episode steps: 1074, steps per second:  27, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.015163, mae: 1.914463, mean_q: 2.325904, mean_eps: 0.439719\n",
            " 624059/1000000: episode: 868, duration: 36.713s, episode steps: 987, steps per second:  27, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.014825, mae: 1.925452, mean_q: 2.339812, mean_eps: 0.438792\n",
            " 624708/1000000: episode: 869, duration: 24.080s, episode steps: 649, steps per second:  27, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.157 [0.000, 5.000],  loss: 0.014034, mae: 1.917764, mean_q: 2.329903, mean_eps: 0.438056\n",
            " 625243/1000000: episode: 870, duration: 19.877s, episode steps: 535, steps per second:  27, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.015666, mae: 1.914154, mean_q: 2.328385, mean_eps: 0.437523\n",
            " 625714/1000000: episode: 871, duration: 17.304s, episode steps: 471, steps per second:  27, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.013681, mae: 1.912488, mean_q: 2.324801, mean_eps: 0.437070\n",
            " 626270/1000000: episode: 872, duration: 20.511s, episode steps: 556, steps per second:  27, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.016631, mae: 1.902626, mean_q: 2.313520, mean_eps: 0.436607\n",
            " 626663/1000000: episode: 873, duration: 14.528s, episode steps: 393, steps per second:  27, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.014582, mae: 1.917256, mean_q: 2.331439, mean_eps: 0.436181\n",
            " 627348/1000000: episode: 874, duration: 25.553s, episode steps: 685, steps per second:  27, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.013001, mae: 1.906099, mean_q: 2.315450, mean_eps: 0.435696\n",
            " 628024/1000000: episode: 875, duration: 25.269s, episode steps: 676, steps per second:  27, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.015587, mae: 1.922468, mean_q: 2.334174, mean_eps: 0.435084\n",
            " 628635/1000000: episode: 876, duration: 22.566s, episode steps: 611, steps per second:  27, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.015205, mae: 1.909848, mean_q: 2.318745, mean_eps: 0.434505\n",
            " 629302/1000000: episode: 877, duration: 24.700s, episode steps: 667, steps per second:  27, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.016514, mae: 1.917433, mean_q: 2.328561, mean_eps: 0.433929\n",
            " 630120/1000000: episode: 878, duration: 30.473s, episode steps: 818, steps per second:  27, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.014150, mae: 1.913811, mean_q: 2.324419, mean_eps: 0.433261\n",
            " 630946/1000000: episode: 879, duration: 30.828s, episode steps: 826, steps per second:  27, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.015551, mae: 1.926604, mean_q: 2.340748, mean_eps: 0.432521\n",
            " 631979/1000000: episode: 880, duration: 38.512s, episode steps: 1033, steps per second:  27, episode reward: 26.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.016658, mae: 1.949741, mean_q: 2.368541, mean_eps: 0.431684\n",
            " 632672/1000000: episode: 881, duration: 25.748s, episode steps: 693, steps per second:  27, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.014308, mae: 1.910678, mean_q: 2.323206, mean_eps: 0.430908\n",
            " 633463/1000000: episode: 882, duration: 29.512s, episode steps: 791, steps per second:  27, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.015283, mae: 1.916143, mean_q: 2.327516, mean_eps: 0.430241\n",
            " 634096/1000000: episode: 883, duration: 23.793s, episode steps: 633, steps per second:  27, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.057 [0.000, 5.000],  loss: 0.015261, mae: 1.926960, mean_q: 2.340069, mean_eps: 0.429600\n",
            " 634828/1000000: episode: 884, duration: 29.275s, episode steps: 732, steps per second:  25, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.966 [0.000, 5.000],  loss: 0.013716, mae: 1.924336, mean_q: 2.336591, mean_eps: 0.428986\n",
            " 635472/1000000: episode: 885, duration: 24.966s, episode steps: 644, steps per second:  26, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.034 [0.000, 5.000],  loss: 0.013869, mae: 1.913671, mean_q: 2.322502, mean_eps: 0.428367\n",
            " 636068/1000000: episode: 886, duration: 22.494s, episode steps: 596, steps per second:  26, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.014098, mae: 1.930343, mean_q: 2.342982, mean_eps: 0.427809\n",
            " 636623/1000000: episode: 887, duration: 20.942s, episode steps: 555, steps per second:  27, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.103 [0.000, 5.000],  loss: 0.016115, mae: 1.941162, mean_q: 2.357830, mean_eps: 0.427290\n",
            " 637443/1000000: episode: 888, duration: 30.713s, episode steps: 820, steps per second:  27, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.016830, mae: 1.926490, mean_q: 2.339037, mean_eps: 0.426671\n",
            " 637906/1000000: episode: 889, duration: 17.433s, episode steps: 463, steps per second:  27, episode reward: 10.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.829 [0.000, 5.000],  loss: 0.013111, mae: 1.915808, mean_q: 2.327532, mean_eps: 0.426093\n",
            " 638606/1000000: episode: 890, duration: 26.223s, episode steps: 700, steps per second:  27, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.015226, mae: 1.941165, mean_q: 2.358002, mean_eps: 0.425570\n",
            " 639272/1000000: episode: 891, duration: 24.822s, episode steps: 666, steps per second:  27, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.016428, mae: 1.939703, mean_q: 2.356334, mean_eps: 0.424956\n",
            " 640051/1000000: episode: 892, duration: 29.182s, episode steps: 779, steps per second:  27, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.014203, mae: 1.929883, mean_q: 2.343112, mean_eps: 0.424306\n",
            " 640453/1000000: episode: 893, duration: 15.276s, episode steps: 402, steps per second:  26, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.838 [0.000, 5.000],  loss: 0.011665, mae: 1.891837, mean_q: 2.298610, mean_eps: 0.423773\n",
            " 640813/1000000: episode: 894, duration: 13.532s, episode steps: 360, steps per second:  27, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.017305, mae: 1.944547, mean_q: 2.361638, mean_eps: 0.423429\n",
            " 641338/1000000: episode: 895, duration: 19.515s, episode steps: 525, steps per second:  27, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.014463, mae: 1.946852, mean_q: 2.362931, mean_eps: 0.423032\n",
            " 641988/1000000: episode: 896, duration: 24.323s, episode steps: 650, steps per second:  27, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.015984, mae: 1.924456, mean_q: 2.338312, mean_eps: 0.422504\n",
            " 642742/1000000: episode: 897, duration: 28.446s, episode steps: 754, steps per second:  27, episode reward: 20.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.013565, mae: 1.921333, mean_q: 2.333197, mean_eps: 0.421872\n",
            " 643323/1000000: episode: 898, duration: 21.505s, episode steps: 581, steps per second:  27, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.015464, mae: 1.938506, mean_q: 2.351251, mean_eps: 0.421271\n",
            " 644287/1000000: episode: 899, duration: 35.972s, episode steps: 964, steps per second:  27, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.033 [0.000, 5.000],  loss: 0.013799, mae: 1.942566, mean_q: 2.359038, mean_eps: 0.420576\n",
            " 644824/1000000: episode: 900, duration: 20.093s, episode steps: 537, steps per second:  27, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.816 [0.000, 5.000],  loss: 0.014825, mae: 1.914782, mean_q: 2.325655, mean_eps: 0.419901\n",
            " 645329/1000000: episode: 901, duration: 18.930s, episode steps: 505, steps per second:  27, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.014116, mae: 1.906217, mean_q: 2.316259, mean_eps: 0.419432\n",
            " 645986/1000000: episode: 902, duration: 24.413s, episode steps: 657, steps per second:  27, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.014025, mae: 1.925118, mean_q: 2.337366, mean_eps: 0.418908\n",
            " 646625/1000000: episode: 903, duration: 23.846s, episode steps: 639, steps per second:  27, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.070 [0.000, 5.000],  loss: 0.014118, mae: 1.932239, mean_q: 2.345359, mean_eps: 0.418325\n",
            " 647567/1000000: episode: 904, duration: 35.104s, episode steps: 942, steps per second:  27, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: 0.015177, mae: 1.934603, mean_q: 2.348234, mean_eps: 0.417614\n",
            " 648122/1000000: episode: 905, duration: 21.042s, episode steps: 555, steps per second:  26, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.013491, mae: 1.910695, mean_q: 2.320401, mean_eps: 0.416940\n",
            " 649081/1000000: episode: 906, duration: 35.677s, episode steps: 959, steps per second:  27, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.015137, mae: 1.925947, mean_q: 2.339363, mean_eps: 0.416258\n",
            " 649804/1000000: episode: 907, duration: 26.837s, episode steps: 723, steps per second:  27, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.016321, mae: 1.924056, mean_q: 2.334132, mean_eps: 0.415502\n",
            " 650768/1000000: episode: 908, duration: 35.769s, episode steps: 964, steps per second:  27, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.013463, mae: 1.931692, mean_q: 2.346685, mean_eps: 0.414744\n",
            " 651633/1000000: episode: 909, duration: 32.248s, episode steps: 865, steps per second:  27, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.014995, mae: 1.945062, mean_q: 2.362553, mean_eps: 0.413920\n",
            " 652398/1000000: episode: 910, duration: 28.253s, episode steps: 765, steps per second:  27, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.016031, mae: 1.953025, mean_q: 2.370466, mean_eps: 0.413186\n",
            " 653231/1000000: episode: 911, duration: 31.106s, episode steps: 833, steps per second:  27, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.216 [0.000, 5.000],  loss: 0.014717, mae: 1.945773, mean_q: 2.362830, mean_eps: 0.412467\n",
            " 653841/1000000: episode: 912, duration: 23.173s, episode steps: 610, steps per second:  26, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.015398, mae: 1.969436, mean_q: 2.390100, mean_eps: 0.411818\n",
            " 654508/1000000: episode: 913, duration: 25.025s, episode steps: 667, steps per second:  27, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.015669, mae: 1.992322, mean_q: 2.417310, mean_eps: 0.411243\n",
            " 654852/1000000: episode: 914, duration: 13.114s, episode steps: 344, steps per second:  26, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.014740, mae: 1.961248, mean_q: 2.381009, mean_eps: 0.410790\n",
            " 656038/1000000: episode: 915, duration: 44.717s, episode steps: 1186, steps per second:  27, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.157 [0.000, 5.000],  loss: 0.015344, mae: 1.954686, mean_q: 2.372910, mean_eps: 0.410100\n",
            " 656830/1000000: episode: 916, duration: 29.743s, episode steps: 792, steps per second:  27, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.139 [0.000, 5.000],  loss: 0.016100, mae: 1.976565, mean_q: 2.400026, mean_eps: 0.409209\n",
            " 657391/1000000: episode: 917, duration: 20.993s, episode steps: 561, steps per second:  27, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.015592, mae: 1.941482, mean_q: 2.356793, mean_eps: 0.408601\n",
            " 658133/1000000: episode: 918, duration: 27.815s, episode steps: 742, steps per second:  27, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.013326, mae: 1.960873, mean_q: 2.381293, mean_eps: 0.408014\n",
            " 658645/1000000: episode: 919, duration: 19.214s, episode steps: 512, steps per second:  27, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.016602, mae: 1.944951, mean_q: 2.360661, mean_eps: 0.407449\n",
            " 659519/1000000: episode: 920, duration: 32.562s, episode steps: 874, steps per second:  27, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.014838, mae: 1.955035, mean_q: 2.373252, mean_eps: 0.406826\n",
            " 660164/1000000: episode: 921, duration: 24.214s, episode steps: 645, steps per second:  27, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.016356, mae: 1.983313, mean_q: 2.407540, mean_eps: 0.406144\n",
            " 660812/1000000: episode: 922, duration: 24.357s, episode steps: 648, steps per second:  27, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.012742, mae: 2.006868, mean_q: 2.436620, mean_eps: 0.405563\n",
            " 661312/1000000: episode: 923, duration: 18.702s, episode steps: 500, steps per second:  27, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.015320, mae: 2.004232, mean_q: 2.433205, mean_eps: 0.405046\n",
            " 662541/1000000: episode: 924, duration: 46.069s, episode steps: 1229, steps per second:  27, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.014892, mae: 2.009637, mean_q: 2.438115, mean_eps: 0.404267\n",
            " 663184/1000000: episode: 925, duration: 24.335s, episode steps: 643, steps per second:  26, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.014757, mae: 2.017879, mean_q: 2.447658, mean_eps: 0.403424\n",
            " 664445/1000000: episode: 926, duration: 47.617s, episode steps: 1261, steps per second:  26, episode reward: 31.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.014874, mae: 1.999981, mean_q: 2.428499, mean_eps: 0.402567\n",
            " 664923/1000000: episode: 927, duration: 17.912s, episode steps: 478, steps per second:  27, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.011646, mae: 2.008923, mean_q: 2.440305, mean_eps: 0.401784\n",
            " 665545/1000000: episode: 928, duration: 23.464s, episode steps: 622, steps per second:  27, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.014927, mae: 2.020966, mean_q: 2.452854, mean_eps: 0.401289\n",
            " 667143/1000000: episode: 929, duration: 59.781s, episode steps: 1598, steps per second:  27, episode reward: 25.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.014407, mae: 2.003778, mean_q: 2.431739, mean_eps: 0.400290\n",
            " 667800/1000000: episode: 930, duration: 24.783s, episode steps: 657, steps per second:  27, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.017146, mae: 2.024123, mean_q: 2.454002, mean_eps: 0.399277\n",
            " 668542/1000000: episode: 931, duration: 28.090s, episode steps: 742, steps per second:  26, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.014796, mae: 1.982208, mean_q: 2.404918, mean_eps: 0.398647\n",
            " 669038/1000000: episode: 932, duration: 18.694s, episode steps: 496, steps per second:  27, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.016607, mae: 2.034319, mean_q: 2.469068, mean_eps: 0.398089\n",
            " 669872/1000000: episode: 933, duration: 31.369s, episode steps: 834, steps per second:  27, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.145 [0.000, 5.000],  loss: 0.014043, mae: 2.007159, mean_q: 2.435897, mean_eps: 0.397491\n",
            " 670588/1000000: episode: 934, duration: 27.172s, episode steps: 716, steps per second:  26, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.014452, mae: 2.011767, mean_q: 2.441126, mean_eps: 0.396795\n",
            " 671091/1000000: episode: 935, duration: 18.754s, episode steps: 503, steps per second:  27, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.016869, mae: 2.044899, mean_q: 2.480326, mean_eps: 0.396246\n",
            " 671553/1000000: episode: 936, duration: 17.608s, episode steps: 462, steps per second:  26, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.013092, mae: 2.039362, mean_q: 2.475595, mean_eps: 0.395810\n",
            " 672635/1000000: episode: 937, duration: 40.804s, episode steps: 1082, steps per second:  27, episode reward: 28.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.016801, mae: 2.036159, mean_q: 2.468742, mean_eps: 0.395115\n",
            " 673468/1000000: episode: 938, duration: 31.708s, episode steps: 833, steps per second:  26, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: 0.014328, mae: 2.040777, mean_q: 2.475773, mean_eps: 0.394255\n",
            " 673839/1000000: episode: 939, duration: 14.138s, episode steps: 371, steps per second:  26, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.014436, mae: 2.070692, mean_q: 2.512931, mean_eps: 0.393713\n",
            " 674983/1000000: episode: 940, duration: 43.209s, episode steps: 1144, steps per second:  26, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.768 [0.000, 5.000],  loss: 0.015644, mae: 2.037672, mean_q: 2.472559, mean_eps: 0.393031\n",
            " 676211/1000000: episode: 941, duration: 46.465s, episode steps: 1228, steps per second:  26, episode reward: 33.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.014924, mae: 2.032376, mean_q: 2.465232, mean_eps: 0.391964\n",
            " 677328/1000000: episode: 942, duration: 42.315s, episode steps: 1117, steps per second:  26, episode reward: 30.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.016341, mae: 2.052065, mean_q: 2.488375, mean_eps: 0.390909\n",
            " 678288/1000000: episode: 943, duration: 36.500s, episode steps: 960, steps per second:  26, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.015379, mae: 2.037204, mean_q: 2.470316, mean_eps: 0.389975\n",
            " 679136/1000000: episode: 944, duration: 32.334s, episode steps: 848, steps per second:  26, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.014896, mae: 2.029521, mean_q: 2.460687, mean_eps: 0.389161\n",
            " 679838/1000000: episode: 945, duration: 26.781s, episode steps: 702, steps per second:  26, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.859 [0.000, 5.000],  loss: 0.017017, mae: 2.061898, mean_q: 2.498868, mean_eps: 0.388463\n",
            " 680977/1000000: episode: 946, duration: 43.198s, episode steps: 1139, steps per second:  26, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.014838, mae: 2.073124, mean_q: 2.513746, mean_eps: 0.387633\n",
            " 682095/1000000: episode: 947, duration: 42.031s, episode steps: 1118, steps per second:  27, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.015646, mae: 2.069099, mean_q: 2.511174, mean_eps: 0.386618\n",
            " 683171/1000000: episode: 948, duration: 40.177s, episode steps: 1076, steps per second:  27, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.016228, mae: 2.066647, mean_q: 2.505173, mean_eps: 0.385631\n",
            " 684316/1000000: episode: 949, duration: 42.885s, episode steps: 1145, steps per second:  27, episode reward: 27.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.015354, mae: 2.091084, mean_q: 2.535534, mean_eps: 0.384632\n",
            " 685191/1000000: episode: 950, duration: 32.764s, episode steps: 875, steps per second:  27, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.016900, mae: 2.093461, mean_q: 2.539634, mean_eps: 0.383723\n",
            " 686046/1000000: episode: 951, duration: 31.981s, episode steps: 855, steps per second:  27, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.016138, mae: 2.069149, mean_q: 2.510513, mean_eps: 0.382944\n",
            " 686881/1000000: episode: 952, duration: 31.377s, episode steps: 835, steps per second:  27, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.026 [0.000, 5.000],  loss: 0.016187, mae: 2.096108, mean_q: 2.542219, mean_eps: 0.382182\n",
            " 687536/1000000: episode: 953, duration: 24.838s, episode steps: 655, steps per second:  26, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.797 [0.000, 5.000],  loss: 0.016789, mae: 2.083818, mean_q: 2.527301, mean_eps: 0.381513\n",
            " 688571/1000000: episode: 954, duration: 38.768s, episode steps: 1035, steps per second:  27, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.183 [0.000, 5.000],  loss: 0.015743, mae: 2.065370, mean_q: 2.504784, mean_eps: 0.380753\n",
            " 689137/1000000: episode: 955, duration: 21.276s, episode steps: 566, steps per second:  27, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.016914, mae: 2.098933, mean_q: 2.544605, mean_eps: 0.380031\n",
            " 689817/1000000: episode: 956, duration: 25.465s, episode steps: 680, steps per second:  27, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.015620, mae: 2.085244, mean_q: 2.531335, mean_eps: 0.379470\n",
            " 691057/1000000: episode: 957, duration: 46.592s, episode steps: 1240, steps per second:  27, episode reward: 30.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.014878, mae: 2.109202, mean_q: 2.559609, mean_eps: 0.378606\n",
            " 691475/1000000: episode: 958, duration: 15.579s, episode steps: 418, steps per second:  27, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.016586, mae: 2.150086, mean_q: 2.609230, mean_eps: 0.377861\n",
            " 692100/1000000: episode: 959, duration: 23.622s, episode steps: 625, steps per second:  26, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.015923, mae: 2.135323, mean_q: 2.588566, mean_eps: 0.377393\n",
            " 692880/1000000: episode: 960, duration: 29.438s, episode steps: 780, steps per second:  26, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.017 [0.000, 5.000],  loss: 0.014953, mae: 2.117606, mean_q: 2.566913, mean_eps: 0.376761\n",
            " 693643/1000000: episode: 961, duration: 28.571s, episode steps: 763, steps per second:  27, episode reward: 19.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.014888, mae: 2.119765, mean_q: 2.570913, mean_eps: 0.376066\n",
            " 694226/1000000: episode: 962, duration: 22.521s, episode steps: 583, steps per second:  26, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.184 [0.000, 5.000],  loss: 0.016645, mae: 2.098194, mean_q: 2.545311, mean_eps: 0.375459\n",
            " 695401/1000000: episode: 963, duration: 44.445s, episode steps: 1175, steps per second:  26, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.202 [0.000, 5.000],  loss: 0.015144, mae: 2.117624, mean_q: 2.569397, mean_eps: 0.374667\n",
            " 696179/1000000: episode: 964, duration: 29.602s, episode steps: 778, steps per second:  26, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.014470, mae: 2.108355, mean_q: 2.558919, mean_eps: 0.373789\n",
            " 696679/1000000: episode: 965, duration: 18.792s, episode steps: 500, steps per second:  27, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.074 [0.000, 5.000],  loss: 0.015165, mae: 2.132105, mean_q: 2.585987, mean_eps: 0.373215\n",
            " 697555/1000000: episode: 966, duration: 33.000s, episode steps: 876, steps per second:  27, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.014615, mae: 2.112010, mean_q: 2.562218, mean_eps: 0.372596\n",
            " 698427/1000000: episode: 967, duration: 33.224s, episode steps: 872, steps per second:  26, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.014130, mae: 2.118236, mean_q: 2.570990, mean_eps: 0.371809\n",
            " 699238/1000000: episode: 968, duration: 30.879s, episode steps: 811, steps per second:  26, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.015437, mae: 2.113650, mean_q: 2.564162, mean_eps: 0.371051\n",
            " 699930/1000000: episode: 969, duration: 26.488s, episode steps: 692, steps per second:  26, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.017530, mae: 2.136093, mean_q: 2.589955, mean_eps: 0.370374\n",
            " 700829/1000000: episode: 970, duration: 34.486s, episode steps: 899, steps per second:  26, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.015166, mae: 2.206794, mean_q: 2.678837, mean_eps: 0.369658\n",
            " 702218/1000000: episode: 971, duration: 52.639s, episode steps: 1389, steps per second:  26, episode reward: 29.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.016931, mae: 2.188521, mean_q: 2.655603, mean_eps: 0.368628\n",
            " 702900/1000000: episode: 972, duration: 26.170s, episode steps: 682, steps per second:  26, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.015581, mae: 2.198026, mean_q: 2.667258, mean_eps: 0.367698\n",
            " 703637/1000000: episode: 973, duration: 28.217s, episode steps: 737, steps per second:  26, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.014659, mae: 2.181631, mean_q: 2.648378, mean_eps: 0.367059\n",
            " 704341/1000000: episode: 974, duration: 26.512s, episode steps: 704, steps per second:  27, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.017414, mae: 2.167986, mean_q: 2.630718, mean_eps: 0.366409\n",
            " 704976/1000000: episode: 975, duration: 24.031s, episode steps: 635, steps per second:  26, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.239 [0.000, 5.000],  loss: 0.019241, mae: 2.220675, mean_q: 2.697941, mean_eps: 0.365808\n",
            " 706043/1000000: episode: 976, duration: 40.376s, episode steps: 1067, steps per second:  26, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.117 [0.000, 5.000],  loss: 0.016409, mae: 2.178397, mean_q: 2.642436, mean_eps: 0.365043\n",
            " 707129/1000000: episode: 977, duration: 41.232s, episode steps: 1086, steps per second:  26, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.015951, mae: 2.187447, mean_q: 2.656292, mean_eps: 0.364073\n",
            " 707746/1000000: episode: 978, duration: 23.364s, episode steps: 617, steps per second:  26, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.841 [0.000, 5.000],  loss: 0.015814, mae: 2.190686, mean_q: 2.658706, mean_eps: 0.363306\n",
            " 708441/1000000: episode: 979, duration: 26.298s, episode steps: 695, steps per second:  26, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.017245, mae: 2.174303, mean_q: 2.639270, mean_eps: 0.362715\n",
            " 709350/1000000: episode: 980, duration: 34.401s, episode steps: 909, steps per second:  26, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.017004, mae: 2.186456, mean_q: 2.654418, mean_eps: 0.361994\n",
            " 710259/1000000: episode: 981, duration: 34.597s, episode steps: 909, steps per second:  26, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.016184, mae: 2.179428, mean_q: 2.645478, mean_eps: 0.361176\n",
            " 711135/1000000: episode: 982, duration: 32.914s, episode steps: 876, steps per second:  27, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: 0.018004, mae: 2.196652, mean_q: 2.665139, mean_eps: 0.360374\n",
            " 711818/1000000: episode: 983, duration: 25.840s, episode steps: 683, steps per second:  26, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.015839, mae: 2.200868, mean_q: 2.671196, mean_eps: 0.359672\n",
            " 712980/1000000: episode: 984, duration: 44.339s, episode steps: 1162, steps per second:  26, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.921 [0.000, 5.000],  loss: 0.015913, mae: 2.187021, mean_q: 2.654008, mean_eps: 0.358842\n",
            " 713833/1000000: episode: 985, duration: 32.647s, episode steps: 853, steps per second:  26, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.141 [0.000, 5.000],  loss: 0.015729, mae: 2.198654, mean_q: 2.667544, mean_eps: 0.357935\n",
            " 714932/1000000: episode: 986, duration: 41.591s, episode steps: 1099, steps per second:  26, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.015038, mae: 2.199614, mean_q: 2.672868, mean_eps: 0.357056\n",
            " 715850/1000000: episode: 987, duration: 34.861s, episode steps: 918, steps per second:  26, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.018236, mae: 2.208242, mean_q: 2.679475, mean_eps: 0.356149\n",
            " 716239/1000000: episode: 988, duration: 14.901s, episode steps: 389, steps per second:  26, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.014252, mae: 2.199936, mean_q: 2.668208, mean_eps: 0.355560\n",
            " 717080/1000000: episode: 989, duration: 32.263s, episode steps: 841, steps per second:  26, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.989 [0.000, 5.000],  loss: 0.016847, mae: 2.187001, mean_q: 2.652401, mean_eps: 0.355008\n",
            " 717570/1000000: episode: 990, duration: 18.914s, episode steps: 490, steps per second:  26, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.024861, mae: 2.195238, mean_q: 2.659861, mean_eps: 0.354408\n",
            " 718573/1000000: episode: 991, duration: 38.482s, episode steps: 1003, steps per second:  26, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.016389, mae: 2.186339, mean_q: 2.652509, mean_eps: 0.353735\n",
            " 719747/1000000: episode: 992, duration: 45.164s, episode steps: 1174, steps per second:  26, episode reward: 28.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.014573, mae: 2.203880, mean_q: 2.674803, mean_eps: 0.352756\n",
            " 720952/1000000: episode: 993, duration: 46.471s, episode steps: 1205, steps per second:  26, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.222 [0.000, 5.000],  loss: 0.015125, mae: 2.232094, mean_q: 2.709196, mean_eps: 0.351687\n",
            " 721653/1000000: episode: 994, duration: 27.035s, episode steps: 701, steps per second:  26, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.014629, mae: 2.225238, mean_q: 2.698918, mean_eps: 0.350828\n",
            " 722661/1000000: episode: 995, duration: 38.871s, episode steps: 1008, steps per second:  26, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.027 [0.000, 5.000],  loss: 0.015275, mae: 2.199835, mean_q: 2.669354, mean_eps: 0.350058\n",
            " 723581/1000000: episode: 996, duration: 35.230s, episode steps: 920, steps per second:  26, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.097 [0.000, 5.000],  loss: 0.015709, mae: 2.238869, mean_q: 2.715871, mean_eps: 0.349190\n",
            " 724389/1000000: episode: 997, duration: 31.250s, episode steps: 808, steps per second:  26, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.015893, mae: 2.220030, mean_q: 2.691561, mean_eps: 0.348413\n",
            " 725279/1000000: episode: 998, duration: 34.123s, episode steps: 890, steps per second:  26, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.969 [0.000, 5.000],  loss: 0.016618, mae: 2.234874, mean_q: 2.713007, mean_eps: 0.347649\n",
            " 726526/1000000: episode: 999, duration: 48.393s, episode steps: 1247, steps per second:  26, episode reward: 30.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.014691, mae: 2.217336, mean_q: 2.688558, mean_eps: 0.346688\n",
            " 727515/1000000: episode: 1000, duration: 38.374s, episode steps: 989, steps per second:  26, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.016344, mae: 2.243489, mean_q: 2.720665, mean_eps: 0.345682\n",
            " 728393/1000000: episode: 1001, duration: 34.071s, episode steps: 878, steps per second:  26, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.019525, mae: 2.236217, mean_q: 2.712260, mean_eps: 0.344841\n",
            " 729224/1000000: episode: 1002, duration: 32.297s, episode steps: 831, steps per second:  26, episode reward: 23.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.018013, mae: 2.235911, mean_q: 2.711903, mean_eps: 0.344073\n",
            " 730279/1000000: episode: 1003, duration: 41.001s, episode steps: 1055, steps per second:  26, episode reward: 28.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.017277, mae: 2.221781, mean_q: 2.693659, mean_eps: 0.343225\n",
            " 730931/1000000: episode: 1004, duration: 25.448s, episode steps: 652, steps per second:  26, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.006 [0.000, 5.000],  loss: 0.016774, mae: 2.262170, mean_q: 2.743798, mean_eps: 0.342456\n",
            " 731593/1000000: episode: 1005, duration: 25.754s, episode steps: 662, steps per second:  26, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.016320, mae: 2.305779, mean_q: 2.795647, mean_eps: 0.341864\n",
            " 732121/1000000: episode: 1006, duration: 20.508s, episode steps: 528, steps per second:  26, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.016017, mae: 2.263447, mean_q: 2.745878, mean_eps: 0.341328\n",
            " 733031/1000000: episode: 1007, duration: 35.179s, episode steps: 910, steps per second:  26, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.918 [0.000, 5.000],  loss: 0.016662, mae: 2.295072, mean_q: 2.782063, mean_eps: 0.340682\n",
            " 733957/1000000: episode: 1008, duration: 36.423s, episode steps: 926, steps per second:  25, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.241 [0.000, 5.000],  loss: 0.016965, mae: 2.269878, mean_q: 2.752484, mean_eps: 0.339855\n",
            " 734620/1000000: episode: 1009, duration: 25.770s, episode steps: 663, steps per second:  26, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.020250, mae: 2.271656, mean_q: 2.751664, mean_eps: 0.339141\n",
            " 735587/1000000: episode: 1010, duration: 37.813s, episode steps: 967, steps per second:  26, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.153 [0.000, 5.000],  loss: 0.016557, mae: 2.281129, mean_q: 2.766661, mean_eps: 0.338408\n",
            " 736235/1000000: episode: 1011, duration: 25.175s, episode steps: 648, steps per second:  26, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.017468, mae: 2.281061, mean_q: 2.771441, mean_eps: 0.337681\n",
            " 736747/1000000: episode: 1012, duration: 19.721s, episode steps: 512, steps per second:  26, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.156 [0.000, 5.000],  loss: 0.018691, mae: 2.283067, mean_q: 2.768870, mean_eps: 0.337159\n",
            " 737467/1000000: episode: 1013, duration: 27.769s, episode steps: 720, steps per second:  26, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.017634, mae: 2.278149, mean_q: 2.761155, mean_eps: 0.336605\n",
            " 737987/1000000: episode: 1014, duration: 19.950s, episode steps: 520, steps per second:  26, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.985 [0.000, 5.000],  loss: 0.019448, mae: 2.258709, mean_q: 2.736449, mean_eps: 0.336047\n",
            " 738633/1000000: episode: 1015, duration: 25.210s, episode steps: 646, steps per second:  26, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.803 [0.000, 5.000],  loss: 0.016440, mae: 2.299672, mean_q: 2.789372, mean_eps: 0.335521\n",
            " 739634/1000000: episode: 1016, duration: 38.847s, episode steps: 1001, steps per second:  26, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.016468, mae: 2.276105, mean_q: 2.760541, mean_eps: 0.334779\n",
            " 740210/1000000: episode: 1017, duration: 22.214s, episode steps: 576, steps per second:  26, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.015727, mae: 2.290326, mean_q: 2.776355, mean_eps: 0.334070\n",
            " 741014/1000000: episode: 1018, duration: 31.282s, episode steps: 804, steps per second:  26, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.016686, mae: 2.310878, mean_q: 2.802866, mean_eps: 0.333449\n",
            " 741895/1000000: episode: 1019, duration: 34.287s, episode steps: 881, steps per second:  26, episode reward: 26.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.016135, mae: 2.295947, mean_q: 2.785002, mean_eps: 0.332691\n",
            " 742495/1000000: episode: 1020, duration: 23.403s, episode steps: 600, steps per second:  26, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.014851, mae: 2.288947, mean_q: 2.779164, mean_eps: 0.332025\n",
            " 742946/1000000: episode: 1021, duration: 17.659s, episode steps: 451, steps per second:  26, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.086 [0.000, 5.000],  loss: 0.015473, mae: 2.321164, mean_q: 2.817833, mean_eps: 0.331552\n",
            " 743927/1000000: episode: 1022, duration: 38.571s, episode steps: 981, steps per second:  25, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.210 [0.000, 5.000],  loss: 0.018396, mae: 2.305103, mean_q: 2.795778, mean_eps: 0.330908\n",
            " 744820/1000000: episode: 1023, duration: 35.285s, episode steps: 893, steps per second:  25, episode reward: 26.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.016876, mae: 2.299436, mean_q: 2.789607, mean_eps: 0.330065\n",
            " 745636/1000000: episode: 1024, duration: 31.954s, episode steps: 816, steps per second:  26, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.017558, mae: 2.315046, mean_q: 2.807684, mean_eps: 0.329297\n",
            " 746440/1000000: episode: 1025, duration: 32.089s, episode steps: 804, steps per second:  25, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.016650, mae: 2.303808, mean_q: 2.793463, mean_eps: 0.328568\n",
            " 747207/1000000: episode: 1026, duration: 30.353s, episode steps: 767, steps per second:  25, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.853 [0.000, 5.000],  loss: 0.017202, mae: 2.297429, mean_q: 2.786822, mean_eps: 0.327860\n",
            " 748332/1000000: episode: 1027, duration: 44.631s, episode steps: 1125, steps per second:  25, episode reward: 28.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.016982, mae: 2.325182, mean_q: 2.820631, mean_eps: 0.327009\n",
            " 748856/1000000: episode: 1028, duration: 20.647s, episode steps: 524, steps per second:  25, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.015604, mae: 2.302980, mean_q: 2.793322, mean_eps: 0.326267\n",
            " 749275/1000000: episode: 1029, duration: 16.616s, episode steps: 419, steps per second:  25, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.016384, mae: 2.337307, mean_q: 2.834467, mean_eps: 0.325842\n",
            " 750788/1000000: episode: 1030, duration: 59.174s, episode steps: 1513, steps per second:  26, episode reward: 32.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.016539, mae: 2.304494, mean_q: 2.795271, mean_eps: 0.324973\n",
            " 751560/1000000: episode: 1031, duration: 30.492s, episode steps: 772, steps per second:  25, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.015699, mae: 2.309946, mean_q: 2.803577, mean_eps: 0.323945\n",
            " 752619/1000000: episode: 1032, duration: 42.457s, episode steps: 1059, steps per second:  25, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.183 [0.000, 5.000],  loss: 0.016023, mae: 2.282104, mean_q: 2.767578, mean_eps: 0.323121\n",
            " 753783/1000000: episode: 1033, duration: 46.461s, episode steps: 1164, steps per second:  25, episode reward: 28.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.017712, mae: 2.284755, mean_q: 2.770340, mean_eps: 0.322120\n",
            " 754725/1000000: episode: 1034, duration: 37.415s, episode steps: 942, steps per second:  25, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.732 [0.000, 5.000],  loss: 0.019135, mae: 2.285437, mean_q: 2.772879, mean_eps: 0.321171\n",
            " 755801/1000000: episode: 1035, duration: 42.813s, episode steps: 1076, steps per second:  25, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.017477, mae: 2.270298, mean_q: 2.753720, mean_eps: 0.320262\n",
            " 756602/1000000: episode: 1036, duration: 31.811s, episode steps: 801, steps per second:  25, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.045 [0.000, 5.000],  loss: 0.016530, mae: 2.273867, mean_q: 2.757782, mean_eps: 0.319418\n",
            " 757234/1000000: episode: 1037, duration: 25.325s, episode steps: 632, steps per second:  25, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.826 [0.000, 5.000],  loss: 0.016917, mae: 2.306686, mean_q: 2.797282, mean_eps: 0.318774\n",
            " 758089/1000000: episode: 1038, duration: 33.960s, episode steps: 855, steps per second:  25, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.015933, mae: 2.283585, mean_q: 2.769547, mean_eps: 0.318104\n",
            " 759230/1000000: episode: 1039, duration: 45.416s, episode steps: 1141, steps per second:  25, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.017146, mae: 2.289342, mean_q: 2.776471, mean_eps: 0.317206\n",
            " 759881/1000000: episode: 1040, duration: 25.981s, episode steps: 651, steps per second:  25, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.018635, mae: 2.297414, mean_q: 2.785551, mean_eps: 0.316400\n",
            " 760784/1000000: episode: 1041, duration: 35.922s, episode steps: 903, steps per second:  25, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.016577, mae: 2.286578, mean_q: 2.773817, mean_eps: 0.315701\n",
            " 761781/1000000: episode: 1042, duration: 39.886s, episode steps: 997, steps per second:  25, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.016694, mae: 2.304282, mean_q: 2.794416, mean_eps: 0.314846\n",
            " 762589/1000000: episode: 1043, duration: 32.185s, episode steps: 808, steps per second:  25, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.016581, mae: 2.334098, mean_q: 2.830161, mean_eps: 0.314033\n",
            " 763807/1000000: episode: 1044, duration: 48.481s, episode steps: 1218, steps per second:  25, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.015677, mae: 2.306115, mean_q: 2.798496, mean_eps: 0.313122\n",
            " 764588/1000000: episode: 1045, duration: 31.415s, episode steps: 781, steps per second:  25, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.082 [0.000, 5.000],  loss: 0.016095, mae: 2.302418, mean_q: 2.791211, mean_eps: 0.312224\n",
            " 765454/1000000: episode: 1046, duration: 34.683s, episode steps: 866, steps per second:  25, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.016830, mae: 2.293290, mean_q: 2.781489, mean_eps: 0.311482\n",
            " 766501/1000000: episode: 1047, duration: 41.780s, episode steps: 1047, steps per second:  25, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.014820, mae: 2.310739, mean_q: 2.802732, mean_eps: 0.310620\n",
            " 767547/1000000: episode: 1048, duration: 41.721s, episode steps: 1046, steps per second:  25, episode reward: 26.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.019056, mae: 2.321063, mean_q: 2.814302, mean_eps: 0.309678\n",
            " 768319/1000000: episode: 1049, duration: 31.072s, episode steps: 772, steps per second:  25, episode reward: 20.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.790 [0.000, 5.000],  loss: 0.016390, mae: 2.294982, mean_q: 2.783417, mean_eps: 0.308861\n",
            " 769409/1000000: episode: 1050, duration: 43.591s, episode steps: 1090, steps per second:  25, episode reward: 28.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.016864, mae: 2.308838, mean_q: 2.800608, mean_eps: 0.308022\n",
            " 769895/1000000: episode: 1051, duration: 19.664s, episode steps: 486, steps per second:  25, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.016552, mae: 2.317688, mean_q: 2.811788, mean_eps: 0.307313\n",
            " 770420/1000000: episode: 1052, duration: 21.186s, episode steps: 525, steps per second:  25, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.017464, mae: 2.327385, mean_q: 2.821742, mean_eps: 0.306860\n",
            " 771350/1000000: episode: 1053, duration: 37.323s, episode steps: 930, steps per second:  25, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.923 [0.000, 5.000],  loss: 0.015629, mae: 2.332399, mean_q: 2.828798, mean_eps: 0.306204\n",
            " 772156/1000000: episode: 1054, duration: 32.446s, episode steps: 806, steps per second:  25, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.016558, mae: 2.350044, mean_q: 2.849518, mean_eps: 0.305423\n",
            " 773371/1000000: episode: 1055, duration: 48.927s, episode steps: 1215, steps per second:  25, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.017249, mae: 2.334597, mean_q: 2.828151, mean_eps: 0.304514\n",
            " 774192/1000000: episode: 1056, duration: 33.234s, episode steps: 821, steps per second:  25, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.015085, mae: 2.324400, mean_q: 2.817540, mean_eps: 0.303598\n",
            " 775346/1000000: episode: 1057, duration: 46.700s, episode steps: 1154, steps per second:  25, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.255 [0.000, 5.000],  loss: 0.017461, mae: 2.326715, mean_q: 2.820403, mean_eps: 0.302709\n",
            " 776341/1000000: episode: 1058, duration: 40.378s, episode steps: 995, steps per second:  25, episode reward: 28.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.019032, mae: 2.346986, mean_q: 2.843526, mean_eps: 0.301740\n",
            " 777324/1000000: episode: 1059, duration: 40.090s, episode steps: 983, steps per second:  25, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.017706, mae: 2.365437, mean_q: 2.867876, mean_eps: 0.300851\n",
            " 778293/1000000: episode: 1060, duration: 39.115s, episode steps: 969, steps per second:  25, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.017200, mae: 2.341549, mean_q: 2.838851, mean_eps: 0.299973\n",
            " 779213/1000000: episode: 1061, duration: 37.115s, episode steps: 920, steps per second:  25, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.017463, mae: 2.344522, mean_q: 2.842912, mean_eps: 0.299121\n",
            " 780227/1000000: episode: 1062, duration: 40.642s, episode steps: 1014, steps per second:  25, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.015689, mae: 2.357151, mean_q: 2.855704, mean_eps: 0.298252\n",
            " 781186/1000000: episode: 1063, duration: 38.789s, episode steps: 959, steps per second:  25, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.215 [0.000, 5.000],  loss: 0.016401, mae: 2.366958, mean_q: 2.867876, mean_eps: 0.297365\n",
            " 782070/1000000: episode: 1064, duration: 35.414s, episode steps: 884, steps per second:  25, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.015181, mae: 2.363623, mean_q: 2.865223, mean_eps: 0.296535\n",
            " 782944/1000000: episode: 1065, duration: 34.851s, episode steps: 874, steps per second:  25, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: 0.016454, mae: 2.377916, mean_q: 2.882030, mean_eps: 0.295745\n",
            " 783607/1000000: episode: 1066, duration: 26.290s, episode steps: 663, steps per second:  25, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.015275, mae: 2.364047, mean_q: 2.865053, mean_eps: 0.295053\n",
            " 784723/1000000: episode: 1067, duration: 44.200s, episode steps: 1116, steps per second:  25, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.015831, mae: 2.359663, mean_q: 2.861045, mean_eps: 0.294252\n",
            " 785424/1000000: episode: 1068, duration: 28.206s, episode steps: 701, steps per second:  25, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.016587, mae: 2.367084, mean_q: 2.869185, mean_eps: 0.293435\n",
            " 786674/1000000: episode: 1069, duration: 49.824s, episode steps: 1250, steps per second:  25, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.017821, mae: 2.365200, mean_q: 2.866533, mean_eps: 0.292557\n",
            " 787623/1000000: episode: 1070, duration: 38.003s, episode steps: 949, steps per second:  25, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.216 [0.000, 5.000],  loss: 0.016473, mae: 2.352530, mean_q: 2.852339, mean_eps: 0.291567\n",
            " 788402/1000000: episode: 1071, duration: 31.222s, episode steps: 779, steps per second:  25, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.842 [0.000, 5.000],  loss: 0.017816, mae: 2.387724, mean_q: 2.896598, mean_eps: 0.290789\n",
            " 789284/1000000: episode: 1072, duration: 34.971s, episode steps: 882, steps per second:  25, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.847 [0.000, 5.000],  loss: 0.017828, mae: 2.378328, mean_q: 2.883004, mean_eps: 0.290042\n",
            " 790087/1000000: episode: 1073, duration: 31.939s, episode steps: 803, steps per second:  25, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.015815, mae: 2.356915, mean_q: 2.856098, mean_eps: 0.289284\n",
            " 790600/1000000: episode: 1074, duration: 20.579s, episode steps: 513, steps per second:  25, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.016798, mae: 2.395936, mean_q: 2.903768, mean_eps: 0.288692\n",
            " 791560/1000000: episode: 1075, duration: 38.249s, episode steps: 960, steps per second:  25, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.017003, mae: 2.364904, mean_q: 2.866347, mean_eps: 0.288030\n",
            " 792418/1000000: episode: 1076, duration: 34.322s, episode steps: 858, steps per second:  25, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.890 [0.000, 5.000],  loss: 0.016596, mae: 2.395842, mean_q: 2.903225, mean_eps: 0.287211\n",
            " 793509/1000000: episode: 1077, duration: 43.737s, episode steps: 1091, steps per second:  25, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.062 [0.000, 5.000],  loss: 0.018333, mae: 2.383611, mean_q: 2.888614, mean_eps: 0.286332\n",
            " 794571/1000000: episode: 1078, duration: 42.094s, episode steps: 1062, steps per second:  25, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.016523, mae: 2.394970, mean_q: 2.903385, mean_eps: 0.285364\n",
            " 795386/1000000: episode: 1079, duration: 32.566s, episode steps: 815, steps per second:  25, episode reward: 24.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.042 [0.000, 5.000],  loss: 0.017357, mae: 2.407776, mean_q: 2.918068, mean_eps: 0.284520\n",
            " 796183/1000000: episode: 1080, duration: 31.510s, episode steps: 797, steps per second:  25, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.029 [0.000, 5.000],  loss: 0.018722, mae: 2.399412, mean_q: 2.906350, mean_eps: 0.283794\n",
            " 797098/1000000: episode: 1081, duration: 36.279s, episode steps: 915, steps per second:  25, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.017721, mae: 2.400571, mean_q: 2.910372, mean_eps: 0.283024\n",
            " 798011/1000000: episode: 1082, duration: 36.297s, episode steps: 913, steps per second:  25, episode reward: 25.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.018087, mae: 2.420077, mean_q: 2.933427, mean_eps: 0.282201\n",
            " 798980/1000000: episode: 1083, duration: 38.844s, episode steps: 969, steps per second:  25, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: 0.016112, mae: 2.400158, mean_q: 2.907325, mean_eps: 0.281355\n",
            " 799847/1000000: episode: 1084, duration: 34.428s, episode steps: 867, steps per second:  25, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.016638, mae: 2.403779, mean_q: 2.913248, mean_eps: 0.280529\n",
            " 800692/1000000: episode: 1085, duration: 34.093s, episode steps: 845, steps per second:  25, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: 0.016417, mae: 2.423442, mean_q: 2.935322, mean_eps: 0.279759\n",
            " 801436/1000000: episode: 1086, duration: 30.127s, episode steps: 744, steps per second:  25, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.180 [0.000, 5.000],  loss: 0.018725, mae: 2.431815, mean_q: 2.945544, mean_eps: 0.279044\n",
            " 802535/1000000: episode: 1087, duration: 44.042s, episode steps: 1099, steps per second:  25, episode reward: 29.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.019225, mae: 2.449061, mean_q: 2.967625, mean_eps: 0.278214\n",
            " 803480/1000000: episode: 1088, duration: 38.132s, episode steps: 945, steps per second:  25, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.019631, mae: 2.446324, mean_q: 2.961450, mean_eps: 0.277295\n",
            " 804340/1000000: episode: 1089, duration: 34.886s, episode steps: 860, steps per second:  25, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.017292, mae: 2.434640, mean_q: 2.952332, mean_eps: 0.276483\n",
            " 805162/1000000: episode: 1090, duration: 33.483s, episode steps: 822, steps per second:  25, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.018747, mae: 2.442888, mean_q: 2.958494, mean_eps: 0.275725\n",
            " 806141/1000000: episode: 1091, duration: 39.260s, episode steps: 979, steps per second:  25, episode reward: 29.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.019375, mae: 2.419145, mean_q: 2.929756, mean_eps: 0.274913\n",
            " 806857/1000000: episode: 1092, duration: 28.725s, episode steps: 716, steps per second:  25, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.059 [0.000, 5.000],  loss: 0.018252, mae: 2.423247, mean_q: 2.933446, mean_eps: 0.274150\n",
            " 807793/1000000: episode: 1093, duration: 37.508s, episode steps: 936, steps per second:  25, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.017687, mae: 2.419026, mean_q: 2.928699, mean_eps: 0.273407\n",
            " 808628/1000000: episode: 1094, duration: 33.690s, episode steps: 835, steps per second:  25, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.945 [0.000, 5.000],  loss: 0.018327, mae: 2.437695, mean_q: 2.951382, mean_eps: 0.272611\n",
            " 809297/1000000: episode: 1095, duration: 26.828s, episode steps: 669, steps per second:  25, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.943 [0.000, 5.000],  loss: 0.017482, mae: 2.448048, mean_q: 2.963866, mean_eps: 0.271934\n",
            " 809874/1000000: episode: 1096, duration: 23.226s, episode steps: 577, steps per second:  25, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.017718, mae: 2.418177, mean_q: 2.926556, mean_eps: 0.271373\n",
            " 810725/1000000: episode: 1097, duration: 34.253s, episode steps: 851, steps per second:  25, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.015690, mae: 2.431968, mean_q: 2.948160, mean_eps: 0.270730\n",
            " 812138/1000000: episode: 1098, duration: 56.645s, episode steps: 1413, steps per second:  25, episode reward: 31.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.016987, mae: 2.455093, mean_q: 2.974690, mean_eps: 0.269711\n",
            " 812945/1000000: episode: 1099, duration: 32.445s, episode steps: 807, steps per second:  25, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.876 [0.000, 5.000],  loss: 0.018884, mae: 2.458772, mean_q: 2.977986, mean_eps: 0.268712\n",
            " 813857/1000000: episode: 1100, duration: 36.698s, episode steps: 912, steps per second:  25, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.016997, mae: 2.441400, mean_q: 2.958552, mean_eps: 0.267938\n",
            " 814817/1000000: episode: 1101, duration: 38.519s, episode steps: 960, steps per second:  25, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.017314, mae: 2.456807, mean_q: 2.974659, mean_eps: 0.267096\n",
            " 815748/1000000: episode: 1102, duration: 37.570s, episode steps: 931, steps per second:  25, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.306 [0.000, 5.000],  loss: 0.018493, mae: 2.436249, mean_q: 2.949374, mean_eps: 0.266246\n",
            " 816797/1000000: episode: 1103, duration: 42.302s, episode steps: 1049, steps per second:  25, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.016958, mae: 2.455727, mean_q: 2.974698, mean_eps: 0.265355\n",
            " 817536/1000000: episode: 1104, duration: 29.741s, episode steps: 739, steps per second:  25, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.976 [0.000, 5.000],  loss: 0.016434, mae: 2.425363, mean_q: 2.939700, mean_eps: 0.264551\n",
            " 818095/1000000: episode: 1105, duration: 22.594s, episode steps: 559, steps per second:  25, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.018068, mae: 2.455643, mean_q: 2.973042, mean_eps: 0.263967\n",
            " 818730/1000000: episode: 1106, duration: 25.587s, episode steps: 635, steps per second:  25, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.016504, mae: 2.456845, mean_q: 2.974869, mean_eps: 0.263429\n",
            " 819526/1000000: episode: 1107, duration: 31.950s, episode steps: 796, steps per second:  25, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.018488, mae: 2.465856, mean_q: 2.985858, mean_eps: 0.262785\n",
            " 820415/1000000: episode: 1108, duration: 35.787s, episode steps: 889, steps per second:  25, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: 0.016967, mae: 2.453524, mean_q: 2.974129, mean_eps: 0.262027\n",
            " 821219/1000000: episode: 1109, duration: 32.193s, episode steps: 804, steps per second:  25, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.016087, mae: 2.471185, mean_q: 2.993505, mean_eps: 0.261266\n",
            " 822163/1000000: episode: 1110, duration: 38.409s, episode steps: 944, steps per second:  25, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.020993, mae: 2.461407, mean_q: 2.980077, mean_eps: 0.260479\n",
            " 822848/1000000: episode: 1111, duration: 28.195s, episode steps: 685, steps per second:  24, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.018077, mae: 2.450095, mean_q: 2.967023, mean_eps: 0.259746\n",
            " 823535/1000000: episode: 1112, duration: 28.263s, episode steps: 687, steps per second:  24, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.766 [0.000, 5.000],  loss: 0.017541, mae: 2.452251, mean_q: 2.969492, mean_eps: 0.259129\n",
            " 824244/1000000: episode: 1113, duration: 29.109s, episode steps: 709, steps per second:  24, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.019574, mae: 2.481898, mean_q: 3.003858, mean_eps: 0.258501\n",
            " 825068/1000000: episode: 1114, duration: 33.444s, episode steps: 824, steps per second:  25, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.018279, mae: 2.441086, mean_q: 2.956318, mean_eps: 0.257811\n",
            " 826092/1000000: episode: 1115, duration: 41.475s, episode steps: 1024, steps per second:  25, episode reward: 26.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.019773, mae: 2.449845, mean_q: 2.966350, mean_eps: 0.256980\n",
            " 826677/1000000: episode: 1116, duration: 23.636s, episode steps: 585, steps per second:  25, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.019201, mae: 2.473123, mean_q: 2.995624, mean_eps: 0.256254\n",
            " 827356/1000000: episode: 1117, duration: 27.674s, episode steps: 679, steps per second:  25, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.016053, mae: 2.460534, mean_q: 2.981680, mean_eps: 0.255686\n",
            " 828008/1000000: episode: 1118, duration: 26.525s, episode steps: 652, steps per second:  25, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.016167, mae: 2.450188, mean_q: 2.971491, mean_eps: 0.255088\n",
            " 828933/1000000: episode: 1119, duration: 37.187s, episode steps: 925, steps per second:  25, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.016611, mae: 2.480308, mean_q: 3.006047, mean_eps: 0.254377\n",
            " 829427/1000000: episode: 1120, duration: 19.731s, episode steps: 494, steps per second:  25, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.017375, mae: 2.486089, mean_q: 3.013346, mean_eps: 0.253738\n",
            " 830010/1000000: episode: 1121, duration: 23.486s, episode steps: 583, steps per second:  25, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.827 [0.000, 5.000],  loss: 0.018543, mae: 2.464516, mean_q: 2.984679, mean_eps: 0.253254\n",
            " 831522/1000000: episode: 1122, duration: 61.115s, episode steps: 1512, steps per second:  25, episode reward: 28.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.018956, mae: 2.525326, mean_q: 3.062372, mean_eps: 0.252311\n",
            " 832412/1000000: episode: 1123, duration: 36.014s, episode steps: 890, steps per second:  25, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.018255, mae: 2.534835, mean_q: 3.071809, mean_eps: 0.251231\n",
            " 832836/1000000: episode: 1124, duration: 17.340s, episode steps: 424, steps per second:  24, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.016641, mae: 2.514494, mean_q: 3.046342, mean_eps: 0.250640\n",
            " 833775/1000000: episode: 1125, duration: 38.005s, episode steps: 939, steps per second:  25, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.020317, mae: 2.530697, mean_q: 3.067474, mean_eps: 0.250026\n",
            " 834355/1000000: episode: 1126, duration: 23.417s, episode steps: 580, steps per second:  25, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.020110, mae: 2.514822, mean_q: 3.046600, mean_eps: 0.249342\n",
            " 835151/1000000: episode: 1127, duration: 32.035s, episode steps: 796, steps per second:  25, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.018257, mae: 2.528074, mean_q: 3.062471, mean_eps: 0.248723\n",
            " 835808/1000000: episode: 1128, duration: 26.591s, episode steps: 657, steps per second:  25, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.764 [0.000, 5.000],  loss: 0.019721, mae: 2.526043, mean_q: 3.061800, mean_eps: 0.248070\n",
            " 836706/1000000: episode: 1129, duration: 36.271s, episode steps: 898, steps per second:  25, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.020142, mae: 2.533925, mean_q: 3.070640, mean_eps: 0.247370\n",
            " 837370/1000000: episode: 1130, duration: 26.834s, episode steps: 664, steps per second:  25, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.018291, mae: 2.521286, mean_q: 3.055090, mean_eps: 0.246666\n",
            " 838652/1000000: episode: 1131, duration: 51.759s, episode steps: 1282, steps per second:  25, episode reward: 30.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.066 [0.000, 5.000],  loss: 0.017216, mae: 2.538129, mean_q: 3.076432, mean_eps: 0.245791\n",
            " 839100/1000000: episode: 1132, duration: 18.393s, episode steps: 448, steps per second:  24, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.299 [0.000, 5.000],  loss: 0.023230, mae: 2.541923, mean_q: 3.078706, mean_eps: 0.245013\n",
            " 839793/1000000: episode: 1133, duration: 28.090s, episode steps: 693, steps per second:  25, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.019 [0.000, 5.000],  loss: 0.019422, mae: 2.520703, mean_q: 3.054352, mean_eps: 0.244499\n",
            " 840438/1000000: episode: 1134, duration: 25.840s, episode steps: 645, steps per second:  25, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.764 [0.000, 5.000],  loss: 0.015787, mae: 2.559988, mean_q: 3.101150, mean_eps: 0.243896\n",
            " 840922/1000000: episode: 1135, duration: 19.396s, episode steps: 484, steps per second:  25, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.048 [0.000, 5.000],  loss: 0.017005, mae: 2.562006, mean_q: 3.102578, mean_eps: 0.243388\n",
            " 842016/1000000: episode: 1136, duration: 44.074s, episode steps: 1094, steps per second:  25, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.017539, mae: 2.566704, mean_q: 3.108761, mean_eps: 0.242679\n",
            " 842957/1000000: episode: 1137, duration: 38.131s, episode steps: 941, steps per second:  25, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.018908, mae: 2.577226, mean_q: 3.123261, mean_eps: 0.241763\n",
            " 843799/1000000: episode: 1138, duration: 34.243s, episode steps: 842, steps per second:  25, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.018115, mae: 2.572924, mean_q: 3.115802, mean_eps: 0.240960\n",
            " 844866/1000000: episode: 1139, duration: 43.396s, episode steps: 1067, steps per second:  25, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.795 [0.000, 5.000],  loss: 0.018349, mae: 2.557024, mean_q: 3.098059, mean_eps: 0.240101\n",
            " 845488/1000000: episode: 1140, duration: 25.322s, episode steps: 622, steps per second:  25, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.722 [0.000, 5.000],  loss: 0.017206, mae: 2.578999, mean_q: 3.124258, mean_eps: 0.239342\n",
            " 845902/1000000: episode: 1141, duration: 16.786s, episode steps: 414, steps per second:  25, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.932 [0.000, 5.000],  loss: 0.018120, mae: 2.583819, mean_q: 3.129708, mean_eps: 0.238875\n",
            " 846956/1000000: episode: 1142, duration: 43.011s, episode steps: 1054, steps per second:  25, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.144 [0.000, 5.000],  loss: 0.017637, mae: 2.553883, mean_q: 3.094350, mean_eps: 0.238215\n",
            " 847602/1000000: episode: 1143, duration: 26.000s, episode steps: 646, steps per second:  25, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.016935, mae: 2.553703, mean_q: 3.095085, mean_eps: 0.237450\n",
            " 848675/1000000: episode: 1144, duration: 43.545s, episode steps: 1073, steps per second:  25, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.019820, mae: 2.582360, mean_q: 3.125749, mean_eps: 0.236676\n",
            " 849048/1000000: episode: 1145, duration: 15.280s, episode steps: 373, steps per second:  24, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.791 [0.000, 5.000],  loss: 0.019297, mae: 2.590972, mean_q: 3.137105, mean_eps: 0.236026\n",
            " 849990/1000000: episode: 1146, duration: 38.603s, episode steps: 942, steps per second:  24, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.091 [0.000, 5.000],  loss: 0.021291, mae: 2.555946, mean_q: 3.096797, mean_eps: 0.235434\n",
            " 850741/1000000: episode: 1147, duration: 30.559s, episode steps: 751, steps per second:  25, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.019576, mae: 2.592680, mean_q: 3.142229, mean_eps: 0.234671\n",
            " 851496/1000000: episode: 1148, duration: 30.963s, episode steps: 755, steps per second:  24, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.019977, mae: 2.599811, mean_q: 3.151401, mean_eps: 0.233994\n",
            " 852511/1000000: episode: 1149, duration: 41.702s, episode steps: 1015, steps per second:  24, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.016446, mae: 2.591879, mean_q: 3.139249, mean_eps: 0.233198\n",
            " 853256/1000000: episode: 1150, duration: 30.527s, episode steps: 745, steps per second:  24, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.060 [0.000, 5.000],  loss: 0.017698, mae: 2.579158, mean_q: 3.122236, mean_eps: 0.232406\n",
            " 854170/1000000: episode: 1151, duration: 37.663s, episode steps: 914, steps per second:  24, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.077 [0.000, 5.000],  loss: 0.018480, mae: 2.581750, mean_q: 3.128892, mean_eps: 0.231659\n",
            " 855159/1000000: episode: 1152, duration: 40.718s, episode steps: 989, steps per second:  24, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.019456, mae: 2.604392, mean_q: 3.153879, mean_eps: 0.230802\n",
            " 855871/1000000: episode: 1153, duration: 29.238s, episode steps: 712, steps per second:  24, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.153 [0.000, 5.000],  loss: 0.018559, mae: 2.584960, mean_q: 3.130501, mean_eps: 0.230037\n",
            " 856850/1000000: episode: 1154, duration: 39.747s, episode steps: 979, steps per second:  25, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.020637, mae: 2.610176, mean_q: 3.160058, mean_eps: 0.229276\n",
            " 857756/1000000: episode: 1155, duration: 37.147s, episode steps: 906, steps per second:  24, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.078 [0.000, 5.000],  loss: 0.017075, mae: 2.593367, mean_q: 3.137755, mean_eps: 0.228428\n",
            " 858619/1000000: episode: 1156, duration: 35.652s, episode steps: 863, steps per second:  24, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.017560, mae: 2.604017, mean_q: 3.155192, mean_eps: 0.227633\n",
            " 859514/1000000: episode: 1157, duration: 36.795s, episode steps: 895, steps per second:  24, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.019949, mae: 2.616136, mean_q: 3.167335, mean_eps: 0.226841\n",
            " 860487/1000000: episode: 1158, duration: 39.611s, episode steps: 973, steps per second:  25, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.761 [0.000, 5.000],  loss: 0.018277, mae: 2.611401, mean_q: 3.163277, mean_eps: 0.226000\n",
            " 861447/1000000: episode: 1159, duration: 39.187s, episode steps: 960, steps per second:  24, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.017542, mae: 2.611815, mean_q: 3.162264, mean_eps: 0.225131\n",
            " 861805/1000000: episode: 1160, duration: 15.015s, episode steps: 358, steps per second:  24, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.016890, mae: 2.643630, mean_q: 3.202367, mean_eps: 0.224537\n",
            " 862417/1000000: episode: 1161, duration: 24.921s, episode steps: 612, steps per second:  25, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.019598, mae: 2.610139, mean_q: 3.162943, mean_eps: 0.224099\n",
            " 863126/1000000: episode: 1162, duration: 29.124s, episode steps: 709, steps per second:  24, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.089 [0.000, 5.000],  loss: 0.018780, mae: 2.612865, mean_q: 3.163956, mean_eps: 0.223505\n",
            " 863844/1000000: episode: 1163, duration: 29.532s, episode steps: 718, steps per second:  24, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.905 [0.000, 5.000],  loss: 0.019412, mae: 2.625548, mean_q: 3.180070, mean_eps: 0.222864\n",
            " 864341/1000000: episode: 1164, duration: 20.516s, episode steps: 497, steps per second:  24, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.018008, mae: 2.626080, mean_q: 3.180474, mean_eps: 0.222317\n",
            " 865251/1000000: episode: 1165, duration: 37.364s, episode steps: 910, steps per second:  24, episode reward: 25.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.018416, mae: 2.610034, mean_q: 3.162746, mean_eps: 0.221684\n",
            " 866424/1000000: episode: 1166, duration: 48.398s, episode steps: 1173, steps per second:  24, episode reward: 29.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.117 [0.000, 5.000],  loss: 0.018809, mae: 2.623643, mean_q: 3.175106, mean_eps: 0.220748\n",
            " 866960/1000000: episode: 1167, duration: 21.996s, episode steps: 536, steps per second:  24, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.080 [0.000, 5.000],  loss: 0.019595, mae: 2.632417, mean_q: 3.186784, mean_eps: 0.219979\n",
            " 867452/1000000: episode: 1168, duration: 20.493s, episode steps: 492, steps per second:  24, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.016831, mae: 2.614388, mean_q: 3.165786, mean_eps: 0.219516\n",
            " 868120/1000000: episode: 1169, duration: 27.691s, episode steps: 668, steps per second:  24, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.094 [0.000, 5.000],  loss: 0.018341, mae: 2.650836, mean_q: 3.211738, mean_eps: 0.218994\n",
            " 868878/1000000: episode: 1170, duration: 31.383s, episode steps: 758, steps per second:  24, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.018685, mae: 2.625490, mean_q: 3.178346, mean_eps: 0.218352\n",
            " 869682/1000000: episode: 1171, duration: 33.383s, episode steps: 804, steps per second:  24, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.040 [0.000, 5.000],  loss: 0.017370, mae: 2.645958, mean_q: 3.204049, mean_eps: 0.217648\n",
            " 870566/1000000: episode: 1172, duration: 36.394s, episode steps: 884, steps per second:  24, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.226 [0.000, 5.000],  loss: 0.018275, mae: 2.643667, mean_q: 3.201291, mean_eps: 0.216888\n",
            " 872115/1000000: episode: 1173, duration: 63.721s, episode steps: 1549, steps per second:  24, episode reward: 35.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.192 [0.000, 5.000],  loss: 0.018907, mae: 2.629325, mean_q: 3.183830, mean_eps: 0.215794\n",
            " 873322/1000000: episode: 1174, duration: 49.652s, episode steps: 1207, steps per second:  24, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.202 [0.000, 5.000],  loss: 0.020049, mae: 2.607876, mean_q: 3.156985, mean_eps: 0.214554\n",
            " 874042/1000000: episode: 1175, duration: 29.640s, episode steps: 720, steps per second:  24, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.017960, mae: 2.625928, mean_q: 3.177270, mean_eps: 0.213686\n",
            " 874754/1000000: episode: 1176, duration: 29.069s, episode steps: 712, steps per second:  24, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.892 [0.000, 5.000],  loss: 0.022104, mae: 2.611557, mean_q: 3.158870, mean_eps: 0.213042\n",
            " 875787/1000000: episode: 1177, duration: 42.513s, episode steps: 1033, steps per second:  24, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.954 [0.000, 5.000],  loss: 0.018980, mae: 2.630868, mean_q: 3.184617, mean_eps: 0.212257\n",
            " 876510/1000000: episode: 1178, duration: 29.983s, episode steps: 723, steps per second:  24, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.048 [0.000, 5.000],  loss: 0.020834, mae: 2.628216, mean_q: 3.180977, mean_eps: 0.211467\n",
            " 877237/1000000: episode: 1179, duration: 30.251s, episode steps: 727, steps per second:  24, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.021245, mae: 2.613833, mean_q: 3.165323, mean_eps: 0.210813\n",
            " 878121/1000000: episode: 1180, duration: 36.656s, episode steps: 884, steps per second:  24, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.018874, mae: 2.664103, mean_q: 3.225855, mean_eps: 0.210088\n",
            " 878779/1000000: episode: 1181, duration: 27.270s, episode steps: 658, steps per second:  24, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.988 [0.000, 5.000],  loss: 0.018792, mae: 2.641445, mean_q: 3.197107, mean_eps: 0.209395\n",
            " 879321/1000000: episode: 1182, duration: 22.556s, episode steps: 542, steps per second:  24, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.018467, mae: 2.620723, mean_q: 3.173605, mean_eps: 0.208855\n",
            " 880138/1000000: episode: 1183, duration: 33.953s, episode steps: 817, steps per second:  24, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.019563, mae: 2.627125, mean_q: 3.182045, mean_eps: 0.208243\n",
            " 881400/1000000: episode: 1184, duration: 52.198s, episode steps: 1262, steps per second:  24, episode reward: 29.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.954 [0.000, 5.000],  loss: 0.019237, mae: 2.657240, mean_q: 3.217443, mean_eps: 0.207309\n",
            " 882614/1000000: episode: 1185, duration: 50.498s, episode steps: 1214, steps per second:  24, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.018119, mae: 2.652606, mean_q: 3.211455, mean_eps: 0.206195\n",
            " 883563/1000000: episode: 1186, duration: 39.587s, episode steps: 949, steps per second:  24, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.132 [0.000, 5.000],  loss: 0.019769, mae: 2.648383, mean_q: 3.205646, mean_eps: 0.205221\n",
            " 884644/1000000: episode: 1187, duration: 46.102s, episode steps: 1081, steps per second:  23, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.844 [0.000, 5.000],  loss: 0.021424, mae: 2.672240, mean_q: 3.232264, mean_eps: 0.204308\n",
            " 885399/1000000: episode: 1188, duration: 31.504s, episode steps: 755, steps per second:  24, episode reward: 20.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.070 [0.000, 5.000],  loss: 0.019611, mae: 2.668406, mean_q: 3.229173, mean_eps: 0.203482\n",
            " 885970/1000000: episode: 1189, duration: 24.039s, episode steps: 571, steps per second:  24, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.630 [0.000, 5.000],  loss: 0.023191, mae: 2.689638, mean_q: 3.255137, mean_eps: 0.202884\n",
            " 886614/1000000: episode: 1190, duration: 26.941s, episode steps: 644, steps per second:  24, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.540 [0.000, 5.000],  loss: 0.020187, mae: 2.674457, mean_q: 3.234975, mean_eps: 0.202337\n",
            " 888066/1000000: episode: 1191, duration: 60.910s, episode steps: 1452, steps per second:  24, episode reward: 32.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.018480, mae: 2.661337, mean_q: 3.221675, mean_eps: 0.201394\n",
            " 888720/1000000: episode: 1192, duration: 27.952s, episode steps: 654, steps per second:  23, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: 0.018920, mae: 2.675088, mean_q: 3.238315, mean_eps: 0.200447\n",
            " 889419/1000000: episode: 1193, duration: 29.496s, episode steps: 699, steps per second:  24, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.017750, mae: 2.670648, mean_q: 3.233187, mean_eps: 0.199839\n",
            " 890445/1000000: episode: 1194, duration: 43.130s, episode steps: 1026, steps per second:  24, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.017654, mae: 2.655590, mean_q: 3.216214, mean_eps: 0.199061\n",
            " 891339/1000000: episode: 1195, duration: 37.663s, episode steps: 894, steps per second:  24, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.015569, mae: 2.650817, mean_q: 3.212106, mean_eps: 0.198197\n",
            " 891943/1000000: episode: 1196, duration: 25.577s, episode steps: 604, steps per second:  24, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.089 [0.000, 5.000],  loss: 0.017687, mae: 2.617879, mean_q: 3.170709, mean_eps: 0.197524\n",
            " 892944/1000000: episode: 1197, duration: 42.575s, episode steps: 1001, steps per second:  24, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.887 [0.000, 5.000],  loss: 0.020083, mae: 2.661469, mean_q: 3.221432, mean_eps: 0.196802\n",
            " 893730/1000000: episode: 1198, duration: 33.398s, episode steps: 786, steps per second:  24, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.017471, mae: 2.648682, mean_q: 3.204868, mean_eps: 0.195998\n",
            " 894695/1000000: episode: 1199, duration: 40.389s, episode steps: 965, steps per second:  24, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.019095, mae: 2.660457, mean_q: 3.220100, mean_eps: 0.195209\n",
            " 895216/1000000: episode: 1200, duration: 22.155s, episode steps: 521, steps per second:  24, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.877 [0.000, 5.000],  loss: 0.019330, mae: 2.641230, mean_q: 3.195261, mean_eps: 0.194541\n",
            " 896025/1000000: episode: 1201, duration: 34.222s, episode steps: 809, steps per second:  24, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.005 [0.000, 5.000],  loss: 0.021761, mae: 2.638944, mean_q: 3.193616, mean_eps: 0.193942\n",
            " 896560/1000000: episode: 1202, duration: 22.251s, episode steps: 535, steps per second:  24, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.018871, mae: 2.641202, mean_q: 3.195457, mean_eps: 0.193337\n",
            " 897185/1000000: episode: 1203, duration: 26.054s, episode steps: 625, steps per second:  24, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.018006, mae: 2.622397, mean_q: 3.175552, mean_eps: 0.192815\n",
            " 898316/1000000: episode: 1204, duration: 47.553s, episode steps: 1131, steps per second:  24, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.018628, mae: 2.651919, mean_q: 3.210870, mean_eps: 0.192025\n",
            " 899010/1000000: episode: 1205, duration: 29.394s, episode steps: 694, steps per second:  24, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.022135, mae: 2.641281, mean_q: 3.196388, mean_eps: 0.191204\n",
            " 899711/1000000: episode: 1206, duration: 29.297s, episode steps: 701, steps per second:  24, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.760 [0.000, 5.000],  loss: 0.020132, mae: 2.638394, mean_q: 3.196758, mean_eps: 0.190576\n",
            " 900457/1000000: episode: 1207, duration: 31.219s, episode steps: 746, steps per second:  24, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.019546, mae: 2.644619, mean_q: 3.202103, mean_eps: 0.189924\n",
            " 900889/1000000: episode: 1208, duration: 18.201s, episode steps: 432, steps per second:  24, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.018667, mae: 2.647459, mean_q: 3.205488, mean_eps: 0.189393\n",
            " 901271/1000000: episode: 1209, duration: 16.124s, episode steps: 382, steps per second:  24, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.992 [0.000, 5.000],  loss: 0.016845, mae: 2.657623, mean_q: 3.219274, mean_eps: 0.189028\n",
            " 902236/1000000: episode: 1210, duration: 41.062s, episode steps: 965, steps per second:  24, episode reward: 29.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.019738, mae: 2.649787, mean_q: 3.206673, mean_eps: 0.188423\n",
            " 902866/1000000: episode: 1211, duration: 26.409s, episode steps: 630, steps per second:  24, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.183 [0.000, 5.000],  loss: 0.020753, mae: 2.652922, mean_q: 3.210457, mean_eps: 0.187705\n",
            " 903822/1000000: episode: 1212, duration: 40.084s, episode steps: 956, steps per second:  24, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.019372, mae: 2.655003, mean_q: 3.213957, mean_eps: 0.186990\n",
            " 904806/1000000: episode: 1213, duration: 41.604s, episode steps: 984, steps per second:  24, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.110 [0.000, 5.000],  loss: 0.020809, mae: 2.659129, mean_q: 3.219206, mean_eps: 0.186117\n",
            " 905845/1000000: episode: 1214, duration: 44.098s, episode steps: 1039, steps per second:  24, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.018543, mae: 2.672990, mean_q: 3.235648, mean_eps: 0.185207\n",
            " 906749/1000000: episode: 1215, duration: 38.211s, episode steps: 904, steps per second:  24, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.016717, mae: 2.645478, mean_q: 3.202373, mean_eps: 0.184332\n",
            " 907821/1000000: episode: 1216, duration: 45.088s, episode steps: 1072, steps per second:  24, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.021240, mae: 2.683494, mean_q: 3.248300, mean_eps: 0.183443\n",
            " 908634/1000000: episode: 1217, duration: 34.050s, episode steps: 813, steps per second:  24, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.699 [0.000, 5.000],  loss: 0.019543, mae: 2.664257, mean_q: 3.224498, mean_eps: 0.182595\n",
            " 909679/1000000: episode: 1218, duration: 44.008s, episode steps: 1045, steps per second:  24, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.018471, mae: 2.659696, mean_q: 3.217810, mean_eps: 0.181760\n",
            " 910880/1000000: episode: 1219, duration: 50.797s, episode steps: 1201, steps per second:  24, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.017135, mae: 2.655598, mean_q: 3.216248, mean_eps: 0.180750\n",
            " 911997/1000000: episode: 1220, duration: 47.296s, episode steps: 1117, steps per second:  24, episode reward: 26.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.184 [0.000, 5.000],  loss: 0.020283, mae: 2.677251, mean_q: 3.238483, mean_eps: 0.179706\n",
            " 912821/1000000: episode: 1221, duration: 34.761s, episode steps: 824, steps per second:  24, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.017258, mae: 2.667753, mean_q: 3.227401, mean_eps: 0.178831\n",
            " 913719/1000000: episode: 1222, duration: 38.148s, episode steps: 898, steps per second:  24, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.018277, mae: 2.695976, mean_q: 3.259982, mean_eps: 0.178057\n",
            " 914817/1000000: episode: 1223, duration: 46.741s, episode steps: 1098, steps per second:  23, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.020233, mae: 2.670109, mean_q: 3.230879, mean_eps: 0.177159\n",
            " 915684/1000000: episode: 1224, duration: 36.868s, episode steps: 867, steps per second:  24, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.729 [0.000, 5.000],  loss: 0.018463, mae: 2.691130, mean_q: 3.257974, mean_eps: 0.176275\n",
            " 916312/1000000: episode: 1225, duration: 26.814s, episode steps: 628, steps per second:  23, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.094 [0.000, 5.000],  loss: 0.016775, mae: 2.674861, mean_q: 3.236427, mean_eps: 0.175604\n",
            " 917446/1000000: episode: 1226, duration: 48.413s, episode steps: 1134, steps per second:  23, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.968 [0.000, 5.000],  loss: 0.020259, mae: 2.679091, mean_q: 3.243524, mean_eps: 0.174810\n",
            " 918425/1000000: episode: 1227, duration: 41.272s, episode steps: 979, steps per second:  24, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.018147, mae: 2.681609, mean_q: 3.245189, mean_eps: 0.173858\n",
            " 919122/1000000: episode: 1228, duration: 29.393s, episode steps: 697, steps per second:  24, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.019636, mae: 2.712550, mean_q: 3.281879, mean_eps: 0.173103\n",
            " 919760/1000000: episode: 1229, duration: 27.374s, episode steps: 638, steps per second:  23, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.018963, mae: 2.688914, mean_q: 3.255641, mean_eps: 0.172504\n",
            " 920598/1000000: episode: 1230, duration: 35.762s, episode steps: 838, steps per second:  23, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.177 [0.000, 5.000],  loss: 0.015482, mae: 2.700878, mean_q: 3.270214, mean_eps: 0.171840\n",
            " 921409/1000000: episode: 1231, duration: 34.453s, episode steps: 811, steps per second:  24, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.164 [0.000, 5.000],  loss: 0.020020, mae: 2.710024, mean_q: 3.278752, mean_eps: 0.171096\n",
            " 922403/1000000: episode: 1232, duration: 41.951s, episode steps: 994, steps per second:  24, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.018914, mae: 2.706131, mean_q: 3.275256, mean_eps: 0.170285\n",
            " 923397/1000000: episode: 1233, duration: 42.327s, episode steps: 994, steps per second:  23, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: 0.018119, mae: 2.708914, mean_q: 3.277366, mean_eps: 0.169390\n",
            " 923980/1000000: episode: 1234, duration: 24.747s, episode steps: 583, steps per second:  24, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.021547, mae: 2.697998, mean_q: 3.266387, mean_eps: 0.168681\n",
            " 924823/1000000: episode: 1235, duration: 35.981s, episode steps: 843, steps per second:  23, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.050 [0.000, 5.000],  loss: 0.019258, mae: 2.711504, mean_q: 3.281040, mean_eps: 0.168040\n",
            " 925513/1000000: episode: 1236, duration: 29.499s, episode steps: 690, steps per second:  23, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.019882, mae: 2.712462, mean_q: 3.283325, mean_eps: 0.167349\n",
            " 926471/1000000: episode: 1237, duration: 40.422s, episode steps: 958, steps per second:  24, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.018950, mae: 2.722217, mean_q: 3.294178, mean_eps: 0.166607\n",
            " 927420/1000000: episode: 1238, duration: 40.426s, episode steps: 949, steps per second:  23, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.019399, mae: 2.727956, mean_q: 3.299938, mean_eps: 0.165750\n",
            " 928237/1000000: episode: 1239, duration: 34.697s, episode steps: 817, steps per second:  24, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.747 [0.000, 5.000],  loss: 0.020037, mae: 2.738005, mean_q: 3.315731, mean_eps: 0.164955\n",
            " 928981/1000000: episode: 1240, duration: 31.760s, episode steps: 744, steps per second:  23, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.019785, mae: 2.715413, mean_q: 3.285938, mean_eps: 0.164251\n",
            " 929814/1000000: episode: 1241, duration: 35.197s, episode steps: 833, steps per second:  24, episode reward: 22.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.094 [0.000, 5.000],  loss: 0.017819, mae: 2.703596, mean_q: 3.272116, mean_eps: 0.163542\n",
            " 930514/1000000: episode: 1242, duration: 29.889s, episode steps: 700, steps per second:  23, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.017193, mae: 2.734210, mean_q: 3.308418, mean_eps: 0.162852\n",
            " 931402/1000000: episode: 1243, duration: 37.840s, episode steps: 888, steps per second:  23, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.702 [0.000, 5.000],  loss: 0.019114, mae: 2.735390, mean_q: 3.311699, mean_eps: 0.162138\n",
            " 932370/1000000: episode: 1244, duration: 41.195s, episode steps: 968, steps per second:  23, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.904 [0.000, 5.000],  loss: 0.018708, mae: 2.747534, mean_q: 3.324191, mean_eps: 0.161303\n",
            " 933317/1000000: episode: 1245, duration: 40.256s, episode steps: 947, steps per second:  24, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.018990, mae: 2.743772, mean_q: 3.319874, mean_eps: 0.160440\n",
            " 934392/1000000: episode: 1246, duration: 45.843s, episode steps: 1075, steps per second:  23, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.018957, mae: 2.744322, mean_q: 3.318250, mean_eps: 0.159531\n",
            " 935333/1000000: episode: 1247, duration: 40.204s, episode steps: 941, steps per second:  23, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.949 [0.000, 5.000],  loss: 0.017167, mae: 2.737313, mean_q: 3.311788, mean_eps: 0.158624\n",
            " 936132/1000000: episode: 1248, duration: 34.087s, episode steps: 799, steps per second:  23, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.021660, mae: 2.736635, mean_q: 3.310324, mean_eps: 0.157841\n",
            " 937035/1000000: episode: 1249, duration: 38.131s, episode steps: 903, steps per second:  24, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.020299, mae: 2.750986, mean_q: 3.327026, mean_eps: 0.157076\n",
            " 938080/1000000: episode: 1250, duration: 44.500s, episode steps: 1045, steps per second:  23, episode reward: 27.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.017815, mae: 2.749278, mean_q: 3.326081, mean_eps: 0.156200\n",
            " 938616/1000000: episode: 1251, duration: 22.755s, episode steps: 536, steps per second:  24, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.071 [0.000, 5.000],  loss: 0.018976, mae: 2.732010, mean_q: 3.304667, mean_eps: 0.155489\n",
            " 939139/1000000: episode: 1252, duration: 22.104s, episode steps: 523, steps per second:  24, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.019122, mae: 2.718061, mean_q: 3.287198, mean_eps: 0.155012\n",
            " 939976/1000000: episode: 1253, duration: 36.024s, episode steps: 837, steps per second:  23, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.018713, mae: 2.719967, mean_q: 3.288063, mean_eps: 0.154400\n",
            " 940626/1000000: episode: 1254, duration: 28.098s, episode steps: 650, steps per second:  23, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.822 [0.000, 5.000],  loss: 0.019483, mae: 2.769646, mean_q: 3.349896, mean_eps: 0.153730\n",
            " 941669/1000000: episode: 1255, duration: 44.534s, episode steps: 1043, steps per second:  23, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.018172, mae: 2.762169, mean_q: 3.341585, mean_eps: 0.152967\n",
            " 942361/1000000: episode: 1256, duration: 29.659s, episode steps: 692, steps per second:  23, episode reward: 19.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.019663, mae: 2.763320, mean_q: 3.341936, mean_eps: 0.152186\n",
            " 942970/1000000: episode: 1257, duration: 26.209s, episode steps: 609, steps per second:  23, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.074 [0.000, 5.000],  loss: 0.020439, mae: 2.758365, mean_q: 3.337215, mean_eps: 0.151601\n",
            " 943585/1000000: episode: 1258, duration: 26.605s, episode steps: 615, steps per second:  23, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.933 [0.000, 5.000],  loss: 0.016494, mae: 2.741824, mean_q: 3.316360, mean_eps: 0.151050\n",
            " 944492/1000000: episode: 1259, duration: 38.719s, episode steps: 907, steps per second:  23, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.784 [0.000, 5.000],  loss: 0.018293, mae: 2.765582, mean_q: 3.345692, mean_eps: 0.150366\n",
            " 944969/1000000: episode: 1260, duration: 20.353s, episode steps: 477, steps per second:  23, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.975 [0.000, 5.000],  loss: 0.018540, mae: 2.756428, mean_q: 3.335297, mean_eps: 0.149743\n",
            " 945906/1000000: episode: 1261, duration: 39.917s, episode steps: 937, steps per second:  23, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.093 [0.000, 5.000],  loss: 0.019086, mae: 2.751003, mean_q: 3.327193, mean_eps: 0.149106\n",
            " 946886/1000000: episode: 1262, duration: 42.075s, episode steps: 980, steps per second:  23, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.242 [0.000, 5.000],  loss: 0.015925, mae: 2.753555, mean_q: 3.331766, mean_eps: 0.148244\n",
            " 947506/1000000: episode: 1263, duration: 26.470s, episode steps: 620, steps per second:  23, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.790 [0.000, 5.000],  loss: 0.019006, mae: 2.747695, mean_q: 3.324017, mean_eps: 0.147524\n",
            " 948540/1000000: episode: 1264, duration: 44.086s, episode steps: 1034, steps per second:  23, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.115 [0.000, 5.000],  loss: 0.017023, mae: 2.751748, mean_q: 3.327131, mean_eps: 0.146780\n",
            " 948947/1000000: episode: 1265, duration: 17.345s, episode steps: 407, steps per second:  23, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.016458, mae: 2.780380, mean_q: 3.361615, mean_eps: 0.146132\n",
            " 949327/1000000: episode: 1266, duration: 16.399s, episode steps: 380, steps per second:  23, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.905 [0.000, 5.000],  loss: 0.014614, mae: 2.750227, mean_q: 3.325219, mean_eps: 0.145778\n",
            " 950291/1000000: episode: 1267, duration: 41.562s, episode steps: 964, steps per second:  23, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.016972, mae: 2.755848, mean_q: 3.332328, mean_eps: 0.145173\n",
            " 951589/1000000: episode: 1268, duration: 55.292s, episode steps: 1298, steps per second:  23, episode reward: 19.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.174 [0.000, 5.000],  loss: 0.018947, mae: 2.785585, mean_q: 3.368171, mean_eps: 0.144154\n",
            " 952429/1000000: episode: 1269, duration: 35.754s, episode steps: 840, steps per second:  23, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.836 [0.000, 5.000],  loss: 0.018668, mae: 2.775339, mean_q: 3.355391, mean_eps: 0.143191\n",
            " 952912/1000000: episode: 1270, duration: 20.604s, episode steps: 483, steps per second:  23, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.008 [0.000, 5.000],  loss: 0.018416, mae: 2.798480, mean_q: 3.384417, mean_eps: 0.142597\n",
            " 954042/1000000: episode: 1271, duration: 48.450s, episode steps: 1130, steps per second:  23, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.018343, mae: 2.764053, mean_q: 3.342771, mean_eps: 0.141872\n",
            " 955089/1000000: episode: 1272, duration: 45.017s, episode steps: 1047, steps per second:  23, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.766 [0.000, 5.000],  loss: 0.020255, mae: 2.784158, mean_q: 3.366079, mean_eps: 0.140891\n",
            " 955570/1000000: episode: 1273, duration: 20.550s, episode steps: 481, steps per second:  23, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.726 [0.000, 5.000],  loss: 0.020689, mae: 2.786995, mean_q: 3.369455, mean_eps: 0.140203\n",
            " 956094/1000000: episode: 1274, duration: 22.414s, episode steps: 524, steps per second:  23, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.021126, mae: 2.775089, mean_q: 3.356101, mean_eps: 0.139751\n",
            " 956913/1000000: episode: 1275, duration: 34.892s, episode steps: 819, steps per second:  23, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.794 [0.000, 5.000],  loss: 0.020455, mae: 2.778259, mean_q: 3.358598, mean_eps: 0.139146\n",
            " 957537/1000000: episode: 1276, duration: 26.968s, episode steps: 624, steps per second:  23, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 3.288 [0.000, 5.000],  loss: 0.016190, mae: 2.792662, mean_q: 3.378086, mean_eps: 0.138497\n",
            " 958146/1000000: episode: 1277, duration: 26.273s, episode steps: 609, steps per second:  23, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.019842, mae: 2.780678, mean_q: 3.360532, mean_eps: 0.137942\n",
            " 959004/1000000: episode: 1278, duration: 36.836s, episode steps: 858, steps per second:  23, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.020059, mae: 2.760116, mean_q: 3.337752, mean_eps: 0.137283\n",
            " 960070/1000000: episode: 1279, duration: 45.481s, episode steps: 1066, steps per second:  23, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.795 [0.000, 5.000],  loss: 0.021541, mae: 2.765669, mean_q: 3.346071, mean_eps: 0.136418\n",
            " 960858/1000000: episode: 1280, duration: 33.419s, episode steps: 788, steps per second:  24, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.018148, mae: 2.791901, mean_q: 3.378926, mean_eps: 0.135582\n",
            " 961796/1000000: episode: 1281, duration: 39.818s, episode steps: 938, steps per second:  24, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.017700, mae: 2.780574, mean_q: 3.362317, mean_eps: 0.134807\n",
            " 962453/1000000: episode: 1282, duration: 27.922s, episode steps: 657, steps per second:  24, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.017712, mae: 2.781428, mean_q: 3.363681, mean_eps: 0.134088\n",
            " 963195/1000000: episode: 1283, duration: 31.661s, episode steps: 742, steps per second:  23, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.016460, mae: 2.768673, mean_q: 3.348806, mean_eps: 0.133458\n",
            " 964365/1000000: episode: 1284, duration: 50.174s, episode steps: 1170, steps per second:  23, episode reward: 28.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.020085, mae: 2.796456, mean_q: 3.381939, mean_eps: 0.132598\n",
            " 965271/1000000: episode: 1285, duration: 38.823s, episode steps: 906, steps per second:  23, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.007 [0.000, 5.000],  loss: 0.018950, mae: 2.757083, mean_q: 3.334407, mean_eps: 0.131664\n",
            " 966138/1000000: episode: 1286, duration: 36.990s, episode steps: 867, steps per second:  23, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.018757, mae: 2.776785, mean_q: 3.356446, mean_eps: 0.130866\n",
            " 967169/1000000: episode: 1287, duration: 43.744s, episode steps: 1031, steps per second:  24, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.021386, mae: 2.780178, mean_q: 3.362439, mean_eps: 0.130011\n",
            " 968124/1000000: episode: 1288, duration: 40.636s, episode steps: 955, steps per second:  24, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.057 [0.000, 5.000],  loss: 0.020140, mae: 2.771246, mean_q: 3.351625, mean_eps: 0.129119\n",
            " 968800/1000000: episode: 1289, duration: 28.690s, episode steps: 676, steps per second:  24, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.392 [0.000, 5.000],  loss: 0.018471, mae: 2.775794, mean_q: 3.357199, mean_eps: 0.128386\n",
            " 969317/1000000: episode: 1290, duration: 22.016s, episode steps: 517, steps per second:  23, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.640 [0.000, 5.000],  loss: 0.019401, mae: 2.774901, mean_q: 3.353500, mean_eps: 0.127848\n",
            " 970056/1000000: episode: 1291, duration: 31.569s, episode steps: 739, steps per second:  23, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.019546, mae: 2.770696, mean_q: 3.348506, mean_eps: 0.127283\n",
            " 971043/1000000: episode: 1292, duration: 41.654s, episode steps: 987, steps per second:  24, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.016623, mae: 2.776090, mean_q: 3.358859, mean_eps: 0.126507\n",
            " 971670/1000000: episode: 1293, duration: 26.874s, episode steps: 627, steps per second:  23, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.242 [0.000, 5.000],  loss: 0.016844, mae: 2.792178, mean_q: 3.376490, mean_eps: 0.125780\n",
            " 972280/1000000: episode: 1294, duration: 26.006s, episode steps: 610, steps per second:  23, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.939 [0.000, 5.000],  loss: 0.016100, mae: 2.793066, mean_q: 3.378966, mean_eps: 0.125223\n",
            " 972869/1000000: episode: 1295, duration: 25.271s, episode steps: 589, steps per second:  23, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.156 [0.000, 5.000],  loss: 0.019893, mae: 2.810564, mean_q: 3.398308, mean_eps: 0.124683\n",
            " 973901/1000000: episode: 1296, duration: 43.960s, episode steps: 1032, steps per second:  23, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.074 [0.000, 5.000],  loss: 0.018913, mae: 2.786552, mean_q: 3.368527, mean_eps: 0.123953\n",
            " 975083/1000000: episode: 1297, duration: 50.338s, episode steps: 1182, steps per second:  23, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.017923, mae: 2.784495, mean_q: 3.367816, mean_eps: 0.122957\n",
            " 975754/1000000: episode: 1298, duration: 28.770s, episode steps: 671, steps per second:  23, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.750 [0.000, 5.000],  loss: 0.017748, mae: 2.804281, mean_q: 3.391842, mean_eps: 0.122124\n",
            " 976644/1000000: episode: 1299, duration: 38.096s, episode steps: 890, steps per second:  23, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.017711, mae: 2.781426, mean_q: 3.362319, mean_eps: 0.121422\n",
            " 977354/1000000: episode: 1300, duration: 30.679s, episode steps: 710, steps per second:  23, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.185 [0.000, 5.000],  loss: 0.022253, mae: 2.802110, mean_q: 3.388313, mean_eps: 0.120702\n",
            " 978155/1000000: episode: 1301, duration: 34.187s, episode steps: 801, steps per second:  23, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.018964, mae: 2.780801, mean_q: 3.362218, mean_eps: 0.120021\n",
            " 979082/1000000: episode: 1302, duration: 39.914s, episode steps: 927, steps per second:  23, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.556 [0.000, 5.000],  loss: 0.018114, mae: 2.783223, mean_q: 3.364527, mean_eps: 0.119244\n",
            " 979887/1000000: episode: 1303, duration: 34.834s, episode steps: 805, steps per second:  23, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.153 [0.000, 5.000],  loss: 0.018203, mae: 2.777692, mean_q: 3.360921, mean_eps: 0.118464\n",
            " 980889/1000000: episode: 1304, duration: 43.117s, episode steps: 1002, steps per second:  23, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.873 [0.000, 5.000],  loss: 0.016909, mae: 2.800562, mean_q: 3.386761, mean_eps: 0.117651\n",
            " 982165/1000000: episode: 1305, duration: 54.551s, episode steps: 1276, steps per second:  23, episode reward: 31.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.019912, mae: 2.823577, mean_q: 3.415926, mean_eps: 0.116625\n",
            " 983137/1000000: episode: 1306, duration: 41.654s, episode steps: 972, steps per second:  23, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.018584, mae: 2.819404, mean_q: 3.408880, mean_eps: 0.115613\n",
            " 984277/1000000: episode: 1307, duration: 48.754s, episode steps: 1140, steps per second:  23, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.018185, mae: 2.832301, mean_q: 3.428052, mean_eps: 0.114663\n",
            " 984900/1000000: episode: 1308, duration: 26.644s, episode steps: 623, steps per second:  23, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.016715, mae: 2.803520, mean_q: 3.390949, mean_eps: 0.113871\n",
            " 985831/1000000: episode: 1309, duration: 40.088s, episode steps: 931, steps per second:  23, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: 0.018397, mae: 2.828932, mean_q: 3.420492, mean_eps: 0.113172\n",
            " 986780/1000000: episode: 1310, duration: 41.076s, episode steps: 949, steps per second:  23, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.019976, mae: 2.834143, mean_q: 3.426606, mean_eps: 0.112326\n",
            " 987334/1000000: episode: 1311, duration: 24.037s, episode steps: 554, steps per second:  23, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.787 [0.000, 5.000],  loss: 0.019362, mae: 2.833262, mean_q: 3.426031, mean_eps: 0.111650\n",
            " 988031/1000000: episode: 1312, duration: 30.303s, episode steps: 697, steps per second:  23, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: 0.019976, mae: 2.848625, mean_q: 3.447053, mean_eps: 0.111086\n",
            " 988717/1000000: episode: 1313, duration: 30.015s, episode steps: 686, steps per second:  23, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.017377, mae: 2.829648, mean_q: 3.420170, mean_eps: 0.110463\n",
            " 989692/1000000: episode: 1314, duration: 42.940s, episode steps: 975, steps per second:  23, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.018845, mae: 2.836995, mean_q: 3.429912, mean_eps: 0.109716\n",
            " 990974/1000000: episode: 1315, duration: 56.099s, episode steps: 1282, steps per second:  23, episode reward: 29.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.020113, mae: 2.868217, mean_q: 3.469372, mean_eps: 0.108701\n",
            " 991796/1000000: episode: 1316, duration: 36.404s, episode steps: 822, steps per second:  23, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.956 [0.000, 5.000],  loss: 0.016996, mae: 2.868885, mean_q: 3.470532, mean_eps: 0.107754\n",
            " 992889/1000000: episode: 1317, duration: 48.944s, episode steps: 1093, steps per second:  22, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.889 [0.000, 5.000],  loss: 0.018269, mae: 2.874474, mean_q: 3.476515, mean_eps: 0.106892\n",
            " 993507/1000000: episode: 1318, duration: 26.588s, episode steps: 618, steps per second:  23, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.016907, mae: 2.875796, mean_q: 3.480151, mean_eps: 0.106122\n",
            " 994630/1000000: episode: 1319, duration: 49.688s, episode steps: 1123, steps per second:  23, episode reward: 27.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.018690, mae: 2.887091, mean_q: 3.493672, mean_eps: 0.105339\n",
            " 995527/1000000: episode: 1320, duration: 38.846s, episode steps: 897, steps per second:  23, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.949 [0.000, 5.000],  loss: 0.018498, mae: 2.876217, mean_q: 3.479170, mean_eps: 0.104430\n",
            " 996507/1000000: episode: 1321, duration: 42.594s, episode steps: 980, steps per second:  23, episode reward: 26.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.021069, mae: 2.904338, mean_q: 3.512981, mean_eps: 0.103586\n",
            " 997095/1000000: episode: 1322, duration: 25.587s, episode steps: 588, steps per second:  23, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.713 [0.000, 5.000],  loss: 0.022177, mae: 2.884891, mean_q: 3.491708, mean_eps: 0.102880\n",
            " 997953/1000000: episode: 1323, duration: 37.236s, episode steps: 858, steps per second:  23, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.018856, mae: 2.899008, mean_q: 3.507419, mean_eps: 0.102228\n",
            " 999136/1000000: episode: 1324, duration: 50.933s, episode steps: 1183, steps per second:  23, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.019117, mae: 2.884005, mean_q: 3.488788, mean_eps: 0.101310\n",
            " 999757/1000000: episode: 1325, duration: 26.872s, episode steps: 621, steps per second:  23, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.039 [0.000, 5.000],  loss: 0.021335, mae: 2.884121, mean_q: 3.491488, mean_eps: 0.100499\n",
            "done, took 34248.290 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 7.000, steps: 481\n",
            "Episode 2: reward: 14.000, steps: 799\n",
            "Episode 3: reward: 9.000, steps: 652\n",
            "Episode 4: reward: 14.000, steps: 1021\n",
            "Episode 5: reward: 27.000, steps: 1122\n",
            "Episode 6: reward: 10.000, steps: 487\n",
            "Episode 7: reward: 5.000, steps: 548\n",
            "Episode 8: reward: 15.000, steps: 836\n",
            "Episode 9: reward: 11.000, steps: 650\n",
            "Episode 10: reward: 16.000, steps: 847\n",
            "Episode 11: reward: 9.000, steps: 519\n",
            "Episode 12: reward: 10.000, steps: 607\n",
            "Episode 13: reward: 21.000, steps: 1031\n",
            "Episode 14: reward: 14.000, steps: 807\n",
            "Episode 15: reward: 14.000, steps: 799\n",
            "Episode 16: reward: 7.000, steps: 500\n",
            "Episode 17: reward: 19.000, steps: 956\n",
            "Episode 18: reward: 12.000, steps: 737\n",
            "Episode 19: reward: 20.000, steps: 919\n",
            "Episode 20: reward: 11.000, steps: 647\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c74d7b715d0>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam  # ✅ IMPORTANTE: usar legacy\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# ==== Constantes ====\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "\n",
        "# ==== Procesador para observaciones ====\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3\n",
        "        img = Image.fromarray(observation)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        return batch.astype('float32') / 255.\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "# ==== Preparar entorno ====\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "# ==== Modelo CNN tipo DeepMind ====\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 3, 1), input_shape=input_shape))  # (4, 84, 84) → (84, 84, 4)\n",
        "model.add(Conv2D(32, kernel_size=8, strides=4, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(nb_actions, activation='linear'))\n",
        "\n",
        "# ==== Memoria y política ====\n",
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=1.0, value_min=0.1, value_test=0.05,\n",
        "                              nb_steps=1000000)\n",
        "\n",
        "# ==== Agente DQN ====\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               memory=memory,\n",
        "               processor=AtariProcessor(),\n",
        "               nb_steps_warmup=50000,\n",
        "               target_model_update=10000,\n",
        "               train_interval=4,\n",
        "               gamma=0.99,\n",
        "               policy=policy)\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.0001), metrics=['mae'])\n",
        "\n",
        "# ==== Callbacks ====\n",
        "checkpoint_weights_filename = 'dqn_{}_weights_{{step}}.h5f'.format(ENV_NAME)\n",
        "log_filename = 'dqn_{}_log.json'.format(ENV_NAME)\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000),\n",
        "    FileLogger(log_filename, interval=100)\n",
        "]\n",
        "\n",
        "# ==== Entrenamiento ====\n",
        "dqn.fit(env,\n",
        "        nb_steps=1000000,  # ENTRENAMIENTO EXTENDIDO\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "# ==== Guardar pesos finales ====\n",
        "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
        "\n",
        "# ==== Evaluación ====\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "DViZgleIyoPb",
        "outputId": "c36e1fcf-bd6c-4bbf-bd0f-1362beaa9e9d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAIjCAYAAADWYVDIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnXe8E1Xax3/ptxfqpVx6L9JERKQoTVAUu6uugm2ta0PXsruiqCx213UR14YKq2L3XVGxgCCCSkfqpV3g9pqb5CaZJPP+kTuTmWQmmSST/nw/HzR3yjnPqXOe85zzHA3LsiwIgiAIgiAIgiAIAIA20QIQBEEQBEEQBEEkE6QkEQRBEARBEARBCCAliSAIgiAIgiAIQgApSQRBEARBEARBEAJISSIIgiAIgiAIghBAShJBEARBEARBEIQAUpIIgiAIgiAIgiAEkJJEEARBEARBEAQhgJQkgiDSmjfeeAPLli1LtBgEQRAEQaQQpCQRBBEzNBoNFi5cGLPwp0yZgilTpsjeX7VqFe68806MHTs2ZjIIeeutt6DRaHD06NGw3124cCE0Go36QqUA8+bNQ69evSJ+v1evXpg3b55q8qQzsW6ThJe1a9dCo9Fg7dq1iRaFIIgIISWJINIcbuAu92/Tpk2JFjEmHDx4EDfffDM++OADjB49OtHiEAT27NmDhQsXRqREpzobN27EwoUL0dTUlGhR0oonn3wSn376aaLFIIi0RJ9oAQiCiA+PPfYYevfuHXC9X79+CZBGHb755hvZezt27MCbb76JWbNmxVEigpBnz549ePTRRzFlypSoLGepyMaNG/Hoo49i3rx5KCoqSrQ4MWfSpElobW2F0WiMaTxPPvkkLrnkEsydOzem8RBEJkJKEkFkCLNmzcKpp56aaDFUJdgA5JJLLomjJInFZrMhJycn0WLIYrfbYTQaodUm/+IFlmVht9uRnZ2daFEyFo/HA6fTiaysrESLEjFarTal5ScIgpbbEQQBgGEYtGvXDvPnzw+4ZzabkZWVhQULFvDXampqcP3116Nz587IysrCiBEjsHz58pDxyO09kduP8+677+K0005DTk4OiouLMWnSJJH1SGpPkhLZjh49Co1Gg2eeeQavvvoq+vbtC5PJhLFjx+LXX38NmQ4A+P3333H22WcjOzsb3bt3x+OPPw6PxyP57OrVqzFx4kTk5uYiPz8f5557Ln7//XdF8fgzZcoUDBs2DFu2bMGkSZOQk5ODhx56CADgcDjwyCOPoF+/fjCZTCgtLcX9998Ph8PBv3/RRRcFLD+cM2cONBoNPv/8c/7a5s2bodFosHr1agBAQ0MDFixYgOHDhyMvLw8FBQWYNWsWduzYIQqL24vx3nvv4a9//Su6deuGnJwcmM1mAMCnn36KYcOGISsrC8OGDcMnn3yiOO0sy+Lxxx9H9+7dkZOTg7POOksyH+Xqk9SesV69euG8887D119/jVNPPRXZ2dm8o48333wTZ599Njp16gSTyYQhQ4Zg6dKlAeFyYWzYsAGnnXYasrKy0KdPH7z99tuiuC+99FIAwFlnncUvdxXuWYmmnjQ1NeGuu+5CaWkpTCYT+vXrhyVLlsjWyVAoqUuAd4/T7bffzperyWTC0KFD8dVXX/HPLFy4EPfddx8AoHfv3nzauXLgwlixYgWGDh0Kk8nEv3/y5Elcd9116Ny5Mx/2G2+8IZKBq3MffPABnnjiCXTv3h1ZWVmYOnUqysrKRM+uX78el156KXr06MGn6+6770Zra6vouXnz5iEvLw/l5eU477zzkJeXh27duuHll18GAOzatQtnn302cnNz0bNnT6xcuVJSJv89SZs3b8Y555yDwsJC5OTkYPLkyfjpp59Ez3D1t6ysjLe8FRYWYv78+bDZbKK8t1qtWL58OZ+nwr1527Ztw6xZs1BQUIC8vDxMnTo1bZdXE0QsIEsSQWQIzc3NqKurE13TaDRo3749DAYDLrzwQnz88cdYtmyZyELz6aefwuFw4IorrgAAtLa2YsqUKSgrK8Ptt9+O3r17Y9WqVZg3bx6amppw5513qiLvo48+ioULF+KMM87AY489BqPRiM2bN+P777/HjBkzJN8JV7aVK1eipaUFf/rTn6DRaPDUU0/hoosuwuHDh2EwGGRlq6qqwllnnQWXy4UHHngAubm5ePXVVyWtD++88w6uvfZazJw5E0uWLIHNZsPSpUtx5plnYtu2bREtu6qvr8esWbNwxRVX4Oqrr0bnzp3h8Xhw/vnnY8OGDbjpppswePBg7Nq1C88//zwOHDjA71uYOHEiPvvsM5jNZhQUFIBlWfz000/QarVYv349zj//fADewaRWq8WECRMAAIcPH8ann36KSy+9FL1790Z1dTWWLVuGyZMnY8+ePejatatIxkWLFsFoNGLBggVwOBwwGo345ptvcPHFF2PIkCFYvHgx6uvrMX/+fHTv3l1Ruv/+97/j8ccfx+zZszF79mxs3boVM2bMgNPpDDsPhezfvx9/+MMf8Kc//Qk33ngjBg4cCABYunQphg4divPPPx96vR5ffPEFbr31Vng8Htx2222iMMrKynDJJZfg+uuvx7XXXos33ngD8+bNw5gxYzB06FBMmjQJf/7zn/HPf/4TDz30EAYPHgwA/P+jqSc2mw2TJ0/GyZMn8ac//Qk9evTAxo0b8eCDD6KyshIvvPBCWPmhtC5xbNiwAR9//DFuvfVW5Ofn45///CcuvvhilJeXo3379rjoootw4MAB/Pe//8Xzzz+PDh06AAA6duzIh/H999/jgw8+wO23344OHTqgV69eqK6uxumnn84rUR07dsTq1atx/fXXw2w246677hLJ8Y9//ANarRYLFixAc3MznnrqKVx11VXYvHkz/8yqVatgs9lwyy23oH379vjll1/w0ksv4cSJE1i1apUoPLfbjVmzZmHSpEl46qmnsGLFCtx+++3Izc3Fww8/jKuuugoXXXQRXnnlFVxzzTUYP3685JJmYRpnzZqFMWPG4JFHHoFWq+UV8fXr1+O0004TPX/ZZZehd+/eWLx4MbZu3YrXXnsNnTp1wpIlSwB468wNN9yA0047DTfddBMAoG/fvgC8kzgTJ05EQUEB7r//fhgMBixbtgxTpkzBunXrMG7cOAU1gSAyHJYgiLTmzTffZAFI/jOZTPxzX3/9NQuA/eKLL0Tvz549m+3Tpw//9wsvvMACYN99913+mtPpZMePH8/m5eWxZrOZvw6AfeSRR/i/r732WrZnz54BMj7yyCOssDs6ePAgq9Vq2QsvvJB1u92iZz0eD/978uTJ7OTJk8OW7ciRIywAtn379mxDQwP/7GeffSaZB/7cddddLAB28+bN/LWamhq2sLCQBcAeOXKEZVmWbWlpYYuKitgbb7xR9H5VVRVbWFgouu6fB3JMnjyZBcC+8sorouvvvPMOq9Vq2fXr14uuv/LKKywA9qeffmJZlmV//fVXFgD75ZdfsizLsjt37mQBsJdeeik7btw4/r3zzz+fHTVqFP+33W4PKIsjR46wJpOJfeyxx/hrP/zwAwuA7dOnD2uz2UTPjxw5ku3SpQvb1NTEX/vmm29YAJL1QkhNTQ1rNBrZc889V1QHHnroIRYAe+211/LX5PKSawtc+bAsy/bs2ZMFwH711VcBz/vLz7IsO3PmTFF7EIbx448/iuQ1mUzsvffey19btWoVC4D94YcfRO+HU0+kWLRoEZubm8seOHBAdP2BBx5gdTodW15ezl/zb5NSKK1LXHhGo5EtKyvjr+3YsYMFwL700kv8taeffjog74VhaLVa9vfffxddv/7669kuXbqwdXV1outXXHEFW1hYyJcPV+cGDx7MOhwO/rkXX3yRBcDu2rWLvyZVposXL2Y1Gg177Ngx/tq1117LAmCffPJJ/lpjYyObnZ3NajQa9r333uOv79u3LyBfOZm4svZ4PGz//v3ZmTNniuqvzWZje/fuzU6fPp2/xtXf6667TiTnhRdeyLZv3150LTc3V1T3OebOncsajUb20KFD/LWKigo2Pz+fnTRpUsDzBEEEQsvtCCJDePnll7FmzRrRP24pFQCcffbZ6NChA95//33+WmNjI9asWYPLL7+cv/bll1+ipKQEf/jDH/hrBoMBf/7zn2GxWLBu3bqoZf3000/h8Xjw97//PWAfSzA32eHKdvnll6O4uJj/e+LEiQC8VpNgfPnllzj99NNFM78dO3bEVVddJXpuzZo1aGpqwh/+8AfU1dXx/3Q6HcaNG4cffvghaDxymEymgKWRq1atwuDBgzFo0CBRXGeffTYA8HGNGjUKeXl5+PHHHwF4LUbdu3fHNddcg61bt8Jms4FlWWzYsIHPDy5Orizcbjfq6+uRl5eHgQMHYuvWrQEyXnvttSLLWmVlJbZv345rr70WhYWF/PXp06djyJAhIdP87bffwul04o477hDVAX9rQiT07t0bM2fODLgulJ+zxE6ePBmHDx9Gc3Oz6NkhQ4aI8qtjx44YOHBgyLoERF9PVq1ahYkTJ6K4uFj0/rRp0+B2u/myVorSusQxbdo03oIBAKeccgoKCgoUpZ1j8uTJonrAsiw++ugjzJkzByzLiuSYOXMmmpubA+rd/PnzRVZwqfYsLFOr1Yq6ujqcccYZYFkW27ZtC5Drhhtu4H8XFRVh4MCByM3NxWWXXcZfHzhwIIqKioKmd/v27Th48CCuvPJK1NfX82mxWq2YOnUqfvzxx4ClkTfffLPo74kTJ6K+vp5fuiqH2+3GN998g7lz56JPnz789S5duuDKK6/Ehg0bQoZBEAQttyOIjOG0004L6rhBr9fj4osvxsqVK+FwOGAymfDxxx+DYRiRknTs2DH0798/QHnhlg0dO3YsalkPHToErVaraPAsJFzZevToIfqbU5gaGxtDxiO1XIVbpsVx8OBBAOAHl/4UFBQEjUeObt26BTitOHjwIPbu3StawiSkpqYGAKDT6TB+/HisX78egFdJmjhxIs4880y43W5s2rQJnTt3RkNDg2jQ7/F48OKLL+Lf//43jhw5Arfbzd9r3759QHz+y464vO/fv3/As3KKlpL3O3bsKFJ0I0FuidRPP/2ERx55BD///LNoLwjgVZqEyp5/XQK89SlUXQKirycHDx7Ezp07Q5a9UpTWJY5o0s7hXwa1tbVoamrCq6++ildffTUiOaTac3l5Of7+97/j888/D5DPX/HNysoKyIPCwkJ07949YLKmsLAwaHq5Mr722mtln2lubhbV5WDpCVYnamtrYbPZAvojwNsXejweHD9+HEOHDpUNgyAIUpIIghBwxRVXYNmyZVi9ejXmzp2LDz74AIMGDcKIESNUCV/OCiQccMcTnU4neZ1lWVXC52aG33nnHZSUlATc1+sj64Kl9j55PB4MHz4czz33nOQ7paWl/O8zzzwTTzzxBOx2O9avX4+HH34YRUVFGDZsGNavX4/OnTsDgEhJevLJJ/G3v/0N1113HRYtWoR27dpBq9XirrvuknQOkEjvcOHWMylZDx06hKlTp2LQoEF47rnnUFpaCqPRiC+//BLPP/98QJqjqUvR1hOPx4Pp06fj/vvvl7w/YMCAkDL4h6e0LgHqtCP/MuDy5Oqrr5ZVLE455ZSw5HC73Zg+fToaGhrwl7/8BYMGDUJubi5OnjyJefPmKS7TSNLLhf30009j5MiRks/k5eVFHQ9BEOpBShJBEDyTJk1Cly5d8P777+PMM8/E999/j4cfflj0TM+ePbFz5054PB6RxWbfvn38fTmKi4slD5P0t/D07dsXHo8He/bskR1QSBGNbOHQs2dPfmZYyP79+0V/c0uQOnXqhGnTpqkStxx9+/bFjh07MHXq1KBLEgGv8uN0OvHf//4XJ0+e5JWhSZMm8UrSgAEDeGUJAD788EOcddZZeP3110VhNTU18Rvxg8HlvZJ8C/W+cAlRbW1twAw+N+Pe1NQkOpMnHCvnF198AYfDgc8//1w0ox/pEklAXnmLtp707dsXFotFtToWTl1SSrjhdOzYEfn5+XC73aqla9euXThw4ACWL1+Oa665hr++Zs0aVcIPBlfGBQUFqvYFUvnasWNH5OTkSLarffv2QavVBii6BEEEQnuSCILg0Wq1uOSSS/DFF1/gnXfegcvlEi21A4DZs2ejqqpKtHfJ5XLhpZdeQl5eHiZPniwbft++fdHc3IydO3fy1yorKwPcQM+dOxdarRaPPfZYwOxusFnUaGQLh9mzZ2PTpk345Zdf+Gu1tbVYsWKF6LmZM2eioKAATz75JBiGCQintrZWFXkAryeskydP4j//+U/AvdbWVlitVv7vcePGwWAwYMmSJWjXrh2/7GbixInYtGkT1q1bJ7IiAd5Zbf+8X7VqFU6ePKlIvi5dumDkyJFYvny5aFnTmjVrsGfPnpDvT5s2DQaDAS+99JJIDinPbdyAVLgXh3OVrBRuFl8YV3NzM958803FYfiTm5sLAAETBdHWk8suuww///wzvv7664B7TU1NcLlcYckZTl1Silza5dDpdLj44ovx0UcfYffu3QH3I2k7UmXKsixefPHFsMMKlzFjxqBv37545plnYLFYAu5H2hfk5uYG5KlOp8OMGTPw2WefidzdV1dXY+XKlTjzzDMjXupLEJkEWZIIIkNYvXo1b1ERcsYZZ4hm5i+//HK89NJLeOSRRzB8+HB+Pw/HTTfdhGXLlmHevHnYsmULevXqhQ8//BA//fQTXnjhBeTn58vKcMUVV+Avf/kLLrzwQvz5z3/m3RwPGDBAtCelX79+ePjhh7Fo0SJMnDgRF110EUwmE3799Vd07doVixcvlgw/GtnC4f7778c777yDc845B3feeSfvApyzZHEUFBRg6dKl+OMf/4jRo0fjiiuuQMeOHVFeXo7//e9/mDBhAv71r3+pItMf//hHfPDBB7j55pvxww8/YMKECXC73di3bx8++OAD/hwgAMjJycGYMWOwadMm/owkwGtJslqtsFqtAUrSeeedh8ceewzz58/HGWecgV27dmHFihWiuhOKxYsX49xzz8WZZ56J6667Dg0NDXjppZcwdOhQyYGjkI4dO2LBggVYvHgxzjvvPMyePRvbtm3D6tWrAyxZM2bMQI8ePXD99dfjvvvug06nwxtvvMHnvRJmzJgBo9GIOXPm4E9/+hMsFgv+85//oFOnTqisrFScZiEjR46ETqfDkiVL0NzcDJPJxJ/DFE09ue+++/D555/jvPPO492OW61W7Nq1Cx9++CGOHj2qyNrHEU5dUsqYMWMAAA8//DCuuOIKGAwGzJkzh1eepPjHP/6BH374AePGjcONN96IIUOGoKGhAVu3bsW3336LhoaGsGQYNGgQ+vbtiwULFuDkyZMoKCjARx99FNbeqUjRarV47bXXMGvWLAwdOhTz589Ht27dcPLkSfzwww8oKCjAF198EXa4Y8aMwbfffovnnnsOXbt2Re/evTFu3Dg8/vjjWLNmDc4880zceuut0Ov1WLZsGRwOB5566qkYpJAg0pD4O9QjCCKeBHMBDoB98803Rc97PB62tLSUBcA+/vjjkmFWV1ez8+fPZzt06MAajUZ2+PDhAeGwrLS74W+++YYdNmwYazQa2YEDB7LvvvuurMvmN954gx01ahRrMpnY4uJidvLkyeyaNWv4+/4uwJXKxrkAf/rppxXJLMXOnTvZyZMns1lZWWy3bt3YRYsWsa+//rqkm+MffviBnTlzJltYWMhmZWWxffv2ZefNm8f+9ttv/DPhuAAfOnSo5D2n08kuWbKEHTp0KJ9nY8aMYR999FG2ublZ9Ox9993HAmCXLFkiut6vXz8WgMh1MMt6XYDfe++9bJcuXdjs7Gx2woQJ7M8//xxQBpzr41WrVknK+NFHH7GDBw9mTSYTO2TIEPbjjz+WdQ3vj9vtZh999FFehilTprC7d+9me/bsGeAGecuWLey4ceNYo9HI9ujRg33uuedkXYCfe+65kvF9/vnn7CmnnMJmZWWxvXr1YpcsWcK+8cYbisOQqp//+c9/2D59+rA6nS7AHbiSeiJHS0sL++CDD7L9+vVjjUYj26FDB/aMM85gn3nmGdbpdPLPKa3fSusSAPa2224LeF+qTBYtWsR269aN1Wq1ojyUC4Nlve35tttuY0tLS1mDwcCWlJSwU6dOZV999VX+Gbk6x7VzYfvfs2cPO23aNDYvL4/t0KEDe+ONN/Iuy4XPXXvttWxubm6APHLtz78O+LsA59i2bRt70UUXse3bt2dNJhPbs2dP9rLLLmO/++47/hmuL6itrRW9K1V/9+3bx06aNInNzs4OcIW/detWdubMmWxeXh6bk5PDnnXWWezGjRsDZCcIQhoNy9IOQIIgCIIgCIIgCA7ak0QQBEEQBEEQBCGAlCSCIAiCIAiCIAgBpCQRBEEQBEEQBEEIICWJIAiCIAiCIAhCAClJBEEQBEEQBEEQAkhJIgiCIAiCIAiCEJD2h8l6PB5UVFQgPz+fPzCRIAiCIAiCIIjMg2VZtLS0oGvXrtBq5e1Faa8kVVRUoLS0NNFiEARBEARBEASRJBw/fhzdu3eXvZ/2SlJ+fj4Ab0YUFBQkVBaGYfDNN99gxowZMBgMCZWFkIfKKTWgckodqKxSAyqn1IHKKjWgckpOzGYzSktLeR1BjrRXkrgldgUFBUmhJOXk5KCgoIAaSxJD5ZQaUDmlDlRWqQGVU+pAZZUaUDklN6G24ZDjBoIgCIIgCIIgCAGkJBEEQRAEQRAEQQggJYkgCIIgCIIgCEJA2u9JUgLLsnC5XHC73TGNh2EY6PV62O32mMdFRE4mlJNOp4Nerye3+ARBEARBEBJkvJLkdDpRWVkJm80W87hYlkVJSQmOHz9Og9MkJlPKKScnB126dIHRaEy0KARBEARBEElFRitJHo8HR44cgU6nQ9euXWE0GmM6KPZ4PLBYLMjLywt6eBWRWNK9nFiWhdPpRG1tLY4cOYL+/funZToJgiAIgiAiJaOVJKfTCY/Hg9LSUuTk5MQ8Po/HA6fTiaysLBqUJjGZUE7Z2dkwGAw4duwYn1aCIAiCIAjCS3qOAMMkXQfCBBEMqvcEQRAEQRDS0CiJIAiCIAiCIAhCAClJBEEQBEEQBEEQAkhJIuLOlClTcNdddyVaDFWZN28e5s6dG7Pwjx49Co1Gg+3btwMA1q5dC41Gg6amppjFSRAEQRAEkamQkpSCzJs3DxqNBhqNBgaDAb1798b9998Pu92eaNEylhdffBFvvfVW3OI744wzUFlZicLCwrjFSRAEQRAEkSlktHe7VOacc87Bm2++CYZhsGXLFlx77bXQaDRYsmRJokUD4HUz7Xa7odcnTxVjGAYGgyEmYcdbWTEajSgpKYlrnARBEARBEJkCWZL8cHvYhPwLF5PJhJKSEpSWlmLu3LmYNm0a1qxZw9/3eDxYvHgxevfujezsbIwYMQIffvghf//UU0/FM888w/89d+5cGAwGWCwWAMCJEyeg0WhQVlYGAHjnnXdw6qmnIj8/HyUlJbjyyitRU1PDv88t/1q9ejXGjBkDk8mEDRs2wGq14pprrkFeXh66dOmCZ599NmTaFi5ciJEjR2LZsmW8e/bLLrsMzc3NovQ99thj6N69O0wmE0aOHImvvvqKv88tT3v//fcxefJkZGVlYcWKFZLxNTU14YYbbkDHjh1RUFCAadOmYdeuXWHJ47/c7sMPP8Tw4cORnZ2N9u3bY9q0abBarYpkB4BffvkFo0aNQlZWFk499VRs27ZNdF9qud1HH32EoUOHwmQyoVevXorymiAIgiAIgggkeab5kwC3h8UP+2pCPxghLOuBzdaKnBw7NBqxfnrWoE7QaSM7yHb37t3YuHEjevbsyV9bvHgx3n33Xbzyyivo378/fvzxR1x99dXo2LEjJk+ejMmTJ2Pt2rVYsGABWJbF+vXrUVRUhA0bNuCcc87BunXr0K1bN/Tr1w+A1wqzaNEiDBw4EDU1Nbjnnnswb948fPnllyJZHnjgATzzzDPo06cPiouLcd9992HdunX47LPP0KlTJzz00EPYunUrRo4cGTRNZWVl+OCDD/DFF1/AbDbj+uuvx6233sorOi+++CKeffZZLFu2DKNGjcIbb7yB888/H7///jv69+8vkufZZ5/lFQ4pLr30UmRnZ2P16tUoLCzEK6+8grlz52L//v3o0KGDInmEVFZW4g9/+AOeeuopXHjhhWhpacH69evBsqwi2S0WC8477zxMnz4d7777Lo4cOYI777wzaH5t2bIFl112GRYuXIjLL78cGzduxK233or27dtj3rx5Qd8lCIIgCIIgxJCSlKL83//9H/Ly8uByueBwOKDVavGvf/0LAOBwOPDkk0/i22+/xfjx4wEAffr0wYYNG7Bs2TJMnjwZU6ZMweuvvw63243du3fDaDTi8ssvx9q1a3HOOedg7dq1mDx5Mh/fddddx//u06cP/vnPf2Ls2LGwWCzIy8vj7z322GOYPn06AMBiseD111/Hu+++i6lTpwIAli9fju7du4dMn91ux9tvv41u3boBAF566SWce+65ePbZZ1FSUoJnnnkGf/nLX3DFFVcAAJYsWYIffvgBL7zwAl5++WU+nLvuugsXXXSRbDwbNmzAL7/8gpqaGphMJgDA008/jU8++QQffvghbr75ZkXyCKmsrITL5cJFF13EK67Dhw/n74eSfeXKlfB4PHj99deRlZWFoUOH4sSJE7jllltk0/Hcc89h6tSp+Nvf/gYAGDBgAPbs2YOnn36alCSCIAiCIIgwISVJgE6rwVmDOsUsfI/HA7PZjIKCgoCDPMO1Ip111llYunQprFYrnn/+eej1elx88cUAvFYPm83GKyscTqcTo0aNAgBMnDgRLS0t2LZtGzZu3MgrTv/4xz8AAOvWrcN9993Hv7tlyxYsXLgQO3bsQGNjIzweDwCgvLwcQ4YM4Z879dRT+d+HDh2C0+nEuHHj+Gvt2rXDwIEDQ6avR48evEICAOPHj4fH48H+/fuRk5ODiooKTJgwQfTOhAkTsGPHDtE1oTxS7NixAxaLBe3btxddb21txeHDhxXJ468kjRgxAlOnTsXw4cMxc+ZMzJgxA5dccgmKi4thNptDyr53716ccsopIssXp+zKsXfvXlxwwQUBYb7wwgtwu93Q6XRB3ycIggAADws0tzJor9dDo4lsdQNBEEQ6QEqSH5EueVOCBhrotN5/2ijjyc3N5ZfCvfHGGxgxYgRef/11XH/99fy+ov/973+igT0A3lpSVFSEESNGYO3atfj5558xffp0TJo0CZdffjkOHDiAgwcP8pYkq9WKmTNnYubMmVixYgU6duyI8vJyzJw5E06nM0CuZCKUPBaLBV26dMHatWv5ax6PBxaLRZHFSwqdToc1a9Zg48aN+Oabb/DSSy/h4YcfxubNmwOUMYIgiGTimAXIPtaIod2A0nY5iRaHIAgiYZDjhjRAq9XioYcewl//+le0trZiyJAhMJlMKC8vR79+/UT/SktL+fcmT56MH374AT/++COmTJmCdu3aYfDgwXjiiSfQpUsXDBgwAACwb98+1NfX4x//+AcmTpyIQYMGiZw2yNG3b18YDAZs3ryZv9bY2IgDBw6EfLe8vBwVFRX835s2bYJWq8XAgQNRUFCArl274qeffhK989NPP4msWkoYPXo0qqqqoNfrRfnUp08ffj9SKHmk0Gg0mDBhAh599FFs27YNRqMRn3zyiSLZBw8ejJ07d4pcum/atCloOgYPHiwZ5oABA8iKRBCEYqyMdwLvZFNrgiUhCIJILKQkpQmXXnopdDodXn75ZeTn52PBggW4++67sXz5chw6dAhbt27FSy+9hOXLl/PvTJkyBV9//TX0ej0GDRrEX1uxYoVoP1KPHj1gNBrx0ksv4fDhw/j888+xaNGikDLl5eXh+uuvx3333Yfvv/8eu3fvxrx58wKWGkqRlZWFa6+9Fjt27MD69evx5z//GZdddhm/tO2+++7DkiVL8P7772P//v144IEHsH379pAODvyZNm0axo8fj7lz5+Kbb77B0aNHsXHjRixatAi//fabYnmEbN68GU8++SR+++03lJeX4+OPP0ZtbS0GDx6sSPYrr7wSGo0GN954I/bs2YMvv/xS5IlQinvvvRffffcdFi1ahAMHDmD58uX417/+hQULFoSVHwRBEARBEAQtt0sb9Ho9br/9djz11FO45ZZbsGjRInTs2BGLFy/G4cOHUVRUhNGjR+Ohhx7i35k4cSI8Ho9IIZoyZQpefPFFTJkyhb/WsWNHvPXWW3jooYfwz3/+E6NHj8YzzzyD888/P6RcTz/9NCwWC+bMmYP8/Hzce++9ItfZcvTr1w8XXXQRZs+ejYaGBpx33nn497//zd//85//jObmZtx7772oqanBkCFD8Pnnn4s82ylBo9Hgyy+/xMMPP4z58+ejtrYWJSUlOP3009G5c2fF8ggpKCjAjz/+iBdeeAFmsxk9e/bEs88+i1mzZimSPS8vD1988QVuvvlmjBo1CkOGDMGSJUv4PWdSjB49Gh988AH+/ve/Y9GiRejSpQsee+wxctpAEARBEAQRARqW80ucppjNZhQWFqK5uRkFBQWie3a7HUeOHEHv3r1l3UOrSTDHDYSPhQsX4tNPP8X27dsTEr9/OSVanlgR7/qvNgzD4Msvv8Ts2bNjdkgwoQ5UVqkBwzB46t3VGHPqGBTlZuH0PrSHMlmhNpUaUDklJ8F0AyE0UicIgiAIgiAIghBAShJBEARBEARBEIQAUpKIpGPhwoVJtbQt2eQhCIIgCIIgYgspSQRBEARBiKBjZAmCyHQSqiQtXboUp5xyCgoKClBQUIDx48dj9erV/P0pU6ZAo9GI/t18880JlJggCIIgCIIgiHQnoS7Au3fvjn/84x/o378/WJbF8uXLccEFF2Dbtm0YOnQoAODGG2/EY489xr+Tk0MngBMEQRAEQRAEETsSqiTNmTNH9PcTTzyBpUuXYtOmTbySlJOTI3lgJ0EQBEEQBEEQRCxImsNk3W43Vq1aBavVivHjx/PXV6xYgXfffRclJSWYM2cO/va3vwW1JjkcDjgcDv5vs9kMwOurnmEY0bMMw4BlWXg8Hng8HpVTFAh3JBUXJxE+ZWVlWLVqFe666y5kZ2fHJI5MKSePxwOWZcEwDHQ6XaLFCRuuPfu3ayJyWuwMdp00o2/HXHQuUO/sLCqr1IArH7fLDZfbReWVxFCbih+M24Ot5U3olG9C7w654b1L5ZSUKC2PhB8mu2vXLowfPx52ux15eXlYuXIlZs+eDQB49dVX0bNnT3Tt2hU7d+7EX/7yF5x22mn4+OOPZcNbuHAhHn300YDrK1euDFCu9Ho9SkpKUFpaCqPRqG7CUpwNGzZgzpw5OHr0KAoLC7Fy5Uo8+OCDOHbsWMJkstvtmD59Om655RZceeWVit+LNC3vvPMOPvnkk6D1LVycTidOPfVULF++HKNGjVIt3EhlOX78OKqqquByuRIqC5Ec7G/WgHF7fw9rl9bnjBMy7G7wumzI0rPoJ3/GIkFkDDWtQE2rt11Qv5ge2Gw2XHnllSEPk024kuR0OlFeXo7m5mZ8+OGHeO2117Bu3ToMGTIk4Nnvv/8eU6dORVlZGfr27SsZnpQlqbS0FHV1dQEZYbfbcfz4cfTq1QtZWerNmsrBsixaWlqQn58PjSZy30Hz58/H22+/jZtuuglLly4V3bv99tuxdOlSXHPNNXjzzTcjjmPt2rWYOnUq6uvrUVRUhNbWVrS0tKBTp04RhxktN910E7p164ZHHnkkrPecTicaGhrQuXNnaDQavPXWW7jnnnvQ0NAg+TzLsqitrcXo0aPx/vvvY8KECQCA33//HY888gi2bt2KY8eO4bnnnsOdd94Z8P6///1vPPPMM6iqqsKIESPw4osv4rTTTuPvv/zyy/j000+xZs2asNKhNna7HUePHkVpaWlc6r/aMAyDNWvWYPr06XSSuUqsL6uD0+W1nk4dpF5bp7JKDRiGwfPvf4uRI0eiOC8LY3sVJ1okQgZqU/HjcK0VR+qtAMLvF6mckhOz2YwOHTqEVJISvtzOaDSiX79+AIAxY8bg119/xYsvvohly5YFPDtu3DgACKokmUwmmEymgOsGgyGggrrdbmg0Gmi1Wmi1sXf0xy3d4uKMFI1Gg9LSUrz//vt44YUX+GVndrsd//3vf9GjR4+o4+De5fImNzcXubnhmZnV5rXXXovovaysLHTt2pX/W5g2KTweDz777DMUFBRg4sSJ/HW73Y6+ffvisssuw9133y2Zx++//z7uvfdevPLKKxg3bhxeeOEFzJo1C/v37+cVzKuvvhoLFizA3r17+b13iUCr1UKj0Ui2jVQi1eVPJvQ6PTyst5+KRZ5SWaUGOr0Oer2eyioFoDYVewwGPfQ6fdvvyPKayim5UFoWSXdOksfjEVmChHAHenbp0iWOEiUno0ePRmlpqWgp2Mcff4wePXoELOPyeDxYvHgxevfujezsbIwYMQIffvih6Jkvv/wSAwYMQHZ2Ns466ywcPXpUdP+tt95CUVER//ehQ4dwwQUXoHPnzsjLy8PYsWPx7bffBpV54cKFGDlyJN544w306NEDeXl5uPXWW+F2u/HUU0+hpKQEnTp1whNPPCF6r7y8HBdccAHy8vJQUFCAyy67DNXV1QCAAwcOQKPRYN++faJ3nn/+eV6RXrt2LTQaDZqamoLKJ+Tjjz/GeeedJ7o2duxYPP3007jiiiskFXEAeO6553DjjTdi/vz5GDJkCF555RXk5OTgjTfe4J8pLi7GhAkT8N577ymWhyAIgiAIgogfCVWSHnzwQfz44484evQodu3ahQcffBBr167FVVddhUOHDmHRokXYsmULjh49is8//xzXXHMNJk2ahFNOOSU2ArEsYLUm5l8Eqx6vu+460ZK6N954A/Pnzw94bvHixXj77bfxyiuv4Pfff8fdd9+Nq6++GuvWrQMAHD9+HBdddBHmzJmD7du344YbbsADDzwQNG6LxYLZs2fju+++w7Zt23DOOedgzpw5KC8vD/reoUOHsHr1anz11Vf473//i9dffx3nnnsuTpw4gXXr1mHJkiX461//is2bNwPwKngXXHABGhoasG7dOqxZswaHDx/G5ZdfDgAYMGAATj31VKxYsUIUz4oVK8Lat+TPpk2bMGbMmLDecTqd2LJlC6ZNm8Zf02q1mDZtGn7++WfRs6eddhrWr18fsXwEQRAEQRBE7Ejocruamhpcc801qKysRGFhIU455RR8/fXXmD59Oo4fP45vv/0WL7zwAqxWK0pLS3HxxRfjr3/9a+wEstmAvLyYBa8FUCR302IBwlzOdvXVV4scEPz000947733sHbtWv4Zh8OBJ598Et9++y3vNbBPnz7YsGEDli1bhsmTJ2Pp0qXo27cvnn32WQDAwIEDsWvXLixZskQ27hEjRmDEiBH834sWLcInn3yCzz//HLfffrvsex6PB2+88Qby8/MxZMgQnHXWWdi/fz++/PJLaLVaDBw4EEuWLMEPP/yAcePG4bvvvsOuXbtw5MgRlJaWAgDefvttDB06FL/++ivGjh2Lq666Cv/617+waNEiAF7r0pYtW/Duu++GlZ8cTU1NMJvNoiV6Sqirq4Pb7Ubnzp1F1zt37hxg6eratWtCnWAQBEEQBEEQ8iRUSXr99ddl75WWlvKWDkKajh074txzz8Vbb70FlmVx7rnnokOHDqJnysrKYLPZMH36dNF1p9PJL8vbu3cvv9+LQ+iGXQqLxYKFCxfif//7HyorK+FyudDa2hrSktSrVy/k5+fzf3fu3Bk6nU60t6dz586oqanhZSstLeUVJAAYMmQIioqKsHfvXowdOxZXXHEFFixYgE2bNuH000/HihUrMHr0aAwaNCioLHK0trYCQEydGWRnZ8Nms8UsfIIgCIIgoicaR1tEapNwxw1JRU6O16ITIzweD8xmMwoKCgKdBgQ5+ykY1113HW+5efnllwPuW9rS87///Q/dunUT3ZPbV6OEBQsWYM2aNXjmmWfQr18/ZGdn45JLLoHT6Qz6nv9mOc5xgP+1cM4nKikpwdlnn42VK1fi9NNPx8qVK3HLLbcoT4wf7du3h0ajQWNjY1jvdejQATqdjt8vxVFdXR1wIHJDQwM6duwYsYwEQRAEQRBE7CAlSYhGE/aSt7DweAC32xuHSt70zjnnHDidTmg0GsycOTPg/pAhQ2AymVBeXo7JkydLhjF48GB8/vnnomubNm0KGu9PP/2EefPm4cILLwTgVcb8nT2oweDBg3H8+HEcP36ctybt2bMHTU1NIjfxV111Fe6//3784Q9/wOHDh3HFFVdEHKfRaMTAgQOxd+9enHPOOWG9N2bMGHz33XeYO3cuAK9i/N133wUsQdy9e3fCz0kiCIIgCIIgpEk673ZEeOh0Ouzduxd79uyBTqcLuJ+fn48FCxbg7rvvxvLly3Ho0CFs3boVL730EpYvXw4AuPnmm3Hw4EHcd9992L9/P1auXIm33noraLz9+/fHxx9/jO3bt2PHjh248sorw7L+KGXatGkYPnw4rrrqKmzduhW//PILrrnmGkyePBmnnnoq/9xFF12ElpYW3HLLLTjrrLPC3k/kz9SpU7FhwwbRNafTie3bt2P79u1wOp04efIktm/fjrKyMv6Ze+65B//5z3+wfPly7N27F7fccgusVmuAQ43169djxowZUclIEARBEARBxAZSktKAgoKCoIdhLVq0CH/729+wePFiDB48GOeccw7+97//oXfv3gCAHj164KOPPsKnn36KESNG4JVXXsGTTz4ZNM7nnnsOxcXFOOOMMzBnzhzMnDkTo0ePVjVdgHfp3WeffYbi4mJMmjQJ06ZNQ58+ffD++++LnsvPz8ecOXOwY8cOXHXVVVHHe/XVV2P16tVobm7mr1VUVGDUqFEYNWoUKisr8cwzz2DUqFG44YYb+Gcuv/xyPPPMM/j73/+OkSNHYvv27fjqq69Ezhx+/vlnNDc345JLLolaToIgiFhA2zAIgsh0NCwbge/pFMJsNqOwsFDyVF273Y4jR46gd+/eMd2kzxF0TxKRNHDldMMNN2DMmDF48MEHVQ3/8ssvx4gRI/DQQw+pGm64xLv+qw3DMPjyyy8xe/ZsOqRPJX48UAuny2sRnjakc4inlUNllRowDIOn3l2NMaeOQfv8bIzt1S7sMFrsDGpaHOjVPhc6LWlasYLaVPw4UmfFoRrv/u5w+0Uqp+QkmG4ghEbqBCHDU089hTyVXcI7nU4MHz4cd999t6rhEgRBJAObDzfgSK0Vh2pj5wSJIOIJqfqZCzluIAgZevXqhTvuuEPVMI1GY2zP+iIIgkgCWuxMokUgCIKICrIkEQRBEARBEARBCCAliSAIgiAIgiAIQgApSQRBEARBEAQhAXl6zFxISQKQ5g7+CEISqveEP1QjCIIgCMJLRitJnDtGm82WYEkIIv5w9Z7ckhIE4U/0k+c0/U4QRGqT0d7tdDodioqKUFNTAwDIycmBJoZ2VY/HA6fTCbvdTuckJTHpXk4sy8Jms6GmpgZFRUXQ6XSJFokgCIIgCCKpyGglCQBKSkoAgFeUYgnLsmhtbUV2dnZMlTEiOjKlnIqKivj6TxAEQRBEIBqyimYsGa8kaTQadOnSBZ06dQLDxPZcB4Zh8OOPP2LSpEm0xCmJyYRyMhgMZEEiCIIgCIKQIeOVJA6dThfzQaNOp4PL5UJWVlbaDr7TASongiAIgiCIzCb9NlwQBEEQaYnD5YbT5UmoDCzLwupwJVQGIvF4PCxsTqoHBJHOkJJEEARBJD1uD4v1B+rw44HahLqvL6ux4OdD9SiraUmYDETi2X6iCRvL6lFttidaFIIgYgQpSQRBEETS43C5+d+JPOLrWL3Xdf7ROjo6IpNpsDgBAMcbqB4QRLpCShJBEARBEEQE0AHM6U8aO7klQkBKEkEQBEEQBEEQhABSkgiCIAiCICIgkUs/CYKILaQkEQRBEAQhgpYYKSORTkQIgogtpCQRBEEQSY/w1HsalhLJAtVFgkhfSEkiCIIgCIIgCIIQQEoSQRAEQRBEBNBqO4JIX0hJIgiCIFIK2gdCJAssLbjLKKjvySxISSIIgiAIgogEGjOnPeTEJHMhJYkgCIIgCD9oZKgE0pEyCzIkZRakJBEEQaQhbg+LLccacKTOmmhRVEE4m0vjlOTB6nBh8+F61LTYEy0KoRA748YvRxpQ0dSaaFHSihqzHZsP18PmdCVaFEIlSEkiCIJIQyqbW9FoZXCoxpJoUYg0ZtfJZrTYXdh5vDnRoiSEVLQslNVYYG5lsKfCnGhR0oqdJ7xtgfI1fSAliSAIIg3xeBItAZEJuNwpqCWoSCo6bnB7Uk/mRKLRhHdGm4vyN20gJYkgCIIAQJ6bCCJcqMkQRPpCShJBEASRUtDAlEgWqCpmFjSRlFmQkkQQBEEQBEEQBCGAlCSCIAiCICIiFffkqAlZFjILKu3MgpQkgiAIIqXI9IF5PKADNJVBNTH9oaaQuZCSRBAEQRAEEQmkJRF+kHExfSAliSAIgiAIgiBCQApQZkFKEkEQBJFS0EAl+cmU5Xq09JMg0hdSkgiCIAiCiIhMV1gzPf2ZBinFmQUpSQRBEGkA4/bgWL0VdsYdcK/R6kyARJHTaHWioqk10WIQGYzN6UJ5vQ1uT/BBMSlJ6lDR1Jpy/RQB1LY4UGO2J1qMmEFKEkEQRBqwt9KMg9UWbDnWGHBP6loys+VYI/ZUmGG2M/w1GowS8WRjWT0OVLfgcK0l0aKkPWY7gz0V5pTop6gf8sGyLHYcb8LOE81wujyJFicmkJJEEASRBtRbvLOwrc5AS1KqImUVI4h40mhjQj9ERIU9jfqsTEKoMLo8pCQRBEEQBEEQRMZAxqPMhZQkgiAIgiAiggaQBEGkK6QkEQRBECkF7QsgCIJILMJuWIP09PlPShJBEEQ6kJ7fKCJBUHUiiEBogiazICWJIAiCSEqEs5N0PglBEETywAo0xnQ9PJqUJIIgCCKlIIUpeWBpap0giDSFlCSCIAiCIIgMIV1n/WOFcCKAJmh8ZEJOJFRJWrp0KU455RQUFBSgoKAA48ePx+rVq/n7drsdt912G9q3b4+8vDxcfPHFqK6uTqDEBEEQBEEQBEGkOwlVkrp3745//OMf2LJlC3777TecffbZuOCCC/D7778DAO6++2588cUXWLVqFdatW4eKigpcdNFFiRSZIAiCiBM0400QRDJBq0szC30iI58zZ47o7yeeeAJLly7Fpk2b0L17d7z++utYuXIlzj77bADAm2++icGDB2PTpk04/fTTEyEyQRBJiJ1xI8ugS7QYRJyggUrs0ZCGGjVOlwd6rQZarbp56fGwcLo8qoaZLtC3IH5kQj+cUCVJiNvtxqpVq2C1WjF+/Hhs2bIFDMNg2rRp/DODBg1Cjx498PPPP8sqSQ6HAw6Hg//bbDYDABiGAcMwsU1ECLj4Ey0HERwqp9SAK59jdS0oq2tFaXE2BnTOT7BUicPtcsHl8X61GIYB42Lgcrv4+0rqs9vthsvtUfy8UsJtU5zcLoYBw2jb3nXx1xmGAaNNzBc63DxNJbj0uF1uuFyuiOoMX3YubUrnjy8dGsl0hKoHDsaNDYfqkWXQYULf9qrKtvlIA5qtDjjckdVBl0vclhINo5I8B2ssKG+wYVBJProVZaslnuK+h3vG7Q7s85Ihn9XG6fKI+2qkjuKutDwSriTt2rUL48ePh91uR15eHj755BMMGTIE27dvh9FoRFFRkej5zp07o6qqSja8xYsX49FHHw24/s033yAnJ0dt8SNizZo1iRaBUACVU2rw4dcb4GaBLQCGtcuAqS0Z9jRq0KYjwXGYRZ0dqLL5ZrAdh0Pnzd5GDdyCMNRGaZva3eCVu24/i3xDmzxu4GCz97r5IAtTgiaLOdmA2ORR4tFg+/btyDewOKlgzsG/znD5k2dgUZnCcxZcOrL1LGr3yN8HpOtBgwOosHqfad6vbj3h4u6UHdl3qtwCmJ3eMJKhDjc7geOW6OXh8mWrBhharF666u1AZVtf2nyQRZZM38PFb9IB9XvF8afjeMLlAfY1edNsKWNhSCFXcDabTdFzCVeSBg4ciO3bt6O5uRkffvghrr32Wqxbty7i8B588EHcc889/N9msxmlpaWYMWMGCgoK1BA5YhiGwZo1azB9+nQYDIaEykLIQ+WUGnDlNGr0KLAab+88dVCnBEuVOPIO1oFpm9GfOqgTyhtsOFhj4e8ryRv/MNQi3DZl2lcDABhZWoT2uUYAgNXhQsGRBgDAuN7tkGdKzOeLkw1Iv/rGMAx2v/8tRo4cic5FORjRvTDkO7kHankL5tRBnfj8aZdrxKjSoliKG1O4dBRkGTC2V7HsfUC6HlQ0tWJvVYvs/Whlc7vcqNi/LaLv1K6TzahpccREtkioaXFg18lmANHJw5WJVqPBWQM7qiIbAJxobMX+am9ZBut7uPjzTHqM690OQHqPJxyMG7mH6gEAZ/ZtD1MKLXPkVpmFIuFKktFoRL9+/QAAY8aMwa+//ooXX3wRl19+OZxOJ5qamkTWpOrqapSUlMiGZzKZYDKZAq4bDIakqaDJJAshD5VTaqDX68G2+aDJ5PLS6XSifDDoDdDrfF28krzxD0NtlLYpTm6DXs8/b/BofNcNBhgMifl8hZunqYhOr4NekPfBn9WDMyUZDL46p/T9ZCVUOkLVA73BJaqvsZCNCzvc8PV6PfQ6d0xkiwS93q1KXnFhaLXqpkuvZxTVaz5+nS7gmXQcT7ih9eWLwQBDCilJSssi6YxjHo8HDocDY8aMgcFgwHfffcff279/P8rLyzF+/PgESkgQBEEQBEEQRDqTUEvSgw8+iFmzZqFHjx5oaWnBypUrsXbtWnz99dcoLCzE9ddfj3vuuQft2rVDQUEB7rjjDowfP5482xEEQaQprAKXSUqeIQiCIIhoSKiSVFNTg2uuuQaVlZUoLCzEKaecgq+//hrTp08HADz//PPQarW4+OKL4XA4MHPmTPz73/9OpMgEQRBpC6keRNhQpSEyCKrumUVClaTXX3896P2srCy8/PLLePnll+MkEUEQqYYG9OFKJ4RGIuFZPVTGBEEQyUMmGPSTbk8SQRBEOGRAP00QcYeOkiVSFU0Ma28mKAaED1KSCIIgiJSCxikEETmxVCKIzIEV9MTpqjySkkQQREpDn/v0Ik2/tQRBKCAZnbKIREo+8YgYQkoSQRAEQRARwdKokSAykiTUZ1WHlCSCIAgiKZGzEqrxcT5SZ8XOE01JOXOtNscbbNh+vAkeT/qnNVWoNtuxtbwRTpcn0aLElQPVLdhbacaxeit2JHGdLKuxYPfJ5oDrwkkBO+PGlmONqG1xhBV2s43BlmMNMNuZqOVMRmpbHNhyrBF2xp1oUaKGlCSCIIg0QOgJLpWRU1rUVmYO1VhQY3agzuJUNdxkZH9VC+paHDjZ1JpoUTKGUPV114lmNFicKKuxRB5HxG8mBo+HRXm9DScbW3Gw2oLaFgdq/BSMZJmzOFpnRVWzHS1BFJm9lWY0Wp3YcbwprLB/PdqARiuDrccao5QyscgV1Y7jTWi0OrGvqiWu8sQCUpIIgiCIjCUTLEkc7iSdtU91oqlDLk/mWJKkcsmd5O0vWJNh3NHJ7ory/WRCatkt4079uk1KEkEQBJE0KBo2pM/YgiAyhlS0dfsb6MXnuMVXlmQjEyaYSEkiCIIgkpK4DEIyfKBDRE80Y8UMGGemHMLBv/ewculCoq4j/SEliSAIgiCIiKBBPqEmyVCdgtXpZJCPiB+kJBEEQRBJg5JBN7mdjj2ZvpQoHKKpjZmez8mYfGF5BnOIk+llF6rep0P2kJJEEARBZCyatPiUq0Mm7DFQC7UGyJmU5amSVP/ldvJQ35HukJJEEARBEAQhgRJliJRL9UiGvPSXQCiSSIHKcB0pCYoq5pCSRBAEQSQNwqV0QitPrL7HmT7QiRa5gVImZWsGjBUzFuofgiBSHhMnRiwhJYkgCCINSMdvudzeo3T9ICcaytf4k+mD8GRMv8jNt1/PKtqvFB9xiARCShJBEASRNNBAPXZQ1iYfmVTflSylS4bsUOoYJphTh0wgVD6lQ/aQkkQQKUqTzYnaFkeixSCIlCaZvuPVZjvMdibi96ua7WiJ4n0iNBaHC1XNdtEAMNaKjtPlwcmmVjBuj+g64wEqmlrh8SgXoNnGoNZi5/+uaGoNqrzYGTdOCuJwe1icbGqFnXGHmQp18cRQDqXlmUx9h5rURNkPpRP6RAtAEERk/Ha0EQBwZv8OyDLoEiwNQcSPZJhtVpsmmxO7TjQDAKYN6Rz2+3UWB3afjPx9f8jrnzSbDtUHXIu1S/qdJ5rQZGNQl2/CiNIi/nqTQ4O9VS3waHTo3SFXUVi/Hm0Q/b2nwgy3h0VpuxzJ5zceqoPHAzgYN/p0zMPBmhacaGhFtlGHCf06RJymaDlSb8WRWit0Og3OGtgppnEJS1eRApXCHVRzK4OdUfRD6QZZkggixXG4PKEfIjKeZPAaFQ1qip+MeWF1Rjcj3mJ3hXwmlNqTfLlCAECTzTurL7dyoMHqjCr8Rpv8+x6P+BlOhtYo6ytHpMo4l2a3W/1aK/JmF6RVpMNyMn+sjtD9CIc4n9ITUpIIgiCIjEK0MTtNRjpKUpGuA5lEk2idO1WqsCIjTJJXUjnvm4QUqZ8/pCQRBEEQXpJ8gMKRjJYggiDSA+WOG2IsSJKTCb0wKUkEQRBE0hAP/Scd3fhm+oAt2Ug/PV7T9t/kqGixlCL9yo6IFFKSCIIg0oB0HCTTYCW+kIUuNUn1pq90D1C8CCqBaKlurCVJboT9Rbr2HaQkEQRBZACp8g2LxyBJ+EHP9IEOET2p0raSkWRsf/4D/nRVAGJNMpZtuJCSRBAEQSQ/GeBJKRqSZRlUJpJo60c8nY8ky8A3UXKIl+omSWYkiEzoh0lJIgiCIDKKTPi4R4JoAJjZ4z/CDzXqg5xBRqhkJoPRRqkI1EbSH1KSCIIgiIwl02eDCSI1iV27Fe2RYuXvZbqSlAwKbawhJYkgCIJIGpR8eKP9OGfCx52IH4muT6k8Vk9K2SMoT9q3lJ6QkkQQBEEkJek07HC5PaKBlMfDwu1RL4WRzmqzrLpycHhYFp4YhJuMcKl0uT0JlSMeBKtmkaY/Ev0illYc/z1mcuIJrdDJoCPFu/4p2YvHyRSrfibWkJJEEARBJA3x+IzGe6O9nXFj7f5abDvexF/76VAd1u6vSfjAYdPhBvywrwaM26PqQK/RyuDnw/XqBZjk1LTYsXZ/LQ7XWuIedzIs+zpaZ8Xa/bWobG6VfSbRDi6UEqwdCNMgzPdEp8zqcGHt/lpsF/Qx8UQq/Q0WJ9bur8XJplb8csTbzzhdqTWRQEoSQRBEBpDoj3i0iDZ3R5maeM/6VjR5B44NFid/zcF4lRKr0xVfYfywOrzxN9qcIZ4Mn1anW/UwkxGWZbGvsgUAcLjWGvO4EkEoPaysxqsc7qkwx16YGKPYcYPwnQSbkk629TF1LY6EyiHF3gozWuzefqbemnzyBYOUJIIgCIIgiCjwJHCQnNLORzTJPYHjL5uc44ZEpyEh1S/RiY4DpCQRRAqS6FkrgogVmVa3Myy5aUk8izDh9SXG+pjS9MVSjMDDZENLkfBySQCZkGRSkgiCIIiMJVX2SYQi6n0pbGYMemJFIvMuGfYkcaSDshBJEtKlHyHEkJJEEASRBqT0khsZZK1K5AKcSCJYFimhYUZjpdWooImp2e7UkEeO4I4bpP9KdJ+SCCUt2HlS6QIpSQRBEETSkKbfWnmSJMGxEiMjlk+ymWNJiMVkjLCOJEM+JoMMRHJAShJBEKlN+hlQYkJGDFYVkuhBUCzKQpWZdaojEROvrEu3EopU6Qr6VgK+CYl03JFKpNqKB1KSCIIgiKRBdoWdcGlHfESJC4lW2DhiNcbLhLEjCzYj0hkrki7vRMvI5IVLOrnjTLL0XbGElCSCSEEyvXMmiGig9hMayqP0I5oy5eb/k8lJRKwIlk1ySlOCz4Sm9hojSEkiCIIgAGTGzCCQnJYoNceekSzny5SyjwXxHKBKlW06KS7JMNgPlEFaKOHVTFzOLEpymiaflCSCIAgieVDwsU318YiU/NEmSY1xciyyNcWLiogxkSp4sVQMg00YxMjhJpGkkJJEEG002xjsON4Em9OVaFEIQnXi9RG3M27sON6ERqsz6rCqzHbsOtEMt8prWUTetOKQMcGX78QgPpkw6y0O7DzRBKfLExc5AKC1rT402aKvDxwsy2JPhRnHG2yqhSmkpsUenjxRxtdi9357LI7Q3x6puOQ2w7Msi90nm3Gi0YaD1S04XGcJS64ac3j54E9Vs7rtd1+VGUfrrKqEFYxI2kK07cfj8ZZVRVNrRO/Hox9ze1jsOtGMqmZvvcgExVCfaAEIIln49WgDAMBidyRYEoIIn2RZcrOn0owGixO1LQ5MG9I57PeFs7iVTd6Pca5Jh+Ico2oyJiPxKL4mGwMA0GlbMLRrYRxiBHadaIbV4Yq4PkjRYHXyg8nSdjmqhClk5/HmsJ6PdqnVb0cb4fawaG5lMGlAx6jCElLT4kBVs50f1IbLzhOB+RBOPd190vt+XpYevTvkKnpHLifNdgYnGrxl3qtDbky9pEVUmlFqDBXNrXxZdS3Kji6wGHGi0YZqsx3VZjtKCrMSLU5cIEsSQfhhZwJnWQmCUIbd6VY9TMat7o6ZdJwBFSrJodIn1cfFKk/sjPr1wZXoXfIqw1lapCx8QOQTIIxbvW9ZNJMwDlfwOqBEx3S7E1fmyjxuCs96Ch8mgelTisOvfmbCPixSkgiCIIiUIp2cDCRTSuQGfclGBozNwiJZrMhycOUluRcvwrKM6Z4kqmBhk8z9RTSQkkQQBEFkFOk+Bgo9yGMVPkcoIda5KLIShhFZshRveDKH9iQXayI5ky3ReR0PJcU/jYlOczwgJYkgUpAM6JuIDCXeH95EtKVYuA4W7tEIqSJJzujHJifSdYZZiFpZl4ye3gLjCj8yT4gMUlJHkkWhV3OJXTIS1MlM2qRSOaQkEQRBEClF1OOlzPvWh4RlM3MQlEwk+7K5TCFJ9LGkIxPzhZQkgiAIImmIx3eYlAEvqTroSbbyU0seOSuN2EoocZhsHHwjRhMHvycpinxKZInLxS2yKiW4MalmzVQnmLSBlCSCIIgMIFUHxByJHoQkO+HsW0nU/g4iOKkwQI3E2hVsuR0LNqI9QLEk6GGyMveSQe5Yo8aepFSzlpKSRBAEQSQNSpShqFfbJXqTtfAw21iEHyJUJelPdB6lFKrtSZIZQYYYWCb7wFON7PGvj7H1bicfbybh3xcHVR7TNJ8SqiQtXrwYY8eORX5+Pjp16oS5c+di//79omemTJkCjUYj+nfzzTcnSGKCIIjkJMnHSVGR7IPAZCASD2JiBxKxGeik6+BJjmjqqlbBu4nKz2jSpYYVOJ5LLCPxaJcJ9TwT0uhPQpWkdevW4bbbbsOmTZuwZs0aMAyDGTNmwGq1ip678cYbUVlZyf976qmnEiQxQSQHtPSIICInFt7lkok0TJKIZEufUBwpZUJpHZPb95OscwRK06XMIT0XprK4Y7kPK1i6ZA+WzYgFd2IyIc36REb+1Vdfif5+66230KlTJ2zZsgWTJk3ir+fk5KCkpCTe4hFESFiWRa3FgYIsA7IMukSLkxbUtjiQa9Ihx6h+99TqdMPicEGjAXKMsYmDSCzNrQzAAoU5hkSLoohEDPi5KNNRQVSbZhsDs51BQZZ8fRJmowYa2Bk3alocomfMdgYeD4uiHKNsOEosSVL7e+KpRAnjYlllFiYH40G12Y5cUxT9bRyrakKOBUiStuivsAYr33geJZAokmqE0NzcDABo166d6PqKFSvw7rvvoqSkBHPmzMHf/vY35OTkSIbhcDjgcPg6J7PZDABgGAYMw8RIcmVw8SdaDkIal9sFANCwHgDKyqmy2Y49ld46NnVQp9gJ54fL7eHldTEMmKRqyZHTYHVi2/EmAKHzkysft8sNN5SV2br9NaK/41lmscbldsHldgNo6+9cDF9HAMDJMNCwwRcPuFxufhAWaT/lL4fU/4PBMGK5AcDFuMC4tPx1b38eWOk9HhY/l9UCACb37wC9Tjq9TkEcjMsFhlG+qEIom9I8cjEusezC9utiwDBauFy+Z5xOZ9jn0QjLm2EY6NrahL/M3ji5fPbJ4XQxYNpG6W6XGy6XS1H6/PPDPy6RjCp9+4TxxOJ76p+GjQdr+L5CKn2itsZqsHZfVYC8Gw966+XEfh1g1GsF5a/jf7vd0ulxu91wub3l6XR643K7vG3M7XK31eHA9/z7ANn0unSS7wvf5eqDqJ4yDHRtdUaqXXDXmm0ubDtmR0lBlmTbFoYp9z1z+pW58B3/+MBqoqoXwvbqahs7+srLl9diGQTvuNigfZ9kXkmkJyyZo3yfD8cvn7UCzZ3x68dEcboYMIwGLMuG7AMYJvETykrzSMMmidrn8Xhw/vnno6mpCRs2bOCvv/rqq+jZsye6du2KnTt34i9/+QtOO+00fPzxx5LhLFy4EI8++mjA9ZUrV8oqVgQBALsbvJ2BTgMMLlbWLE5YgSaH971h7eLXlNwssLfRG2+fAhY5aaIk1bQCNa3h5ee+Jg1cbePBUO9wZcwRzzKLNQeaNXB6x00Y1o5FnR2osvnSO6iIhT6ELvB7o4afHYw0b/zlCJcWBjjWIi6n9lks8g3A0bbrXXNZtDMFvuthgT1t7WJAIQujzLfYwvjC6pXPIi8Mo5OwDilNX3UrUCuo124PsLfJ+3ePPBYFRqDRAZy0eq8NLWbD3gPS5ABOWKXT7l/vTTqgfyEr6kdKcrz5UNbs/TvfyKJnXuh4/fPDPy4harW3BgdQYY1dvyuVBi4eqXvdc1k+73Uab/8sZEgxy9fLfoUssnS+cPKNLFqc3t9ZOhb9CgPl2duo4cPsV8jyZcTRIYtFicTwpt4OVNpCV6QCI4seEmUtTGuhkUVpHnDYDNhc3uuDi1noNIHPyuWVRhNofSjNY+Fw+/p9ue9ZsxM4bvGV+Ukr0Oj37eXi02q8eR4pwvbap4BFkxNosHv/7pTNolO29znh9780j+XlM+iAgYXy8UvlVSTfPiHHLUCzM/o2IWxbQ4pZkXWz3AKYBXEIZeb6UWEfLEVpHotCeWNq3LDZbLjyyivR3NyMgoIC2eeSZmh12223Yffu3SIFCQBuuukm/vfw4cPRpUsXTJ06FYcOHULfvn0DwnnwwQdxzz338H+bzWaUlpZixowZQTMiHjAMgzVr1mD69OkwGFJjKUgmYdrntTJoWA/sR7YqKqc9lWZUNtsBxN+SlHOwDgAwtmcxCrLToz4drbfiUK13T6ISS9KaNWswevRouNsWgYR6hytjjnSyJBUfroetTTuZOqgTyhtsOFhj4e+f2a8DTCG0pOz9tbwlKdK88ZcDCK/vq7M4sONEs+haj+IctMs1YHvb9UEl+ehWlB3wrsfDIvuAd8b+9N7tZJf31FscfFgjS4vQPlf5V1tYh5Tm0aFaK47W++o1I2i/p3QrRMd8k8gqffbAjmFbkoTvn9GnPbIFWpJ/vc816nF6n3YiOfp1zEOhSYOyT9di5MiRKCnKwSndJUbsfvjnh39cQtRqbxVNrdhb1aJqmEKk0sDFI3VvcEk+L49Rp4XT7RHdP2tAR75ejuvdDnkmPR9OxzwTai3e1S/5WXqc1ku8kgYA8g7WgWkLc1zvdig80gC3y43t27dj5MiR6NMpH/06BWo5/n2AHJ3yTRjeLbCshWktKcjC0K4F2HKsEU2t3ln4Sf07wNBmrZVqF/55pdFoApZjDe9WCKvDhcN13vZxas9iFEp8z6rMdvxe4Vu1sa+qBSebWiXj02s1mDygY8h0yyFsr6f2LEa12Y7jjd64+nbMRa/2uQDE3/9hXQuwu02+bIMOZ/RtD0C675PKqyN1Vj4PIqnTu0+aUd0S/VhE2LbOGtBRZEnaeaKZr6tTB3USfa9HlRahXa5R1AdLMaxrAToXZEUsn1pwq8xCkRRK0u23347/+7//w48//oju3bsHfXbcuHEAgLKyMkklyWQywWQKnGI0GAxJo5gkkyyED73O2xw0bctUlJSTXq/n34tnmWq0Hj5efRrVJ73eEHZ+6vQ6fhlZyPLSibu8dMk3wJs2fdu0rsFggEGQl95rehj0wZc56PU6eDzc85Hljb8cQpS1KU9AOekNeugNvvTodHrJcNwe1q9dSH/idII4DHrpsGTlE+WpsvcC+glR+/XGr9e7fNf0BtHgRAkGg8svTJ+c/vmp0+sC5dDroTdo+fs6hfninx/+cYllVKe96QVpjUUblkoDF4/UPa1OL8hHLTzwBLwrzGf/v/U676SCUaZ96HQ6sG1+toR1CeDKUrqs/PsA2fTKlLXwXe4Zg0EPvZPl08UpSVLtQkncBr0eejcE7VE6Dwx6tzjPJL69vv5BE1W9EIWtN0Cvd0OvY9ru+eTTicpdWKa6oH2fZF5FOZZQayzi37aE/ZCwrnr7LPH32mAwiPpgKZJl/Ku4746xHEFhWRZ33HEHPvnkE6xduxa9e/cO+c727dsBAF26dImxdARBEESqkiQryZMTqQ3XSD6vcamCyHFDFF4U5F4NXSyJ8X+nVn0ROQuQPaxVfD1RxwJkUr/in9KAvyPIi2T11ChHQpWk2267DStXrsRnn32G/Px8VFV5NzsWFhYiOzsbhw4dwsqVKzF79my0b98eO3fuxN13341JkybhlFNOSaToBJFQMqebJtQiVb7tarmV9QQJJtGua1nxqDCm4UfizjjZScRAlWVZ2SWQ7hDyKJVWycA/XilXdqhzHM8uSmBdVZLOhPcpcYhfUZ1I1U5FhoQqSUuXLgXgPTBWyJtvvol58+bBaDTi22+/xQsvvACr1YrS0lJcfPHF+Otf/5oAaQmCIIhUQa0zXFKFsA6TlXw/XXIi/ki55Y4E2X1oMT60VOrMISXxqCFLpEHE8pykSKTKhOYTzLKUrv1HwpfbBaO0tBTr1q2LkzQEQRBEuhD085Ke33OekId3stxzqZkRyTYeE45lojk7JlFLkaTqgb/ix+lvsch7RQpZ0PflrXxqIydHklXJhJFu+aD8cAiCIAgieUm1xd5ySHxlNVA6s+17SK3Z/VjDSSkc4yXkMMuExZwaBKtOwqWd0eSgVmagL1Ji4lREiaoJcvnsr4jGa09SqkwkxEZ5Zf3+jn2cyQYpSQQRBZnQSRBEshH1zLNqkkRGrAdeIS0bEvEHDoASnUvJTdePVyJ/z04AXq+KwVBaF5XtSYpPucgqKwqeiTexliPcCZpkyRf1UbInKQ5ixJGkcAFOEARBEIB6CkzKWJJi4CEssrhTI7+Sgfzd2zHkb97zGL/fehQe1nfuSyjl0v+usJ7KWZJCo8wjXHghyoTJhn4mFiRLcxY7RZH+na4EpjH9E02WJIKIgkS5ISVSF0+IWedkI9Xk5RGI7Z8GpYObRKVdtGwwAhmU7knyv5buAz25vAw3jw1Njfzv9uu/588WA8IfNgYuaQos+0gH40qflasPQuScO0TbRrzxCKwwkYTh97dQUk4+j4dVLGsk7UDqHf/41Kp/8SKyskjOtEQKWZIIgiDiRIudwS9HGtCzfS76dcpLtDghYdwebCirQ7scI0aUFiVanJCwEr8dLjc2ltWjY74Jw7oVKg6r2cbg16MN6NspD7075Koqp5Bgg4ommxO/HW2MuQxqkcxL9OTKs6rZjt0nmzGsWyFKCrOChOBDw/q0ImN9LU6a7UGfD5YtwntVzXY0WJ2Y0K8DDtdaUN5gw+l92iuSyZ+9lWacbGyN6N1gCMt4X1ULzK1MxDJGg5L5SYvDhc2H60V5PLZXOxTmqH+Y6YHqFtHfdRYHtpc3oV/HbADAwWoLKlucAXlltjP49UhDSkxQ+IuoRLlOdciSRBBRkKgOId06okzhYI0FLAscrbMmWhRF1LQ44HazqG1xxC1OZfuNQj/ELWOqaLLD7WFR1ewbyCp5f1+VGQBwqMYSWqAwUdp+91W1RCRDqPClbqdSlxJJ/ydXnrtPNov+Lxun4LeGcfG/dXa7/IMK8H/c6fKgyebEsXobWBY4Umf1W+KmjGgVJCV53Gh1wu1hcawhuv4sWnfjcsp5WVt/K4SrB5EjtHrJC7XzRFNbfN42XN7oK08hB6sDZYxOqtgRtAziEH8iICWJIAgiTpByGznhLuNQOnsvR9xcCseiToRSkiQiZdn0HeiojZZx+n7bxcqIpFMM4cA6XCWK9f9buuyiQVppltvnFIhOxbai7BDb+HqDjCR/Y3uOU2IIWBoaSSApli2kJBEEQRBpR7SOGxK535CTPLz9J8oHtdLPsRFZLBJNIpb4aVxCS5L6FhvhpXg4IIlW8dJqY99YItnrEuu6kWmTXhmWXACkJBEEkeKk1oxd7D4zauRDMnz0pQZD/gpL1MtzFMgRr1oVG0NS8FCllLBkKPtUQWhJ0rX6WZJU3qcRsA8k8qDCIpzDZKO1JClJU2C8miD3lIcb6r1UORsoFgphsqY1npCSRBAEESfooxM/FHv2khlKZZrnSu9yOzU8laUnwkGo0JKkddj9nlMjLul45cKPNspw3peqI5G7Lg8n3vQgldtItJNTqQgpSQRBEGmI/2AmsnX1qUuwAb+yWdd47UlKwAwwy/0vNUc00ezxUQORJcluC+/lMB2TJMo7dDjxaqMYSQb0UyqEwV9PzeqdtAT7prAp3qfIQUoSQaQgoo4ovfokIsNR5t0u9LvRDi7jZUlS7TBZuSVHUvtNZJwL0KBSGRqG4X9rW6Pdk6RQo+X/ipNSLdvIAi/p4rEniWUlf8cbVuZ3OhJQ19I9wRKQkkQQBBEnMuIbkyTmJ24gJSVO/MdY4UUYC29lSuJMlfqZiDGyMEqty6ck6RzBz0iKNrKEHTPhVxtiOWkQdX2XfV9qf2P4CUkF60giJIwoX5I/K0WQkkQQBBEnaKY+NGGMd4IStSUputcTSqiZdn5pDNXHiAjXkqSm44bYDDKVe7eLdZVRM96Enj+Uyh2IDJE52EhtSEkiCIIgkpxIRhzRfa3jdU5SssCySL8RTowQWZKidQEe4ppHgbYfC0tMWM4corZ8RpLG2NVVpWesJXLZX6wIlqZgnv5SwdoWCaQkEQSRNKTjR0dIYtfSp0/eyp8JpGzDu6LDZMMVKgxCud7m0hFpmYXaNxEszmDPJCOJEFNoSYpWSZIi2HlV8UqvbBuLUqFSEl7IdxSGkSJVOGkJUIqUKLMxkiVRkJKUxDTZnPi9ohkOlzvRohBJzO+VzWi0+rwtldW04ERjmB6X4gTLsthXZUZVcwzW8RMi1BjkJsKYopYiqTSYPRVmlNW04PeKZjBuD3892rTbGTd+r2hGcysT+uEIcbja4rCJ47A6XNh9shk2p0vmTS8iZUqFPUnhvn+kzoodx5tgdUjLeajWgvL6wL4s0QMxjcCSpLWH7suEg8sqsx37q1qCPl/T4gvT/7yiQzUWpWJGxIlGG8pqLAF5HOwcNv/6Fw3H6q04Umfl/66zOLCnwgy3YNbjRGMrjtb56sXeKvF9JXHsr2rh2w73Xao2h/ddilc9dLk92FNhRr3FIS9LohtFGyGX+sZJDrXQJ1oAQp7fjjYC8Fb+Yd0KEywNkUwI+yGbw40txxoxbUhnmO0M//HoXpyTIOnkqTY7cKKhFSfQipLCrESLE3di+YHIsNVhIfEfXAoRDlpdbpZvM1qNBoO7FACI/nDePZVmNFicqGyyo1cH+bYYjYVvb2UL6locqGyyY2BJPn/9YLV3IG22Mxjbq53i8OI50HK5PfyAP8eoQ//O+aL7dsaNI7XewXJpu+yYLX/UaBR6VBQ8o43CknS8IfQEVo1ZMBj2k83mVH/SVBjFvkqvAtenY67Ms4GZVdEUrYc/3+8mG4MmG4NuRdkw6rXYXt4U8Ly/othgcUrmq1S5uj0s3z4AoLLJjqHdCrzfpYZWdB4S+F1K9LKyo/VWVDS1oqKpFdOGdI5pXEqXGoZ6Nl0gS1IKYGfIkkQow+VO7l7L6fKEfoggQqCklgdTkuRoFfS10Y7JbY7Y99s2GQuMUhkSufxTOPEvZQQQll+yDcZEjhui3ZOkinOB6AKRkoFJ8Lck3PbrUPhtkcor/++mGoqQmip9q5O+m4mClKQUQBuHMwgIgog9yTbYS0bU2l+Q6LwOepitxGGoofYphYwv6s3ziVsKI6WQCi15/gNmNc/MiUQZFjluaPNuFywcVb3bxQk5JSXR7SoclNaN4GWX+AQrU9oSLycQWookyM6wICUpBdDROhqCSAvSyXlCMqJU0VDkuCFeh8lGfFNh+BGHEdu6GqotCPM/pstUFc75C+UVWZJcDDQuV8zqSzwGlVKKgL+SxKVPbXFYyDiDUMXCpuxiOIfhRjuZkU5IHkqdZnlCSlIKEI/TrAmCSB9YNr3VMSUf4kiW26XbBz4cWJaNetY8VrPukZRlLBHuSQIAbYgDZaPy/haRe+xw41A/zGiJZw+mFWi44TiAkENt2RNdFopIBRkjgJSkFEBLliSCSA9S7EMSrfOCRBIsq5UUQ7zSnli38MH/jmncYczIB7UKRitIBMUs9G4HKFtyJ0eoAXWiqofssleFAiXFMjWFIgjLLZSSlCjLXuh3YiBIJHEmvthVhZSkFIAsSQRBREsSjFniSrTWh3jPTUUibaYUaeB5LeoRSTEHWJLsXs9qcnUmGoUhqfYkHT6MrONHVY8rVsu2IrHoeFg2jLjjUzqJqgP++ZCJ8/WkJKUAOiolgkgL4vWxS2WFSC3ZIxuYCvadxHBAEOyw0IjDlAkpqAMJPzmStd6osdwu2hCEIgRYkuz2mFke42GR8TkP8cUVkOdOJ9C3L06fPi7k8kJhmBHLFN3rEeNSYbldKqO03JQc6J0O0PA7SfEIGiottyMIItEkcvlM4Fk2sd+nkcpLDRNFrGpIoHc79cKO5PylQEtS23K7BNWZ6BUSCUuO39/65ib+t6m6KroIFaBKf6M0CMFz4exJilWXGHgeUfooHqmmRJGSlKS4BY2CltsR6UKm6/tp9K1LeoKNdZQMOuLm3S6RdSJKD4DqiRFiH0gM446kmDUu8flU/IGycsvtggUWaj+WYqmiR7xPzM+7naWF/22qVU9JYsNa3qZCfCGueULtSUqxQX684HIl3b5xpCQlKcLZDJrRJNKFdOtA041o3WarIoNKgxA1PaJFu5E63NcTt1k/fhGHExUb5CzNROSV/3IzXWsroFH3AFGeeKRPIg5/XUHbIlCSqiojCTJakWIWhrAOuf2tlirIES1KZIiFnEqX6qYzpCQlKWq4oUxm7IwbTTZnosVIGhqtTjhcbv5vj4dFvcWR9vUgVWm0OmFnvOXVYmdgdbgkn3O5Pai3OPjZyVjOQgoHaN79JYn/2DdaY9PGlXygo19uF1lYZjuDmhY7nC75kX2kJcO01ScpZYZxB9EkFCCVxlD9kFCOcC1vZjsT+iEuHpVrr83pQoPVCZZlI7IY6lptor+V7NGJFBYs8vfsRM6RspDPWh2usPKVw+Z0o9XpFl1rtvktKbRY+N+mmtBKUrSwLPg+NpowFD0nqF9uT6BlS02FQK26HOy7I4qP9bZhq8OFRqsTTTZn0HyVkq/V6UZza2C9kjzfKqQ8oSROLvSJFoCQxn82I93YcLAOADC2dzsUZhsSLE1iqbM4sL28CVotcPagzgCAgzUWHG+woUO+CSNLixIrICGiwerE1mONAIApAzti8+EGAMDUwZ0C9jfsONGMRqsTvTrkoF+n/LjLmmi2HGvE6J7FyDdGdlhjNASzisjdEW3Oj+AwU6fLg1/a6oNSpDbNy8W75VgjLHYXBnTOR4/2OaJ7R+tskCK4++zg6lpZrQXl9Ta0zzNiVI9i+YDCxM64setEc9BnhHKrPVe0saweADCka0FE73NKkis3D3qrhV9u523/EuUYtAyCo2+ox7hLZwAAvt1dKamNcuX48yFvuiYN6Bgi1EB+KqvDWYM6yd7XtJj531lx2pPEjRPUDTf4/XBcgAd7Uq4uKMH/LX+ZXW5P0O+OkGP1NpTVWAKuTxvSWbE8P5WpXw6pAlmSkpQ015F4/GerMpF6i3e23SOYCD7R6P0I17U4EiFSzEiHPUkNAuuIUzB7L/Vt5SwpJxq9g6hUbteRit4QA2uSElmiH1j7KqvSZWh2V3Qz36Gw2L0zx5XNrTGNh4Prh7g+Si1sflaLUNkbuHRSnYZU2+KIaDk7pyQ527UHAGhbW6EBEIvtw8ZKn9VG61T2PXDEoB6yzT4lydAUeiIgGZwNKLXaxMLbpBxqbJ+Q+u7IZXeVOXZWTimSodzVhJSkFIA2ChLpQpr1n2ETr+Sr9aFSQ6mNp2IsHuxEt54+EktSJEhvJE9EQwl/A3282nOw/WXR5lVky+28SipT7FWSOEuSrJOlKERk9TpfvALnCbEgWL8hjNvQ3KhinNLXY7XSXIknv+QjcgnDdfyldC8lC3Fepuu3nZSkZCVNKxwRSCQf+XTtkIjkJVLFKxY6khJRoh1kRbonSQlqKbFRu37233sR5YcnZv1SDPeIKBahLc7269bwSpGzTUnS2r2z9boYzAhoBZ709JbAZVNqEixbhUqS0B14JGEpkkWNs7GU7kkKpoSz8u0idi7A/ZbBRhFPvI+QCbknKS5SqAcpSQRBxI10WG4XTRoSuRQh1ZdBiGYtFXxqVfVuF8NPu29PUsyiCEuOZIlbmOf+Cq+aoobbnEfd+kf+N1PcDgCgs3uX38nN2kdj1dQ6fEvs9DZpJYllY9++hd7tDE3qWZKAyBwAxDr+mMWlQsqCuWr3J1ZHyMTbdXuiICWJIBJMJnQ0HJmU1kTCQv1BRtyWCkpc8//MK6pHKgqcKfU2mr0ZsZwAiakr4ijkZoq8zix09lZoNJqYDEiFnvNivdwOAEzVlZKZqjX79iTlHjsc80YRq7NkFXnGVKHziPd8oJyypI/zOZvp1leSkkQQBBEhmjA396fZ90MRwTwvRYpcVoutD8FyW2b5TBQyRYrkHok4WZeiXhKlihShSdaTENzZXg+D/HK7WChJAmcNwZbbqVFXNK+9holnj0Lffy4JuKevFrv97vXaS9FH2Ib0PiE1LC4ROG4I8U44z0aKf6jh92Q+wl1ux8r8zlRISUpSMmFDHJF5hOqvqaoTSlAygIp2CZJosJAhFTNZk+nx05LULA+l3sak6pw7KxtAaMcN4bhh90e03M6qjiUpq+I4zpg1Ht1XvC66rrvrTgBA71dfCHjH4HeAbL8XngwaR9RlFDPHDalH4N5B5cRsuZ2MHOnmaIyUJCKhpFuDioRMGYClO4qKMYZlHQuLjRrOCxLluCGc50KGE4c9SYlAqESy/H+iCC9G+aS2gwkh0TQbT7ZXSdLavS7AY7Pczqck6azqOG4YsGQhcsqPYNCTD4tv5ORIvwDAUFkh+rth7BmqyCKHGiWsNIxQ9Unecp14eKuzzH1dnEb5yt2tJ0OuKYeUJIJIQUi5JIKRYt8hRUSSJrkld7KDHpnrai/3itZKFc4rqVAXgi05lLufDLizvEpFyVefQ9dilvVuF430WqdvT1KHH79Dh++/jjoOvZwL79xcycsahoG+xnuA7MG7vIqVx2QKGoewzExVFej64QrR/irRs1KOG2KkJUke2uyvhAepe4moi9EoFtF4t4so3uRsqhFDShJBpCmpNmPjT7LKH81ccTw/sGpvfE7WgWow1JI43nUxUTkd7jLveOVLgHc7VZfbRY7blMX/7v/IfTG3JHVc+w1G3nEtjLU1EYenb25CTvkRyXtstrQlydBYDw3LgtVqYe/SzSuXU/kBw6ddNhNDHrkXvV95XvE7ce0rhb+ToJsLJYPYAhxiuWa4e5LCyIBk/UarCSlJKUD6V8PMJhUHn0QgGfC9iIhwJzIVOcBQmNeyliRFcoT3fNCwgt5LXMVJtsGhHGqeGxMVHg//c9srK/nldgDQ6X+fBNmTFLnAOoGSxKE3N0Uc3qSJQ5Hl54SBR8aSpLdZAQDunFx4sryKYSglSZhkU30tAK8lTClqWG/TZQlYNNLJ9b/RpjmZlyCqCSlJSUqSt1lVOdFow7oDtTDbmZjF4fGw2HS4HrtONMcsjlTmYHUL1h+shdPlQWVzK9YdqEWzLXblEQkHqluw4WAdGLcn9MPwfgR+PdqAbeUyS0uCUF5vw48HamF1uEI/LGBflRk/ldXBJSNjJO262mzHugO1aLAqn7l1uNw4WmcVxx1+1OL3I96TFFpLYllv+9x5okmZLGCxtzJ4XnvDDbxWb3GgvN6mKB6pcJLprC+1Faxk/e7EyrudRqN8Lx/LAqxAYWkaNZZ33MARydKmkOckOQOVJM5RhEg2BYWncbmgdbvlZckVWJIEz3He+9ymLHiMRlm5QsFqA4ec8ktfY7S/Ldr3WenfQhyMB06Xsu9UYxj9Oh+v4Pfuk834+VC9yLnJt3uq8e2eajTZ5MOuaXFg3YFa1Ft85Xio1oLDtb7vxubDDUG/O0I5bE43fjxQG/DdCXgnSfsYOUhJIhLOvsoWMC4Pfj9pDv1whDS1MrDYXag2S6+JTiTJ0Gkcq7fBwXhQ3mDD7yfNYFwe7DzZlGixRJTX22Bn3DjZ2Br6YXg77WYbg3qLM+wP7oHqFjhdHuyrUu5NigWLEw2taHW6UdmsfO19KHadaAbj8oSl7B2tC08JkCNedbO5rX3WmKUHXv4DWZYFTjYG5nWwvQUc28qbwhdQ7T1JEgMtKdfCqrhBDmM2Pdzy9n880voS+jBR+YCjraNh6TUC64nHaAxQknQxUKCl9vHoWiNr3yEtUIL06Ft832NOKXNnZ8Nj5CxJ4StJcvMlUkWoynJhhWEkwSdYRMA+qCD9WqOVgdXhgs0ZqPxuP94kmwe+70oTf+1IbaCCo/S7c6TWCqfLgxZ7eBOLyQ4pSUTSEFsPUsnWDSY/ic6yeMQfSb0QDtiTaalkOOvUk41YlnU4g+BM6ydSJbkx9W4XzsMCJYnVG/ilZxw6q/QsevDllsHhrDiieCSUJCU5YmhsCLiWbdT5/hAsJzQIlCROBk9WtsCSFNoCkr9nJ0rffU0gYxKZYQWE3AMU4v2SwqwQT6iMUuUvhopmsDaYfewIery1FNoIlflkQp9oAYjMJlU+0qkIy4a/NCiZlhIlA+ENsGMnR7gkkyxqwcr8Dv5O+NaRjMLjQcGOLbAMGgpk5almGYo1iZCLBXglyaPXA1otYDCIntG2WgFkB7wbDZLL7WyRDT6NTYFKkqiLEyhkWrsvDl3bb7cpi/dqp8SSNO7SGX6RKe9QYzbAlww3DGcFot/ev2L93YzUw16sJ8vkyuiM8yZA4/FAb2nB4dvvj6kMsUaxknTPPfcoDvS5556LSBjCR5J+m2JLRiaaiAeRKIxAbM74SVUi3pMUruMGJc/EZZScupY5pWT9+yWc9tBfUDNtNg4ve1t0L1OsapEst2PblCPWIB5CaVvMoiVrHNFkpVbCcYO/JUlp/ZSyJIk6OYGSpGv1LWvWti2382RnR7UnKSwlKVZnboVwNx8JSg8kVkqAPBHK51G2LSoiguWZpi3igt3bYydAnFCsJG3btk3099atW+FyuTBw4EAAwIEDB6DT6TBmzBh1JSQy5mNFKCdWVYKUAjGhNnUna9NUa41/sioHclJJXU9K62iSZGvOq68AADp9+yUOI/xvjcihheoDRaGSGuS5eGYmZ0kyeBWF1j4DcOyaP6Hn28sAAO3HjIBm+3FeiVIDXds5Sa7sHOjblKNI9yRJKUmichPsfxI6h9Dxjhuy4TFyliTl3u18kSn3/hfPvjVoVArWSsa7j0nW744/THG7RIsQNYqVpB9++IH//dxzzyE/Px/Lly9HcXExAKCxsRHz58/HxIkT1ZeSIAgiCUmRb1XaEatBQiLLU3RGUZzi9HTqBN3RI3GPN7kIw7rhcEIDwMMpQVoNDv7lUXT+5gtkVVUAAHLL9sMyeJj4vaCOJ4LnOmdJKrv7YRTu3oYun38ovSdJQeFJLrcTWZJ81iGtXc6SZBLJFQ6S3u1k8iaauqjUY6FkvKH2J0k8EHclKUbPho9EXggsjM7i9jGNPR5E5Ljh2WefxeLFi3kFCQCKi4vx+OOP49lnn1VNOCKzyMwPdHLNCkXzcVGbuCyoChGJVG4IryWTlVe0Vj4GciWXVUmpx7YYi5ECBMsDd+fO8RNERdQqVw00ogFusHbDsizQphiwbZYk7lUN4zsugduzoxacMuIxZcHddthrwHI7hflhaKwPuKYRuPrWyCy34y1JQscNjDOCglD+fZE74ywWRKIYAUDxd1+j9J3/ROT6PRwC9wompmMr3PYrei99DhqXvAc7U201/9stczhxKhGR4waz2Yza2tqA67W1tWhpUe4yl5AnmQZf6QDlZvikU55FmpZQ3z6xYhJhJDFALVHUSFP4h8mq80y0KDkPJdXxdPQpSZrWVsAofZhophBy76LfcjvvpBIrVjQ88ucQRQK398djMvGDTimvYUomMaSW22ldDPihoOxyuzZLkimLtyQBQLuN69AwYYpkXCwrsSEmzo4blIYbyuW2HINvvhoAcGzymUCPwdGKJkugd8fEMPbqOQAApqgY+Pt9kvlUuO03/reWCTxrMdX60ogsSRdeeCHmz5+Pjz/+GCdOnMCJEyfw0Ucf4frrr8dFF12kOJzFixdj7NixyM/PR6dOnTB37lzs379f9Izdbsdtt92G9u3bIy8vDxdffDGqq6tlQkxPUqxORUyqNR4iuVGjOoXaZyE1DkhXqH2qh2hpXQLzlc31KUWG6qrw34/T10kNF+By+RyJC3BuuR33rlfRaPsttVdHBccNHqNPSVLTu51OMJDVOIIvt3NnZ4ssZaNvugI5hw5IR9YaeJ4dK7cnKYyrsSCcNsg/ava5SDdWnlRVnpAyJLgvzjuwV/Ze10/f438rcROf7ESkJL3yyiuYNWsWrrzySvTs2RM9e/bElVdeiXPOOQf//ve/FYezbt063Hbbbdi0aRPWrFkDhmEwY8YMWAVnDdx999344osvsGrVKqxbtw4VFRVhKWIEkezEzotP+CTPYrvUsKaK95Ekj7zKXd/GHiVLOMMVTdZxg1/Ck6dEwkPqgNmYILB6aB2tcdsXFVBOkrP7wd4P/m44iM89CwHv3Y6zJLWFIVh+pJGYPQ9GqDi5w2TdWfLL7QBl+SDpuIERDGQVLLfj0s6RU340MCKWhencWYFxuZUfNBpXS1KQuGRvnfQpRtrm5qjiD/lOhC7AY4WWkVF+3G4U7tjC/6mJxANikhH2cju3243ffvsNTzzxBJ5++mkcOnQIANC3b1/k5oZnqv/qq69Ef7/11lvo1KkTtmzZgkmTJqG5uRmvv/46Vq5cibPPPhsA8Oabb2Lw4MHYtGkTTj/99HDFJ5KYRDd8In3xDsrCVwFDLrdL8yrLyvxOBCJvZ3EYQMU77YlwRiEa3DudUckQ08PA42axku8nWEDCkuR9ViOyJAUODKOR3rfcLgvuNvfiOkfgAbNK4jNIWJK0jNN7tJPbLVLwdFKOG0xZAZ2iVJjs5s3QbdwYcF0n4exB/rDS+BFqsktSlhMn+J+Gqkp15VEx8bGYbNQwjKSMuYcOQG/zGTlklakUImwlSafTYcaMGdi7dy969+6NU045RTVhmtu08XbtvG4Dt2zZAoZhMG3aNP6ZQYMGoUePHvj5558llSSHwwGHoCGa20yiDMOACXOGR224+JXIwbhccLXNurgYV8JlVxsubYyL4X/rNLqYpdPF+OKRiqPF7ruvaVtDxTAMPB4Wh+qsaJ9rRLtcY8B7LkE5RSo7wwSG4XK7+c5NKlyn4B1fON46LgzLo/V+0Lh0tMs1or1UOri65hbUOzfQYrMjy6ALeD5ShOUtlS6XX16wHp+xm5fL5RK1Z7fLBVfbYEUYpn++sh5tQJ45GQY6beCgyD8u/3vc/YPVzaI4uN9Ov7LQQCv6Wy79jNuDo3U2dC4woSDbIJIFAH4/0YCuRdnIMwV23cK66HIFppVxMQhVRf3l8283jDb0B9ftcovCcTEMGEa+LvNxCfLcX/b9lU3o3ylP0G+I+5CGFhuqmh1oZcRxO52MqC/1L4MA2d2CNuhXfxpaXKhstoNxyZehSyb8wzW+pTm/n2hAcY5RJD/DMOLyYxgweq6u+fojXx61/e1yw+UOvgfmkKCOCmEYBh7BchjW4YSrLW1ul7tNHl8/tK+iCX07+iZCjzXYwLIsH7bWo4HTGTx/91U0oU+HHFGZeNMj0c6E6fX7Bvr3u3L18li9DUa9Fl0Ks+B2B9Yrl8sFjyANFY1W2JxuyTS4GAbu1lZo4VWSXG4X3FoWLrcbWkGdYO2tkn2zbL6wGrg88u2KsyQxej2YNqcJmtZWuF3ecne73DDbHNhZzojqj1R8UpYkT2sr3HluGOprxDdsVl//1Wa5YkymgHB1jfUB19ybN0sOLjVOh2QZSLX5UHXJH5fg26KV6G+Dcbzewv9m/OQJbJvesDXHjvFp1J48LhuXsJy8cupCynWy0YKe7XxOD7ztxdcPMIwL3d5eBo/RhOOXXh00LKm89cc37lCY304HDlY1o65FvKTSeOKY6G+Nwy7zHUr8eFapDBE5bhg2bBgOHz6M3r17R/K6JB6PB3fddRcmTJiAYcO87jOrqqpgNBpRVFQkerZz586oqpJeP7148WI8+uijAde/+eYb5OQkh6eNNWvWhHzGwgBHW7yDt/JsFvvUPcQ74exu8KbteDaLmlbvb70WMB+IzfyR2QmUW7zxOA4HxsHJAwA6DTC42FtOdXagyua9N6xd4HvHLUCzUz5cJRyzAC1+Yexu1PDTV1Lh2t1AWbN4cO84zIrqTeshFtz4v94OVAZJB5f+kzksn14A+H0bi36FESVLEqEcUumqbgVq2+qD7RALnSCJnIwnsll0FLSHrVu3gmnbGyQMU5hHXFjCcgbEeSSEe67IxOKYn4G8thWobg18yXyQxcFmXz52yPKFo9MAloOsKH6p9FdYgQaHuJyE73ALGaTK8GCzBo628XKOnoXNJZax8QCLnBA9vr98DQ6gwuq91nyARZaCL4ZQDgCoymVR3LaNQa7v8+/vaiXyd5sG4MaSWToWdrd0nRXSfICFxeVrw47DbEAdEGLSAfV7vZFU2oB6u/fZ+v0sL58Q/zJsdQGHzMHNj1sA6LRA25gHBUYWx/PE9Yorq31NGrgEdZuTPUvHon6v+H64OA6zGFxejgFtf+/ZsR1NLicADbZv3+7NY4+vH9oCoEceiwIj4HQDB/z6H43Gm9/+1/3T3j2XhU4LHBPkZ6GRRXme+FlhXh4xsTgkaIfHWoAWpq1eHmSRJTGPI2z/w9qxAfWSi9cDX/+7BfI0HWDR55dfcBqA5lY7tvy2BUadNy/OETx3eM9elBnFianJY3HcIp0vWkG9lmJ8mzOs3w8dRvvKCgwHYKmrxfbt2wGA/7+/rP710OCw4xxLoGOtHb/+iopOlei2f4/oev2xY9jymzdHelZWoBuAo9U12PLbFlF66/fu4Z/j6L51G8RO0L0wZnPAsyeyWVhdgIURy3vYxKLRodz6fySLRUNbe9VpgZaDwdu6HCdzWNhcgLmtTtTksWh0+OTLNbCo3A30W78eQ9veadq3NyBdQoa185VTgZHlw5ZjC8R9vH8/4KhpxGVLHgEAfF7aDx69/LlcwjGWHPy4I0R+ceVurq3FF99tCLg/aO8eCE9KbWqrL0K4b2OisSnc1xeRkvT4449jwYIFWLRoEcaMGROwzK6goCDsMG+77Tbs3r0bGzYEZnw4PPjgg7jnnnv4v81mM0pLSzFjxoyI5FIThmGwZs0aTJ8+HYYQh83VWxzYfsJrWevVPlc0g5cOmPZ5Z636dszFoVqvedao12Jivw4xia/O4sCOtvycOqiTrDyA15JkP7IV06dPx6F6O042tcq+93uFGVVmu+x9Jew80Yxai0MURtb+Wn4GVypci8OFwiPiWcGpgzqhwerEtuNNAIApAzryVpID1S043iifDi79/Tvl4WCNRXQv0nRJcbzRhgPVFtlwD9dacaTeWx8m9e8Ag85nSeJk7NcxDz3b5/DtafTo0bwlSRimMI+4sITlDIjzSAj3XJfCLAzpIu43jtXbUFZrCXjn9N7tUNAWX/9OeejRLocPx6DTYlL/DqL4pdK/5VgjmloZ0X1/meXe3XykARaHd9auKNvAh8Nxas9iFGYH73f85atoasXeKu/A6rRe7ZCvQEvadLgBVqdv9nBIlwJ0yNEF7fuE9bZnuxwcawj+Acsz6fm0StVZjtN6tUODzYmyGl+dk8pPYbjjentXMhystqC80SvHyNIibG+TT4h/OZhbGRQdawwquz+d8k0Y3q1QVK+4ssovq4OzbXQklJ2TU3g/XKYO6gTHBx/yfw/r3w+u08dj9bpNGDlyJApzTbA63aLlOoNK8tGtKBstdhfyj4r7H61Gg9N7t0P+4UA300L6dcpDnlHHf9+EeSBEmJfdirIxqCSfv7f9eBPqrV4r2Lje7SQtq402JwrLm/i0CtsHR+f8LHhYlu9/g3Far2Lkt1lbctu3x5hTxyDHqIPN6UbjqLEo3vYrAGBAz1IUnjpG9O7QrgX4vcIcECYA6LQauINoSVlt+T9w5EjkFnqVr2KTESNHjsT27dsxcuRI6PRiLXFsz+KAepjvpwRxjB42FF179EeX42Wi6z09Tow5dQy0Gg06ZHtHtd0GDgROHYPWnbugveMOmNatRY9sE8b4pXfg4d8gRbYGAc/265iHBqsTDTbx0qwuhVmobA6+rFBIaXE2/40z6rSY6NffKqVfpzyYWxnUtHjrxLCuBahotqOhrb61yzFiVI8iaAXKace8/IB0cbhdbrjKt/Hl1CnfxIcdDGHfkn+wDk63rx+o27KLvzd26BC48uXHtn065OJwnVX2vjAupfnVLjdHMr1dqsWWpPZ5uYHl3SlPZCVLFGazdHv0JyIlafbs2QCA888/X7zpkWWh0WjgDmH+9+f222/H//3f/+HHH39E9+7d+eslJSVwOp1oamoSWZOqq6tRUlIiGZbJZIJJ4pwCg8EQUjGJF0pk0Rs80Ou8xaPX65NGdrXwpc3A/9bptDFLp17vy0+pOLh7AKCBh39Or3cFf0+vD3pfCTq9HnqdWxSGXqfj1/xKhWvwaEQyc88ZDKyo3ujblAxdCDn5e4LyEIarFsLwpcL1l1OoJMm1B51eD7CagDCFecSFJZU2KSVJmB/+cgplFL1jMAS8x/2t1WlEf8ul31tmrOi+VFySeafTgxsr6QTh8O9IpCUgfj/5dHpGkIfK+iGdXge94BPgfU9QDpLp9ojikUqzKA5BWqXqrChuv7Zv0Otl1/zrdL406gVyGGTK3D8tepd0eQWDq8+iut9WVjqdHnpW0B/5tQG9Tg9PhC4WDQYDXC5fQendbkDf1hfrddDr9dD5rb7h4jW4A9Op1SKgjkvGq9cHtCGpb5wwL/3ve9uJL1+4+iWOhxWVu7DOCMPxsCzf/wZDpzdAd7wcAODoWgq9Tg+9Xge9W4Pdz76KiWePapPbHdjPBKmjOq0GGo28ksTtP9Jk5wI53slSndPBK0Y6vS4gbL1EOeQf9w5grb37oXbKDPR60+tky+B2waDXI+/EcdHznb//GtnmZhT16OrbS5STiyyjAdkDhwGXXQqsWwtTc1NAXDq7tHKjc9gDZdXrodN7+PLkn9WF7gfE4Rig13knhnR6raK6KBmOTg+93lcnfOMAT1vYOm9d9Pjk1TkdQeNywVdO3nSFrm96vZ4fX+v0euiF4xJBmzcyLiBI3HqZvotDown+rZFC63JJ94eM31JMhpFoC8kxnlUqQ0RK0g8//BDJawGwLIs77rgDn3zyCdauXRuwfG/MmDEwGAz47rvvcPHFFwMA9u/fj/LycowfP14VGQgiGEl0tmpUeCJckpMKtB1VEhGROnRIdjwSM9PRbn6P10ZqReckKT1MNty4E+CaO1HOP1iWBQT7BTQMEzJf1ZCVZZOnLobddxz0Wltae/Tyvt/Wdzg6d0HjlGkoXvut6pvVheckeYxei45WwgGCCIk05ZQfAQCYh41E2YK/o9O3XyLn+FEMPn8aGtbt5A+arZxzCbp84bUwZh8/hvbrv0a7X71OGNwmwTrnDt5VH5KOGyS87wGA3tLi/RhpfZNfctkf7WGyajkskA1GxnW6WnhY8MvNA9JiEThHcAS6WhcSi+5F6vwjINBpiZQTk1QjIiVp8uTJqkR+2223YeXKlfjss8+Qn5/P7zMqLCxEdnY2CgsLcf311+Oee+5Bu3btUFBQgDvuuAPjx48nz3ZpSCq4fE5VlA5K0kUp9CfSqiWVH3L1NFj9jUe2xst9c7iEOmsqIuKcQMXRqSRX3Dx9BnFdrYar4qhQ6OY7nt8NTdlBAICtZx/v34KqzbnGllKSIs0XjcvFO4XwmEzwZHFKUijvdoHx5e3bDQCw9vXuQhMeetvpq0+ht3iXH5mHjkD+np3IO3QAulYbuj/o277gyRYoSe3bA5BxKy6z30Pj8UBvaYGrIPRG12iLNZgzjHDjlpRFpCQpXxaoFJfHA51W2mmSxupbXixntYslchMB3LlI7qxs6Oyt0m0hmT5OCohISeKw2WwoLy+H0+/AKKUe75YuXQoAmDJliuj6m2++iXnz5gEAnn/+eWi1Wlx88cVwOByYOXNmWGcxpSqpVpGSnWR2Lx7JRz7cd1KxPiWDzJJKUvzFCBu18k7N82gUx6nSM4QC/JQkpWUsdfZVVO7Dw3w3IX0DC+CI1xpjK+0VcNvT5nku3AM0g32bhOfMuI0m/iDXkJYkCQp3bgUANA/3Lgu09eyL7JPeJXYeg9Fr5QHgysvnXY0LD5QFvINfvux5S1LgHjw2yKZ4Q3OThJIUmAfRWpKC7fOKBl4soZJkj4ElKcjqD6GS5F9GMUNQHnJngXGWI1devldJSoPDZCNSkmprazF//nysXr1a8r7SPUlKBnpZWVl4+eWX8fLLL4clY3qRGUOCzEhlYkgGhSMVUcsKQtmvLkrrM9V7eVjW/xDUOA5oUrFcbDZoGrxWE3uXbgDEFmKP0avASOVjpPVQJ1CSWKMJbpPXkpRVU4Xs40dl3/OPz1hXi+yKE2A1GpiHjQQA7F7yL5w5Yyx0ra3QWy3Qt/iUJM5i5H9oLWfJAuCzJDU3tlUmQW60KUmV51+CLp9/KAwC+uZGoLRn8IQjuMc/JUSqZCl+S9h2YmBJcgvPhfO7p7EILEkxiFsKYV8hb0nyKUmmupq0WG6nDf1IIHfddReampqwefNmZGdn46uvvsLy5cvRv39/fP7552rLSBBJiypr9KMPImS4yWxJiwdy6Q+VK9LL7eTiSB5iUt5JlMBo0hd0SanQchbB/qSUa2eiw2QTf3aJcuKfz9qKkwAAV3YO3HleT3six1VtG8FVmz1nWd5i5NHrwer1vCUJACafeyYKa6sVBVXQZkWy9h3Ay86064CTF18FwLtXiFtu58ov4C1JWVUVonC46wB4JUnrckHn71q8TUmqn3BWgCxSlidpktOSxBPj5XZut6gzEtMitCSFWHoZIhuULrEXHpgsZ0nStNV9V1sdk2oLKdZDRqYkff/993juuedw6qmnQqvVomfPnrj66qvx1FNPYfHixWrLSKQxImtiqrWeFELp9yKd9iRFulch9Hvhhxv3bE2ithSu4qCq9SeJ8kEOTkRhvYubBUyw6kPrCmO5XZTRKltSyUr+BvyWgSoJS4UM1VR4FQZHSVfJjpJtsyTpmMDZ82CxS4nW/+mFOHPqaJjalBTOSuUxiQ9MLK6VPi/SP8jCXdsAAM2njBZdd+V6B7M6m1W03M6T5XXRnHP0sOh5zpIFAMjOBtt29qTRb18StyfJnZWNnc/9B3UTz4a1bR/X6D/9QVEFj1bHidlyO+6HSElS3wrrDpJHWmuCLUkyFiLOC2IwJSnViEhJslqt6NTJ61e9uLgYtbW1AIDhw4dj69at6kmXwaTcjGQKkYkOIoKlOVnzI1FtQJgdaik3aqdEynudMJJYjA+SqU8SD5KTR654E23KhQMfKFhul6RdRVQoTZLm5AkAgKOT7/gRoa4U6Z4kKXq+9QqyqivR6w3v/mvOguT2O95E53IFvAsE9ulZlV7ZrX36i66728649FqS2pSk/AK425bbdV/1juh5keMGAB5uyZ2/hzubd5+MOysbNTPnYPsrK5F7zKdw+TuekKpXkn1cGKirJPmFdf/9wJtv8n/GxJIkkN+/j9MIvdu1xmdPklZgSZLzbsftoeMtrRITBqlGRErSwIEDsX//fgDAiBEjsGzZMpw8eRKvvPIKunTpoqqAROaQioOdVLG8KLckpUiCwiScwZ3w0bCW28Wx+gabZZQjVQa4SvqBeCclcQp77OJlAdFyOy3jDGq9ESLXLiLdKxbSdhvm86HejwRtjXdpm6OD75BP0Z4kbrmdzABSjmCy6axexYWzIHmElhwAOpeyuPRm78G9rnyxwwRuxl9vboauzTrhzs0XL6sT4M7KFls828kpSV5LklCpOnTbAp88gj01st5C5ZOjiEj6SCUYqiuBp58WXdPY7RFVsuJffkLHNf+TvBdMydMIljfqQrgAVwuRJUlGKeT2KrlyvYcep4MlKSLHDXfeeScqKysBAI888gjOOeccrFixAkajEW+99Zaa8hFIrsGNnXHD7WGRK3HCeVIjyEM740G2Udq1pj+hNu6rdW5I7AlmSVIeitvDwuJwoTA7+sPguMOn1UQYpn+ylA44xc9JLKuJQC6lqVQadqPNiXY5Rv6w4MBwIlGiAt9Ro25a7C4UGOXn41rsDBh3eBEpLssohlpKorA6XKK+MCK32QpfarH7BsSq9RkReLdrsTOqn7vmdHkC8jJcHC43GDeLPIkw7K7wDriXxOqdvXfn5Une5pbbSW1qb3VKW3xCwTlO4CxIrN8BmLKWJL+/9S2+/UZCuOV2pppqaNoK35WfD4+MkuQxZYlm1n2WJPE+I9bWlleCcI7e8Gf0ffkZr9zWFqBDRwBAi90l6a47Wu92rc7Iy5wV/RbLoWuQ3lOlYZx8HVCCxunAmPne8z83/t8G2Hr3E90XOW4QiNBkc8Ld2MT/HWpPklIYd/BGLdyH5O/Qg5elbblda4/e2P7S8gDLYyoSUY909dVX87/HjBmDY8eOYd++fejRowc6tLmFJNKTDQfrAAATB3SAyf/48hThp7I6TB3cKW2tJlIEPWckjHB+O9qAFrsLQ7sVoEthLDrA+O7LkIoj4miDLAFTOyk7jzcjx6jDGf2k+9tI8q6sxhL0fqTlcazehsO1LZL3mlsZ/HpEPAvtH4+GYQIGh9Hkp3fiQ53Z658P1ePM/h2QZYi+L2RlfnNsPhx4Hk20aNxCS1Joq4TZzuBAtXRZhoN/+zC3MmHlpZRr+vUHvN+mM/q1R45RPLTZWFaPHIUTY3JwHsVcObm+awqX2x2tk3eJHQxOueEdNvh9s+QsSaIlwwzjc8rg53qbU/iyj3gPyWWNRnhMWWAF8TgGDYFp3x7vH1rxZIfPkiRQHFgWbLM3PqGSxBqNsJd0RVZVBZ8uAKhtkV6SFW3/f7A6eH8mR6hJC31DneR1rcMBdxhKUv6+3/nfBbu3ByhJcssNfzvaiJEnTwriVUdJWn+wNuh9rdCS5HJB43SCbavz/PW25XZMYRHqzp4pGU6yLu+XI6LldocPizfz5eTkYPTo0aQgZRBWhwozc37Es+3E2vFNeEQw6x/m84qX24W432L3dpQVTfE/wC5eiAYYYSy3ize2IDOlkczCHquPbCCnBLkPY70l+Jr1gY8/iMlnDkFWxfFYiKUKwcohmWFZVmRJAsOE7FcarNEvnwkWh8XhkyfSdmZulbauRLv8ijubxi1QkoQ9ZrDDZCMl79ABAD7HDf7IWZI4+rz8NKaMH4D8A3sB+JbXcXDLorj9SJ78NkcOAktB0933yUfQwaskCR03ZFUch97SAo/eAHv3HjLxhVZgorUk6XSxmQQ11EsrSbowz64qaHOmAfjOsBLikbEkAUBWdaUv3pB7koLnI7daJpR1WOOnkEtZk7gJArn6mopEpCT169cPPXr0wB//+Ee8/vrrKCsrU1suIkkGYvEknoPPVJvNiARhEoN9cIR5kU7GtUiLONIlWqm4py4cYpG6UIeSlv73TegtLejy6fuqCBNxu1e61yay0BOGcAmNmoP7UETb/arZfysOq22zvDsCS1IIATDkr3fhtEtnIH/3dpHHQT5swV6kE5f4VvLo5SxJbTWxz7+fFQ2iGT9LUsvg4eJ42vYs6Ww+xwCts86Dpf8g3l24CP6sJJ+SVLjDO+BvGTgkYA8VvwfKKrZGdvxuNUbPuwimSp+FJOoiDvJ+v2cXYdBj94fWDCRk0ddJW1y0zvAmDrNPlvO/CySVJOn3OvzwDfIO7vPFG8KSpFZT0fgp5NJKUpvLelOGK0nHjx/H4sWLkZ2djaeeegoDBgxA9+7dcdVVV+G1115TW8aMJ9U+vOGQzmlLJtRabhdroh88RR92qOeSVRkKtVwrEqkTmVat4CPMFLUT3VN6hlE09SmW8yjCwbVa0RTs3Ire/36GP6tEEYK9Ot49SdFJE6/awsr+ETu4zfJiS5IP/jDZMJUkU00Vun7yHgr27ESXLz6SHPQKB537Hn0GVbMvBCBeAqUE/z1J7rx8VN96ly+eAu99vUBJQnY2Nn26FnsfezYgPE3b6iFDYwOyjx9D3xcXo3DHbwAAy8AhgfHntYUvWG4HACP+PB/tft2IQY8/6JMlRg1Qa7Oi1xsvo/v7b6PjD19LPqOrrkLfF/8hacE2yClJYViSTBUn0HP5Mv7v/H2/S3j8C0y/xuXCyNuvEcsqsz+ID0exVMHRhrAkaZxOtP/5RwCAxyBehpfKRKQkdevWDVdddRVeffVV7N+/H/v378e0adPwwQcf4E9/+pPaMhJE1ARs4k+IFNLEZe+N6imOPryYp1uF8CX3LCVT5ZEjBjLG2/qaffwY/9vttwE4KlGCWEsTWbbifTbhC3LaH2aj78vPoMe7/1EWHwC4/Rw3BDwg8Y4KpEIT8se3J8nnuEFYlfjDZMO0yAn38xgb6qCTOIPGf/kSZ7WSsyTJZTCnpAhhSnweid1tSlTD+Inee/kFwVcXtG9Tkpoaccqf56P3qy+ix7veiXJ/hQzw7YHytyRxCK0rsaojBoGC1unbQM9yLIBed/4JvV99AaOvuzSgT9A31kuGG46SNPy+W8TvuhjkHDkkuiZlSco7uDfgWiglSS1CWZI6f/05/9t/D6mQVGv7ETlusNls2LBhA9auXYu1a9di27ZtGDRoEG6//XZMmTJFZREJgogWpbPtobz5pSqybrsluuxIZzCTSXmKRCnWaOKfBqnaxsmec8KnJOnsoc9ViSVKo1Oq3MQyr/P37lb8rMbPBbgaaJxOQKsFq4/OA6rIMuqXV5F5EYxKHGisUsvtfDXYE8S7XTCE7rNNtVUBnuKAwOVL3Ey9Uu92gPcgWP+N9gDAdOnmC7dtT9KJy64FU1CExlPHo2eQb4Kug89xQ/6BPaJ7/vufvNc4S1ILdJYW/jwdDqGntlhNyuhbmvnfBTu3ST6T9/N6AEDO8aNo8rsnXIooum5X7oq7aPuvAdcMZnFMUukX1o2KC69A10/ek5XHF45isYKiYYJbkoTye4IoSalGRJakoqIi/PGPf4TdbscDDzyAiooKbNu2Dc8//zwuuOACtWXMSJJovJXRpMseneDL7ZKntiWPJPIkkzIkRyQyJsJJRbD2Jfz4R+rBiYVY8U+FshMSibhCj3Uh8XMBHirCkAPXqipMnjAYw+++QbkMCYRlw8hji5TjBkFYbQqIRsISFAxDcxP/u/jXn3HGuRMCnglQkowhlCSJRPnvD+JwCSxJnjbrD2swoGrOJXB06Ra0jWoLfI4ePHrxwNidK6UkeS1JHb9bjbPG9Ufvpc+JwxO082jdzMt91/RmnyUp9+gh6AX5z78rk1cAoLVJW270zYHKrRzOYt/yYS7f9BaxdU1Kem6ZYuPocWgcM857zRrCK2moGq5wjBOw3M4vH4TlX3/GFGWBpgARKUmzZ8+G2+3Ge++9h/feew+rVq3CgQMH1JaNIGJGMg2WItorouAlpQdDpiuRpjlSz4ehXlMyM6pWvYxISQp1JliEsoQLJ7tw+Yq/JSms8JKw7sdScdP4bfzPOVKG8XMm4tSrzoPWb9ZZ47fcLlq0v/0Kvc2KTt9/hbwgFq1wrQSBLvXD79uizWafJSnHd01w3+e4Ibx8lBqk++M2igft3HImpYfJAoDHIG3Zc/Tp6/sjTCuYpi0vtA477AJlC5CzJHmvFezZCQDo+6+nRPfDWbIWKUJLEgAY62oCngnmeEDrZ0HhrHpGGdfgUjg6lvC/bT16eeUyi+WSWtEgPO/K3bbs019Z8Sdejhs4hyVVs+YCutQ8HkaKiJSkTz/9FHV1dfjqq68wfvx4fPPNN5g4cSK/V4lIf1LdO1wsBk7JnCfBBv5JLLZqhFPe4nIMfC8ZB92ACuWYAKtpMMVMK5iR14axlEVING1SqXOIWBDN8j5/Jan3qy8g9/BBFG3/jR+cet+FyHGDzt4avSIhiDt/364oQ4sMufYpeVhyGCnWhLIkhXAB3vXDFejx1tKA61LL6wLC9lsmF3q5nURaZTbTewQe74xlB0PKIqJNSdLZW+Hs0Fl0yyVx6K7Unihh49KF6SEuEvQtYouNvyWGZQOtbsLc9FdKHJ286TbKuAaXwtl2kC4AWPsOaJNL7MxCypLGKXheJSm3TZ44LbfztyT57SvjPdtJLOmMhTzxIiIliWP48OGYMGECxo8fj7Fjx6Kmpgbvv/9+6BeJsEi1ShUO8UpbOuehEpJRgQtteVE3TKl7kRwmK7u/KYTAiS6CUPJJ7w8Svq+qOCERulKOxpLkr4gF0wWjVYAVvx1DhdR/uV27n9byv/3dUwtnh3VWS+g6HCJu1uobsGlc8udHKbKEJ5lLTo0t0JIkxBNkuZ221YYhj9yLAU8/CmOt2HJhULJMy2/E7FtuF4YlSWaPmAYamMeeDgAwX3CR4vAAAG0OVbR2e8DaWXdOoJLkllCcOv/vE58sKlgzQ2HwsyRJLVdjw7AkOTp5LWjhWJI4RXrPoufAFHv3dflbuCQtSWafJcmlUElSC39PigY/C2g6npEEROi44bnnnsPatWuxYcMGtLS0YMSIEZg0aRJuuukmTJw4UW0ZM5JED6jSnWTK37h4t1MYR6KtJGrmRcRH4rDSv5MdnaUFOqeL91CVCgTd7yAYbGYLnDj4k0JFxCOd7ChSIrDgCJUTrc0Kk2CGW+Nv5RAoVDqLtMexcNAIZtnD2hsVAjXaodJJElm4QaCcRYZ33BA40Bd6avTf4O+/YV8K/6VNbChLktTkTxC3zPtfXQHj+h9hmnMuYAtjM1CbkqRzOgKsvcEcNwgZ/pdbBUKq15rlgvK32EjVe6Hlzj8Yf0uSvbN36Vw4liTOQYWzqD3vBdDfwiWF3sIpSYW8JSnqPUkK8bckyStJ6eP+G4hQSfrvf/+LyZMn80pRYWFh6JcIgog5crOvwTrKVFIE4oIaA7IILFTRRjjq/LNgOlmOtZvL4M6VXhIUDK+nriD1JM7qiFBJ6vjD1yjc+guaR58WVxniQ/T5KrS08coJy+LMmeL8ElqSWLAiS5Le0hLyrK2Qe8AFliStjJLk7aOiM6VFlGPRZLPbDU2bNUfOax+3T0jKkpRTfoT/7W+JEB72KqRpxBgU7djifcZPAfEtt5M7TFbiWhBvg+6CQtROnYWuRhNgC2Npq8A1v7+yJ73cLlBxEqJ1u6FxOiW98KmF/94ff4cJgLyTCwDQtootN862/UVhWZLaHFR4srPBtB3g62/hkrIkcc8wBeott1PaEv33i/kvE9UwypbbpRoRLbf79ddf8cwzz+C8884jBYkg2ojcchGbwacw2GCegtQY/JbVWLDpcD1c7ihdEgmQk0upx8FIl4qJN4VL3JdbbhckTLebxY8HpQ8hjIbDtW2ziE4nsk4cg4ZlUfzrTxGFFc2wtabFjrX7a7DrRLPsMy0MsPFQPRqtwTeHc/nrfyin0vN/RGGF/UagHN5wgodUXm/DxrI62Bn5JWZCXG6FSzNlHrM6XPh2TzUfjtYusOC4XGi/bg2mDesCY4P4TBehlWNjWb3Iu13WyeMYPvNMTPzsPUVpkBYs9HI7Dwvsr5KeNY/kwGel7VFyn46y6ESevfy9uPHXOUuSxGGyOccO878DN7xLOysQLlvyt9J4eMcNyq11chYwYX9a0RTm3j+BkpR9UnzwqkvSu11wJQkA9LbglhE5jjcoOy/I35Lkb4k5WmeFU5BX2pMnMGzGGej52kvev/0sSc523HI5cbjB4CY13KYsuAqkD9iVqtf8cru8Arhz286cslnR8dsvZeOqalZnn1eABdRvmShX74NZLFORiPckrV+/HldffTXGjx+PkydPAgDeeecdbNiwQTXhCC+JXgLFkYz7WiIl5ZOSZPIfrbPCYnehMowOOdKN1MHPfIo+Y9RYpieFO8TAOBIO17YNSgUDs6EP3B5RIqRdgIs0BVkqm+xwuVlUm+2yzx1r0aCVcWPLMd/HNagLcL+ZS6agSP5hhcSq2RyoboHN6cah2vjsD/BHOIDR2awYdesfJZ8TDsjdjEvkaEHDssg7fBCTPvtv5IIIZrXllttVm2O/OV8pLMsqaipCi5vwoExh/eW920k4bjDW+SZIApQkGackwr1P/tYmToGSO0yWZdmAPiCYJanVqUy5D0Cnk7UcMG0HzQpRoiSptcdGdrmdxW+5ndSeJEGa8t74D7IP7kf/55+AobE+oPyYNscX4cjNW5KysnxnRwXxbtf5y08x6LH7kXvI60XaUdIFLkH9GPrQnxXHHSlav32hnb/+At0+eNt3P8RyVB9JNngJQURK0kcffYSZM2ciOzsb27Ztg6PtY9bc3Iwnn3xSVQEJIhYki+KZDESyB0feeUH08sQKpQpUyM3pct6zElmnBEqSocUs2gMRD9RMOZeP/suWmMIiVcLXBNHMoq2/kRxEHE2chdt+RYfvvxYNoqWWD3EIN8YHdYYRwbJdANBYhXuSpAfeyvdHSv9WIoc3Hj8lIYp8FuYbK2dJMnCOGwKVJOHA2n9Pi5zba1d+IZqHjgAAVJ13segeq8CSlFu2T/yONohb5iCTFaEs956swKVplXMukVyyJqcklf/xJjiLvGcHySkbxpoqdF31bsByxXAxtFljuLOK9JYWZB87jC6f/Jff28cKMkRXXs7/Lt68gV92yeFqm7wJpiT51z2uvYosSX7tlvNIy7Isht93M7q//zZyjh8FAJiHjYQn26ckubNzcNagTrLxq4GuTbGzd/K5Lx/86P38b6Xe7VKNiJSkxx9/HK+88gr+85//wCCYVZkwYQK2bt2qmnBEepJOFik1SHRuJDr+WCGsZ6oO4mOYYRG3Db+Bmf9sqRIScU5SMIXFf0Y++8SxsDNf8nGWRW7ZfpGzg4jCkXxQcZBB41CqcI+9eg5G3nEtOq35H38t2MG7IrfqDvmlVYbGBkXx+8O5yQYCz1XhUHsyQXHRRLFPUOjZi5U5A8ZnSWIC1jeLlCT/PUky5eXKL8DWNz7Eb8s/QcWFV/jF5bUkye5JYoHxc8/yvyr5LBDdUlvWlC36+/cn/4nfn3hR8lk5Jall4BB+H6XcuT+n/vF8DFm4AP1e/EdImWTT43ajcPuvAAB7l+4AAL21BRNmn4Ghf70bXT/2WlGFy1L1+/bwv7OqKgODzMoOKrcUIktS254kf+923LfAv97auvfwesTTaLDr6Ve8z+gN0GkjL0Ul3x3O4ukQKEkA+H40Xb3bRaQk7d+/H5MmTQq4XlhYiKampmhlIkCWDrUJOIwwSbM30xVIRUtfYnyej0i5Cqc4Ell0fkqS1KxmKPEkl9tFIVKkSB0mCwAlX32Oki8+jDr80tf+hfEXTMaApxZGHRYgHpDFs98WzqgLD+X0H4SL3mGEbtXbZrMlBjVZNVXhC+R2A4KlSxpPhEu4JFDTKhQJnFdA1mCQ7YBYQT4GnCkjsiSJ2yZXz3c9JT5DyZVfAHdePppOHQ9oxUM1TiHLktu/I6kRymdaNN2cvyWpfsJZsoeJCq0fQpzt2kt7axPInHPCa9HpsG5NGNKK6f/MY9C35b+9SzdvfAKvcsVbNgEQe4E07NvL/zbVeJUkVlAenHKnt1mDWGCFf7C8YuwxZYPhvNuZzdLv+CncnHIHAE1tjmyyqk4CLldE38ZgE1VCOMXO2UFsseL6Ea5vIUsSgJKSEpSVlQVc37BhA/r06RO1UERykk7jd6VJCafPSdXsUVMxC6eTDrmsLYIlffEoA7XiUFUhVqAkhUIt3TOcVAWLU2pDe/9nF4Upi//gmkXv554AEJkjCOk4EoPcIaSGIBvIhTPk3B4DT1Z2wHNZ1ZVhjbNzDh3A5DOHwvjxR/y1YOckxQMl5eJNj4JZdM6S5DcAFFpfPYJVNf7OG4JZkrjBp6NzCapmzeWvu4K48jcPGwmPToeS8iPIK9sfcF9TUxN4LUYdp4YVD+LdQc4YkvtAuPPyA879GfLQn3HG7DOgs4r7MrnznoTIJafn28v4363dewDwa0dteSS0HAotoqa2yQNXXj6O3HQXTlx2DVoGDvW+wzhx5tTRGPz3e4PKphFYDt3Z2T4X4BazqIF52tbbsRaxIuwU7PVydujkU9jatYMuDOcRQpR8irglgs72HcXX28qL669DeSZMtXFkRErSjTfeiDvvvBObN2+GRqNBRUUFVqxYgXvvvRe33HKL2jJmPKlWqYjwUPVsoCjfSaeqJkqX3AxfiCU44VgGEpp3flaXiDY/h9CSYtEPBbNecQNNW2kv/p6hsT7w+TAFcwVxACEXUjRLumKFsSn8JXEdv/0Sp9wxz7sBvW2w5s7KQtWsC0TP+Z+BEoriLZsDXEBHe05SpGP6mNRTzjJkkN6PBEDk1ctfwRcuxcqqrsApf56PwX+7G6fceT0/8PaYsuARKBica2gpHCVd0XDqeABA4c7ALQ6Gw4ckBJTOGI0mOguo1m8QH8x9thxuUxbvrY3ru7p+9gFyyo9g+IKbMPzuG/hngzmgCAdbr74A/Fx3t+VRwHlibZiqvWXlzs7BoTsfwL5HnuItYIB3cqHbRyuCxqsR7AX0mLJ4JUnrdovqCVcibKN4MoRp51OSWL0edZOmef9oaUH+/t+Dxi2HktLn+gt/JYmz/HH79tJtuV1Ete2BBx6Ax+PB1KlTYbPZMGnSJJhMJtx333244YYbQgdAEDyJGVom67I2lo39crJkJpbL7WJtAUpolfLfk2SNxJIkzlilnr9iBTfQ5LxHAd6BhBTZx46g4w9f4cTl18ou6eFwFRTAEIGCIUe0zZX1+7/4nnwBRLJvqHD3dgDeJTHHr77R+9uUhd3PLEPJ6s/45+TcMMvVB5010FmEqofJBrsXVXtUVsF5xw3BlCStxnufYUQWO1NVBYra9sEAQM+3XpF8323KEg0wuQ39clh790WHzRuQKziDiUNbcUJCwCDL7YJkQ6jlWHo/iyYbJI/k8GRly5770+HH78ThyzjOUILblMUP9m09vaueDAIlibO2SR0IDACmWp+SxMtjNII1GkUOO3RWq+xZddzeHo9eD1avB6vTwaM3QOtioG9p5t/jnMCwzeK9SkxRsejvHf9ajtPPn4S8wweh93tWKcr2JLUpSW0OLzh8liSl3u1Si4gsSRqNBg8//DAaGhqwe/dubNq0CbW1tSgsLETv3r3VljEjSdIxvCqkc9oiQWogFEoRUHPvQ7qWR6xceStaxhNZ1JGjwnK7UCitc+HkezBnEdxH11VYLPsMx7iLp2LA04+iz8vPhHzWFWSGXkgk9Ue1tqQgHENDoFVNKYU7tog2j/sTbv0p/nVjwLVYLrdTa5JLaTBaBZYkAIAp8KykEbdfqygOj7+SlBdcSbL18I61csqPBtzTSk2SyFmSoImq3lpPn+AXYPjTBu6sLN7lefEvPwVX6KKwJLV2K+V/cxZq0f67UEpSdaCSBABsvtghBbd3ib8v+K1pW7bGW9w0GsFZST4lhz8vzm+ff4D3RI0G9q7efUqGFvGzSlFS/L7+Qrw813+5XbopSWHVNofDgYULF2LNmjW85Wju3Ll48803ceGFF0Kn0+Huu++OlaxEgknlZVn+fW4s5FfjJHlfWKoEozAy9YJS0wqWqDomOkw2DCHCVVxVtRr6fTj9lz5x8QUjWSyY3ACYtyT5HViucToD1r3r2/Z5tP/5R4h2y0qkWbTXI4VNt5Est+PIrjzpc0MssScpHE9dPV97CR3XfRtwPerldkn0leH2pYTabwGTCbBYoHXYoWEYsAYDCvbuUhSHx2QSbXoPticJEChJJwLd/WssgZZATYzy88SzL8P93fdwZ+fA2aFj6Bck8Jiy4crxLrcr+epzMEXt5J9VYEmSU6KZ9h2Awwdx8uIrZWSVXm7HFLeDobEBurY+yV9JQm4eUO+btDBVV8LWu59/sAB8liS3YHKCyS+EsaEeBsFZSbwlyU9JYorbB0jNLSE2RGBJUtr78Qfg+k2qBFiSQu1JCk+8hBOWJenvf/87li5dil69euHIkSO49NJLcdNNN+H555/Hs88+iyNHjuAvf/lLrGTNWNJ1pj+RqJWnyfQhj5REpUGtMhB5F5MJU36vSfhCxPKMqIiD8FOS+vz72YBlMKEI9bGM154kDs7rl/+AJOh+mRAe1VgAbsGsr3CpTdD3krATltqfFQ6cC3DOkrTzuVf5e3qlliSPB/2ff0Lyltw5SWqgzJqrnuWTX27nN0APqL8dvQPvYfffiskTBiPrZDmU4snKEgUo9GImBX+IqcRhqBqJa7Hq5l29eqHi4itRPXsuGk+bEPoFCbyWJN/ytNL33pJ9NhpLEleOdZOni7wR+gKXtiQ5uorLIsCSlCdeWpdVHegqnEPKYQq3z8dYW+0vCiBQkirPvQgnLgs8KJqrC3qJyTElKGkD/DJBOUsS5wEyk73brVq1Cm+//TY+/PBDfPPNN3C73XC5XNixYweuuOIK6GTcPhJE0pFMYx428GfE+26iTFe0g0Gl7kRl449EaVExLP8Aw7MkJRCJAyzb/7wurCCky07pQFNgfYsyJ3jHDdxsrkb8mTI0yyt/igbmgnSWfPWZ6JZaytCAJx/GwMd8E4ZaeytG3nIVuv/3zYBnI40ynD1JLQMGB1zjZ4bblv3UzDwfB273Hg6ps1oUlWP7Dd8HXONciqu6J8lfFNUmuZShVbAnCQDQzetWOn//79BbLej1n5cUy+I2mvg9LwBCWmW4pXn+nvQAQBPGcrtoCXW+mhI8JrGSFIxo9iT5WzuEy++E+FuSnJ06i/723/foGTBQ9Lf/OXXCnNf6tTsAcHTuAgDIqvaVP38wdZuFqmrWBfj9qX/DI5FPnCVJb45wT5KClqBzBFrAAN/+Vw1/mGx6OW4IS0k6ceIExowZAwAYNmwYTCYT7v5/9r463m7jyv8ruPSYzYwhx4kd5obLTXFLKWxht/jLltItJU2Z0hQ36RZSTJt2u802hUDD7MQQx8x+th/Tve+ipN8f0kgzoxFdeOC+bz+p75NGA9JodM6cc77n//2/igWjGQA9ozl0DzvJ/cpZznrHcjg8JHaTODqSxdER7+SBQegezuLYqE+G9imAw0Pj6J3ifZxIhM5sX8ZkyxY17O5NI19B3EG+ZNaRK2rQdAN7+tJI56ikjVX8qPeN5XFoMHqm9iPDWcGcmkoatgWBoMTnGeoJeDf4ZXxffwb7+91sSyLED+zD0lu+gtjQAPJF3aekg6FMAfv7vS0WXgxTUZQkUZ8lape4eeMG1/lcUcPOnrHA++UFZWwUC3/531hwx88QG+gDAMy/43Z0PHQfVt90vfCakfEiDg4497p7OItjI/7th3W3e/QvT+DINW90HZ/95/8BwO4M2zlffHIt0eCZ1dK3/Rh7P2AqWl7JZIMwmitib1+aTw/jiZ5Rdp7vH8iYa0eI1zTsEhOG3Q4AMJ+1OKhpN6GFF/REEomjR6hG/eUqIugrAqr8sT73O+JFAT7R4pshu8VOIxaLoCSVvxnvxM2Ygvy2G77BnCfrB29JohnlAECrY60pha9/k22HW3t7KdFLElhk8rPMBK2JHuf5lzQDR0eykHpM6xLPKsf0z3JJjpWrJI2lsfQ7X0HDdm92PNsClnC720mlEhL9fVZfWsrqw1RFJCVJ0zTEKVOaqqpoaGioeqf+GbHl8Ai2HRlFrli+0Ln50Ai2Hx1DJs9+nIqajq3do9jaPQpNjy7g5Yoath0ZxbYj5XHw+6FacvB4oYTtR8ew+XC4RSLsbveM/i9Gvqhjf38Gz3eXPyeePTiM/f0ZbD48gn39aezry2AsF12wCvOI9vVlsLcvnAsRPzP4OeXtbhcxJilS6QDk3YJSgnP5CBK6+fsY9n4BwMpXX42l//UtnPjp60Jfs+HAkPh5F4toe+Qftlvd6ImnMKf93O3CWJLohKrEhYTGkeEso7AA0dYpmbKgSJakH8Sm9/R+9vxAuoDnu0d8FQXekrTv3R/C6ElrXOW0VIrJ4UPQ/tgD5nlK6OFz1YjQvOFJJI6ZwhxvxTDq6mEopjtUue52T+0dxN6+DPYPePeBXr+PDLPPcDyvoXfM/T6EQeLIYTQ/97TrOCFuMOLhLEkEs/72p/CNKwoGz70IAJCd6+9qBzhKksiSJGQnLONjq8jV/wAeeeXr3QclCaX6cLKkTQiiaWh77EGh9cRrpLwlSeMF/nwOMAyHqMNCsZ1TkviYpNmzhe0QDOad+yhSNnKz5gJwr9lbu0dhWDmvCpyiRkNtN2O4orpYA6aMo3zvu1j6w2/h7FdfKiyTOrgfDXt2AjDHPr5gkdN2Jo2GXdug5LIoNjbZrIHHCyI5dxqGgbe97W1IWAwuuVwO733ve1HPUR3+4Q9/qF4P/8lQ1HQkY5W5LRY1LrkbpRjphgElonmcr69S1GIfvlDy7+NE7P1Xo41qkj+EbrOCa4cy7McgSs+L1jMbzRYr+hizhCIC38UJwlSgAB864xwkuw8hdeQwGnZtn7DmY33mh7z1iYcrrqvrtu9j/ldusP8eOe1MbLrlJ1j1xU8heazbpXAYdOJHLiZJ9ExoS5IiUJKibiTxpen6iZIkebBlmX0sb+Lw92F80VK0bHjSVU5PJH3jBBhLkqUkecUkNW7dhDPe+goAwL1bj7nHZej2Tr+Xu52hG1DSY9AaGoXnCdjNPv97xN/D8YKG+njwd9TgiDsuuHw9AODJO+/B+ILFdh9t4gYfVy/DgMuSJFFa7rZPfxknfP4Tvv05eO17kJ81BwPnXhzYd83H3Y4QbwyecS7aCPNgBEtSV1MCXY1JtNTFMJgRW3T9ridQFQkljW13x/U3YXj9OZh75y/R+qwzX8NakuSCqWQs+PVPsOpLn0J6+So88b/hXIt5JUlPsRYhOZsVvqtFzorDK0lSjBWlXQx0TBvms6Hd1ogliXa3sxFCSVqwzFTOy7UkSXv3On9oGsCFzpx39dn270JbO575+Z9w1qsvQ2KgD0p6FI1bNwMARk86FRBYCmlMwfBOX0SyJF177bXo6upCc3Mzmpub8eY3vxlz5861/yb/zeD4QhnGpymP6fai1hJMPEnE+3I8WtqqQQE+4SB02XUN2P+uDwIAZv/lj5ECxwNp58Pk0ijTxYpGx+/YZIyGoqDv0qsxdIaZPDPG7ZbKlEuTFGJDh3bjIwxv1QSdSJS0VY37wiPOWZK0ZJJhqsssWoqdH/0cSk3NvrS8tLBWsmiYFY88W7x7nexyiZSgE0uSx5iXfukzuOSsFWgSJEENi8B31AjnK+BV5qzXXI5LzlqBhm3PA6DGGeRut8ZtyQOAzJLlTtJPAXb9x6cBmArt0Ve8DoXOLv92QMUkFQvgTY7EEnjkmn+hjoZfuWRJwuzmZMUbtrOb3fTyel09jr7idShxblmEAjywb9ZaN/v/fg8AaNi9I3R/pCIbN+OyJOWyQvrvYhvLKBek0BFFTtgHgSWpaKU54GOZAEDqs9zY2r2VpFiH2b+yY5LmzrV/1+/dybbPvceFtg4UOmfh8BvfYbY9OoqklZeLtiI1JKuT9HeyEWkUP/mJO+h0BpWDFj5E8V3lUAtXFVNSKqwM031I3ixuEz8ydv5OePOeCCUklXG7qsaMWE2roSU4GLE4Bs6/xD7ctOU55OYtZNr0jiGVUL9zG078zHXY+76PYuCCF0XuhlTytpiERWH2HCT3OkTexFWsYAkJ8f5eprw85ihJQfl9DAOQC04feXc7A9HXBl55pHf2icDlFV9VNgzDTdwgK4ygue/frsOxl70GgD8tL001rVk0zF6WJCZo2zCYXffhteuhXXU1jN23AXC728UG+3Hq+69FyyYzDmz5zV/Esz++07NfNKK+c1GK+5Vd/N/fxfNf/6FjSQpSkk4/HbqqupRiLVWHEpUUmcfBt74nbHdt0M9ULhYYoZu8BxrlwuYVk1Qpyl7zuf6EdbcTWc7CglxLLKt8jjAlOy58V4Pc7SRIjKXQr482cUOKjgU0x64IYtgky0qf94lJQqupZJHUD+0P34dl3/4yXrjpZqRXn+R9HQG1KZLoOYbMCofohd+UIsQRxUYntxOxGhMCCmCi/WFqh7KSyc6gdiAf3KlEOatPob5UC1Pp/tKopFfljqnSO1GrWzlZT6hcRXMquNvpsRhycxfg2NWvBAAkj3lT0fKQJOCcV12C5i3PYfXn3akcQlElV+EmFGfPYf42LNcP22+/l3VJqbvvHvu3Ojbi2lXnIQe421U6hMW3ftv+TZSIckkMvCBnx11xE5JWYlzY6N1uPtiaBu3GQwQfrxgq2jVPzudsC8uu//g0nvnl/8FIJABFtvtDY+4f77AVJEAcD0bD7zm48t4JylaFkj9GrGKEuCGA3jiVQkEUT2QYvtaHcmit9YTDIsYTBagWBTjTpk8y2UkB1x9XnI8HbEutn3bm8exlap0E3JYkc067N3p4VzdRX7vf8Dbssdgh/ZUkLpksHAVR5ajbpVIJ8hEz/s/XumgpSeroCBq3bsJp730TmrZtwSkfCal8jzoWrNgYa43ySpNAlH51bNRekxklaSrtmFaAGSVpCmCKyus2REpSJX2eqgrK8YZq5gnxwkStgxM5Z8QClyH8PWXAffxzlqLhyvzu13Vq579U7x8v4ofmZ58q+1oA0FVWECVxILbfPqf4Nd7huOdJhsEwioneAYlyh6u2u13q4H7M/dPv7L9l293OJyapjHYUAfucpGnMc6N35ouN3laMArVLTuZNfGRYqMTQ9L7q2KgtUNLufDZxA8d8yVu+CAV5NcDfQ+E81zTM+ssfEbdYuFzlBBeRxKUOBXiwMkMrLwSSrgOyjNxsM3YkvXyVq0xU0PFRvFBOLEmlunqkV6wGABx78asqbtNsmP2zfCWLqyhkChny/hoRPz7x/j6TmAHOPOZz/siFgtiS1MZacXirF+mKTaaR957bIgrwkrW5oabHmHmYONYNqViEFk/Yc0cIS0mSi0Wc9bor7cOh8yaNOcpZ/d5d6Prbn+yNnbiXkmRbkkZtIpfcbMdtz+vxTLfckjNK0gwCMb2mtBi8YFuLMZUrO0/2/a1WXhsg+INZC/2CrtPrd1Xb8CozaUl5DZvdjnz8812WkuST1JAH7VaRnb/Qp6Q/znjLy8tiWSJwucDZShJhgDrCXsBZaYIEA3qnWKQIiJ4jL0zT95U+xdOTywJLEmlTHs+UHUOg2MHfFI1wRxcjvNFWhFKT41LHg6Y3LjU2o2gJejFBEDntTqmOjtgCJc2eR2KSkse6mWvrDu5n/g6yJHlBtEkRZuNi6Q+/iVM+8l6cct27nOuopycK2LcVvhB5kkhNhsjaZJjWzQ0//h2e+vXdOPyGt9mnHv2rm2wjFCQJRastiaMBt93t6urwzE//Bxu/8zMceMf7ym2mbPh9D9KUSxfgWDGDoAiYPMPg9He82v5NlHrewioXC+KYJEsJIaDfLfr+MHFiHnAowJ22NWtzQ9J15r2oO7APgLUe+xEiNDQIlcwwOaUkSJDGHEvS0u9/A2uuezfm3/FTAEB8QKwkkY2Xhp3b7OS5+S6H5e/4sCPNKElTDsKYpEmWoie7/Vog/Jimz6s+Wc+pVpaViRiPqIlym61l3ERgu3ZMElEo3MkJgxDz+BiWg9ThA2VfK3NWEsKWlrM+wIneHuZmS5ywHcTwxBA38IK6EfwcF//oO7jgRadh4U9/6D7JufoR1yBauTj3xecCAC668GRcfM4qyBkBXXMAbCUplcLG796O3R/8BIbOOh9aA60kOS5BpQZvAZRxJZIkjLaafycErppS0VH21PSYE+NhCZ2G4Tyvhj07Mesvf7TLpw7uY8cQQUkKelcEapNL2V3yw28BAFo3PCGsQyTYEjc42SMmSaRAiOKWiBtqdtFSjK45Hd2vfQv2vftD2PDjO5Gl6JSjQrOEYD5XEmG30+obUGppRf+LrvSMpxKNIYpiFLasKw/bez6M/e98P5769d0AgNz8RdjxyZuQWbLcv54QMUmijQ5CYQ04Fh/ezVEuFITzgI/p83KdJFbEcO52NKtknW0ZU9POelBnvTPZIFptSbKtSTSMkNY52t2OoOtv/wcAiA84ltcn73Rcm4klSSnkbTdB1t0uXNNTHTNK0hSAUFCrxJ3N71w5geo13CE3UJ2XibUg1Epor73UPimKToVtHoc6tAsBXjmuMmW3U9b7CcrdzvyYE39xJTPmLusBlVKSRPTNUfrGM6/x0H0oM2XOBY64PJF4G7lUZBQdeZwtT1tnXLErMNwU4GGzllpYfvMXAQArv/Y51zmFc7MhbdG708meo4Cu265+qT27IrXf9bc/4ZxXmuQcWqoO/Zdcgf3v+bCZa8YjJsmPNKDAMXeNtZp/ExcaGrQAGRsdodztHAGcWF8AYNm3v2z/5pm7RK6OYb41YeKPhNTvoudMKcV+LlK2khtiZ552SXQOsm0bqoo9H7oeQ2edH1ifH0okZooSyqVSyZ6HYWm1JwL8d16vq8fu6z6F0TWn28cOvelfGSubCAphjqtAcDBEzwjmfRTS9UsS41JKW2wZS1IshLudNe8ZEhTq3VWpNZvkhPMlbSAQKknhYt1oS5LdT+tdJ/FGB9/yboyd4OSsK3GWv1KqjiEK8dpgnm6b7jNK0nGCWgrw1a56UvQAgbA0nTFVes+7U5T/3fIf0UQq99V4lyY2hsoA9pk7joSqlvi78wHdfohRO4Z8PElUJPr8LVh+d8flbmfthurUrq9MWTSIJYkIGX7JZs1r2V1eXqCJbBGkyvPseqQtnvXv1Pe/tewG11z3bvs3H0DOBIPXiV3vaKRXrEaxpY05liXCmsAiR7sNqmOjtrJKrBQGDEYwo60X/O56NRn/glwkadawzOJlwjqE+YaIayQRnH1YAu12BWWECloVoFlCOa2c03OwVKaSVC0yB/p7EDaQn1ZASDwVDSWbtSjqK1CSPIgylEJebFE0WGuSF105ef+8LElSqYTGB+8HAGQXLGbOiRjuFELAUR/iOS5Y4O53SEIQaVTAqmfNeaIk5WaxCXMLnbMwTo1B5TwAZixJM/inQa3lvenyMgXnz5kCqku5lgjyu5zrp8Cwaw2GuMHjJk8WoYMBAE+acQ0jp5i7ssTtg7ds+PWRtiT5EQ2EgchVi4YfYyZvSSJ+9bR/Pa10kPLEHc83zqe/Hyq3a8q7fQkFbhhIHO3GvN/+3LtuOG5OBAt++WPEe4+5lNXOB+916ta8FVKpkMe8394utOoAbuXHoOIWmHPcInv/hn2477mDePLOe12xDprCMbpRoAXIZbd8yXZtZIgbVMfFR6efGbdDz1OE+yEoJtC9Ccai6flN9u/6/XuQsmI96HIiwZa4fpJ7YYQgbqBjkgbOvgAAcPh1b/UqXhFK1v2lLUlESdJVVRwfxaHSz2/Y68OWoy0Uoyecgk23/MRVJnVov6/goGTSmPfb2x2SjghrM/8OE7BKkoe7HSFu8FCSUgf2In7sCEqpOvRedjVzzma4o9ztnNiyEErSmWe6DoVRktr/+ifIB/a7jpN3PWnFgJKYULrux/7yeHC/pjlmlKRJwnihhLSVUbzawpVffbwAYBgGk9k8ky+5rg9DAW4YBkbGi8hXuANdDYS6nVW45ea9qrweGpUoWvyVpG+lgASblY6BCX6urCq+4sjQDQPjhfB0y+Ig8ICuhHC3MzzqDmqnLAwNAQfMGKDRk08FQO1o+rh98IhRrF9CdzuPgWcL7nc+0dfj25bf2N0xSeaHnrZK0AI8sSTl5pjUy63PPmELR3wz0nveK2gvXGzMurdfgxNu+Kj9N7FskfVTKhbR+MJm5pr2xx7A2ve/VchGR5DPOgJV8sghe/cYAFZ84yaccMPHsOaDbxde66IipgRHkUXD7nsyBSMeFwpRmsqRFdDVU5akukMH0Lhjq1mf9Wx0nXXx0RlLEhc3U8iHii+hMV4oCb9HBW6NGy9ozLNv3L6FOX/ei89x1SFKAEqeGxF6CwoXk0SteOR91+NOmc23/BQbfvJ7HHrTO0XDqRiazb7nVpK0uoaydyAZC1DAqh62CTmsJYmKnyu2taPIJZ0FgLoDe4XXJo52IzY8iKXf/gpOuOFjNlmDGmBdpiHKtVYo6cy8ZvJPUffHUZLEFnwyn0rNrS6XP6IcxijimUhK0vr1rkNh3O2Wf/o/hMdtS5JFypCbNUdQSELfJSab3sgpp7GnAlueHphRkiYB2YKGx3YP4Ik9Axger47LQbkC1+bDI3h8zwC6h7M4ODCOx/cM4IWj7E6rOLidPXpwcBxP7x/E43sGIit91TDtRx1+pfLp4SHzXvWNlce0w/SlxgaIR3ZXLyBfhDDMb8756g+WrvPJvYN4bPcARsaLE27h4tvbdHhEfKLa7faYyQaLTc123I6tJEWgWVYGnTiisO5244USHt3V5zquBJARRLEk2VKYJEG3XO9IIL1ULNqCe8+LXwkAmPOnO3HhRafYCiI9P+J/+qO7r5QCY8DwfFx1h1gyCqK07e41x3rKR96DxT/5vuu6pq2bXdYrpn1LoEodOoDzLz8D511+hn1u4S/MxKzNW01LCJ9viVeS/BjCiOuV4ceSBdj3WC/4W5JoEIFvd2+ac7ejE56661PHuXnitQFhGOgdy+Gx3QN49sCQ6/xTe9kYuP6xPIYyTl9FSrtUNNcIw/w/ZvefKMDEqkDODRSDv1WFeY7bk1Zfj6EzzwtNbx0VJWsOyvmcvc5EEqwBqMrEiIFhlalSoxNXV2jrQLHFHWtTd3CfiwJcGRvFBZetwwUXrUH7Q/cBcMgaTv6Ew+z33A9/xVz39C/uwtgNN9l/u+Yk6T+1ceTlxqjHibudh5JEYsW4JLYAkJtrzhua9Ea15p+f26T9OgtikvSgeWcYtnvyMz/9A1tvIQ+TyZPkQJrNXw0A2HrTzdjzvo9gyzf+iznu5V453TxPZpSkSUC26Agg/I5XrcFPUCLkHxjIYE+/uTgcHWYFK78ga4JM3hxTSTOghSg/2aj0Rd3f770zPNVQ0gIsGpXMwCm2XUTmXs9Y9XKwANEUQYL+sTxm/+l3uPC8E9HiwahVFVhWk2KrE1tCPsL8x9qXuGFowP4dlrihbywvTJSqCnZjg+oCgNYnHkbiaLf4JByXO2JJoi1lg+dcyJSNDQ7ADyVLwfBjovLrL+1iFu89hq577/a8PuajJBFFtu3xB826LBpx0ZxZ+r2vMX/zsRED578Ix178Kuz6j0+7rt3+2a9i9IRTsO1zX/fsC+BQeItcLr2S4hKLkSxx7nbEkqTrwvro+IsgdA+ZyvNYLpyluGfUmRuiXC8NO1+AAQMt//g7LjzvRHTd82cAwPiCRdh884/N/hF3uwKh2A92XzvyoY+h/8JLseXrAvbDKoNYkubc9XtceP5JaH3iYZtprCSIm2lIui0LC9vqsG4RK2CHtfoEQWJ+h7UksUoSn8gVMMlTWp9lqdPrLOVCLpUA3ZGx5v325+h4+H7774ELXsRcl7zoAjR8+pN27CPZ4Cm0taP/vEuw4cd3mvVSSj7jxigJ8iR5rClkA4iOHUzETDF8fOFiALBdQQFAGScxSWxeJgDoakqgrSGO9YutdV/AXujFaGh3nXqf0ytPRPer3+T0tVCAnMvamzjF1nbX9QBQamnFvn//CHLz2LQRU0w0KBvR0zzPoGLwbjnHGyZ7TGF81qtVb9XbqKCOKZnktAJUM39TpOvKbpaKW7J+nnz9B8x/P/pveOT+57jSVXpe/aYyQAfg2/k6NM3cMQ/4WAKAQikVXsIwD003hLumQZYkr7Ev/eE3/a9TVSDv9I8kJDUkSUhzzb8ThbZ2xAcHoCsKii2tULPjjHXE89kL7gftqtawa7tnn7VE0teSJOctyxkX3N/65CP277GVZk6ZjgfuYcq43O0UBc9/7Qf2n3VxBeOWO+Sxl74ax176agRBs4RFkbsduVfFpmaGap0ojAbAuvyRPD6UgqSrMVthUjOsMu2vxA/i1A+9F0Ysjq1fvEUoONKQJOd5xgbcCnPq8EHkTj0Nq/71jQCAJbd+2+4zua/Nz29EvK/HHreQuY6D1tyCjT/4ZWC5aoBYkmZbVOvr3vlajFs5zkSWpOVdDRhIF3Bo0FT+TprXBEWW0Fofx8nzmvF8t/lMo+lIbOET5jZh2xH3fKfrVBQJC9vqsK/PvZlCK0nFljYUmx0FrtDcam8iuEAnYe3rdfpzw0eRb+9EYqBPmJD1lPnNAMw4Tml83FYyM0tWYOOtv3b6T68BHjco0N2OWJJSDv33orZ6LGyvA849Dfgh60roZRVsb4hjzfwWtnIR9XxA3B/9XhpqjHGPlXTNXrcMWY7MlDhdYs2DMGNJmgTUQpittEa/XR5hd30aDCQ4cAUK+JevBaYEyYKFcvpSzTlUSVUSd32t9LTJflqGQAFylfGLsykzAWIYSBbhAm1JohMV0h9svz4GUoALrtENsUAg8uvnrxMh3yl26bCvs2MwLEtSzhT29ETStcvPj0EqFhGzqMkfue85xyWRcyET3SOl1+2uxViSPLLSA6Zg5JcTiFBh8wKNQrlKNu7chsW33YKGXduYMi4lqQqwY5J8LEm8sMmw2FH9ti1M1M76A49vR8bK+xLWkmQAaPnbn9H54L3ouvdunP72V4dW5AHx84kP9gvdPuv37kJ24SL7744H77X7H8aSNJGfs5KAmKHu8EEAYuuDBG/hlT4u12AQTLuG932iiRu0VIpxVSx0eFBhaxqzxtLvW6G1zXbZ2/qlWzz7R1xGbeILTunweofpcTh5ksTrPXk3+CS2AIBF5pwjbHJ0X0IpKAIlKei7Q1vH9FjM5R5LNkKKjc2RtZ5qWSMnGzNK0iSAz+lTawNApfWHIW5g2pt0kbY2mA6Wmkp7WOtnN1G3MOzyHCbeDuDd7aIPIj48GEqoK+v+9xMlyXGHoHe8eUptLyhDdExSOAFUNwzhhzhYSfIYp+6/82nYAjxrSdKSKWFiSBrxgT5IhgFdVVFo77AFe9piYhjiZ6Du3+c6RgvMXlnpw4C4DPI00TzpxvKbv2gnJSUIsqaUI7Hb7nZF9xwgCmVuDqskEYHSMHhGRYO5DjAFRJL0Vs2Ed7eLUwx/zVs3oe2xB3zL0xt/XkqS1+uWm7sA6eWrAJh9J0KvHoItbiJR9LFsRVWgGde4CAJu6GSyIScjTWhA4nQICh1dwmvkUtGTpKbQ1uE8P5/7RYhOFMu66WV91wVkJ2RsdkySh3Ki5AU5kggs90gRnXsoKneBAu+lrBEwlqRYjFnTpGLRtiSVmrxjHY93zChJkwDG3S7ErnTkvB2Re1R5fWF22icKQsYyF6vfRPVm4sAPKewQp4JiVdHz8An2nkgYPn8BwNLvfIUtUa3u9bstSZCkaLmSDAMq7W4Xkp5Z0w2hcKJ60OhSzQmhBrnpxbiYJJK9Ppl0SWtyoWAF5lt1j5m7oqWmZkCWA11jaMSf2yDoSzhLUhCIokcrSVKpFIp0IzvXnRuFRjmkOCTY29eSNIe3JFH0yNQuOZl7RBHVFQVQFJTqrVxMafZ5+70TsaMsDXrSgxbd6azTZ5ESG+/v890ATK84wb7esSSxQvZkb5YXE35KUsrznBCS8GfkMXpdG6WeDT++E5u/eRuyVpwOQWbxMjz7o9+62yx6K0lqesyeh7rP/TKsc2QN8lKI+y++0rMOcs+V7LhwMossSfZ9sa6lx0FiO0PlSRJaknJQMmlxglw4liRDVQFJYt5ruZB31szG5uD2OXg97+m2iT6jJE0CauJuF4H2OypEHxKXQF5mE9W6FVHv6VR6Tae7wjbd+88jsrtoSCz50XfKuzAAxN2uwLFAiXIlea4FIyOMYiQKshe9Y7phMLEpBIoHQ5RfXYBbaHa1pxJSAcuSlHcsSTx4Nzp11NwVLVoffCIE8axroq4lnn0GAOtmRucAqkRJsoUig1KSCnlXjisCEnMCANlFS8pu1wuabUnyiUlqa4dGKQw6lUx28JwLkW83g+0VSzgliijZrdfsnDDesVo8YlzurRNu+JiLcp0GkdHqd+8Qzuf5v70dyf1iKmkAdk4kSSvZQqYfrfpkLIMlH8uI0KWLA61E07/9XKX4NYQv6enO51MHj6GzzkfvlS+z/372tjtw7OpXYu8HPobBcy5Egd4QgrleKR6bCuroiK0kab6WJOJuZ65BvCXp2f/6NXqufBm23cCSp9BWN2K9k3Rd7IZMb+rwIGQ71DiIVatcd7vU0W5cdO5qnHv12XZdTN/Je2Fd2/3qN6Hv4ivMc4aBuOVdQMeJhUW1EhJPNmaUpEkAb0maSM3aS8CTJPjsyNesO2bbta0eQPljoBf840wXqAokSeKISGoTKxWZVr6Gk8qrJ7z1l9+9C6JeLhuEuIFjH7LJG8JYkvpZIT+sJUnXxTlIlPGM70vnFZOkBLhfudjtfHz8+Rw8RCAnH3xbSQrBAKhaNLi7/98nhf2KVdmSJBcKdqwSjzy12zu+0F9JKuc9CBOTpMfiTHwIs+suy3jhCyYJAsk9RBQuUi5vuU2RHCxBMAwgZlmOSDwTACz/xuc9r5EAnPSxf8fp73odAGD0xDWuMp33/9W7TcVx7ZQjsNtNpHXJ191O9E74dI6NSar+IOQKAp0Gz70Iz3/9h/Yax2+KSMWip0VYzTpkDH6WJCTMZ+tlSRo8/xJs+eZtDEGO3T5ht6NcHEW50WTbPVjgCkksSdY4pELB3igp1QW41QJCJQkwN5RSR7vRvOkZ9zlO+TficWyhiF/iAyZzaqmpepak6YYZJWkS4CfvTcW4l7AJN8OcAyYg7iVMmSl0n6dOT2qvEE/kWMOMJTBxLF+uVMLCH3wLjdu2uMtwV6pUUkAgfN6SqBARNwAUDThtSfK6J7ySJGJzE1ymGwZiw0Ou43KpBMkjp47ZDy9LUpCSxMckWT7+Atci3pIUs/3rzQ++zbzm4YrCwFI0i41Ndj4RokS0PPM4Oh+81y6amzUnXAwB6acVp0Dfc7lYdFjvOIytPsXsvywj3+VPdFEOHHc775gkPRZjqJl5C4seYxV0213NuufjlgWsjqI7Bvy/DapFnjG+dIVnuzQan9+EOX/+A+KWG+nIqetcZUQxXYdf82azr5aSNPcPv0bb048x/Z8qKPolDI7obleuix2veLEWBEnwS3xdFOickiQXC76bQcSS6GddI+tBUEwSD8ZCpqrO5ovA5ZisxcJ+kPVa0yCVSljwyx/Zp0o++c9sBCjwzZufdR2zN0IoqzgdE0Y2f0K1z9c9oyRVjoceeggve9nLMHfuXEiShD/+8Y/M+be97W2QJIn576qrrpqcztYIfskLo9VD/ebqqzToPJzSUV4bk+WfWuk9r9UCUBkFeHnXV6ow0tdPId2zqrDn6R/+gCU3fwlnveZygLO28GPn3dCiCM5h0bT5WcjPPQfArSQRS5KX2xYDS0kiyoaI3U4EzTAQ86Dk9cuVRFuS1OEhtD36AKDrtoAiCo4GHEuSw27nLXS43e2If735wffKaSJ6H+zYp0TKFqZI/euvfZVd7pmf/gGP3/Uweq5+hbD/ItTv3YXZd92JJJUfSi7mPWOSsnPn48GHtuDBR7dRmSTFKGeZ8s2TZJE5GGqMiR8jO/vk1tksX3ZMknmvyL3LWhawuoPe7m40DF2DYinj4wsWu9oVQSmyQnPaolFnynDWusOvfyu2f8aMHSQKeT1FyexiUJzsmCRfS5L43nh1mVZaajGuatbJv+9SsWiTIvheF8LdLigmKQjE5U5kSXKIZrxjkgBTOVn59RupC0MkI6aUOtF7Uc8xYwK0JYlSklTV9npIWi6uxXIsSR4zbbrJCJOqJGUyGZx66qn43ve+51nmqquuwtGjR+3/fv3rX3uWnS4II1QyRAiTbGsItSM/hYgbRKhGl6biuPwwUdayyb4t4vbL/yL73re+Pvtn6zOPc9exfeKtIvzuZ6Vo2rQBZ7zxJbZbmUtJSpJA4PDudsQNSmhJEtwWXTeQ6O9zn4A/vTN9j9e9/Rqc/u43YN6dv7DZzkQ5jwBHeXJZkkQxSYS4wfrbZmqyY5KIwsUpSYJ2pZwT+O1c51YiRk5dD62+ATs//nnsed9H7eO0pYuOKQKAjofvx8mfeD/m//Z2pu9eym2howvF9s6yXGDCwD9PEnGbi2HccnsrNja55jZPhRy3EhUTJYNYklKHDjDXeb16SnrMdkfMz57r9NWHwc3gpPIMZYGyx8Pd4/Ty1bZAyrMlmv0PzpM0kfBTkkRxL36rIn2OdreLupJ6U4xT+bMq/Gjw7HBBliQCf+IGYkkiSlJISxI3XpLgOdHfy54wDNt9TWhJovoWp5hGQ4NWkgRWRHXMvR7b77jKjpXM8/o9OwEA2fmLnGvCshnOWJIqx9VXX42bbroJr3rVqzzLJBIJzJ492/6vtbXVs+x0geHxe6oiKgX4ZGOadXfSXf8qzZNUK0zWe+LrbkcJjikrH4kX+ISqXuxLgY17YOHPb2MooQstYktSqHYtJanQ7q0kiSANDGDJrTcDAHoufwmTsV3khmf3jRpn405zh3P+r39iEzKUGsQ++O6YJO9AaD5GwWFqMmOSbIuQy5Lkblei2tFtN72Cq7BDTFCP7te+xT5eqqvH0z//Ew6/7q146ndsQlgRpEJBaEnqfvUb0X/R5YHXVwLNz5JUImxYMez82A04/Nq34Mk/3GefJ3eDjodrf/h+nPZec14QwbPYbM5VdWw01AKkWnNJS6VgULvqfrv9Knf/xqlYJgL+HtPCpVBJ8rMu2MOYOOmw5CP0hyFuoFEuE13YotW8K25LUjg2yDCWJC/ihrAgivu6d7wGc3//K/v4iV/4TzvpL2tJsu6MLNvEErHhSpUk9+aBiG7fi5CEbGY07DaTZIvenSAcJzoSxD4NUwgPPPAAurq60Nraihe96EW46aab0N7e7lk+n88jT+0ojBJGo2IRxTC+5zUEab9QKKJkubOY/VLYvxWgWCrZx0olBZsPDkLTDZw8T7zDWtR0qnwRxaKj/xaKJbZ+yfkokeOaBpQ0DZolvdD3qkhd79Rp9ltUplAsIi47bfSN5bFvIIOT5jShPqGiWNSo/pSgaxpKmm7dmwIkSUK+qGFz9yjmt6Ywpzl4safvV7FYhGSw+n+pVGTGUODmA31OslimisUiSty4SL2lUgklzt2qUChCAZvrhIZhGNh0eAT1cRUrZjlCoEaPv1iAKqkolTRbORXN22KxKH4mpSJzb4sKXOWODaWxpz+DE2Y3oTGpWmOxrim5691+ZBij2SJOnd/sOidLMoqu+cwuK7t608jkS+b1gvoBoH/Mfcysy1xq6fldLJVwZDCN3T2jyGtAslSCIfHPuwQZkrAtVxvcKlgSzPdisYiibEAeGgKZ9bFj3Uw5+t6ViiVIVkwSyfae7DmKpscexOBZ5wEA9vWOYnkXqwyUNGdeFYtF9I3lPcfQsuEJ5u/xVD1Az3FLGZCHB5nns79vzH6eJJha7umBAiBnBeNLmia+B/S6oOnQLFc/AMi1d2DbJ7+Ahhc2o3nbFij9Pc76UtKYfwuC+UuUpUJzC8OmRJfTVWuXv2DeF4nkEYknXPUZ+RxeOOIoaorlbpdvaDTvM2FkK+TY51h0zxvJEsAKqgpYc00uFGFQ7Gw7P/Bx9jrVmZN6PIGBU0/HwKmnIwyM3LgrJmnv296Lndd9yvwjpDtkSXO//37QSpptret46D5cdtJsHL3q5RhfsBitzz3l1KsoGJu/AM9/+ktMf2TIKGk6ChYznJzPYfXnPuLUH4ujpJVgWEKiZBgw0mP27ju9FtGwGRybW2FQeb+k3Ljn+CROKBxvFQTccy5RRWoeaQJXxqKqMO3Ra4VhSCgWi9A8xlBtaCUNRR+lrRiPu9/hUpH9Vpac7zjdb61Ust/1IjceWZdc307mnnD1ODKGc+8kSfL8FoQBrxwa+SwgyAdXqm9w3OfUGEqGDmjsN5qMRU+adSasuVZS1FD9UyQFJWo9K1FW1RM/cx32vfTVAICFlKWYnmcl+puZSEAp5CFzRDB8P0ol2S0XSBKImqTFEzAkidlEU8bG3GukRayShcyus2QjyLLejs1fyDy7MBu7Xu9yiZpbk4mwfZjSStJVV12Fa665BkuWLMGePXvwyU9+EldffTUef/xxKB4+ml/60pdwww03uI7//e9/R11d9bOTl4OHH3kEx8ZN4eRgykBrHNg5Yv49vNNASgX6c7DLNMYMjFnC4u5mA3HB0Es6sH3YLNO33UATtXbmNGC3Vf/oLgMJ6vrnB83jSdVAXpPsTb38XuclOJwBhvPsvkBPvYEWap06MAa7jyM7DSSpmUXaeFI1sKwJKOrADquvexMGRouSvW7l9hiQJOBQGhgpmGVObgt+IceKwIExs3xmt0HLJwCA3izQm3XG0F1noIPSvUgfAUCRgBNagXvuuQc9WaAv6653x4iEIkcANrZL/GwIMkVg35h7TNuGJGjWn+T5bB0SPwvReO36dxtIF4HDGfY50GMDgA0Wyc2jMrCqxcBADjhqzbVDKYO5TwBAMsRsbzBwKM2eU2Wgp8HA3lHz+NF6A23cZh1pf2ejgfESXPV7YWCHgQZr1dd0YJs1Z7rrDPvdSKrA3mefs+8fwcGUAUVy3iEvDO00UMetgvQzJxjZZSCpACdt2oTl1rH081uw4Rknf05LwrDfk31JA/Oefx6nAxhoasFcy81i6aevwz1f/D4A877yc3vniISCNa/yew3XsyNoHBrAVVZm9nwiid4Fi7HhuY1MmTk60AWgb/MmbFhguhqN7TLstWZ7g4Fma504/amnsADAQSiYDdNiQI8NAA4kDeykltB0EZC2bcOZ1t8PLDkBh5/ZgOVqHM0Ajm7YgM2pFqaOjRvNPh6rN9BtzVM+yvTgomVoGB4C2Q6i+7FyPIs2AAd27cLzHRtQt28fVgHoSaex4ZkNTF2Hdu3CRurahQdM1659QyPY8MwGdA2PYD6AVTd/CU/F63HQIkRIqQayJfa+X5odhwJg085dgAFcAFMJw81m/IqmqPjd2nMAqj01n8dl1u+spjHjCIqsPeW9b0Y9F+t1eHDY9UyCkFQN5Erh3jeCE7hv65y//slVZs/BQ3hB0BdFAjQDaBgexEUwLTWZZglEbEwXCuYYdB2XWULc1scfR6a5BYC5fhzJuPu78oVncTqA0VgCf5+3BKut42NHjnjek9KWLTiJ+nvDhmft+15IJBHP5zB46CBofsCdh7uxy6qvobcP/P751l170JtzFv59CQOD1jsvScD4bgP7xoBMsfb76CnVwEIfy8ieo8ewhbs3gzsMjBWB/pzZP/o7ni0Be6x1vK/BkSFGCmDWfUkCsnucdYuWVQBT/jiYduSbgmZ+y5c0Gvb3j5wL+y3gsWg8Czqt7K7NWyAfPIBlXLmBtk7MspSkoqoK5wr5vp40Omav7QCwWUkI5ziPmAwM7TCwbcgcy4maBtoRlqx5NHb39eN5q276m3mZoiAG4Ngm9hq+3w0xA0cErNwkEnK8WEQiFkOMspLrw4Ouepa+8ALOBJApsuv9OQDIzDIkCY92H4NxzHKr9mFCpnEwZbi+owDQHDdwIARZX60xHpDLj2BKK0lveMMb7N+nnHIK1qxZg2XLluGBBx7ApZdeKrzm+uuvx3XXXWf/PTo6igULFuCKK65A0yRnDS4Wi7jnnntw3nnnY/+QqcEvbq/HvJYkGveYPttnLGpFUyqGAwPj2N1nvtzt9XEMZMzJfs7SNtTF3Y+tUNJRv9vcfVgzrxmdjc7iOZYroXm/ab49e0kb6hPO9Yntpt9sY1LFeMGxJF262lmCth4ZxbFR1pR94pwmxsKz6fAI+tOmBe/Mxa1oTDqmX9JGfVzF2UvbkC9qaLDGO68lhb6xPAqWlnTJyk7IssTUR/fFCwPpPDYeNneKz1/egQSnJe3rz2BvvxNIvryrAYvaHImP9BEwLUm5fc/i8ssvx6HhAvYNZFz1tuwZQJbTks5d2o6Uj5Y0kClg46Fh15jqd/ahZN138nxTO5xEh6Lx0+MlOH95B4bGC9h6xNzdPnNxGxqTKjM2Gqos4aKVnTg0NI6dPeZcW9ZZjz194oD7E+c04YWjbF6ThKrg5LlN2HDQFOhOmN2IuS2sPzRp/9T5zRjLlZjn4Ie1C1rQXm9+qYuajrpd5vxe3tWA3b1paCUNW7dsxGmnn+ayJC1ur0dMkbCr1z/vzvpFrWhOsW4Ve/oy2D/A9pHcS+Wuu+xj8/Ui1q13GLNmNyXt92RBawrSZjOHi7x0ObBvFwAg3tzMXMM/29a9Axi3tKRLV3d5Pru2Jx4BAKSXLMfjv/o/6Ikk1nHuQY0PrwIevR9LUwkUrDbPXdqOxr3mu0e/w8oXvgAAqD/nPODeuyDrOtatO53xu1nYVocVlOWrP53H0W7zmaSXrsCsf3kzZgFILVkKbNmAdbNaELPa1UoaNm7ciLVr10JRFZwwuxHbjnnELJ1zPlIP/8P+k75fjW2mNWDpgvlIrF+H+Q+bFM6dCxcy5QBgydw5UKhjXTHz3Zx90klYt34d2u91Ylve8tVP4a+bD5ttJFWM5agdUMOAagkbJ65fb9Ojq7qGy3/zY/P+aSWsO2M9Ow7K0hyvq3f1zw+NAjKMWUuXRqoDEIwlAFpJQ3bD44HlFq9ehZSgLzFFRlHT7fgv2dCRaGwETH0eqdZWewxGXT2kTBqnrVyGrEXG4DUvFg2apBbq7DlYecVVeOETN+LEL38GHYm45z1ZdngX8zddzqhvAPI5zGpqhCHL9o754pNPQZNVbtbTD7rqXL12LRYscUTxBa0pHBoyLRiKLOHilZ147tAwBjPezI7VwIUrOmBoJTy18znPMgtOOAFx7t6sW9iK/nQeBwZNAfGkuU2Y3WSuAWO5Ep6y5IRT5zejo8GUIXrH8tjS7XxrZEnCJasc+veDg+PMOrtmXjM2W+WXtNdjaWc9CiUdcVXGfdR6tryzwZZxCNYvakVClfHC0TEMjXvfw6Y5c5m/T1w4H117W9wFV64GDlkMiqk64Vwha/D4H/4XeMR85rvf82Gk3vf/EOZtS8YUnLW41f4+pTq7gJ0v2OfXrl3rUpTmnH0OElZf6HVYbWkGhodwxs7nmfJ8v9vr41i7QDBe0qf6ehhjKYBSkuoKBVc9nRlznUk2NTHn1IYGwNrYK7S04fSzzrTPyZJkyyb1cRXJmGzLpzSWdtQLv/Wzm5I4ae7kyuKA42UWhCmtJPFYunQpOjo6sHv3bk8lKZFIICHw043FYoiV6WNabaiqCtXy+1ZVFaoac/62+kmXUVQVqmIu4uY4BL7SkkbVoTJjjWng6neuJ8djagyqJkGyXPHo6+m+0MfoMoqiUP1l77XdhtUvDbJTVlGhqBpUOOOTZclqU3P1xQuKqrPtqKyywo9BVVRhHwFAovqixnTmWcUsQUtVVag6u0tiPhtvJSkeM6g+UvdOVUFMIeT5qqoCkjZFNH66X/QYY6rhut98ObtdRTLbo+ef6l0+FhPNA5k5rgreM6ZuFZ71u9qj55hMPV/+WaoqDC68MhZTEZPlwLZiqqC/quK6jtxLUAn5kn29rn7QYyXMWVpLK/a9+8NYcuvNKDW3MteI7pWqSPY5z2ehm++GXlcHqakFollXIrlohgaZtYGdz1b7u3cDALLLVzltGGxcRox751VVRyxvfhzzs+bY9RbbTQEqOTTk6r9i3VvVZ2zF2fMY5YwpZ7mBqJo5H4jyYqTq3XOzpLH32hLcjSbrGXC78PSaRC8fUqFgu63IqXqb+U/m4rZc46H+NuIJ5vzY6pPRuJ0VhIKQW7oi9LtD90n1XpKE0EK0obe2C/siKxJUyJDqqW1uagNDgmRfZzQ0AJk0EtkcitT6Iao3YeXiKrW2QVVUFOcuMMtnxz3vicq5K9LlxpetQGKwHw0H9zP5qaT6BrucJHBlk1Ip7p2PQVVMtx1Flqhvt7fbdTVQl0yYLvUJb3c7KVXnsY4570WcWq/juiQ8TpcHTEJFRr7gvhn0GkPWTVLca70kSCbiaEioUNWs7z00uJibeD4PVZAnKU/F0hiJhHCukLFIFB38+KoTQ79rqqIgHo/b5XWOxVQRvIDFOfPF67AVE9fx5CN22ezylYHylwuK6mLEUzNjUGWFXVvJRk6MvTcGNfeL7R2u509emXhMRTymCJ+V1/crsO8ThLB9mFZ5kg4fPoyBgQHMmTNnsrtSEYwKQtJrGeNfCYue4fmHg8kM5OO7FHakUe530P0LM/5Kn29ZFO+VtkmzutVogpaTWyzMvQh7v+xS1O4Tn/iUp8En7Hal+kYMn34GAIdhrVJIVmyP4fMhL1jKSjwo0enAADBk7ihmljgOJzwNuPsdMqgM8o71sNDeAQBQeXYn+lqfB1po63Ax9RE47HaWYCqg1LX770omaz2PJkIBLnZV4rtGE19oFHFDFGS5pK8bv3c7+i65MtS1L9z4Tex530fR96KJSX+hh9CqeJIQHkYsBp3QtVP3j05Qa1jkHApFFe81L+LEtbRzFgCKZtnHZUaUp+a5H/4Ke973ERx78TUAgBYqzgpgE7BOB3Y7LelDAR6RTdOL3S4qvKifI9URUAVPRqNkx4XJZPsvucL+nbSSEXvBoJSbKDnt3Ox2wdfS+c2Y6wXr2O4f/yZ0XwgMWXYlBJd0HTIXg2fnj+LmOj3P6XxowrYi9256YVKVpHQ6jY0bN9qmyH379mHjxo04ePAg0uk0PvrRj+KJJ57A/v37cd999+EVr3gFli9fjiuvDPdxmapghUpOUBPMuMiC5wTMWpfAxAmIInglj2OSsZXdn6lNQQ6wi6Fh+D/zaiCw2iq1O0Vvd9nwnT+UkuSXBwhwKLC1hgabdlpNV0lJIsHifkqS9XGLDwQoSbtMt6TC7DnQKMIE/iPrgiGm4CYCrJx1B1KHQaGtA9s/8xUMr12Pzd/6EXPOYbezrDlESRMmkxWz2xU5CnCCOf/7W5x3+Xqktm5mjisWEZAhSTBicSHr1c6PftZ3TGOrT2L+zs+ei22f+7rvNZlFS3Hs6lfiyDX/gn3//h8TxqkbxpJUsmKIXKDeHZsKua/HPnbw2vc4RS0lKeg9AoC4la8lP2uOVbcpiCpZ72t5gRAABi54Efb9+0eEFMkAy2gmerf8FOTJSNVRbBAEplgQsdv5KTBls9tNwu5nwlKaCZTsOKNsE+Rnz0Fu9rxQder1jnWqksTfxeZgBmbdi7qem5fp5auQX7BIXNYHhqoyDKWEDl/NsPfIZrfj5jWdD4xstnm25fHBlI8TertJdbd75plncMkll9h/k1iia6+9Fj/4wQ+wefNm/OxnP8Pw8DDmzp2LK664Ap///OeF7nTTCWHkY8bWFGLt9auTrWvyRFrRYjpRHxZ3gt3Jp92u5ONSq+5HvS8SWKYbX4tPLZ62j9WymvfIrouxJGWw/BufR3beAnS/4W0uRZ2wKpXqG1G0EpiqIf2g6YqW3fxF5GfNgVQqITYyhL0f+LijJPns+pOkqbRiJrwnlqtdfvEyRjAU5clhugYnYSJDnUw+uD7X+z2bQnsHcvMW4plf/p/7OsKaRixJPhnsmTxGhoHYKMmTZN4XXgk86ZMfBACs+uA70X+3E5dDWOb0RBKQJOjxBEoNjUwerO7XvlU4lr6LLkPzxg04/Hr3+VK9vyC25Ru3In3Cyb5lagE9ROLKopeSREFLphAbHbGVoKd/cRdGTjvDPm9Y4xcJtzziPaaSlJtlxqKQxMx+liT63KZv/5g550WPTdOLCy1JnOwhWsMnUjYsNDd7nvNOCO21WUmTM1RgSarCDQiqImHNBwIlOw417Y4/1eNxbPyvX2DdW16JYy+5xrfOsi1JYPsrtLxQC97QurO566mrOUuSkh2348QjQVYYJUmrb4CaHkPnfXej+w1vc4oRSxIXwkFvBhDPAC949e54SSY7qUrSxRdf7CuU/e1vf5vA3kwcIitAHr+ricoXtmBBOZy7mRGy5PQDvWiwz9QQHp8oTHayYi9MVq+E7VoHjXTafopKPofFPzYTYXe/4W2ueU+EP62uzhbMY2MjkTTkxq2bsORH32GO9Vz9SkhF8wOo++z6kw+dKOkpA8uSlFuylBESXe52ro0Gx1pEu9sR4TJIyRJWCn/3Dp2yJDVu24Kue+8GIHa3o91v5HzOThpLngVJcMojdWAflEwamhWjQJJU2gKyJKHY3MIoSaL2AWDTd34GSSvZOViYsVD3TI/FXUltwygitQBtSdKSKdtaSMMrMTK9lvC5Wsh9t8vWE3c7R7j1+nYkLFep/GzTkqTb7nY+liRLSdr7nv+HvstezJzzel7EnQ9wuyAB0XMP1RpaKskQT9DIzlsouMIb9JJULSuAn7Llp2AGKWlHXvNmrPyqY71VxjOu5N2AOedynbPx0INbXLmAeBgU+3Gprnz6taIgRY1CuZlu+u7PvC9eyD4zJTuOcnQkQ5GZPGeGRWc/5647UWpoQmbFaqRXnehjSXLWqyLnWitx9Hae8t5xIsZNq5ik4wV+iqFIYI0a8yESZiqB6Hq+H2GsY57udiILU41dDCdFAPdyt5sm8OryRIzET5EzAKQO7PUUymOD/YhTLj8VwSOrO+8jbxi0cJ10rBe6HmrnnCDJuZUAQPJoN+QQ7nbEZYKOzRHexT17AFhBzpJkWxIC3e0AKDnLkkQL/JxLnB9EcQSajwsRnUz2rNc4SVW1pCngjK12LC90kliSbd6QZXuXODYoVpIAYN7vfmH/JklxaQG57xIuPsjL+qIoQgXJHISzIKRXrHadLoVw26kFaOUgaBfZtx5OkeKVJFh5vMK428X6zPg2osSULIFWzY47UeQcFMuCWmxzC62y4D1+7oe/ZOae8N0S5E6aTEhgXe6e++Ev8ejdj+HJO+9Bfo7AzSyk4FqRJansK8Pj0JveiQ0/vhOHXn8tAMvdjosR7X71G20ShSAFCQBDBlGJu51ok4em4hYlerXx7W8zfyrZ8bJkBUNWGMV5+6fNVAUtG5/BKR//d5x9zYsAeMck0ffL9d66W4vcv+mEqfXG/5OAj98JegcYd6ZK267w+lBteAxIrAxVqc2IJcK3Gz7WKeg8E5MUtvmImGjdS5Im13xuAFj04x/gvBefi0U/+b7rnFQs4qILTsaFF58KJRNOORFuCpAn5qEkqaMjrmdKFAA9HoeeTNnKg2oxdYWBiOghdWh/KHc7w7YkBdARHzoEACjMnWfVKVZyeEWVJm5g3O1sS1IwDbJIWPXbgiR1y0W2b7plGdj4/Z87iRAppTnRZyqbpYYmW9D1U8aSR7vt36d89L1mHZTCuuf9H/W8NgqevfU32PaZr2Bk7XrXOW2S8vpplMIXFI/gWw9vSeIET9vdTuAmxYNsQpA66bplgaULAJKHzLxYWYsJj4Fgjo2tYuPGRO52YVCJghEVsgQ73hEABs67BNlFSzF2wimhrvcia6AtSUFEDLUYblCVhqpi6KzzUbSUeCU7brs3E4ydcEo0hU1xxOFIShLXCG95ga7bzHu6orhiGpn719QEWPncACA3Zz60cpQkbu6OnnKasFyYmKRSvb9VbRru90bCjJI0yYjsbheqPG9KitSlUHBZq0I0R9YC/7iV4xcMQYXh9bv8OxDVgkjmSaUcEr5WnhoQVBjcC7HymzcBAJb81832YUmSUP/73+LStY6AVLePzZviqsvupk9HPZSk2Miw69k5SlICkCQUOkyBM+HH+sb9zQcoA0DdgX2h2O3Ih462qLg2XL79beChhwAABSv3CHG54ymuXX31cLcTKSmiawG3kmQESFw6ZUmiQdyn8rPmYM8HPmbWTVmp5vzv7wAAw6c7+T52f/AT6L/gRcJ2YqND9m8RK5bW2MQwoZWLwfMuRvfrr2We4+HXvgW7/uPTk+avQrtw0kpSZvEy9F10GbZ+8RbPa+lXgCdH4IPVjU6LfdHKx+LdId2ei0TA1JMpJxhdFJdkGEjt3wsAyC5c7Drdf9Hl6Lnipei7yLFG8sJruUrSRINxy6zA0lXudOOVwolUEm2WQ0FMUmQmQsry4kXsEQb8ZsD8//mNbUkK5a65cCGe+tWfMXDuRdj8zVvLc7fj5kG+a5arTOc9f8bKr91glufmeqnBsR5pQUqSx3GvaTBV3fu9MKMkTQJ0WlAxgpUgViisrO1y4oVCUSmH6FctF08vpcPniuhtVPHl1o/37RcLlbh+himbovzQh9azAbH1//sH5u/40GD4xr364mNJ4kGUE/KxJrSvfNCxJ0olLL/5i67D8cF+it3O25JE2NvkUtH7Zn74w/bPohXvYVuCgmKSIGa3I+QKCONux+WyKTa1+JYXKX4AK3zYsVhUmcYdZk6inqtfYR8rdM3Gxh/+Cgfe6jCuEYisfTSdMOB/76OCpt3e/rmv4cA73le1uqNijNoJp91UC+2d2PT9X+DoK14Xqh7a2qPH4i5BTLcsl8keZyNANE1pS6gt+MqyPedE7qvxgX6omTQMSUJWwA5mxGLY8q0fYf+/foDpI1MmYk6qyVrSj1zzehiy7Knw0/D7BEvM7+p8q6PWQvoXVlQgc2zOn+50Wcx5ko1A0A8wgrIpQWL6O750BfQ1a+y/W597GqrFtKl7xMLxGD11HZ677Q5kVpxQlqzAr016IokC53Z66off6Zzn5j6teJd4izv3bLxjko6PoKQZJWkSwOo84hnG7viKf7Plxb9FGBkv4vCQNysQABwcGEc6Hz5TexiGs0pfmXxJw4GBDAql6In6yhXWp6ou0zuWCy4UEmGHKJoPEldB7Vj3xMdbKYWDdhnIFjRks6xC47VjXdR0HBjIIFfUPNsyrBMkvofPExMbHXa917S7HQDkLPriZK/T51zRnNMlzT2nBx98VNhfZTxjxwv57XbTO6ki17cj+1llrWgpccTVxCun02CmgKMjWRiahll/NxnoWHc7y9pT8Ha3OzpiKke8JWnPh6/3vAaA7SvPU6kzAjlRpChLVsyiQacD8wnGFy1xHYsND0HOjmPRf3/XPrbt899g+6JWLyFi75UvN/uy0N2XSlDO61hI1eHIi18JAOh+7VucEyGi+el3RxfQwtPQ55lKUqLHstRpGhpu+wFSB/Yy5eh5RNO2OzTg7m8Zca8stHf67t7rDCtjdEtSud+0asqPR/7l7fjHU7ux8Qe/rFrbfmUC3cpD9SKAjjxsLR7xaIA/XbsIhTPNTbYga3YQDFVF7smnsf0/zQ0uJZO2LUki63Oga2E5H1XZvYHj5zrLW918lSQOnuEVvldNH8woSZMAV56kYL8o4bUhilt/s0ee3j+I7UfH0Dcm3hUHgJ09Y3hiz0BZbXrnSRJfy7C++bS18eAwdvWksaXbvWsfFbWQ5YPq9LIYRl0DS5qOo8NuJanWZuyDA2LFOmyrtehda4/jCkUrAkeGs64PqMh1DQCe7x7Brp40Nh4a9m+MEtaKLWxQvTo64k5CSrvbAchb9MWJY45y8tS+QezqSWP7MTcz0+HNbvdAwFKSSsHEDbTQRxQGpotbX2DKk36Snfe6g/vY+qyLnz0whK3do9Aeetg+V2x1din5hK8ijOXM/ivWPSq0tOHJ3/0d3a95s+c1dB95yx0tCBNFSqLyJMUtkgYREUGGIk3otRK2xkaGsfzmL2GF5coJACXOysXT5laC0VNOw+P/+yCe/N3fq1ZnJdj8hW/jid/fh6OvfL19TI+oFGpMILxbSTLmEiXJfB+67vsL2q7/CM578bnMokhbCOiNEFtJEliSiPId5DaV73SSevLjKzsmKUSZlrrqKdgSLFfGCoV7OiZJiUBvVx+vnkWVIOxQcvME8WYW9EQikjVDm78Aj979GB56ZGvoawAPlj5ZsZULNTsO1ZrDnvmRfOCjB3qC96oAxAoaQamRVYTouKrAmCSP48eJIWlyKcD/WRHE1OV3rGJBk6pgvBDeUlRuGzTIIlyuME8Eq6GMe4c6yNpWDQG9qnl3vCyCIa4t+TgpuxTkiJ0uZ4y1ijELM09aKMWHd8HirRQJQWyJAWAgbV6XtuaXJ5sjVR+vJMVGR5DnSD5sdzvL7SNnubPV79ttlyNW0UHBnPZyy1MyaYq4gV3CFVmy82rQO6lyIe/yLWfuzyOP2D/HFy5F69OPo47b0edhHDps/x44z8l35+RJCuNuZ/ah1NiIsRPXBJR2lKQY5w5Hu7Hw7nZSqYT4sOlqKWKeGj79LGz7zFegjGcwdPYF6Lr/r4gND6HjwXvsMlpjk6l0UgILraCm4gokCRjPBzMCeiGzfFXka9ob4vb8DUJbQxyDIctCUZDmEuD2XvHSSH2jFRSRJcmYZ20a9PcCmsbM9+ZNG2wyC/IcjViMkbw0HxpwQvQQZE0odHRi03d+agqQvItSDWOSZjenMKspiZ7RvPB7FgWSJIVeaP3kVlmWsHZhCwwDiFEkBkHCbktdHLObkzg24t64q7Wg3H/hZZ7nIsckAcguWlpWP0TKGK3Eqz6WpGqaXJ792+NIPfIgjrz6TVj04+8hMdBvezD4WVRp8g+AtSQFxiR5eg4dH3mSZixJk4DI7NaM1cFLuJ7YmefnvhalJ+44h/LGMR1evEqsR+U1GLJYFTvjYkCrwUDpGlOU2xWfD4in5RbRaUcCbUlq5i1Jwz6WJFNQGzznIgBA+0P3It4fEKwOINErVpLU7LjjbsdZkrqaKMFAURw6b2JJovpoxxydeipw3nn28XEr0L1uv7+SpFjU2D1XvJSxWoWxJBHYwmxIgYbcy9joMHO8RBNH2O525vOKWbFohiy7npvZUQndr78WB9/+78h3dNn1qxSlsN7ivo5WUJd1NqApWT3rQFgs6QjPwpWKlbfjv+2zX8X+t/8bBv9FnDDXC1qAu51hEZlIum66q1JKSoqyYtpKEjdH/NztvK4Roe9FV2HwvIvdJ2oo4UsA5rfWoTFZuSJWUTe5azsaEuhsjK5czGl2BPAJtSBwsViZpSvs33YKhEmyaBDlQs2kESPfghrn2couXW7m7IvF8Ox//w49V74Mz952h9m2Dw16sYml+abfV97djiGgwsTLnhONGSVpkhEm9ww9CcMwnfjnMBLHDvlROYd5BbzqpTGV2E5CxyR5HK903SX11jpfUs2VMWlyF8kExWwlWR+iWXf/Eae/4zVIdR9iy4YkTPC0RJK8R6rq+nDERgQU4KR8zBQ60qtPQnbeAsiahtSh/e76OSQttzyNE/QYdzuOAlzmXjKbBlyQj8hWYrhYDJKzp3H781wf2V4qlnWGVzzCxCTZ/Y0oPNjudr6WpIRVt9l+fNCMRyq0tnnnM7JQbGmDIUmQdN120QMArbXNvaFDKaiTJYhFCbAvt4/dr3srdn/ks4H3jgftWiRSkqRYHIbl5hMbGWY2NZLUu0rcaI04O0+J0Lf6xo+56iYKshY1eJ9GiMWTSetQxjJYjWlTrcSvUwFkPkeZq/QGS98lVwqP1xKirkqSw3KnjI/bFOBeSYxrgcyKE7Dlm7dhfNlKAP73g7ck0RtAgXToEeW96YYZJWkS4MqTxJwTCGgeSk6Y+icMXgoW1ZkwH/Ry++4V71NpvV5tCM9HaMTTIlhBPyfLmhbW3c4sxxaODfRhxVc+iwW//FFZbScpVxtiSTrlo+9F25OPIMElkA2tJHnNH1vpibtcEMSWJNbdDnAUCnWMjakh84Gugwj3w+vOYsqaxA3imCQ+lkBEYmD3jySLtT6IpGmSU6N+7y4ha5/d1pBpSeJdD41IliQ2bisI5F7G/GKSCKufdf/JveZjikQwYjFhgLPW5E6ouOf9pnB+5BWvgyS5FdQJwRQWRFhLkjg2yLAYt9SRYSg5R0miXWO9rEJtT5nEJomBfjRtfpY5RxSuMElEPVHmglopMUJURJ13U3jKlAXaQlKkhH09nog01mq/viQOTxnPIEZikoTEDdVr2K8mP7Y/PmEsybNVqqsvm1b+eJlnM0rSJICnAA+C4fnH5ME/rsrbWhWlnlpiUtoVuCROppsgabvSLgQpqH6Y94dfY9Ht/4VVX/wU6vaKiQr8kMjSSpK/5SIx0OeybkSy5FECPR+IHhsdYaladd3JZi7IXq6OipnjaChWckQ+MaQfcQO/q6xzCgP9sOxksVzsRbGtA9k5ZlB9/Z6d9nF6eImj3Wi5729meTpPC6g4kDAxSZZgHHaHldSt8AlEqQ+57WZjzQeiIIZluyI+/DQMgZDf89Jr8Ohfn8QLn/8WJEiVpKiZEFQqjEW9mn5HRJYkSIDRZirYseFBxpJEk6zItiWJfX6HKZKPzn+whBf2BkWsfGuCNAGL80Tr1bWiZfaqt5oKgBfo91qrd6wefu5l1YTX2G2W0KwTkxSWArwW8I1JamItSaXmFuQOdePhf2wMrNfzLTlOtKQpvqwf/zAQLFi6EkAKy/i3ISrHXuI9o8MIkl5t0IJjLXdaa+22Vu02Jko5it5MdTsWNM4Y5dLUvOmZyF1J0JakXNZWLDzL9/f4nveCAcNWkox43OWCwFtcJIoUgbaS2EpS2ltJUtJjgGFAtcY2tooNoJdLJVtJ0APd7cy2RRTgdkySIECduF+I4j0A4ILL1iFx6AAAgSUpFt6SpBSsmKSQblGeFifDXcYmbiBCdkg2urxASdKTSeFczi5YBCgmacNECIQ8oiypEy2QB8UkSZJjSYpxliTiKivnczYxA68k7fnQJ5C2XIniA1aCZl2HksnYmyGRc+XQ4J43He9SKZy5UvlDqbUFs1a1+ychD18PvSbQ63JFz74KIN4GSi6HhhHT6k6/EwQT9V76uts1uC3l0uxZ0ALovwGf8Aov4obAGqcWZpSkSUCY5GBeysxUJSjw7C/1mywGtR6DqHo3oUDIumrUV0+FqxJ3O9ff4SqrZIwSpIqUR1pZaN7yXKhr6PZoJSl1tBuXnLnc91ol7a1EBVoC8g4RA59VPca72wUoSTEuBxG5tHHDk7jkrBVY+ZXP2grf+JJl2PUfn8bOj3yGaQ8QWZI4dzvOkkTPCUL+QGKS2Bw35q6jnHMzVvEocTFJepSYpDLd7XzLkDGXaUkSKUmGQLihIWFyYkOm8matFhSTBMBoM6mGY8NDkCnrYP2eHVBHhnHe5eux7p2vBQCG/hswLZ6H3vwuAGbyWAA45SPvwUXnrkbdgT0AKrMmSIZDZXj4NW/Gxu//Itx1E/xUplpMUiXjL0dhoJVnmq5ajycmRAHxaoP+Rpz35zvNPk2qJcl77RRaej3AW86ipnyZbpihAJ8E+MUgCadbiJgkP0WqUguIUOng22Bc7JzfQQphWcGuIre9Kao80pgIFz83acdEtEn95s9x1Ox8d+iEpUTQiYKkgP7XD6pPebL4C28ZF5PEC2xmniTKakopSTTzG/GZd8X6WJcu/tqNAICFP7/VJofQ6htw4B3vAwAs++7XoOSyUEfM63klSZJMZY/k1uCZ3hj3VxKnJLAkEapal1ubALy7nR2TpGlmg4IXdsn3v47mLc9h5JTTzX6GJm4IFnqJwkUsSI4lKRz7XLG1zXUsSLiRJOm4yTBfLdDJZEvcHCGwlaSRISh5Z67JpRIuPnc1W1agSJO8VyR+b9bf7gIALP7JD8w+VGJNoBLUbL/h6x6FKnRhrMKUMedduHV+Ks1QX++XSJYkZ03gUwFEoRqp5vsrSaZSr6sq5JLjdqwlBJakqrXqDy8Sk97LXiLMHxdW2fW2JB0fmFGSJgO8UBnkbheCOa6MphlU8/selep6Iqix/SjLQ9dRna4AcFgKy6lzKimEQfMm6NmqaYdmWc6yAnmQBbVh9w4kQgjxNPzc8RRJAopFzPrS55A/6yIMrz+H7Qtx4YnHXVnZY6Mcu53lRqbFE8xNIkn76HHToOMgiJsRvTtaamyCkssi3m+6F/HsdpL1P3L3DC5nEGPZ5YgbaNiWpDz3TAzDld2QZ7ejLTZSsSgMnl/2PVPo7HjoPvOaCt3tmDUyzo45qiWpVO92MdFDWJImhbdhIhuN2BQdkyTKTyVJEmC7n6YDrZY8ux0Am2QjNtiPrr/9yXW+kpikIev9H7eSK1cT5LFV4+lFnQITOWf8mvL7jEXZUKTfa4NKCKzHoylJ5cJziJIEra4eMrUhNqmWpLi77UNveBt2fPrLFdU7hcSRmmDG3W4S4G/1EZT32akX1x/Wzar86e2yGHhUFZWkIgyCBfPJeW2jtFqLfFdCZsTIdZTdfHDdgmO0shDGakFj0S+iM+LxiSfpPsm6DrzhDej6/s1Yf+2r3O5ilCWJ981Tclkg75T3iokgsT4udjvSE0oBkazfWp2jJBFSgdRRM5Erb0kC2PfDITEgeZJodzs2Jok+R3zn6TgRwzD/k7nn5KYAd/okYtUTIXyepAjudnYy2SJzPAg8vTsAIXEDjclit5vKu7V0/IVQSQIA6/2Qi3lXXjMeQkuSVW98oB9rrnu363wl7nalllb844mdePyuR4ILl4lqKCyTwqrohyp0p1xLUq5rtlPHBFGA+4GPQap1niQ/iDar/OLswk4rL1nGa25PlnxWLmaUpEkAO0lYEvCCpgvKs9cahoF8ic3snsmXhOXNFrzadpAvutuNAq9pH0hK4frb8K2vWvBTRorUMxCVyxU117FQbVJVabqBoqa7nkeoPFhRdtl8HoBzqkJ3TG5+8nPTD6yS5CYJ8LzXuo6mbWYen2OXXhW+PR93u3m33wr84Q/23+2P/IPth03ckIAhCGDSKZIDLWMRK3AfJiKA8+x2RDeyrTsWDEliduTzs+cCgJ3Dx+By1/DCOtlllYuiPEnmmptTAJEAAJqgSURBVKGpKnRu4hHLiUhw5ZVZt7udo4yEIW8AIrDbRXC3kwt5wDBsRY3ulx9KDe4M86JdWBoSpCkXG8Kj0u5FjTWh4xxEtOoAHCWpULAV8oIo4S88LEmEQtyDYKTS4H2tsSm0mybBhDPWRSnLFZ4MshECP2E50hdJdtbAQnsnnvrNX/DE7++DoaqTNj7SLm+BFq1zVbXs+XKAu2W8nqtfUXETnt5JkWuemphRkiYBfpakbUdG8Xz3CLymnmEAT+8fwsM7+5G2FKNDg+PYctg7n0kYZPIl72SyoVzmxBYjxpJUJQVItPAFMwRGa6NPYNQwDGBPXxqP7OrHeKE8RYlg8+ERPLijDxrXsWcPDFVUL49HdkWP84kKWmnb25fBwzv7MZhxB+0bhlu9o2OSeHc7cq8PDrACkAFg2be/hOZtWwAAfRddHrqvvCWJnp9zf/JD5hzNtrerJ42ePvMd0+NxxiWLuN4ZGaf/mRHTrc/g3H1IvhjC6kbj0OA4YLAfMq2unpFs8tROKSAW/EWWJFtRoMoRX/necQ2P7x0ADScmibIkWU+aZ7zjdyhpS5JISZJKbmrwICXEKce2NXDuRXjq13cz33+iGEqGAUnT7HissJYkPgcWAEDx/1RK8tRnt5toMJak9nbXeUkCjIRj6SQKeX7WbFdZQGwZ0OoboPskuZ2ohKIAoCrmw+BzlYlQPW67qWFJirpBIEkB7nZRPth0DHQigdFTTkN69Uk+F1QXfreftySF3aipBWir/s6P3YBN3/kpigILb1TEPdbGKTAtq4IZJWkSEERmcGzE2+3AMIDRbNEqZwplozlWEAm7vNTKWsMG69cAE2DO78mKG9nXF40oIAi5Mix4UQJeo8aERYXXozgwkHHVLYxJyni7243nTUV0Z88YM6ea/vtWLPnRd+y/+bw2Q+vOxo5PfB69L3JbmFbfdD1kWlGi+kQnsASAZi5BZX+/qdDp8Th6r3gp+s+7BLs/+Alh/A5JXJvv7GLqMBKkrNuys+PYmO1iR1DiBHZ+rIbqJm6ghXUnsaplBaPG6ySkVZAtaMy76oyJXYsMw/CkBWc6YWHh7be6TxfcYw8dk0S5qxRa27Dxe7djdM3pbB/pmKhC3nE1rCAmSWQ5pDFZMUnVQnNdzPwvFcOcuuqs2qIkyi4kHKufYm2SiNgFAffzWzO/GZAkIX2x3YeQz7xcSBKwblErmutiOH2ROcZlnQIlu0ptNdfFsG5Rq+t4LeFiMxNMj+ZUDF1NCSzuqPPtzxmL29BcF8P6RW5yFKYNwbH2Bo9nyShJk+fORoPcAz6JsnDTaCI6xLV98Nr3oE/wfSRYOavRjNENgTXzm8XtUSNb0GZalZMxBbGADaephunV2+MEfIxRpE0TwfIhsKJ6tlceBLEuPqx8USxSvHWh3L7WSjHjPCPDlxWdD33QH9LzW3DSJ96P1MH9vlVNFDlFuc9MKhZtwQgIH5PUef1/MH/nLBc0gg23/xGH3vIubP7OT4XXX3jJWidmyKfvqe6Dwr8LbR0w4nFsvPXX2P+eD9uMRXT/6w7sBQCML1rK1LF8oblzJ1KSZBmul5m3avBuS253O4kRUohwGhuw3PMEFOC8ogU4woaSzWJWk/mbPGdlPEBJokArswRKJUoSJfT2XP1KoXWBtjbJhQJF3MDu4tbFxRYIYUySFKAkSRLkKvnbnTC3CR2NExtPsai9DmcsbsP6Ra1o95AzowrjxZY2ZJauQGbxMqG7nQQJoHJa2ZakLg8libMidjSY15aafJQkn3lVLeWitT6OMxa3oSlpzq+4KuOked59MhuP3ofGZAxnLG5Da7234uepSNQYkiRhzfwWLO/yz6vTXBezFaWo7HanLRQr2jRVOx8rGimPWPiiocG728kh0iKIMLfFPyZSBKKYEMR0b+8XRZHQ1eS8Kwvb6yDLkvD+8ccakzHmWqeg83NFVwMuO3EWzl/RgZPniZWqqYoZJWkSUAmbm6g877IV1te3qvFzhvBnTYgAylnMJoJ+e6KQvOoKzLnrTpz0ifdNdlcABLhN+DAz0lYkwIyzSR4+ELn9fEeX57nDr3mz65iaHsPcP97BddQ9CnWM7V/T5ucAAKOnnMYcF+UUqju4DwCQXbiYrTRllRUoCpIkuS1JXD4mXoAXETfQGLfarzu0z92e5fYmcgHRqJgk+qPIu9uly0iwKVIQwxM3OELg6EmnCssYqmq7QMrFImVJCutuV+8+GCBtSZgcH/wgFz/GcjjRHVQUPPH7+/DE/z4ICFziJAlA0h2TxFtfCXgliSilvpYkn3lVSze1sK6XUVw0w7igBcW3SJPiFFoOInyvg3aJaw7vO8q724nX/RAthHxo9NPlDTZh40NphN34mS6zqhzMKEmTAJbxzTv2SHic+cucmFpAtH+lCoLQAlRBPVUL2BTUzf+ejuCD6HnI/WacUVDy1YlyuwzrP87PQ0VAg33m66/2r0Rz74aJdv4JdvznF7DhJ7/H0BnnMMdjVgZ00icRQYGaHmU+wI3bTaKI0ZPXsl0iVheqjmT3IQDA+ILFTFnH3c7dnixQknhLEp8B3U0BzmJ8oWnJIpYt+hGQjyZvjQJoxS/LCJOGwSpJz/ziLte1LnDPTKgkhSVuoNxphk87Q1xIkuxycj7rWJLCEjcI3e0ChM8qsttNlsJVCxjxuNBSacNSfOIDfUge6wYAZKl3ZuDci+3fXqQdJEGzCL5EH8fJTZ7Kbp7+ffORAyJ8lKQwbEeTBN7dLrPYP9m5F8p5xgpnVRtfdaJ3/V51VGtNm8JzNAgzeZImAfQ7bSCakCqkefZxfXOXDVsyGrySyQbngIqOarDBlOeKVqmyKXh2MMAn3OQtg17QOP9r/rKg2LdqIOhZ+CmvxFKjpVK22118eNC3PpI0EgCOvORVeHjZSWimhXjefz6ewNCZ5yF/x8+Y44QxjryLatqdP0nSdSjjGVsxIUx8hFGLQLc+hLQlibDoEcpvu05q55yHLAHgXCJ4JYmPURIlk6WRXbQEAGzXTPoR2O52CqEAp9qlFD/yrSWniZI0eMa5nklCacQH+lCikhXKAtKK0FAUbL35RzByOWQ5V0YaxZZWKMeyiA8NRk4mKyZu8M+4MlnsdtNZ+ABgu9s17thqHxpedza2ffarSC9bhXl3/sI+rossfABKTd7uO35K0lS4ddV+flGrq8X8CVul6PNE+hPpy2VMriVJ6JJm/cu72/W8+JXltVHGbOUVnJ7XvBHG0BAGzzo/dBuqLCGMg+C0X4d8MGNJmgRUkhxWVLzE7aSErbOaGzBeehEbKxTcYLkc+kFXlR3rFEmDjV5/6n3/hvOuPBMKxfLmaxmkhPmg3feJUJKAqEq+81tNm2POd8wKfR0hRMh1zcbmL30Hu9ey1gTJY8y7/+PTzN9anMTZmOUVyvVv+IoXO30kiQA1zbYU0dTGABW/Q1mHiCLB7yQaSW93O1mSXPE+vFLE/63zShL3oStaAiRR2hj3K9vdTmRJchQ/xpIEh7hB98sd9K1v2T+THCEGURBpEop4X693XRz6rnoZjr3sNb5lSP6c2GB/5GSyRiyGfe/6IA6/7q3OscCYJFRV6p54GunwjGxVa1MCDEHMkJZMovt1b8XIurNMdkcLep2YEMHPksRvUrDtVz6icmuopnsSXVfQkMoZcq2mYvjN3PIRpe+1eOdod7u97/h3V8wUEPLdK8eSpLAXSaqKA+98P8Y4TwizfnEDlcRZHi+K04ySNAlgFQojkmIgKhrknhWlrnKvrSzOKtoFge9eiOqmRIySYSDx0x8j1X0InQ/83T7sqyQdcQROZXzc92aHva0VsdtJ/tcbHr8Bx3pTbPFgvhIgZimTYSwYNHJzFzBsd4SCm/Tdztc0bx723PoL5C3LBzlOkzK4lCSi+FAkFCThKr+TKNmxPgLfdK2E2EAfc0zjYpJ4dzuJd8CV2PeDuDrZCpGAuEHkhuZQgGdtC4mZow2IDZnWPk/GMgD48IdROOkUACzNO+CMXU8kceBt70WxqQXHXvIq77rKQMF6fvHB/siWJADY8+FPYvtnv4rua/4F+c5ZGLrm9YHXTAUqZn9Mwf4JlCTapZJ2pfW0JPnEJPE5vGhMwbtx3KFcRTSKTHDoze9Coa0dB9/8r2W1VQuQcdObZGHdfUUoR1ephqtcGDr74x0zStIkIMwCECVqJ9A9i1PKoqKSK4KUp2rtGE1EFudKm+AvT/Qes3/TbiG+z3PQcUdT8jnM++3tng2U5VJY1hj9FDXv+DtiSfKLKeJBBF7ejabQ6k8pC4BJ1EorNLHhQSz7zlfMPyymLLIDHRszLUnEwmNIkkvxIX8rFAU4cR/kA3eRpKxO3P1IHTls5y4iKNX7EzfYli4yRrY1m5TBjj+impTtmCTL3Y56jpqVUFVNj7oEHdua50HVbLdt04izCqGjJCWw66Ofw4OPbEVu/iLfuqKCWJLiA/32PS2HDnrb57+Fh+97FlpLi285XjmtBDyN+0QgXPB4dfskQYLkYUkioK1Eep1YSSpS7naZxctw5JWOQuunyE+mTkvajtIHr1WWrqNWVolaIOzmWhAKHZ146IHN2Hn9TcLztX6X/GqnvxWi2M/ACqIVYhBFwfGMSRLUUc79rPbaMZGYUZImAYyhwGM1SGzeCHV4yP9aC7y7ne8SU6HCJKzSxa5XQV0h2qjG+zYVyB3sYHoArU89Zgu8vpbBQTZm54QbP+7K70MQ1t2uFlY1UY0uS9JYdCXJy3Xq6MtfCwDIzp3vee3Qmefav4llyDCA5d/8Ajoevt880dQEwLD7pI6afbTJCurqXBOQdk3j6+fd7UAJgEThIyCMeDQ0zsWIt2LFRobZC7h3Q7csSXKpBHB0+3aeJIG7HclVk+g5ZltIDADQdXTd82emjBcIGxkfg0T+thXdgHgfV70hythKEm1J8iMQ8IOiBK4XsiRV1ZIkqkqUqmkayx6e7nZ0PiQ63kgXxYrBsRoC5vtBW4+iWKmridBsZNP5AXqgkjERATzy9zniGjJRoDfJKkkkWx5xA3dRDa1Rx+E0tjGjJE0CGHY7uD/6TZufxaIrLsRZr7nMdW0YdzuXK5zX74rcscLFVYURlsMgyKPQKw5qIhG13dQBRyhe8Juf4szXm+5gbqWXgpXvhoZXfqEJi0kK625n/SEVi4Bh2K5spcYmbPnqDwAEuyR4uU7t+dD12HH9Tdjwk997Xnvoje+0lRbiDmfAQOvTjzmFmppgGI5wplqWJPKvIdjNphOvErppL3c72r2It7CkREoSLxhykjIfo8SD/jBLnJVKKrHEDTRyXbMBmKQLCnWd/OtfI2lZQAOVJDv+ilUGiZVNj9cu8aPtbtffFzkmqVzU2t3uuKTZFeUxou4jbUki1k0edA4mPZFgnrOfW2417me5CkE1nyRd13QSVv2+l1X7hke4H+XOB9EcsIkbGHe78nnSyulZJEuSR9GgOuxv+vG4NlmYUZImGH6xPAQdD98HAEgd7XYV4BcPXTeiJaOtIHYodBs1KE0L/OW8kFMhSS3fB95yQP6OYkkCnKByM77Nu71awDCi3RdpcAAXXHwqTrr+A7aSpNU3Yshi3JFLRaz88mfc7Vj/egm8eiKJQ2/+V1+3LSMex4G3/zsAR1A3DCBD5/qxPmpkB1DJ5dB5/19x1uuuNMvXs5YcwFGS2p56FBeftQJLvv8N28WLd7eTEk6/FU5JUq1Yn6MUKUFQbovu17J5oPh3g1WSiqxF1rYkWR9v6kEWW9uhx+KQDAOqpRQZBqD87Cd2mXynP+GGQ3fOjnPNde+yCpTJShViwuUsi2Lq8AHPZLLVbFKWJARwO1QMMYtWdYSTyRBxJMBmt/MCHW/k5W5HrIaAFc9EbSToCW9FfCooFNXoQiXjCHNprer3/T5NAU+PakBLOt8LL0tSrVxdeQWnnLVCtPEzFd6bicSMkjTB4N/9XFHDxoPDzLFiU4v9OzbEWg7ohWV/fwa5kjtvDN3GQDqPLYdHXGXMcuWvRIeGsnju4BA03V0LK6hHVJk8ivPH9/dnsOnQsF2/6LpDg+PYeGgYx0Zy6BllXX7o4vw5Lwxmgskwh8cL2HBgEGO54MRtIvcqIHxMEgERpJ87OIwSlWcnjCVpT18ahwcdS1TUOTGaLWIkKx7rC0dGsfMYnQvJQMsdv0B8eBBz7roTMcudtNjcwrilLfz5rZ7tySQmqUyrgK38WO5zBjiXuGuuMesnrmLFPE66/gPOCISWJPP6jofug5LPYdn3vua0x7vbSZJNisC7oRFK9LxlxQFMSw6Pg295NzKLluIfT+yEzrnf8R8wPebsXkqlErYfHWP+BsSWJMgy8l2mEhQ76rhzGhT9+djqk9zXUSCuVAo1TjoWrGXjM77XVwKSH6rp+Y3outd0DzQqsCT1j7mJNmhUk9zOS5ip1FI11YQbSZLsZLJeoOONeBITAsbdLpkMZCK02w9VqraYjGcymTE6YTGddCS/8bLuduW7BJZlSarC5FIVdx0iucKPBn26Y0ZJmmCE0Rlo96k6K7+J1/W7etz5XWg8xylg5dCPixQdTTMwkC7g8NC4IE+TuOJKiBv4F3N3bxp9Y3n0CYQXUnTHsTH0j+XxfLdYSSTwUiJ57O/PBJZ5Zv8QhjJFbDw0HFiWjkmiUdKiudsRQgJNN3Bg0KGQ9jJIpQ7ux9JbvoLY0AD29bnHlDxyCEu/9zWGltwPI+NuJSlX1HBkOIth6pxhABLlekVyHhXaO313fGmQ68sVeB0LEbEkGVAz5ju0/aZvAtdeC92g4mnyeTZmSsCwpde5rUsAYMiysJ9EeXC5oVkxaaXGJgytPxsAhFTXOz9xIx6/+zFoAupjL+IGwCFqsMtyliTXBs6suQAA9Wg3qQ3SEfP3ppv/G0aAFUBE3JDsPep7jR/mt5nPblmnv4shAGQXLjHbpsg6KrEkBaGayWRJfTzaG9xzKUqTs5oqd29sqavePTQtSf7vMUPcQL17TSmzH4s76hhLEuDkohk9aY1v3Stnh4+FjIqwj0WksJBn2iZ43kF11IICvFbwy5O0pEOsEEfFZLmBkXHQ7naelqSQ9TUmnc2sBW3ibw4NXsHxe/ZRNmbyRd1eS/yeUyo2NePEomImmewEI4xOoI44hA2tTz+GkbXrPcvmS26XFd8YkSpv0RQ1f9uDKFbIL2YqKn23E78T1WIVktSgzPuVLwqeC91HXbcTfPLwtQD19LgO0cIvcdVr2PEClIEGoH2hq/z6t7wcif5eNO7Yik3fu911/vzLzdxDhqJi33v/n+u8kh5Dy3NPY/CcC72D4UUKMQBQ8S3ESlJo7wgdVB/FdeqkeU3Y2s0qeuSj1f7oA0gc7YbRuRJKxkr8apEkGIZh51GSCwXku2bbuX4MgULk5QakJVOuL5MECUpdChgdcbmhKSOmklRsbMKzt92BRH8vcnMXBI6TqZ+jWTt3ZScMWYak64KYJGJJMj9m/LzLzzItWiplSZIOd1vn/OORALG7XbLHUZIGzrnQ/j2nJYmjw/4W3dWzm7CorR6puIKdPWO+ZbX6euQ7ZyHR57wvsdHgzZAzlrTBMAzs7c9gMB0mjaIJSZKE/vut9XEMeVigT5jbhG1H3BsRvFzSWh/HSXObcGRYHHsYFg0JFeev6MAju/pd58K685y+sBX3bw/OaXXGkjZIEvDUXv/k0MKYJAp0niOyGbGgrQ4rusx3dXlXI+Y1O4JooWMWMstX4eF7N6BoWT3r4grGC6zHxcL2OnQ0JLC0sx57BRtFtcD6xa14Zv9QYLn2hgRWz25EQpVx37bw+cOAqRcb4jet/CSHuS0ptNbFsacvjWMjFSSfniRIkoSLVnUiu5tyBVVVyDKgl+FlLEHCGYvbkC/pkCQgGUIBkQCsXdji8lQS9zdaf06e14TlXQ1IxRXP61VFxoUrO6eUYl4OZixJE4wwMnecYrWbfded3PVcTFJUdzb6d1hLUqQWosU9ha272rE2k23OTx7rZpKP0vDNk7Rnj+sQLfzKsgR5PIOzr3kRFl54JmO5IUj0mx/e1icfsY8p6THAMBA7dMAp57Hrf/LH34fT3vtGLL712979FIC3JMWIJYnbCRZfa94Tx90uWElSZdm1m0Z8xNX0GM58/ZUwDNiWJEK3TVuSpEIB+Y4u+3rp2DHw8GLdcrnakTooogclkwEsa4djSWqGEU9EVpBESKqKTYZBSCXsfnB5kvj3iihCsmU9MnQD0jFzTtAugd6NmwIwsRgCrJK09cvfs38nVAV18eAPfypEGYLxRUuYvz0peCk0p2JoqYsjJqKSC4CQLtdHQKjzEHRM1z3nQkWWkIwpZcUl8N+LMMKVH8Iml0yoMtSAspKEEEqSY+0h724qpjD9SCVUPPXru7Hj4zdi94c+AQDIz5lnW6frEu4NmIRqPt+4WhsRSLSC18Xd/fB6pJGeN1VsugukNFJxZVqMx6uPMUWGQpGNGKqKRJkud5JkvnupuBLpHS5nHePbFR+XQq3FcVVGTJneasb07v00RBgBX6VofV0UvxxEQf6+rDEMs151VIVqJi31dNWjjvPsgHzdk6UAhVbeDMO21uTb3QqCp5JkGMCuXQCA5374K/swrSQpkgQ14+yMxoa9d3Ila0urcdsWXHLWCqz+/Meh7nPipAot7cLrSOLbxT/6jmfdwu7DYJSkRL9lSRIpSR43kwj6YdztZMk9F2gf8cRAPwADClGSKEuSTtFXS9TWnzTq3vn3SnLpYraD9dGxlKR4fx/Ov2wd1l/7KrMtQoneWL4bEP9NkyTHnY7PwWTnSbI+3F7udoqVwFjK5+y5VhK4+vEglqQFv/oxGna+AABI9phK5pGXvxaFjk7Pa6uB8YWsknTkFa8LfW1ZlLvVkugk3z9Dn6ugSXGZWgisAUqSnkxhx/U3Ydd1n0Kpw3szZXTN6Tj01nej2O6eU6JuEyW0Ugpur6v9XMnKRZjvS6C73QRYmsKOcyqk4aBRi/lt1LmTyfLthJmDZfdNEv70KxbquLvcNNBmy8SMkjTBCLMu0IoRH7fALywieTqsu13VErlWQOVZLQVrotbb1icewVnXXIqmTRvKroNOAJoY6MehN77DOWkY3sQNPT1AOg1DljF41nlIW6xs695+ja18yJLEMKLFB90xTARE+F/8XzcDAObfcTtix5ydfp5YgIeXJcwLhsEpdFZcUEGgKPI5hOw+RbAkiT4+6VUnuPqkjHNKEhx6arlQsOm8ASB9s1sx9LQkCZQkAECXaZnqfODviI0Oo+W5p9D22IOof36T2Q/KxSgqRB9TPqGsXZajAOddUIm7HbEk0aQLYWLI6Jillbd8FQDQuGMrAGB8yfLA6ysFIW8ATKWMd4us9poR1spC4LlLC+mfIs+OJEmAquLoS67xLXfozf+KA+98f9nt1JqavRJUo2cS87v6Y53OAvBEPHrf+0O5ZxuKUvadnKz3PGy7U/gVqxgzStIEwwDQ9uSjWPGVz0IqiBmT6N1/uejPqlRJLpxyXN3CnI9GSW6I41d84paq4m5XZh3r3vkaNO7YilM/cG0ZjZr/0O5HOz5+I/Z84OP231Kx6E3cYLl66R2dMOIJxkJAEnzKMqtYxwf70Xn/X7Hs5i+6naEtCuZiS5t9yAnSdyvolcIw3MqPrih2LqCBcy+yjyvj4xAhqiWJn1u5eQsxvPYMp0+AbXnT6htMKxJjSSrYytym7/wUhatf4mrHS0nyTJK7wlRu6w46xB2nv+v1znUVWZL4YF3JZrhzxSRpPux2AHJzTBpt5aDpgkmUJD0WDxVDZlCJc9s2PIErf/Ff6HrwHgDAyJp1XD8Dq4uM3Jx59m+RVW+qwpUDcpoKIGGF661f/T6e++EvAYDdMOJg52SJeD8m4/6JNgeF3ahC32hBNhyddOVthkVUBWuaTnVvUOyjJLdfOfe/nPtSDcXquHseZWCGuGGiYQBnWgJRftZsHHzbv7mKxCnab1FMCQ2RkhTekjQB9heRG5yPa5w3BbjYTVA0hokYV3woICDZ71oSi9PcikNveRdkyiIjF/Leii8JgE+ZwifNlkPih2RJgkEp1vHBfpz88fcBAEbWrkf/xVfY54glic5KHz+wn+qLeO4VmlsRJ+QimibMdu71BKRxNvhcp8gNnvvhr3DZGlOwVbLjKFH9svsU0ZIkElae/8p3cf6VZ0GLJ2AUS7YSVKqvh2GY1llbScrn7JxKWjIlrM/L3a7oFWu13LSiNG7dLDyd7wwR7+MFyS2YkHkSyG7HDS27cDEA091Ozo5DtmjTvWKteBgUvbOaSWP9/XcDMAOYR08+1V0+VK3hwcazTD0lyUuAlCTWkuQnaPq60ESQcKotOEtStI2ogQsuxYOPbGU2bHiUOz/8Wb0qQ5Q+TYQ1IKiFcly9aoWp5m5XLnzJKWhLUgWJ1KrxmHyfdYX1H8/K1IwlaYJB7+XX7XMH4UPX7fwxgElhy+8A04i60FQzOepEIsiS5LZmBY2ustHr8QQSPUeZhsO2GB8wlaTxJcsBSYJOuSXJhbx3TJKlJBE3Jno3n7jVyZLEKDcpioghxil2REnSqN2uxOaNTl84dzqpVEK89xjUcSfmibaK0RA+IxiQMywrGRNMryh2XhSSx8jG3j2I9/U47HYB1MGAe0eeQLcCwJVCHlLaiTHS6htgwIpJIsxsRcfdzkvQ9lKSRLFWkgRbSaLvI8G+f/0ASs0t4o6HgNjdTmxJsnNFWQonrwAWW9rsnG2pQwcgZf3vQ6jOAOi9/CXQBFa2agtNGmXh05OV019XHZ7udtPbxSkK6ClSbG33lQbL3fyajHsZtqtR+hYmhngqWB2n69ytSa8pJYnfpIrSbth7ys8RZrOlHAvW9HyUVcWMkjTBCFo81dERJlAcgKdbHuBhSfIlbqB/h1vJo8YVeSliYqsPf21wG2HiqvwI4qoBJZfFBS86Dctu+Urka21WNxKLI8t2UKdcKHgrSTlTaSF5dgzZUTCI9dEwDEZJohns5KJ4kZap+ZXc/gJVnrUkrfnQO3DhJWuZ44keMQOeaM4YBiALiA9oEIWNVpI6Hvg7Gk86AeddeRbq9psuamHc7bx2zjQqWFwaNDckdFWFHk9ANwzTmiRwt9NTKbFrqJeSJIi1AmDHJInQ96KrPM+FgWjEInY7qVBA/a4dAID0spWe9RGGuLoDex13u5BKkpQVx6z1XeIeYy2+xaV6RxELm4eLYDKFA/du/+T0o1JUu9/lLul+BF+1ureivgoJJKphIQhsZWqiWsRRfpDs/5scSJTV3W+zO7CeGo/B06od8uZN1zUqDGaUpIlGwIsSt+KRaEGEFnorif8Bqh/bM1EIUuh4xSywfJUII5bcenO4iijEBdTXOpW8NMiS5DBCOeWI4mWAVXrann7M1S4P2mIkUck3eXc7wmpHI+mlJFFDOOEz/4H1b3wJUCxCtRjtvCBSkhp2bjOP5XNof+wBAOHc7WQPlx+DskIplgVOq2sAJAlmiJwBPeblbifoc704hkhkSTIMAM0sMcPY6pPt36GotSPCiV1zlKSGnS9AKeRRaG61E6+K7lXeYrhL9PVAIu52IZUkWWApA0wmsokAba3SpqAlqTrEDVXqS5UlyVpaEyLHJE1BxaGan95KrQXBDVRwqZ8rmuAmTGciEiGo8cjFgtAdOlQ15TRdxjWuOo6zx1EOZpSkCcayf9xn/5YMd1Yx4hJV6uqCYc1QfkcfAFqfeBirbvy4md+Gg39MknMytLUliLiBK+Bp9RGUN6z/ifrnVWeY81EsSW2PPoAT//NDUMb8rRwy7wIWEaSPiT4zTxFNgaxbio9czHuz23HudrTFkXbd4vPhECz7zleE55S82FLJxErlssIy3pYkB/N+/0u0bNqA+icfQ4wihhBBpCQRim4aehhLEiThvKGvlS0lieRIMmBA1x3LA81upyVTYqWrwSOZLOXGyKClhflz+LQzkFm6AuNLl1esJImEDIfdztmgSR05DMBx+QTE71ih3aSBjw/2288kbEyS5PG+ZOe7ExwD1d9ZLtE5SkIo1TQmhCo58omI9VcljqHyOqqFcjf1/EgHa/Wcw3ppVLv1ICa/iXicU2nOTDYY5sEKLEnlPjjJ47erXMXP7Ph96DNK0kTCMHDWrT+w/1QFGeCJkqS1d9ixKrLA3W7t+96KBXf8DCd/7N+jdYHpTvBCfmwk58pW7qpTGCNk4MhwFpmCszCUNAMHB8ZxYIASnsJadMIVAwAMZgqBrH/02dPf/QbM/eMdWPCbn/peExM8LwBIdh806+TaHMkW0TvqdjlK9Jh5Z0geGgDUsw7vbsew1Wm61Qd/VroOgTWIjz2yjzOxTfuFZeIeliE7+StVd/t//xDKiPgeEpD8O3Rcnih2J4zQ67nwy7KtKGWP9ABw4lcOD1kuZZa1SclloVjvn55KoXdMcK8oaumHHtiMQqsZfD7iZTHhlKRicwue+J9/4Nk/PSAkwYgCCe5x63ZMkqMg2wpPnVjBIyhYeWfig/12TBLvbuflzpS97ErXscd/eZfwwdRiB7lExSQRuvPpAEnihBs/Ib9GuZkmClGUlKFMeWybtRTao8RJifpRFQYyhuRj+mAiHFki3d9yFZGQ1w17fA9CMRJOUn6rGYV3RkmaWFCJOgFxotj4sOX+09bOxEUQkN1WEifR+eA9TPLZINBrehhry/PdI5BKJdTv3uG5lSc6emQkhxeOjGJfX8a+fnS8gJ09Y+gb86c1F/fb38JEnz44MG4rGsnug/4WICrxqhftNIGcEysTZ73mCuHxp/cNYvPhEYzlWOsNSahJ8tAA0dztiJJEWyKJIm3AsH+TPEo01DRnLdM0yF6WJEZJOigs4yJYsEBGoFIxSE33/EVQkl2FswsWAQDqDjrviiJQksJYkvx2VW0lyCLRIAL1vr4Mc57eyNCSKfSOmveKdXGR8Ojdj+Px/30Ahc4uPP5/j+DJO/6KzEo2JxMAKLIENDbaVmLApAo3VBVaiDEFQTjkOGG3czYsbKa6Og9rlwXiMhgfGPAksPD6gOcvfhGe/dFvmWOetOiovvsvnaeJMPnVGqri3IuWumjWKwJe0bUTn1bSMQpEqfWL1akUtRSuoioWovKpeGWbEUGoZC57Kl4h6pwIoba1Pvw65dedxmQwuXJjorx3qNaIcp//ce8z+PGnv44Mif0s4xlFTMEWGV7Vl5snqdbv10RiRkmaQEgb2ASk9G45AEDTECPuP63tjHWBgKyf+c5Z9rFzXnERU034eJsQBQ0Dq77wSZzzioswP8DSQmN43Onzqi+a18/9w6+dApoG6LqbAtyrG6FbNlHSDDRtfhbnXXU2TrjhY+76SIXUM6Hdc5x2nZa9LC6x0WHfvmSL7C42sSTlu+bYx2iroedYOSWJ1nLpxK7EPTM/aw6evfU3eOHGbzp95RRqNT0GxUP5oy2Y8QGxxchLSSKDUMf8LUc8xq34mNQBfyWpIksSHCWIULlrXK4jkkyWfrZ08D8fB5BdtASZ5asBmKxwYyevdbU5uzmJmCIDsszEyyRaW8z6q6AliBSWhgZTqaFzVDmuc/5K0sITFgMwY94IcQPvbqd4fMElWcLgWeczx0oB7VUTC9qctuhYOwK/212usHnWknbMb0thYXsdTpnfHNCGx32TJOac6P7Obk5izQIztu30Ra2RFJ6zl7ZjWVcDVs1uCn8RhXOWtdu/G5MqlnU1oG4KC0X83Vs5qxGdjdZG0wTulIuet5BoJeIyQL/zQRYHSZKYpMdRhz+7OYmT55U3b3gsbq/H8oC5M781heVdDThzqTc1PN+/iYYvRb9kxpkeXbIisGytETTXq7VJ1dYQx8nzmoMLThPMKEkTCMlKBkqgUnTIzRuexMVnr8SKb30BAG9JcoRVO66HSgCZ6OthYkP8ffvFzHMiqCPDOO+KMzD/t7cDgCeTm0jZoheD+XeY16/86mcBAE2bn8XFZ63AeVeeGch2RuoPjEni46JgYMmt34ak65hz153uRKoETz5p/1Qy4kBz+7yHkhQWBgzI+ZwtmOdni5SkgrfyStztBDFJtgJnOPNFj8cxeN7FOPLqN6L30qsBuGnA1fQo5Lw43kjh8i0Jy3hakswxqAFxXjzGFy0FYLKp2W3UwpJkKTwkcbNWxytJZv3ExVJLpZivTBTBhID+gGtNzkekbq7Jdler/F4KWUcoS1IYJSmuyqibb7qExgf6PNntaOuJC7IMnXIhDHLvC4swwu2SDqctkZJUKZpSbkU9FVewenYTVs5qREL1VxzoITRTVidZAlSZVpLc1548rxldjeZ8aquPY36r+zl6zcu6uIolHfWI0cKyF4mE4Hh9wvn2qIqMJR31SMTcYy1XAQlSuKJWS68DzXUxLGyvvaIemgJcMJhKNkvCuW6VX+fSzvrAeR0WiixhcUc9M5/4vslWmaZkOIsS/c7XEvQ9iWqRLee1CIo1E7YjRbEEeWzYhG2L+n3inCY0C9bG6YoZJWkiMWBaiQbOOAcAoKSdgPT2xx9kYi9KbW224CwxliQr1oMLpG/a/CxVxrsLrLud/2I8785f2AHeAGCIvtYIb+VRLZKJJf91M9TsOFJHDqPOYi4T9Y9tw8vVT3xcN1iihbr9bE4qwzCAwUHgY46VSc24STBo0JakQnOrb1katLBC3LcMSUKRqoNWiL30OduSRJJ0Uu52tjVI13Hip68zT8ccdyPiIsUrO+roqKe7Xf2uHajfvV14nd2ul5JkW5KiKUkFy0JKlBcAUAXKayV5kgBHyYpzxA0ERsI8T4JtXYxunCUpKmglSe8kSlL0engI+2JZ3ZZ+96sAgPm//G8s+97XzX4EkTC0mnNUTY86Lnq8khQgJdDKvJ+SVG0VUZKAQ294Gwpt7Tj82jdHvnYiwQZYS4xQVI6AFLnRsotX9tRqFafj1QZf81QMufB0t/ZCxEFUMp9qMRerWeVk0OdHuSflktNUZxzlKVpRUbP1apIwoyRNJIZM97rsPJPdSc2M2ZIR7waltbXbVMU0u50BoPH5jTZV+MDZFwAAGndsZcp4gSVu8O8u72JleAhDIlpyv/eEzt0jeSRYc9XvpTwJYpIAUwFMHT5g/z3rr39yX3zXXcyfqoApkAZRJsZWnoDH//wIc04qFDzvO7kXhuHEPWmpOuYm2WxqHq5vANzsdtSgiQLX9PjDTp2USxrZ/U/09zJVxsZGXG6EdLzMSZ/4AAAnAS4A5GbPxfNf+g4AoOu+vyDex9ZJxkrq50GIDUSwWf6sjYHY0ABannsKAOxEs0A4JclP2CLtxDzc7QzOwuKOw4kO+ppSm+OyZHSa5Ag1o+Tfaq4NdYcOQCqVsPqL/2mfCnK3I8kQlWzWtujx13i52xHQ85ROgMyUQeVB8CLs+PSX8dADm1Fs7wwuHBGVWv78rDf0PQ1SQn3h5+7HWEPLrN6j/krEpGrHX9BC21TJ3UQgsvbpEZUkRsEOGJ+Eyu5v5Ps3jeTlKK5wdNlK52uYdmvtpmdancpvl95wD/oeTDfMKEkTCMmyJGXnzgdgur8QAZUnX9Abm6hgfkeINQzgrNc7yRjTq08CAKQO7neu9fl4G4YZX9CwfSt0w0Dd3l12jh0eLmIJObyZnX7h6N3q5OEDUCnrg1QocDTh3pahKNB1g7HMzb/jZ6xFDgAOH2auUdNuqmm6b8TdTkvVMcxZABAb4eLLPODl5kR22Ml5oTXJh92OuELVb3OUZXrekGfAs9GpY6No2cTGynW/xtl1T/T3AoaBrnvvBgDsfc//w+N/fIDp/5oPv0M0VLt+GsOvfC0evv85++++F7EMaBpxO7QUwhVfv9E+V2h1FIuSR26isCBW2sYdzwMwGeaYfrSwlkKde15ShYJXcY7DbGh4JJcth21IeP7IEfsnz1LopyRJEhwlKZe1KfIJAyGB6hWTNMk7inbrZTAGTgwFuPccou9prQgWqvF4/Nblcu+hHKR0VyTk86aG8uvyQ2iLgaB9zxQQYaqrgb8d3Z2pmHNq8uF9T6p2v8qsJooCLbw+5DUaJa/MKEkzKB+WJSk3Z559iOSA4Ukc9GQCesxN3MDvXY2tMpUkOobD190OBs67+hyc/epLMev3v8a5L7sAa9/3VmFZ3kJgeAkbAWt6sdmxHCz5r5uZc145fSqFbrAxRon+XrQ/+gBbyFKSxq28Lcq4W0miQZQOPZ6AwcXEELctEeglQ/FgFSNKkirICWTDx5KkFPKAriO1y3FfpBUUIgzz1sHZd93pamb0lNPs37k589DxwD22NXPozPOgNTYxwnXLxmc8u6xylN/Zk9fAiCfw0D82Yscnb8KO629izhMLj1Iw7zX9zIqUkqT5sKSFgc1uZymXvZe/lDlf4pQkP0tSOR9CnbKKSVxb9vFylCRRb6h4nKbnN7KnQlqSJF1HzLImahzByWR8FEPtvtZYSauV4U+SWEWhbEtSCKtCcBX+pWoRR1d1S1IFRAXlopLbEtXdLioFeFR3KPoZh3k2k7k3ws/XmnWlAnfrctal8hScKJaxyhDZRXQaYUZJmkhYlqRCazt0yxJBrBfEEtF72Ytx5JWvx9gll4spwLnJmF55IgCLMtlezHwsSSXNdis74T8/DABo3vys0HTBu0oZHi+diDSBXqzowPt5NMMdwDBuefYZ3tYxr5FqxaJt+RladzYAh1XORreZ2JRQcwa621mWHD2ZdK1aPCGCV1+9LEnEMiUiKbDhYrdjn5mczyHe1+P0iVKSbHc76jwAzLrnz65mCu0d9u/cnHloe+Ih++/h088U9t8LqW6WOly3Yn8KXbNx6E3/6lJ2bLfDfB4wDJvtDgCKzY5iIWIijAJaGc0sXob0qhOZ81IiDlBtuJSkMj6S9EerRCUSlrwsMYJPV9CHL6gvJ3/i/czfQRTgoM7HLFfNUgNrSQqrJBV9XCRrIVhVUmWY/lSqH3i620GCQsck1egrXY3YAW8X4/LrDpzjEZ8su5s+tXa5oxA3hJluYZ5pVOsC3Z2axCT5WFSrU39t4XdP3IbL8nozWbM2bLvVYGadqphRkiYQkmVJKja3QG80hUNCFkBc2w5c+1688IVvA7GYkN2OJ2zILF0OXY0hNjpCJTX17oPafVh4PDbktoTwQflSmTEDfoK/xCc+NVw/BH+54YqLolzn8rNMFjlaaTAM2JakjJVPqHnzs0geOeTZhs0aZwny3a9+k30uNjwQSmjydrcjsR8+ShLnbidxSpKSzyE25FgkafptIuTz14hAJ0HVkilTiQaw5Svft+PkdE64PvX91wop0mkLp3mdP/uQTjH3SaUSE3s0vniZ/btSd7uGXduputwKlyxJQLtjueIZ3Vif9OifsIE3vx3jCxbj4FveHUkwKEtI+eUvPU/5uttBAmIxO44o3msq2Ly7XdgujbX40/hG+sxO8R3tSiBJgEIxBiohBlKOjMIq+uXdLD/hqFzPr2oL4kxMkqv9ytqqIKWR1b4bIZZoro7wSoYkRb+/9DOObDWZYPFe1L/QzyJCVyWP30EQuWGGek+q8E741eBZfchmZ5SkGuGhhx7Cy172MsydOxeSJOGPf/wjc94wDHzmM5/BnDlzkEqlcNlll2HXrl2T09lqgFiSmlthNJmChu1uN+IoUAQ2LTSd34QSggHT9WrMiktq3mzGevhN19i+PcLjSYpCnIBPwurFVCYibiA/Ft/6bcgWOYOLIQzh3O1MCnCP3TWvl9NSknRVtRNi0v03tBKwcycAYPC8S+zjHQ/cw9ZP/SZxMpqlJG278RvovezFAJx8O8I+Ur+DYpJUL4VS04Cf/MSsL+5mtwNMS5c6QitJjmUskMWMQrG1HTs+8XmzzkLBzlmUXuUkR+X73/mPv2H2//3BVVcdFSsHOJYkLxB3OwCo27cb7Y+bVqznfvALphxPtBAV+9/xPvv3gXe+33VeAoA2R6jn719ZliTqt97aisf++gR2fuJGb6FFcDjIaCM8/cY3InviyfafuVkO9TydSsATlkJMrJQipdIP3a9+IwDg/te+zb9glb+ztXe3q16H2bgPVjEilrpqD6cqAmwNZKNqu9uV865WilrR+QehJu52dP2hLFXTdHeiTERXHKOj3PlU6XwP+yxn3O1qhEwmg1NPPRXf+973hOe/+tWv4pZbbsEPf/hDPPnkk6ivr8eVV16JnB8D2BRG6Z578PtP3IDcnLkAsSSl04Bh2AJ8qakFgPnR5Jm+AEAWCOOjJ50KAGjY+YJ9rRdiB/YLjyd6jrmO8ZYkNZMWbnOJmpMAtD36AJZ/+0v2scyS5e5ypSJH3GBB19H22IO2hStox84lsFgKglZXb7tpzfrLH21K57pd24FMBmhowOCZ59ksgX5WL+K+RwvyBWt33M/djiF/sNjteCIAIniKlCTDMICf/cw5YMWY8FYhOZ9jCEB6rnq5/Zu3hOQplzoXJMmxYhYLtttlsYVWGtwWiFl3/w97QNNcLo4GlZBVBLIxAACnfPS99u9iS5v97ACESibrhz0fuh4P3/MMHv3rk+i98mWu85IksUqSb0xSdJTLLBYmWaQIxHINsMQc2fmLAtskTH8k15DLkuTRJ3J022e/hgfvfhQ71p3j3e8KXKhqgVD110gukCWJcWEsN+Yr8CpJ+DNSJZ7udkFt+yBIiI8eA0L95mNWJkmeJ9+EqFYjEaSIi5EUUeqrtZWgls9AkmqzVjDEPdNEKfRXcD3W8BlL0uQqSVdffTVuuukmvOpVr3KdMwwDN998Mz71qU/hFa94BdasWYPbb78dR44ccVmcpg1OOw0HTjwVeiJpW5Jio8OQigXblU1LOkIkyeVCu9spHMEDABQ6THYsIqiTXYeSJogzOtot7FrqyEHXMSLQ73v3h+xjIpcqUTuSBNRzuYlyFqsfU64gtiS13vUHnP6u12P9m1+Oku6dTNbz+NAwAFNJKjWaSlLqyGHMv+OnAID6rVvMguvXA4piu3LxiqEmSNiqU4J+0aJyjg0PIlcUJ6wkCpxhGMHsdgIlqaQbwG9+49QXtxQEbvBqJm0nP935kc9g10c+69TPCfljJ65h/s7OW8D22VJCYsODtjJWouKH6Pr2fODjAIDm5zeyjHuFvMtFM1C5kWVbQWvYvcM+XGxusS2S1YChqsjPnY/sArGSIEkAOp24IYOPpynHkuRxjZdQKHZFCmgD4o+hTrkn5rtm49G/PIGN3/kZ0iec7CrL99HgXCv5mKTA8StKKGUsCqZabEk5oIfAL2O0YlSrvCPVYbervnBUS4vZhFmSQparxv1jdaTgTZTIt2AC5d/p+F5XorSHxWSpIGG7ehwbkhDC12JysG/fPhw7dgyXXXaZfay5uRlnnXUWHn/8cbzhDW8QXpfP55GnkmOOjpoWmmKxiGKNmNTColgsQjckaCUN2jxTYYgfPgCDEowLqgJDK6FUKkGzBEojn0NJM3fRpQGWrruklZC3LCXq8CBKWgnFErDxwACOjboVGuXIEdcxAGh4fpPdhtmoAcWKf9r/urdgya3fNg+PZ1CiBMbdPSPucZYUlBQgydENZ7tmucrSYwPIc1LQ8uf/BWAqWn/d7rZyseWLKBZLTD3zX34FADOGq0C5eM3+nzuw7w1vg2RZ7vT2dvOeWcqpNJ6BVjKVnf7RcfSNUjFgloJTisXttnKWe6Q62I/N3WIa8ELBHFOpVAIsBr1iMsn0t2C1L2fS7HMAcN8LR3Fhbz/qABgLFmDodW9Eabzk2oZUjznPdt8b32HGklh1FRKskD+y6iR0PHy/U/7a96B+7y4Ur7ravB9WHAphNNPVGAqxmF1fqaEB26/7FAxFxcF/eRsW3XYL1PQYEnt22DFeMSq+atOXbkH79ucxcuY5KKX9yTqMeBwoFGBIkq1k5RoaYVDvb0kr2c+J/MujWCy67mVY6JqE0gc/CNVSThOHDzJ16Rrsv0slLVQ7xWIJxaJkXePMV00rCa+XILs2IDSqXXEbRaZusubRyXKzLa0YmzcfY/Pm289TBF0zr5dSrPUvl0oxfaDb8+pH4LMqFVEslXyFRnr91kol4eaMqw8+4yvJBkoa2x/7fgnGxEPX4brPPDSfekpF+jlJ1Hwyrev030XZQFHwXO26Su6xSpBRgm6P0XUN1b7dhlXGfk6GZG7SACiVJOf+WNfFFcU8prPvgPmtMwLnqqa7y+ia//tUKpXcY/EpT79f/LVhnrMfRH0BAF3wTtPzUSsVUSzKKFDHYoqMojWn+fsMAMWSwbRFfheZ98x/zheLRWZO0muS3xiD5jlTXtPZeVX034uPUn/Qsypx73ypJEPTNN+1Iso7TxBXFPu90rSSa62x6yxqzNqnlTSUdHbdKRWLKILtH9+PUrGEYohMBhr1LeLlIq2keI5P02SUILueQ9HjnvDPiX5nJ1vODouw/ZyyStKxY6ZgPGsWK1jPmjXLPifCl770Jdxwww2u43//+99RF8TkNAEwIGHjxo2YpxtYCyD33AY8v2INiCr4zKYtgCShJWHgzOERLADQu/8ANjxj5rKRn3sOJDLk3te9DRue2YBs/xBOBJA7fAgbntmAhALkxbIITty2Fe3U34Ndc9DWexSJpx+32wAANZ/HVZbA8vTO3bhQUaFoJWx96kmMtfknZmyMGWjJDOOtv/iRfeyRl74WWjYPfj+5e99ept2eegMtCWDVWBrE2Yk+z+NA0sDOOuBAGhgrOIv9VdYiFB8ewo5jvTjFOj4gK+Y92rMHywF09/VhwzMbUDc0gqUAhg4ewMaNGwEAv/3LA9AGx/CGm2/ElnMuxkDPESwF0D04ZPcpPzSCEwDkDh7w7CcZ00AOWLV3L1YCODqaZsqvPNqDUwFke3qE9awdGkYdgMff8Q5sffoZ9GYlnJvPg7YPzf7mFwAAuVQdntm4ibl+wcFurKf+3pBqxPxkCglLEd4+OIxtV1yDJtXA6DMbsPrgYZwKQLaC9bOpOmzY8CxT54aTzzB/bNyE09s60HnkEA48+ggODJoKaMPQAC4FoMsy/m/WIsTnLkLqsccwUvD/KF8kK0iBJQp5YtcedPT0gNi76Hu0ceNGJKwPSFvCwFAeaI4Dd+8FMkXgyLjk+T54oU410NcEvML6O7Z7B9NmUjWQK5njOJgyUNSB4bz/uIZ2GqizVtzDGaf8yE4Du0fd1yoym38CAJKKgZwmbqclYSC/F9gzCmStvuX3mvdweSaDVqvc5t5+HPF5pxrjBsZLEuakDAxuB84vFJk146mdu6Cr+wEAc+oMHNCB/hzbp/xe8zl0Z9jj5N3i0V1noCcr+boKk7EAwPZhCaUAV6X8XgPPD3o/k5gMFK06kqqBppg5ZwDg2Lh7TDyWNxk4lJHQlTLs63jsGwMyHkJoZreB7cPmuZRquJ7Z4Yz5/PNW3f054Ng4W4bgSAYY5OafIplzqGDNff6anAbsHjGvGd1l2O8Q4DwnWXJ2ietjBnqsNGyjBaAnK2FBvYG7t5tt7Bxx2s/uMS96YUg8dnLPdIMtk1INHE0ARzLe9753u4FmzrBLP2f63QSAgR0G9o+Zf7cmDBygwiLTRdjnysHBlIEdgnBPTQf2pcH0I7/XwJFx89uc22NaFAwD2J8GEgrQEjffl9l1znyixxWTgZEd7hfkkYcftt8zeqwi5PcayGvALutZDe4wUB9g3NcNYP8YkFLhOc/5sW+z5nXfdgNNAXm/D6VhfxP4OcrD730G2HcKMOdsriRBC7GuBM2FOXUGVBnozUqYV29gr7VmH6s30Jpg+0bqLOrADqs/5DulGbDXrpRq2O+31zgbYoY9X4Kwa8T51uX3Gsx72Rg3GBmJRkPMgCK5n4PXPeGfU14DDqYldCa918KphvHx8eBCmMJKUrm4/vrrcd1119l/j46OYsGCBbjiiivQ1NTkc2XtUSwWseN392Lt2rVYpqaBX/0cC9IjWHvCKgCAlkhg3RmmKDu7KYnmv/0FADC3ow3r1q8DAKx4/ikAwOFXvh6lT92EdQDaC6Z1ok0vYd36daiLKxgviKXCTp4d7/yL0faHX6Ot9yjWnbbWTrwYo/L+rDn3XOipFJT0GNauXInxxUt9x9nRkMDcv91l//3IH+5DevkqLPr5ba6yC2fNQtEaGwCcNLcJs5uSGPrl7+xjZ5642nZHc13fWocVsxqw6fAI+tN5YZllSxbbv1Pz5mPd+nVYZN3HeYsWYd36deh6/mkAwKyGeqxduxYbN27E2SeeiLPWmfTgc/ftwqFr/gUA0LV4sf08OsfM+9QmwT7G48Q5TZjTnMThoSzkP5kWsnaqDgBoK5nPpdmjnnrLqnjm+eej8+T12NOXwZ7//AJO+4gTtzNvn0lqosqyq47GBtYa0HHNa5G79y4ktpluh4tOPgV169ehsyGBvnQeXWOmBanOYl9EW5vn+AAg1tYOHDmEE+bPQ4dVLnX4AADTPXHd+nVIxhS0pGJCCycNtaEBGHUslM9872dYd8Z6pBs+Bjx6P45dejXWrV8HraRh48aNWLt2Lea01uGUec2edT61fxBjufA7xq11cZy+sAWDn/wM2r54I/Z+4kZm/M2pGEay5k7UkvZ6LO2sxyO7B5D3sJQAwPpFrWhOmc9x29ExHBkxn/nZS9rQun/IZUWJKzIKnJbUlIxhNCfeAbt0tel2+/T+IbsMOdb3xLPA/X8HACw97zzM8XF/O3dpO1JxSmL+xjeB3ebc0pNJnHb22Uybu3vTODDIfnAuXd2FoyM5vHDUVJjpZ6Wo7i3RlbMasKs34xugTMYCAI27+1EI0JIuXd2FxPZez/MJVbGfF103AGZMHQ0J4dpyycrOwMSnzx0cxuC42HJ64YoO1O8y37PGpGrPT74vBAcGx7G7Ny0ss+PYGA4Ps2t7XJGhKpL9LeCvGS+U8Phe00X7nKVtqIurKBaLuOeee+znpMqOJamjIYFT53u/Y88eHMaQNdYXrTI30lI7+lzl6H5ouoHUTrNMe30caxe0MPNGhDXzmtHZmGCO0c955awG7Oxx2E3XLWzFhoOmlZ98LwgGMgVsPDTM1EXWwDBY1FaH5V3eRCb3Uf3yeq5+oMeVjCk4b5mzXUGe1QUXXIBd/eazP21BC56zxkOvUXQfckUNTXvM79a6ha1oqassvpNHUdNRZ83rU+c3o6Mh4Vt+65FR+5sQdI/83mcAOH95B+p3O942bXVxjOVLtoVOBNKmaC4QLG6vx7JORwbRdAMPWPOWfN8TgmedL+lIbe+x177m+gSKmmGvO+cva0ci5l4PRXWFwZP7BpHOO+tItqChca/5rP3mdVt9HHFFdj2HofECnj047CpfzlyeaiBeZkGYskrS7NmzAQA9PT2YM8dhY+rp6cHatWs9r0skEkgk3C9lLBZDrMJg72rAAKCoCqSVpktS6shhxK2AdD2RhGqxTamqClguWGqxaB+PW4H5WkurfUy3kmzGR0egKioURYGqiD/ecY7FLrt0BQxJgqxpqBsdRcHK35Kw4qC0ZApqLG7G4aTHEC8WUQhgxFIUxXa1GjnlNORWnQQVgNHofGANWYak61BKJXscABBTzeekUCbeuff9Fcp4BloqhZ4Xv4qJCVJUFbFYDKqqQlWIi4gjaGWWrkBuxWr7bzWfN++RbpaVk+Y9NyzihFguZwtx8371U2ZcMUIYUldv91kmeX00jRkHDdXuYxFx4r7W3MKWt4Lh1UxaWI9imYbVVAqKokJVVAxc/Uo8ePYFWH3Dx5h8R89/+XvuOixCEMBkN9O75iC7eCmaLSXJaGiEqqj2fZQS7PZoqbHZc3yAk9y18dB+xO75M3qveBniRXZeK4ps990PRpJV6GC1nT15LR589AUUm1qYBJuKqtjzxguqokIgm3uXt55Z5rqPYctVr0WxvZNZLOOxGNSCOc/UGHm+CjTDx3JBrUHmfbbe6XgM8ZiKErfdqagyVM4NIx5ToRbFNLJs3YbdJgCkX/cm4Ms3QldVaLPm+j4Ds5/OzaJd9YzGJvZ9tcbE12ceL7mOK6oibDumxqAqij/pDPV8Y6oK3fBXkkT9oqGqsv28+LkjU/M0GY85awtXf5CSpKgqVEXcT7p/9Pz0mscxas7wZdSY+71SVBmqLNnfAv6amCEx9cViKnWtYr2zEsg2fCLgG6pSzzYWi0GSJPGzpuqQdYPrg3je8GN1jZ/7htB/x6n7HI+zY4jHDFdbzLckADFBXzz7VYb8QV+vKoqwDnMemd8Heqwxah2gy+qSTN1z//6XBVmn5JhguUv1mdeusgHfjhj3HiiqClUDDHivFaTNmKp71s/fJ3rexgVrICmrS5otTyiqAkVRAclw1p14DDHBh6nceaOqKtSSc13JYJ+117w2n4Hseg6i9yNqn6Yqwo5hyipJS5YswezZs3HffffZStHo6CiefPJJ/Nu//dvkdq4asNjFYiNDTpLSOKvcOcQNzk4koXimmcZKza12XYA3mYGSSUOhaKHNelpRbG1DfHAA8f5eFDo6IRXySHWb+YII9bFOYmYExA0iyFY7dDJQOgFosakF8eFBhrEMcEgOaIKKk/7TIY5Q02kcesu77L/J7ju9A00nqN343duRXbQEh974Diz41Y/tfFRS0V5JzHosIgWFMsGS5Jl226PmtSxNu8MC5wX6cTRtMWnaRznihKL9DIeFddhjiseZ+oqt7cxc4PtHQAu6RUupHl/kWAR5Sx2Ze/b1jf5WWHL9yq/fCADY8fEeDK83LQ6EDTBsjDLPgEfnROLHSlD1YG/J+VFsd7uX0rKxXTRCSDTfX0WWXEqSqDZPtvAAIonSrNl4/H/+AUnXXUyHQW0YFP25IbDGT8NY60DQlLa1Ik6gMRlxz2z+oOAxlpPUVpb9GdwmYurQbG5hmAJFj5u4xk11hJmqEzGfjzf43TG/KTXRbIp89dWkAJ8u70C1Mansdul0Ghs3brT9n/ft24eNGzfi4MGDkCQJH/7wh3HTTTfhT3/6E7Zs2YK3vvWtmDt3Ll75yldOZrcrgj3HrESVcqmE+LDp8qBzFjBRMll1eBgAKwgXWkwBW8lmIedznvk7EoJcSJAV5DvMuK+ElQfl9He9Huve/moADgsbYTNTOHc9EQwActqi4KYUI1rYLTWZViUv5UIVsPgBQOszT7BtCYZKK5X5WZZF8oqXAnAUSVvpsJQkMk6a3a7ECeQxq09EoQEcZcIv3xNR4OS+XqSOHIYhSRg9eS1ThjxPdTzjTrALQCb1x+OuMRdbWpm/NYqFzh4LdUy3xtx36dXONZaSQ6rW4+UpSQQLf36r/RyI8h92fXUpSQ3e7ixhEXVtp3QkIUSCRphEjsLfkITCm1hYK/+rl1l5AtJWTrUoMJodC7AuUpLK7hHXToSHVGva3TAJNCsXQKKWn1zhNljBoAUqyToSvc+BDG0V0MXzQ5hO6kKYvFxh7g1dohasZJHndQ0fQrXq5tddyfOPyYXf96Gs9SNg8+2fAZOqJD3zzDM47bTTcNpppwEArrvuOpx22mn4zGc+AwD42Mc+hg984AN497vfjTPOOAPpdBp//etfkeTdcaYTrEVJqquzk5Ke/q+vA8BSSwNUMlnakmQpVLSgTifWVDJpT2GDJIxNL1uJ7Z/6EgbOvgC9l70Y+U5TSYpblhNaESHKA29JWvq9r+HiM5dj8W23QCqVsO5tr8LJH3UsfLKVzJVWjGjhvWgpSbxyQfqueuQdatrCkgfY9NrUMVqpJPeQKBK2kkTopH2UJIVKPluqb7CtPLRSQiit6TZ5kDHFdpqU1tl5C1yKTKmp2V6FRNYkiVKSePCWI5FSYVBWSkM1+zx24hrsf/u/4diLX8VYlQA3VffRV7zOVScNXklKHTmM5k0mOQBRuMImxDOS7GaBSOmrNWwhz+PLQCtJ5cgZ/A6dEvIL5FUqmPo3bM8EaGmxf+qCZ+F1jyZbqK8EE50csRY7tIEqTUQBKOwc9WpjosC3Sb+rYawoUebtlNtZj2hJmqykt7WC6NmFfZrlbkBFVtqnoFIY5rLpvJ5Xgkl1t7v44ot9X1JJknDjjTfixhtvnMBe1RZktJIElFpaoFBJXHkXJzuZbJF2txsGwCpJkGWUUnVQs+NQMxl4hacTS1J+1lwc/pe34/C/vB0AnDikfndQJEluq1kxKkrWtCQt/f43AADLb/4iZt91Jxr27AQAvPD5bwINcdvdjlbgaJcvUq/sYYFRPNzOkj1HIedztkIptCRZFPC6GrN9RIiypljKm+3mZwnwmsV8KFNKkkqRBxiKYitYjLsdcYn0sSQl7/0b8PD9UOeawfLZhQLiC1kGWluBwUHERoZQ6GQDI+0cQfE4eLG8xClJ9D0XQVed1343lUsJcD6atOvnts98Bf0XX+FbpyZgjpzzxzvMusizQrjdUJclqS7YklT93Cr+oF2PyBwMv88udrcLg8lwlTGaaEuSd+D+RKLWt0ELYUma7ogq9ATFXwmvkSRU25mwkrw05YxhqoPNuRat/PGc36aaKNvdboItl9WuP+pGyvGISbUk/TPCVpIgQaOC6QHW3c4wnB34rnvvxoKf3wYlk6YsSey1dDJSL8UzPmCysRQ6OpjjtCWJjxHKWe5qfjFJREECgISl9MmWFYZ282JiSyy3Hd7dzgAAXbfd7YZPOxMA8PyXvgOdMO8JXPHoITtuXo7SSSwpSiEPGIZjmeEsSfUH9toJXWlLkpLN2olaWSXJvN7P3a7z9dcA3/0u2j75UQDA+KIl4oJtpnuf6mdJEgQb5jtYhSpIqTDU4L0RnWqn1BgsGJcEilnjzhfMuojCFfKDrHOWYlciVwGqvctFPghetbLKSuWShtDdTrQr6m1KEv0Mvi4MWijClRq620VBrdvUKemxVjuo9M51mM0DP5RjEGCS2Ya4fvpYkthG6XeVH8PxJviFsYZUc96V2wemfI3f5mo8Y5eywygP02MSldNNdmNveoyz2phRkiYJkgQkLHIEAldMUsz5e9WXP41VN12PmOWGVmxrZ8oySpJHmySeiCgEBAVLyE709dgKAkF+1hyrb6bgmjza7TuuZM8RGIaZFBVghWfabYoQJQiVi9FRSFa07+Zv3Yanfn03jr38tXbQfmxoEEp6DMkjh5yPe7GI1IF9AAC5aFmSKGuIRt1bqVh0KR0FKv5onmUBUSiKSFqZK1FWPCMWTNzAg3dts2HFqcVHOCXQMJz6BTFJYyeeyhYPUCr8lCRRTFKpMdjdzYuiHTCtcGbd4T7Ieqtzf5/7wS9CXVPt9TvIYkOf152dD1/QHxm+6FS2JIHaFNBqRNww1b6/x8MOe2CMHPU7zLsZdo7SCJqvXiQJvtdE7gXVnxASj6j96eKVFvXeTJdxhQU/j6u1rPgpcvwZv/krSWxNtdrcq159tKtqdeueLphRkiYY9CvscpOK+++gz/3T7yBblh5XsL6ljJgxSYKVzzBsFj2NY7fKW65d8b5eKJk0c65gMXsZFg3k8lu+zFhYeCR6TUuSZLnbsZYkyvXOEqqFysWgqQhqqRQKnbMwuuZ0AECx1VKShgdx7ovPxfmXnwH10AEAwJzvfgPnvfgczP/lfzvudrRljrqXcrHgxCRZx/Nz56NoWfZSliKojDnudna/GxoZJYNYXPzc7XgEWZLoHFUAIGmak1iVY7cDHHfJsMjNmR9YxojRSlKwJYlXknZ+9HP2b6J4h/0ga62OwppevtqnpINaCdnexA3O70p38SWpPCIIpmz0LoQHFZNkNIgsSZNhLqht9XRM0oQocJMgrEbdGQ5yVStH4ZkI+FmSjjdEdY/ic7NNd1QynHJnhl8M3MSjzLgqz7hS+vfx/e54YUZJmmhYL7EsSdjzte+iQFmEvNjteJTq6l0kD0TpUMczroWi66//i4vOXY3O+/9qtcMqSQXL3a712Sdx7svOZy+2hIXUQSeNcttTj3qNDoljRwAYkC0WPiY+RlGw790fxuHXvRWZ5WYCXRcFuGHYShITdwVHSYoPDSBhuQ42PHAfAGDut78KAFj9xf8UutvR8V5yPue0S7mVHXi7STyx5Gf/heWbnrGZBGnkZs9l+0tbkjxWaIPbvswu9FCSVpsKQeP255nDNKW5iLgBANKnrRfXSWHzN29D/wUvwp4PfjywLGNJCsEuRytJuqri4LXvsf9W06ZSbRjhPmI65Yaqp/zpqglq524XXC8RNIJZucR/SXBy2QSh3A9wJfTkBqUkFZevKLue6YSJEB4nW/diLEk1crcrZ75Wel/8dvarLcBONRUj6jo4GYQhE41qfBvc7naS8LfVoOjnhKD6lqTa1T1dMGXzJB2PMLhg4LFzLsBTv74b5195FgBWMO1L59DC5U0iKLa2uY6RwHlFoCSt+Q9TYCUxNRoX80HHtBBiBgAoNLfi2MtMKvDGndvs422PP+QxQjNeKL/lBcR3bIMhScgsXsac3/OhTwAA5vzPbwB4WJIGTEtKkYvZKlDudgTZoRH0juVQv2Q56vftNuvMu93tIMvQY3HIxQLkQsF2tzuScZQ0Otbo9d/+PADAkCTHigO3qxz9zKRSycUKJxXytuug3ed5C91jBoCzzHnQtJll8KOtVPftHhK60+295TasfO1L0Xv5S8R1A+i98mXovfJlZr8k8QeSHNNVZxy85VGEQpsT56bVNTArqpp2cnOF+SYbKWd+hmkbqAVxQ/hdc5u4ocw+eLHbRYktqqm/OPU8cqe7lXGvpiNRek+xOAbGkuTVhyre88kQtpk5HKJ8Oe52QVdMRJwDw243jX2GvN4nNm4kuDyNqWBJquYU4IczEfMrCjlDrbvjt0FQadv/rErSjCVpAkG/wBLMF7hAKSgxik1N170tSQVBQk06JolGsvugqyxvhSpYeZJojK08AQ89/DzyluVk94eut881b3yGKbv5m7dh379+AACgjqex4Fc/BgD0X3wF8nPFrl2GB+GBYcCxJHEuhSQJaqLPYeFb8KsfY/PBYaacarnJuZLzkrxT+bytnI1QzfPtAUD/RZczlqBxzgpEExxIAoVP5dwXR0461aVI2bCUpMYdLzAEGbZrINzU3ASF+QvxyL3PYOcnwjFBBgkLdMLRAkcMIcL4wsX2b57pTk079yAM5SzNbsfP1VqBt+TYliTP2+ScIH7wC9rcDH+iOkUQPY/2Bmf+Klb/6uLu7Oxsb6K3HQRj6XL7d3GJRzyd6Loqiv5xlf1ULWgLpzyHtdDxWNRuPstZTez8i6m1+WR2NprPmh8njbYGa/0SFCH9TMUVu65Fbd5xggArQCZDjKsxGX1PNYxSQu5pQ0Jcf11CPOfDgu4B//6EVbaXdPrfy4kAmZNh0dEg3mQFnPWgtS6YFGcqYW6L+d57rYOi90e09s1rNeuZ0xLu++K3fqZibF+YJM1lLrxknIs7os27ctvz+i7T78fcZrNPDWWsA9MZ/1yjnWSwCQolSBIrjDbs2MqWp4T8fHsHEgP9ANyWJFmmlKQMqySt+fC/uvrBW5K0eveLqNXVA4rz8u9/5/sRH+jHwl/chvq9u8w+dXRhw09+j/GlK5A8ethsP51Gx8P3AwAOvemdrnrtscUchcWFLVsAAIV2xzohSUDHYlNhI20BQKr7EDrv/yvjtkfyDPFKph6PAxmT2IGUp5Uc3r0PAHJz50OPxaFYSss4ZxmjY3fkQgE6F5tDKwjP3vobjJ20xj1egkWLYHR1Qe7tRec9dyM3dz5GT15rW5J0VfVcrSUJkSRhWZKgCYVYK+9ULAb94CE8uquPmaNeoOOcZMoaCbDWQi+xeVF7HQ4MmPTrjNupR6T1GUva0D2Yxgbr70o2uRqTKs5c0obBTAHPWQp3ELsdDfJaz2tJoSmpoj9dwJ7etP9FFCQAKiVMNiRVnDKvGcNZRzk+Z2k7sgUNLXUx7Orxr1s0DXhZVZbNjRhxfziFsa0Vj/7lCej19ZgXsj2geuQHSzrrsYhTQOe31qE5FUPPaA77+8c9rgTOW96BB3f0RW5zUXs9WuvjaIir2Nvv3O+4IuOsJW1VJ6toSsZwzrJ2JHyUlYaEinOWtQsFwbb6OM5e1o5UTIEEIFMooTEZw6Eh73sDABes7IBhAKri3e6FKzuh6QaSsejKSpjbdPbSNmTyGlpSMddFaxY0o7MhgYFMARutdzNoWomeDRlnzGecIpy7vB2qLCOmSOhqTODJveL8fUGoxnxZ1C4WmFnXL+d4c8qZU0XNYCyBF67sRFHTURefXiLgCXMaMb8thcaEitFsCduPjWIs53z7FVnCukWt2HDAzYBLY0lHPea3phjFPIhwgYfXnPKtx/4/f9DjjIJyp5mXRZEeS0djAu0N8Wk3ZyrFjCVpAkFPQwnOhCaEBoXO2Ux5SdPs37n5i+zfxKJC0JiM2XWonCWp6YXNrn6EEXo1nkZaUdD3oivNn5bCkO+ajfGlK5jyTS9sRmx0GFoyhaH153jWX2o0A8BpVywbt98OAOi9/KX2obb6OJJzTItX8shhpnjbow8wSWBjFk26y5JkWSXkgkPcQFtmeCINwHTBUyirTt+lVzHnDUWBYa0kIvIGxRpfvnMWBs+72GboE0KSIK033ZlO+fi/44y3vBzLbvmybaHytECZF/uccyNUfMG8ebYlMbhCR4Dqu+xqALDj7bLzFtjnvHas6A+NNntOYHN1cQVx6ppKhJDGZAySJKExSVkFBfeTtkp4ubU0JmORYzckSWJ2H2OKhHru45iMKWitj3sH2AY2yRZoTMZC7wjKkoTswsXIt3cKFR+vPlUrUWV9XBUK8ebz8h94VKGYRlMyZllCKNdRRUIypiChVmbd4CFJQH1CPE4a9QnVc0wNCRWKLEGW2bnsh4SqBCo/cVVGymPnPghhdrYTqoK2+rjQ6tRkvZuVWDwkKdw46fIEdXEVcVV2rQ/l9KEShH1XJcbC7cypVFxhlOuYIk8ZYTcSQY0k2XOiuS4mHAM/V73clsm6Xy685lR1YqCccVZUDxf76oUwG1oSrO/bNHZZLQczStIEgnG3k5zF4elf/Rk9l78EW794C1Oe3oHPU4KjSNB23O2Cd7B5S5IIJYF1iSctoC1QREkjcUGjJ67xFeoJ653KMchJ4+NAt8kuN3jOhc5xSQKs/E7JIyx1+oI7fsYkwnUsSTylumO9koqWJYliqisJaKxp65IWT7gUVEiSXa/Y3c5i+QtI8Grjox9l/lz8k+87lqRY9VwjvNa5SuTaTbf8BN2vfiN2ftx0+dvwkz+g58qXYeP3bg+sn/4WjF9yGUaufSe2feYrnm25d+TKX7iJsUr4PWJ8uj2UgZBuZX4fKfbDI/FNVwz+eRtG+BgTethRYhiqFe4wlXzhJ5e5avqhWvIUXU3QvHJZQmv4zMLO8UoF57BXT4XpORX6QFCtrkSph57ztXSDrmZ9moeWNEPcMONuN6FgLEnUjMssX4UtN/+3q/zw2jMwtvpkpFeshkEpNgUBcQOJp4lz9NEjJ52K5q2bmGM8u50ImkCoz3exli463xLvspddsAh+KDWZtNKxsVF0PPB3LPzpD/HCTd+CbPkIa3X1trUJsBYbS0lKBeRqspUkD7ZAueDEJBkUQUF2vrvPdJySV74gIxYDCnmc8eaX4elf323nlgJgU6qHVpIuvhil+gY7lik7Zx4W3n4rAHf8Fo2oC1iYWIGodfZdejX6Lr3a/juzfBW2fPM2pkwomUKW0ffVm9HdnwkuGxJ+wkzYpK1uNcYE/30Jc98k7kNKu9uV8zEKEsJEwr3XFOCL0teWNPeN9Go5EnFD+KITDvp+RN9F9b4Jx1tyRtFoKlUqRbGBok0JLyKa4AZEh2rwXCboUbPK5OSTMkwGavFaRapzEl/rcueu7qUkTemVeWIwY0maSBCqYPuN85+ARjyOJ39/L7Z++bu2UgGI2e2IYJ7oOcoc55nVAEAXWJJ2Xfcp5m+RUK+n6hhrC60k8eWDWMmKlgKkZNJY+763ou3px7D6puuhHD1ijmf2HGZlkiTYShLB+MIleOb2P7rqjlnJWF0xSba7Xd52t6NjkqAoePKOv7L9pFzwSoIcMWYdZjvJnqM44XMfYc4l+s14CF83Ox40UcSSFZj/W9MSo2a94wuiLmVewkutP6vVWoxdSfkqWMv94o8YdwUPq1JYYSQqcUM1wbdtGEZoAZZVCMUCqgjVIm4IWCWr0kZYqP9kriaVomJGLWJVneYKZS17z66D0/s+HQ/wW1drzm4n+f/tBS1ETNI/K2aUpAkEmYa2ihRhAtIWDZHAneuylKReVklScllXWU3AGHbgHe/DC5/7ulPGw/JBK1i0IsSXFyliNIiViKbXTvT2QDliWokKs9i4FAmSS0nS6uqFyUZJMlaeGc2xJBVs4gbakgQAWgNrLaLd7UoNPpYkCy1PP06dMDD/Nz8FAGQp9rcgqD7JequFCkI1KkJYkTbq4lzJWu68j/4WJS9FrlKCAkliY8TKGQvbdZHVKNwxEWgFTuSWUav7UmuEd5VyMONuFw3VsiQxCHK3+yd+RIwlabL6EDUms8oqpKu+kNZCv35EyjMXcHYqWme83O1o/JMaJmeUpIkEn08lyqsyfsLJ9m+Rux2JWUr0HGNms5J1K0nCBJ2ShPSqE+0/SzxxgwVGMaJ+85akIJc+I55wKWuGokA5ZlqSCqLg/c5Oti+pOiHZQsqKWaIT9QJUTFIhb7uuGSrrccqPg1aMaGseUy9lsaKtPfN+9wubOIPPrxQWiWP+roUEkT9MkyRJhIlJCgOJu6aS8YR9H3kXOQfsoKJ+TCRJsim+yd9REaXvgNnjKK5jxLhZiqD5RHH38R2yz7mJ/nDXKmh56olNUxeiRz7VFaMZ5XriwLpmVr/OIMgVuk5XgnLb82S3q6AvxwtmlKQJBHE/IQtmFGEoferp9m9NQDCQt5jxlEIesSEnLkm2LEm0wiCyJAGAlqItQ2K6UZoZj1a2eDY8TaSIcaBjjgBLSSKWJBGrWn09CvMdpjTa3Y9G0lK0im2s5YnEKJl5kgitNmtJopWk4StfYrP3AUChU5wvyEWoYC04y7/1BftQziNfVFB9dQf3h7om6mLmxcDGkotUf4kM7ZoWqkxl1he+tShxSF7sduWiUktSEIKsZMxx4THzaBR3u6luSQoL+t79szE7VYqylAMun6DrdBXnlfCdj9Dl0KQtkzBt/ll3/vlbXRW2uRqVrTbKj0nyqI92Ky+r5umPGSVpAuHKBh3hWq25FYdf82YMrT8b6ZUnus4b8bidZDY+2G8fJ+52BYqVzcsVjiVi8LAkUQoWG5PEKlVhkoD6KUn5WWIa6PG16532raSlW7/wbYytOglj3H0p8EqSxXbnRQEOAHpdPY5e9XLsXHsm9v/gJ4AkYfsnv4D08lXYdd2nhX3i477UsVHAMGxa8tzseRg8+0LRpUJsu/WX9m+55E3WwPQh4to4WTubXgut25c6wGlB4i1J5ffJCQ73V1S8+sQrA16Ck18flRrvPopk+ygCP+mT2N3OC8ffZ3VGSfKG6P3wSHNWUZ2B11TWpH/dU/DxT3cGsuozvFGC/SRoin7jmcznUx4h0AxmlKQJBJEvypmssgRsv+Hr2PCzP3pSaxNCh9iQlfBO120liVZaio1itzFGSfKw0tD1aIxVqQ4G9UUMQzPOs+XJhQLUo2ZMldCSBCC7Zq39m5AqHH3l6/HkH+7D2ImnMGXpZLSA4xY373c/d2KSBPdy01e/j9998D/tL/zhN70TT/zvgyh0zhL2SeEIFeKD/ZCz4zaD3uN/esjTMifCyPkXCwkpjr34VaHrCIKX8FLrj0qtqq9kt9A/0FasvDD5SKowKFr4rhZLFw1+jIYRTVEmZYW+61WwJJUbDzARIhDdetQcWP/s+P/t3Xt4G9WdN/DvSKO7ZEu+27Ed5+JcyI2QcDGEXiBboLRcyy40pWHbhW0XttB2W6B9aWEphd3t8tAtbdpuC326BbJLH2BZHihPuJSWNiQQSCAQQgqBQMgFkji2Y8fW5bx/yJJnRqPRjDSSRvb38zx5YkkzZ87Mmcv5zTlzppibMdr3Ceb+bv65uGKUo5JbjedQ7Bo4pdbktCSZbS0ssstvbtrGXafLeQrJudloY9pTdbREBklVMDFij6WZCsoM6FD/8ovovPcuhN7akf1NORhAMqI/SpsyMNI+q5OdRhH8qJ5tkiRVN0AzLUkDC49VfZYH+rMtSQMN+l3bxmbOyv493D1D/ZvmHUbalqT6V14CkH7hbWaI7VSe9QQsPH+haUnyHPgQnv7xEfY83myLl2lS7juedl5xNbb+y48NZrF2OsxXeVG+vRyw/4R+NJ7U/V57MSn8jE1lqh35utspafeSvM9dGXQPVFa+rbyLSDftAt0GM6yMcJiZdGRMv/x005kk11TlZlI+O0aFlbq19HbRgvuVA4uIsXV12PZMkm0DNxQ/ran0bG+Vsze9WsQgqYIykfjEg+JWDrz804Z96Yp+ZkCH3tu/h3m3fAtL//6z2WnMjJimfN5ISPq7Rko1cIO68q/somemJenwkmWqz96DB+D+IP1S2NEW/e52Yz0TAyCMaIKkvWdfoPqsbalSdlPMBkkGA0x8ODSa9zel3X/zedXn8I5t8I8PxR6vj1o+00iQcrbfgRUfN+y7YvVk5rRuQ8XkJl8rj56IwRvr9YZ11r/7qL+8zPFXCuXDvvJ4Oftk86dno/UDcoNQAYGQL/dt8YB+WRiNfuST9dMJ6LyNvhhGZatdRtCb/hwusD3MTqNltSUp4s//Qm0lr4WytqLYQDVzTNQHzOU/n2LOM4Wei7RyXBSil7uQN/9+ob0Om92+pW5HI/m2sM9tz/FXa+x+XlSbZiFG5+JyX3WLvXUY8Oa5FihW3FOtIXGrjC+TraBShgDPN21PUxA9jSHsPjSS8/4k//jIaEmvD/H6KLz9B7O/BX1uDI+m7wrLbin9kkhFJTzvc0t5hgAHgGQ4DOwbn18TfPg8LgS9MprDPryxbxAAcKBP/ZyOPDzx8tC4zqh1ABDvmQiMcoKg+Qvx2o0/QOvjD2P/Jz6d0z3ujWv/Gc1PP579fKRnFkY6u3WXY8U7X/4qkl4/en75I3gGBzD/5uuyv6XydI3UOn7GRNlJEpD0qrd/vqBROY8VheouhdJb3FWPsUQKiaRAPJlCa70fG9+a2L9iIS8Oj4xlG9liIQ8kScLBoTFT+bP7Dtbctghkt4Sj8RQ+HJwIfjsbAmityx/QG/X3P2lWI/b0j6CnSd2V0uxzV1oLp9Xj4JExdDembz40hn2Y1RLOCcKO7Y5i865+AOntWh/wYHqjcXdObXkLAbTV+TE8loTH5cJoIgmP2wWP7IKsczHUvkQ24HVjcWe62259wIPe1jB27BtSTdMZC2AsmUJjyIst7x5EOUyLBrB972D289LuGN47NIyuhsKtt70tYezzH0WLQfkD6oqH1Tr/zKYQXBLQUqc+PhZOS2+7xV31GB5NIhr05kuiKo7viWH/UCK7LxarIxrAaCKF3YdyR1m1aklXFEOjCTSGfbk/5imX+R36vSaMTBvPc2NIp0wslv9Jsxqx9/BIwePTLpIkZfep+mD5AjM72d+aou4KXUz6s1vC2D84ioERc88EA+lr+AeDRzGjyeSL48vA6rO9ADC9MYjOWBBvfjCk+/uCaXVIJAX8Nt30qjUMkipIOwS4UizkxaEj+SuQ+Xb12S0TQ1Tne2Fpyh/Aq//yY8y95VvY8fX04AP1AU82SOppDGHngSNIJgV2Xv4VhHe8joMnnKKfli9PdzsAKUVLkjbImt4QQndjEMmUyAZJqWAIr37vDnT/5heIvL41O20yEIDw5qk0BILYdekV8L//Lg4vWprz8/sXfQ7vX/Q53VlHuqbjaGt7tpXn0PEnl/5kMdJdE9+5/B/hGehHz13qLnGBPYWH8I4GPTl3GrXbL56ni2SGUd//5ogPHwyqW8VKHbmuJZJbsfTKLowl0lHRsukx7O4fwbb30y2YTWEfokEvDg7pV5ZLDYoKze9xuzCvLb0Nn3gtHclPiwWy35lahuZz2Cejt1X/3VnFaKv3o61evV1nNOVWrpoUlcSwz6M6B+SjLe9kSkCSJMxqLu6C3tsaVrWSTG8M5QRJLpeE2S3p9Hsag/jT+Pcd0QDe7y+90pxZRk9TCG9/mL7BEvC6TZeJ7HKZ2nZKVo8b2Z27jLBfzpZzS8QP2LcL2SboldHbWniE0kL8Hjfmt9dhYCSe05U3n3zP0jRHfGiO6ARI0Bybitlb8kxvRLnflirsky3vY3qs7HdO3aeqIZGyECQp9ptpsQB8Hhde3Z0OksykUR/IvY5XmtXLqNslFTxftteXfh6oZQySKihz8td7JqnQQ3EuE7cw9d6fBADxujoMLFqK59c+lv0u3zMMb17zLcNl5HuZLKDtbqd/YGnXYs/5F2PPORdh5eJpE/nNM7BExhvX/bPh70YS4QgwHiSZeW7KjPS2FBhYsLi4+XUetswMV56hfcmtltUHpM1OL0nmuyxou9Zol6DXrW1iWu28hfOnbuWx/X5kTj7MjiJVyQdczT6crd30+d6wbpbV/U05tZVhxJ2g1kcPqxSnbBplz1C7R/F0yjqqcKfMK5USprt8Ks+lEjSvZbBpG5f7/YTcFew3NTsZVknuy2Qn9uhCbzw2s+/na0kabc0dKU7ZgCJBMv2EY9Kn/zJZAEiF87ckGXK7Ve9VShgEBKWeBJTDjpt5bsqU8Tz1Lzsp56fdF34257u8CWQ+SZJqqHUhSXkH0siw2g2oHI8k5Tb1K/6G5LjnoEzFCXkCMaOLXd7udsq/K3w10y4vVeJLjErJvdX4rNBAFpXclHZUup11FDhPqfcYlJVdu085Oc/2TZLBSarJjtc35JMUQn+EOZ1ptc/COe16ZU7+G5WWR/QjAAySKsrofFrozq6ZE4n2maQM7bM7QPEXe1VLkualtsrudtoX1qY0g1ZoJRQvo03U5W9JKjlIUgRg2taaYmWyNNbciufveST7/eCc+dh+/fespydpujV6C+fTaqW7UEtNMdtZ+1C7thXGeKht68uX8vxdLqUuoxyBkdkHdbWLLrVyZ7klqZTR+xxUEa3JetMUY+WF2JW+WUH2KnQqKXTzWZWW4m8JmnfXWctWXpKNaVFlsLtdJY0f0ZkKhpVRWMyczLVDYGccbct96F95sZck8912PAcPZP8eVow0B6jfOZTTFS8bJOmvRzIYAg58ACD3JbNKpQ78rA6SbOpuJ6W72wHA4WOX45V/+Qkir7+Cdy+9Aqk875tSz6/5DKia+oSJ56asVt7KUTcodOfNuLuddVZGtytWvi59Rour9t1lvbzZ3e2olPT0bggZbs8C6RWbE7OroG0RpfIq6jVhinNwOQ8/J5a+E/PkFCkhTB/nym7SkqR+xKF81xebu4NyZ7Adg6QK0r5MVrlDV7q7XbGnVt8He7N/pzSBkHfv+4plqgOzQs9pKFulEgbPJJXekjQRgNn3TJLavk9dgH2fukB3WlPpaRKUNS+r1WP5maQy3BLXpql9lqMcy8ymX8T+bHRjYKJLrHIZub9bUY61L/aZpFLleUOAKVa7+tlxA8kupaw3VUapXUmNsBLqLIXKQ/MKQwvpSqqberVyc6Q2cllbeMqvAin7v/kuKGYqAvm62w1392jSKv5h5J1//1UkgiFsvzZ38IR9X/oKEqFw+qWnmnc0JAucrJRBktFIbqWeBBKRiZYkbZfAYpU8MpuJbwqxGiRZfd9LMWlaegan1O52RayO1RYf88twUP+wcXZf5K2mZuWGkFYxL9e1k3LftbtFjnIVM/AJS6WWlbf0dB/F0TmOtXtdOY71cp8+2H3UfmxJqqCUpsuZcn8uGCSZSD9fN7UBnaGytRVYs9elgSXL8Pvn3sgJggBgaMXH8PsNO3TPBIUqRr79e7J/D8+YnXe6Us8BSVVLkj3PJJVKe2LLfHz9/92Ked+7Hu/+zWoTaVhdpsnpMNGNpZCci0qRZeWUVhpA28XOeXcWi30mqVSlVCB0TwUGyZWru10xnFHqZKScMbVTjnuyn3a/UXYfN9tib0Y5AxltyoyZSscgqYK0L5NVKtQsbGpnlyQkAwG4R0aQcrvhSqbfgxRvaMpJq6QDNc+bvCVtE5VCoSAwsPvd7N/vfvYLxeetgHI8k1SqfCXx3sWX4fDi4zDUO9/+ZZbh5Kl9dEodVBTIj84If4WoJrG7O1mh5RnIt6tX84Jl97JLSc9qy1Alh1TXo1xVtiTlZ7RprFxvSi1uK/tXKS2igL2V52Jxl7SHtiyVPSPs6sFZ7iDb8BhkgF8UBkkVJDRRkpVd1uzF+cVf3I9pG57BzjMvQGzjnzB4zKKcaSRI6oEbYM/dN6McFmpJyrzkdWTGrLxBWOGlFFaO0e3sll1DScLggiVlWUah/amYE2rOe5IsdOl0UutRvmUU20W1ULp20x/y1t4l2v2eJCOFn0mylFxJWCF1JtUgSOVcThnTpirT7DjKZ2itdhGuFgZC9mOQVAXZZ5Js3J9drnRr1OFjl8N1Sh9GjsQxMn2GQR4Ud/ltykcp6bz8w7sw/Zd34r3rbjS9jMw6W6F+T5I9b5Iu9cSUO/x1+U905bgjrh29Tt3QUygoM/6sP1P5ur/pdYm10jJmlKY2XbuV0gpmehkOuhZbKXu3S7Jc4bEzOE6n4aCNN0lUq4XPCZVSJ+ShFGUZadUtIZk0fu2IFeVqMbR71UupS7CVXB8HbqiglGYIcOUhckxHHXye3OKQ3RJkt4SGkNcw7aVdMfg8LizuqkfBQ0/TK86ug0MvHY/sgs/jQm9rWGeOCQOLluKVO36J4a7phtM1BL1wuyW4XMDMprDuNjOSCDmju50y39rtVlwF3Nr0bklCU8QHt0uCVzbYhhbS7W4IIeB1o6cplPNbJn+9rWH4PUYthcWxsv6ZPMxuyd0ne5qCCHrd6IzlBtBml9HdmDvse3NE3WrZEQ0g6HVjus60pZrTGoHf48ac1ol93eN2oTHsheyW4PO4sGBa/sFR9CzuVI84Wcp7khZ01MPncWF2S/r49XlcqPN7xs9dE5oiPgS9brTXGx+nHVE/gl637nbXmt9ubb0BdUsWKxLl117vR9BnrjwzFk6rz+7XnbH0sdXTVHj+oNeNWMiTvU5p9/MciuL3e9yY2Zx7risHo92uPiCjLuBBW4HjpJLao36E/TIaC9RbSqV3DgeApV1R+DwuLMpTnnqbsynsQ9gvoyM6ce7viAYQ8sloCtn0TsUynz6sHjvK7MxsDuW9Lk5lbEmqoMT4HcxMtyTlAVMf8ODU3mY88dq+7Hd+jxsretPPEw2PJQzTjoW8OLW3GQDw3qERw2m1x6m2m9TKY1pV+ShFVyyAmc36B50k5XalKXSTNxby4uNzW7Kfe5pC2PnhEby5fwgAcPLsRjz/9iHEE/pNTMrR7fS62506pwlPb9ur+q4x7MWBoTHjjI37+LwWPP36fsNpWup8mNEUwoa3DgKoUsVLAo7timY/7h84ipffO1xSkl7ZhVNmTzz/pvdeoemNIUxvDOXsX/kGrzBS7CNJmTzomd0SweyWiX0kb4urwQJ9cjr4eefAxNDtSxTbGkgHLSfPbkI5BLwT5w2lpd2xotNsqfPD5xnEaDx9XJWyx0b8cvZcpQyo/R43Tp3jwR/f+BAA0NsSRshX+BIlm9yWXQ1BhHzWA3TlKanWgiQnPDNjlex24eRZ1o6NzPUzw+yxJUkSlk3XHxW2EL1jrBokScIJM4pbh3JZ0FEg2LSJ35O+Kff2h0dU30eD5utDGS6XhJNmqt81eUyH9ZsqhZTzFFLMsZOhrG/SBLYkVVBKGyQpftM7cEy8Q7RoyuXZNRy01WT0njWw4x0XRuujfE+S3hDgel0XrFSMzEwphDpN2W09QMhZruU7+8a/21G5kvJ+KDAtzHUhUXeDKn/l1Uq3lhqrS5tS6RYVp2xD1Usmq5gPp6v1bl9mTIV1rDRuUXIyBkkVlG1Jyj7vYHx6cKnuxNtXUZckSf3uD5veNKmXR6uV12IekNQ++6JtGVNStiQJj7muAHYMOqCdRlm2ud3tKlHhL/SF4dfmllHBq1+5FpXveZSpWFlSHpmWh5zP83fudM7brqrgsIwvRCbnc0rgTuaxzKgUDJIqSNuSVEixd2sLBSYS1BUV7QP3xarWyUi7XMMgSTG6HURulzy9dbCjBUE7+pKqJc9gVDjTy7U6fYGF2DPaofkgP/eBU2vpV0Khlt/8U08+tTr4QDGDZ1R5BHIiIqoSPpNUQUlh0N1Op1LlVoSwVuokZiY1qqQXywn99SVJvd20hNeHPed8Bp5DBzHSPaMMy9ffBtqXspaju6MVlb4hXu5VrMQmrNXAwC6Vfl8RgxNymql9BiiPqXRelSTuQ7WGQVIFZbqSZZ41KtyNq9iWpMK/K4Myu4Ib/VaY8tMGmO4CD3O9euudBmnpfGfHSihbkoRQd7erQntuoVYYWyqoku6feSbVdjk0kXyFu79JFtaH1Mw+P1b2YLqIeay+14kmr6lUoZ8synZNrzFTcZ3twO52FZQJkuTxWnGhdxWVs2Umqbjw29bdzux0Nq9WTne7Cp8NilmauutW6d3tLC/facsotYthJdbHyrST8II0VUMFu9d7Mu4bgPF6TZZ1nizrQdXhxGcuyRiDpArKjElgNiYpNnYp/OJOSTWKnG0DN+i1JOkFf2Xu66VsmbHalbBcdwqVqQpoB24oyyKrzigQtDRzvkkk/b/LRf08yyQtNCMlRAtO2FoCoqjWx0p3MyQi+zj5XO3grNE4BkkVlEilBwrQe0+SnuIHbij8e3mu++byW86WHkmaaKkDnDMalVFrkR2j2xkVp5ngNd8yS7nA6L0nKf+0RS/GVPp2c8ZeRZXAEIkyeNzbj9uUnIxBUgWNx0hFjW5nZ1whQd3dzi56q6U/IIW9p8Xc0e0Uf1t9f5CJ9EslRHGjbBmnaa08Kz3MuPWGJFNPJVlLtERW1mcyXvhLeneWyYDZiduNDUmUwTv/k4OTW5fIWRgkVVB2dLvse5KMpy/2gX4zx385HkY2e+Ip57NWEiRV+nYEZHYEFEZBTM6gBU57XsiGZRTuApp/XnPL4kWPyoVREpFzGR+fTroy8DJVexgkVdDE6HaZIMm4NaE57NNNx+2WVP9rtUT8xhmRgMaQdzwv6a+mxQIAgPaoet66gMc4LXWypnSOL6s+aJx2NOiBz5POYEud/rbIyYOmu11zxNx8yvmt0m6jroYgAKC1Ll85qE/qEb96kMmAx21p+bGQN+/d7vaoX3d/KDUosUyTfmM490W+mTxk9s2CSaqCsPLwKJolg76JcvHKxqfOyRi0Fbqvkjl3dEQDRS9Dud3KEZoUGixHT0MofQ6xuwW8Ejpj6XNRzOQxVS5t4+fCsL+2B9Rtq0/v28pzQTlltldb3mtJ7St132wcPz5r5ZRbrXzGgtU9B9Sq2j5j1Zj5bRG8FxLwy5nR7XKdOqcJg0cT8LhcqiBCeXFvDvvQFQsi4NU/UTdHfFjaHcVLu/p1f5cgIRr04viehmwac1sjaKvzo15T4Q943JjfHsGGtw4WXD+zAzd0xgII+2RE/DJ+v/2DvOkd2xWFAHBkNIGohQNc2QLXEPKiOexDPJXC5jzbI+PUOU2QJAl9Mxuw6QX99LTmd9RhNJ5UfdfbEkZLxIeIX8a+gaN5513R24R4MgW/Jijqbggi6HPj5XcPG+Y349iuKN7vH9HPX1sdXC4Jfo8L2/cOYvBoAoDOM1ImlhMNetA/HDeVp3Sa+SukizujOHBkVLWOp/Y2Y2QsifqgBweGRrPfL5hWh7BPxiu7D2N4dGJbl9Kdzyy3S0LfrEZIUvpYWNodhexyIeg1f+pc0dtUnsw5zPy2OnTUB3LOIYCz7uZa1RBSnytrSU9jENGAx9LNrnLojAUQ8csI+2q7yjEtGkDI667YeiyfHsPQaEL3mJos6gMeHD+jAX5PcffsYw4/PlfMaszWJ6oRIGXqGRG/B8t7YhAC2PTOocpnpEbV9hmrxjRHfIj6AHn87rRedySf7IYvXPhgL9wKUzioUKbhckl57+hE/OZO0Ga7pUlS/mVlxEKe7HYqtC7aCr/2jm+hbZXhk9PbPeiVoWwoMFqviF/OCZIy2zJfF7vM136POydAyszfEvEj4B3CyFgy53ctozvcmVbLaNCrav3QzpGvC6TyW8tBkkFLj9sl5dzZ8sou3RaahpAXPtmNaMCL4dGJYLBS70kKKSpEjXlad43olXEtKtSSZHQOcYJSehibPYeYUcl6kplzbaXyYeVGl5NVcj1kt2vSbDcjpQaBRsdntVuYfAbn/0r0OFDWM7T70mTs8WA3drerEVaHOzZ8OLpMx4W96RY5sh/UQYMdWSp2vUrtOmRlsWYqgEYDgZTzOTEzDF8wamJL8FzvbGbPXyxGIiJyCgZJDmGlklfJSqOlfNk5Al8JgYnbIBgoZvlGjyIUk3y1HgNXBY+5Y4DbTl0xzl2AlOdv0+k7uErt3JxNbQymiaYWJ10nnJQXModBUhUVe8CYGfXO+M58edjZdFtKSvaMaJf/U6VYCabMDM9sVDzaTWZ3ZdJqcmb2JVZ4awcrB0Q01aWvWTwX1hIGSTVCfde9tIOsXP1Q9VIttiWq6BfpQtvdrvR1tWVQK0UMU473rljtblfot8zHUnYVuyrGmTwYBYJOC5iclh8ncUo/eGfkgoiInIpBUhUVO4RxqXWMctVRSn2uxa58qVqSbEjTKZW6UhmVTzlWsZJdNdlSMTko9wOrL0i2im8/stckOU3SJMP9kkrBIKlGKCvqZls2Kn1y0B8C3HwmlBXdUgIuuwchMB4Ew/qyzFb+LA3cYGIao/0mpyVJv13QQo4KT21r90xeCB2N5UNERLXG0UHSjTfeCEmSVP/mzZtX7WyVhbUKY4ktNiXNXcZ0LY7gp7fc9MtklbejS82UPUGXmWeGSkrfROBl+Jya9icHtcDVYv2aLVvFKWerbZkbpoiIDEngDaNa4/j3JC1YsABPPPFE9rMsOz7LphUbFpk9yCSpwhWDkrtM2ZAFSYJbEfonbdgAdgc4ZlOzu+iMBrTQVuptKQtL0xZevlFR8rrjbCwfIiKqNY6POGRZRltbW7WzUXblaEdKVzxza5Zle0+STs6sPWs1kd+SBgxQzJxM6a+/XcFjuZ+bMKv07na2ZcU0090OeeuNbMJdiYiqxWnnH4dlx5EcHyTt2LEDHR0d8Pv96Ovrw6233oru7u6804+OjmJ0dDT7eWBgAAAQj8cRj8fLnl8jmeVn/k8kEkgkE9nvXAY11VRKZKdNJhOm1iWZTCChEyQkE66C82uXlflccHma6RIJ47wmU8lsZdkluZBIpsbzmDRdXtrtqMy/SCUQj7tU30mSpFtB15ZPMpFM5wupvOsfjyfgVvyuzXPm+6DbjeFkOj2fSza1bun1ShpO43Gny9KdJ4/K5RjlU7l/AYAL6XT9buDI0YQiP/rz6xFiIs1UMoF4XL3Nkzn7dGoi34m4alkplwSPJFTfJRPj8yaSSCYSECnnnPJdSFraVlZl0k4kKnde87oFhseS8Mluy8sUqfR+bOa4Vu8zxeVVL71EIoGkYh9OxONAqnI9zifyIVX9WpSP9hxohfb4pPIqpaymEr16SSW3mbI+4YaAlMp/Ha6UzPJdUuG64GRldr0l4ZRb4Toee+wxDA0NYe7cudizZw9uuukm7N69G1u3bkUkEtGd58Ybb8RNN92U8/29996LYDBY7ixbMjAG7BpKV+yOiQnDu/lCAK8eSk/QFhRo8hdO/7VDEjIxUnNA4IOR9Pxhj0CP/ubL2nowPW3UJ9AZmvgMAF1hgZEEEPYA7x2RkBiv2/ZEBN4eVK9EZ0gg6jNYziEp2wzidgHjMRJmRARCnsLrCACHRoHdR9LLXdiQTqx/FDiaBNoURZ5dBwmYFhQYjAND8YltlJkXAN44LGFsPD5ZEBPYOwKE5HSaLgnYO5xOa3adgM+N7O91XnXeDo8B/WNAoy8936FRoDUAyCbqZso89EQEBsaAem86vZgvnVaTH/C5gZRI5+HgUfX2V66TEMC+ESAgp9NRUu5fQDp/86ICiVR6ngYfMBBHdh9SpmvkwNF03poD+X8XQM7+fCQO7BxUHxspAewdTm/j8Pi+8eHR9N2wRhPHQyUZbWs7ZPblBr9AR4VOa6PJ9PbO7HNW7R9J71cNBucDADg4CiRSQEuefcaqzLaK+QSmhdLrAOTuc+WWyUdQFphZV9llV4Le8UlUbe8dAfpH818XK2FgDBhKAG0BYCwJ7D+aPkYKnQvLJXMuylznp6Lh4WF89rOfxeHDh1FXl/+E7OggSau/vx/Tp0/H7bffji9+8Yu60+i1JHV1deHDDz803BCVEI/HsW7dOvzVX/0VPB4PPhgcxcu7DwMATpvbbNitSAiBp7Z/AADobQmju6FwzegPOz5EfDzqOGVWI/705gEAQEPIi6VdUcN5n3x9PwCgvd6PY9rrsp8B4PR5Ldm/letwXHcUL+7qV6VzTHsd2uvz10ae2v5BtlXH43Zl8/uxOc2mXwq75/BRvLZnICdv+dZJkiScNrcZAPDSu/04eGRMNW88HsePf/sEjll0LNyyOyfNRDKFZ3Z8CAA4oacBEX95GmT//OYBjMSTqrwVoiwnK/Np5/XJbqyY3aj6/c0PjuDtA0csp1uMQ8Nj2X3p43OadVtZtcfTVJIpq65YAHNaC9zxcIBqllVmW3XUBzC/vXrbKpOPWNCL47qjVcuHkal8TNUalpU52/YM4v3DI6rvyn39UnJiOWXORV7ZhVNnN1U5N9UxMDCApqamgkGS47vbKUWjUcyZMwd/+ctf8k7j8/ng8+WG5x6PxzE7aCYvHk8KslvOflfo2YvMtF6T6yLLMgRS2fSzy5LlgvNnppXHp818zqSVnc6TVOVLOV16WuNleWQ3UuOtR263BDE+4KLPW3h7ZPMgJ1TbsdA6SdLEdB5ZhuxO6c7rlt2Q3bn5d7nFxPYpsH6lkGUZ8ngXMrPLyN3+5vOmKmPZnTOvLMumtrMdvB6hWpZRV1QnHduVMnF81ta6V6OstOeyapnIR+6x5TRT8ZiqVSwrY8rrVkY1tpeTyil7LnK7HJOnSjO73o4eAlxraGgIb775Jtrb26udlaoyPbqd4u9ih7EuNJSx8nc7hz229H6lEhZbzHZxzpMv5eO0B0yJiIiIKsnRQdI//dM/4ZlnnsHbb7+NP//5zzj//PPhdrtxySWXVDtrtlBWRK0FBUVU7CtQ6ZWK2JuUgVU1+n0yGNDnpM3CMiIiomLw+kGlcHR3u/feew+XXHIJDhw4gObmZqxYsQLPPfccmpubq521qjI9BHieCe0MRlSBnt6yrCysClGSk1/66dycEdWecr/QmYiIJhdHB0lr166tdhbKqthKsPnudsqucOVX1PtsqhAJqFvwSpu/nMOeVLVKxwiNiIiIpjBHd7cjfWZbP4rtzmctL/p/Z1hrSKp8WFBckDT5IwgntbBNhe1NRET24+WDSsEgqQaZHBlbpdytVlanzc5jfRadNIpPxUnBgJPolSUvNkRERJMDr+mFMUiqoqLvkBcxul0lDoZiR9DLqMYbu0reLpP0MYdqnzsZvNLkxX2bqFJ4LaFSMEiqQaYP+gp0tyuk0LuKq92Vysl3UkrNmpPXjYiIiMjJGCRVUbF1WLPd7ey4g1Kooq0MgUqtlFejJanU1q9yqmYjVbWDVyK7VeP8QkTVxUsZlYJBUhXVBzwIet1oDHtNTd8c8SHodSMWNDe99uTQEPZCkoDWOr/VrGJxZz3cLgmLu+rzL08nKCtUMSnm+Sqt5ogPfo+7qPXqbgjCI7vQ3RhUfd8ZEpBdEua2RXTnawh7EfS5EfE7a4BIZX6P7YpamndGcyj79/x2/fWulIhfRtDnRoPJY2Oq6W4MQnZLmK7ZbylXT1MIslvCrOZwVfMxuyUMt1vCnNbq5oNoKuluSJ8rOxsCCHjdaI74qp2lqpvXHoHbJWHRtPz1OUpzVg1vinG5JPTNajR9135JVxRCCNPTuzURyHHdMSRTIud7M1rq/GiO+AyXXcwdG7cNt3ncLgmnzDa/HZX8Hjc+0tuUM29QBj7S2wSvV7+Sflx3zFJZVEpXQxCdsQAA661Bs5rDmNkUKmpeu7lcEvpmFlemU8Gc1gh6W8LcPibMbgljVnOo6tuqpymE6Y3BqueDaCrxe9z46JxmSJLkyGt2NXTGgpgWDXBbmMAgqcqs7qRWptfrSlZMgGS0bGVLUTFd11x2NCWhtEp9vnkLpenUE0w5tkU1OCkvTsTtY55TtpVT8kE0lWSOOx5/E7gtzGF3u0mslIAow8pzTcUszY48EhERERHZiUHSJGZHV7ZCSn0BLIMkIiIiInIaBkmTmKvCpasXkxUauKESgRzZgyVFREREUwWDpEnMlu52FpIopo8rW5KIiIiIyGkYJE1iTmilKdQdz8nvKSIiIiKiqYlB0iRm18hxhkp8QSNbkoiIiIjIaRgkTWJOaEkqhEESERERETkNg6RJrBIBSKGGpIIDNzBIIiIiIiKHYZA0idnR3a7cIUwttHYRERER0dTCIGkSq/PLJacRC3kNfw/7jJdRH/AY/x6c+L2t3g8AaK3zm8ydNZl16YgGypL+ZBcNGu8LRERERJNF6bVocqyI34Nl02PweazHwit6m3BkNIHGsM9wupBPVi3jpFmNSCYFfB4XjowmCgZZ9QEPjpseQ8Djhld2oaXOh8aQ8TKLtaSzHgeHx9BUpvQnu4aQF0u7owgVCIyJiIiIah1rO5NcoSAlH7/HDb/HbXkZypYls/M3KOZviZSnFQkAZLerrOlPBYWCZiIiIqLJgN3tiIiIiIiIFBgkERERERERKTBIIiIiIiIiUmCQREREREREpMAgiYiIiIiISIFBEhERERERkQKDJCIiIiIiIgUGSURERERERAoMkoiIiIiIiBQYJBE5VMDrrnYWiIiIiKYkudoZICJ9x7TXYce+IXQ1BKqdFSIiIqIphUESkUP5PW4s6qyvdjaIiIiIphx2tyMiIiIiIlJgkERERERERKTAIImIiIiIiEiBQRIREREREZECgyQiIiIiIiIFBklEREREREQKDJKIiIiIiIgUGCQREREREREpMEgiIiIiIiJSYJBERERERESkwCCJiIiIiIhIgUESERERERGRAoMkIiIiIiIiBQZJRERERERECgySiIiIiIiIFBgkERERERERKTBIIiIiIiIiUmCQREREREREpCBXOwPlJoQAAAwMDFQ5J0A8Hsfw8DAGBgbg8XiqnR3Kg+VUG1hOtYNlVRtYTrWDZVUbWE7OlIkJMjFCPpM+SBocHAQAdHV1VTknRERERETkBIODg6ivr8/7uyQKhVE1LpVK4f3330ckEoEkSVXNy8DAALq6uvDuu++irq6uqnmh/FhOtYHlVDtYVrWB5VQ7WFa1geXkTEIIDA4OoqOjAy5X/iePJn1LksvlQmdnZ7WzoVJXV8eDpQawnGoDy6l2sKxqA8updrCsagPLyXmMWpAyOHADERERERGRAoMkIiIiIiIiBQZJFeTz+fDd734XPp+v2lkhAyyn2sByqh0sq9rAcqodLKvawHKqbZN+4AYiIiIiIiIr2JJERERERESkwCCJiIiIiIhIgUESERERERGRAoMkIiIiIiIiBQZJFfLjH/8YPT098Pv9OPHEE7Fx48ZqZ2lKufXWW3H88ccjEomgpaUF5513HrZv366a5ujRo7jyyivR2NiIcDiMCy+8EPv27VNNs2vXLpx99tkIBoNoaWnBN77xDSQSiUquypRy2223QZIkXHPNNdnvWE7OsXv3bnzuc59DY2MjAoEAFi1ahBdeeCH7uxAC3/nOd9De3o5AIICVK1dix44dqjQOHjyIVatWoa6uDtFoFF/84hcxNDRU6VWZtJLJJG644QbMmDEDgUAAs2bNws033wzlmE0sp+r4wx/+gE9/+tPo6OiAJEl46KGHVL/bVS4vv/wyTj31VPj9fnR1deFf//Vfy71qk4pROcXjcVx77bVYtGgRQqEQOjo68PnPfx7vv/++Kg2WU40SVHZr164VXq9X3HXXXeLVV18Vl19+uYhGo2Lfvn3VztqUccYZZ4i7775bbN26VWzevFl88pOfFN3d3WJoaCg7zZe+9CXR1dUlnnzySfHCCy+Ik046SZx88snZ3xOJhFi4cKFYuXKleOmll8Sjjz4qmpqaxPXXX1+NVZr0Nm7cKHp6esTixYvF1Vdfnf2e5eQMBw8eFNOnTxeXXXaZ2LBhg3jrrbfE448/Lv7yl79kp7nttttEfX29eOihh8SWLVvEOeecI2bMmCFGRkay05x55pliyZIl4rnnnhN//OMfxezZs8Ull1xSjVWalG655RbR2NgoHnnkEbFz505x//33i3A4LH74wx9mp2E5Vcejjz4qvv3tb4sHHnhAABAPPvig6nc7yuXw4cOitbVVrFq1SmzdulXcd999IhAIiJ/97GeVWs2aZ1RO/f39YuXKleK///u/xeuvvy7Wr18vTjjhBLFs2TJVGiyn2sQgqQJOOOEEceWVV2Y/J5NJ0dHRIW699dYq5mpq279/vwAgnnnmGSFE+kTn8XjE/fffn51m27ZtAoBYv369ECJ9onS5XGLv3r3ZadasWSPq6urE6OhoZVdgkhscHBS9vb1i3bp14qMf/Wg2SGI5Oce1114rVqxYkff3VCol2traxL/9279lv+vv7xc+n0/cd999QgghXnvtNQFAPP/889lpHnvsMSFJkti9e3f5Mj+FnH322eILX/iC6rsLLrhArFq1SgjBcnIKbeXbrnL5yU9+ImKxmOrcd+2114q5c+eWeY0mJ71gVmvjxo0CgHjnnXeEECynWsbudmU2NjaGTZs2YeXKldnvXC4XVq5cifXr11cxZ1Pb4cOHAQANDQ0AgE2bNiEej6vKad68eeju7s6W0/r167Fo0SK0trZmpznjjDMwMDCAV199tYK5n/yuvPJKnH322aryAFhOTvLwww9j+fLluOiii9DS0oKlS5fiP//zP7O/79y5E3v37lWVVX19PU488URVWUWjUSxfvjw7zcqVK+FyubBhw4bKrcwkdvLJJ+PJJ5/EG2+8AQDYsmULnn32WZx11lkAWE5OZVe5rF+/Hh/5yEfg9Xqz05xxxhnYvn07Dh06VKG1mVoOHz4MSZIQjUYBsJxqmVztDEx2H374IZLJpKrCBgCtra14/fXXq5SrqS2VSuGaa67BKaecgoULFwIA9u7dC6/Xmz2pZbS2tmLv3r3ZafTKMfMb2WPt2rV48cUX8fzzz+f8xnJyjrfeegtr1qzB1772NXzrW9/C888/j6985Svwer1YvXp1dlvrlYWyrFpaWlS/y7KMhoYGlpVNrrvuOgwMDGDevHlwu91IJpO45ZZbsGrVKgBgOTmUXeWyd+9ezJgxIyeNzG+xWKws+Z+qjh49imuvvRaXXHIJ6urqALCcahmDJJpyrrzySmzduhXPPvtstbNCGu+++y6uvvpqrFu3Dn6/v9rZIQOpVArLly/H97//fQDA0qVLsXXrVvz0pz/F6tWrq5w7yvif//kf3HPPPbj33nuxYMECbN68Gddccw06OjpYTkQ2isfj+Ou//msIIbBmzZpqZ4dswO52ZdbU1AS3250z+ta+ffvQ1tZWpVxNXVdddRUeeeQRPP300+js7Mx+39bWhrGxMfT396umV5ZTW1ubbjlmfqPSbdq0Cfv378dxxx0HWZYhyzKeeeYZ/Md//AdkWUZrayvLySHa29txzDHHqL6bP38+du3aBWBiWxud+9ra2rB//37V74lEAgcPHmRZ2eQb3/gGrrvuOlx88cVYtGgRLr30Unz1q1/FrbfeCoDl5FR2lQvPh5WRCZDeeecdrFu3LtuKBLCcahmDpDLzer1YtmwZnnzyyex3qVQKTz75JPr6+qqYs6lFCIGrrroKDz74IJ566qmcZu1ly5bB4/Goymn79u3YtWtXtpz6+vrwyiuvqE52mZOhtrJIxTn99NPxyiuvYPPmzdl/y5cvx6pVq7J/s5yc4ZRTTskZRv+NN97A9OnTAQAzZsxAW1ubqqwGBgawYcMGVVn19/dj06ZN2WmeeuoppFIpnHjiiRVYi8lveHgYLpf6Uu92u5FKpQCwnJzKrnLp6+vDH/7wB8Tj8ew069atw9y5c9mFyyaZAGnHjh144okn0NjYqPqd5VTDqj1yxFSwdu1a4fP5xK9+9Svx2muviSuuuEJEo1HV6FtUXl/+8pdFfX29+P3vfy/27NmT/Tc8PJyd5ktf+pLo7u4WTz31lHjhhRdEX1+f6Ovry/6eGVr6E5/4hNi8ebP43e9+J5qbmzm0dJkpR7cTguXkFBs3bhSyLItbbrlF7NixQ9xzzz0iGAyK3/zmN9lpbrvtNhGNRsX//u//ipdfflmce+65ukMYL126VGzYsEE8++yzore3l0NL22j16tVi2rRp2SHAH3jgAdHU1CS++c1vZqdhOVXH4OCgeOmll8RLL70kAIjbb79dvPTSS9lR0ewol/7+ftHa2iouvfRSsXXrVrF27VoRDAY5tLQFRuU0NjYmzjnnHNHZ2Sk2b96sql8oR6pjOdUmBkkV8qMf/Uh0d3cLr9crTjjhBPHcc89VO0tTCgDdf3fffXd2mpGREfEP//APIhaLiWAwKM4//3yxZ88eVTpvv/22OOuss0QgEBBNTU3i61//uojH4xVem6lFGySxnJzj//7v/8TChQuFz+cT8+bNEz//+c9Vv6dSKXHDDTeI1tZW4fP5xOmnny62b9+umubAgQPikksuEeFwWNTV1Ym//du/FYODg5VcjUltYGBAXH311aK7u1v4/X4xc+ZM8e1vf1tVgWM5VcfTTz+te11avXq1EMK+ctmyZYtYsWKF8Pl8Ytq0aeK2226r1CpOCkbltHPnzrz1i6effjqbBsupNklCKF67TURERERENMXxmSQiIiIiIiIFBklEREREREQKDJKIiIiIiIgUGCQREREREREpMEgiIiIiIiJSYJBERERERESkwCCJiIiIiIhIgUESERERERGRAoMkIiKqWW+//TYkScLmzZvLtozLLrsM5513Xvbzxz72MVxzzTVlWx4REVUfgyQiIqqayy67DJIk5fw788wzTc3f1dWFPXv2YOHChWXO6YQHHngAN998c8WWR0RElSdXOwNERDS1nXnmmbj77rtV3/l8PlPzut1utLW1lSNbeTU0NFR0eUREVHlsSSIioqry+Xxoa2tT/YvFYgAASZKwZs0anHXWWQgEApg5cyZ++9vfZufVdrc7dOgQVq1ahebmZgQCAfT29qoCsFdeeQWnnXYaAoEAGhsbccUVV2BoaCj7ezKZxNe+9jVEo1E0Njbim9/8JoQQqvxqu9sdOnQIn//85xGLxRAMBnHWWWdhx44dZdhSRERUKQySiIjI0W644QZceOGF2LJlC1atWoWLL74Y27Ztyzvta6+9hsceewzbtm3DmjVr0NTUBAA4cuQIzjjjDMRiMTz//PO4//778cQTT+Cqq67Kzv/v//7v+NWvfoW77roLzz77LA4ePIgHH3zQMH+XXXYZXnjhBTz88MNYv349hBD45Cc/iXg8bt9GICKiimKQREREVfXII48gHA6r/n3/+9/P/n7RRRfh7/7u7zBnzhzcfPPNWL58OX70ox/pprVr1y4sXboUy5cvR09PD1auXIlPf/rTAIB7770XR48exa9//WssXLgQp512Gu68807813/9F/bt2wcAuOOOO3D99dfjggsuwPz58/HTn/4U9fX1efO+Y8cOPPzww/jFL36BU089FUuWLME999yD3bt346GHHrJvIxERUUXxmSQiIqqqj3/841izZo3qO+VzP319farf+vr68o5m9+UvfxkXXnghXnzxRXziE5/Aeeedh5NPPhkAsG3bNixZsgShUCg7/SmnnIJUKoXt27fD7/djz549OPHEE7O/y7KM5cuX53S5y9i2bRtkWVbN09jYiLlz5+Zt7SIiIudjkERERFUVCoUwe/ZsW9I666yz8M477+DRRx/FunXrcPrpp+PKK6/ED37wA1vSJyKiqYHd7YiIyNGee+65nM/z58/PO31zczNWr16N3/zmN7jjjjvw85//HAAwf/58bNmyBUeOHMlO+6c//Qkulwtz585FfX092tvbsWHDhuzviUQCmzZtyrus+fPnI5FIqOY5cOAAtm/fjmOOOcbyuhIRkTOwJYmIiKpqdHQUe/fuVX0ny3J2wIX7778fy5cvx4oVK3DPPfdg48aN+OUvf6mb1ne+8x0sW7YMCxYswOjoKB555JFsQLVq1Sp897vfxerVq3HjjTfigw8+wD/+4z/i0ksvRWtrKwDg6quvxm233Ybe3l7MmzcPt99+O/r7+/Pmvbe3F+eeey4uv/xy/OxnP0MkEsF1112HadOm4dxzz7Vh6xARUTWwJYmIiKrqd7/7Hdrb21X/VqxYkf39pptuwtq1a7F48WL8+te/xn333Ze3lcbr9eL666/H4sWL8ZGPfARutxtr164FAASDQTz++OM4ePAgjj/+eHzmM5/B6aefjjvvvDM7/9e//nVceumlWL16Nfr6+hCJRHD++ecb5v/uu+/GsmXL8KlPfQp9fX0QQuDRRx+Fx+OxYesQEVE1SCLf06hERERVJkkSHnzwQZx33nnVzgoREU0hbEkiIiIiIiJSYJBERERERESkwIEbiIjIsdgjnIiIqoEtSURERERERAoMkoiIiIiIiBQYJBERERERESkwSCIiIiIiIlJgkERERERERKTAIImIiIiIiEiBQRIREREREZECgyQiIiIiIiKF/w+EEQ864XuT3wAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Leer los logs guardados\n",
        "with open(log_filename) as f:\n",
        "    log_data = json.load(f)\n",
        "\n",
        "# Extraer rewards y episodios\n",
        "episode_rewards = log_data['episode_reward']\n",
        "episodes = list(range(1, len(episode_rewards) + 1))  # Episodios desde 1\n",
        "\n",
        "# (Opcional) Suavizar la curva con media móvil\n",
        "def moving_average(data, window_size=10):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "smoothed_rewards = moving_average(episode_rewards, window_size=10)\n",
        "\n",
        "# Graficar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(episodes, episode_rewards, alpha=0.3, label='Reward por episodio')\n",
        "plt.plot(episodes[:len(smoothed_rewards)], smoothed_rewards, color='red', label='Media móvil (10)')\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Reward')\n",
        "plt.title('Evolución del reward durante el entrenamiento')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQp3q8levgGT"
      },
      "source": [
        "# Modificación arquitectura de Red Neuronal para mejora del base line\n",
        "Se introdujo una cuarta capa convolucional para mejorar la capacidad de extracción de características, y se incrementó la dimensión de la capa densa final a 1024 neuronas para mejorar la representación abstracta del estado. Esto permite al agente aprender políticas más complejas, especialmente en entornos visuales de alta dimensionalidad como Atari."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cAnDBKVuXU2",
        "outputId": "d19f590f-c8d8-4e6f-880e-307a6671eaf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 1000000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    420/1000000: episode: 1, duration: 1.848s, episode steps: 420, steps per second: 227, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1131/1000000: episode: 2, duration: 2.778s, episode steps: 711, steps per second: 256, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1941/1000000: episode: 3, duration: 3.065s, episode steps: 810, steps per second: 264, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2831/1000000: episode: 4, duration: 3.431s, episode steps: 890, steps per second: 259, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3206/1000000: episode: 5, duration: 1.429s, episode steps: 375, steps per second: 262, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4151/1000000: episode: 6, duration: 3.674s, episode steps: 945, steps per second: 257, episode reward:  8.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4943/1000000: episode: 7, duration: 3.038s, episode steps: 792, steps per second: 261, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5441/1000000: episode: 8, duration: 1.864s, episode steps: 498, steps per second: 267, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6091/1000000: episode: 9, duration: 2.431s, episode steps: 650, steps per second: 267, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6621/1000000: episode: 10, duration: 1.984s, episode steps: 530, steps per second: 267, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7336/1000000: episode: 11, duration: 2.826s, episode steps: 715, steps per second: 253, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7969/1000000: episode: 12, duration: 2.328s, episode steps: 633, steps per second: 272, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8706/1000000: episode: 13, duration: 2.704s, episode steps: 737, steps per second: 273, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9295/1000000: episode: 14, duration: 2.172s, episode steps: 589, steps per second: 271, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9963/1000000: episode: 15, duration: 2.434s, episode steps: 668, steps per second: 274, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10634/1000000: episode: 16, duration: 2.535s, episode steps: 671, steps per second: 265, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11268/1000000: episode: 17, duration: 2.354s, episode steps: 634, steps per second: 269, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12387/1000000: episode: 18, duration: 4.198s, episode steps: 1119, steps per second: 267, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13065/1000000: episode: 19, duration: 2.516s, episode steps: 678, steps per second: 269, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13760/1000000: episode: 20, duration: 2.673s, episode steps: 695, steps per second: 260, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14307/1000000: episode: 21, duration: 2.044s, episode steps: 547, steps per second: 268, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15484/1000000: episode: 22, duration: 4.421s, episode steps: 1177, steps per second: 266, episode reward: 24.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16700/1000000: episode: 23, duration: 4.537s, episode steps: 1216, steps per second: 268, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17705/1000000: episode: 24, duration: 3.791s, episode steps: 1005, steps per second: 265, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18229/1000000: episode: 25, duration: 1.960s, episode steps: 524, steps per second: 267, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18804/1000000: episode: 26, duration: 2.154s, episode steps: 575, steps per second: 267, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19459/1000000: episode: 27, duration: 2.600s, episode steps: 655, steps per second: 252, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19991/1000000: episode: 28, duration: 2.099s, episode steps: 532, steps per second: 253, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21242/1000000: episode: 29, duration: 4.878s, episode steps: 1251, steps per second: 256, episode reward: 21.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21943/1000000: episode: 30, duration: 2.833s, episode steps: 701, steps per second: 247, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22521/1000000: episode: 31, duration: 2.393s, episode steps: 578, steps per second: 242, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22963/1000000: episode: 32, duration: 1.838s, episode steps: 442, steps per second: 241, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23730/1000000: episode: 33, duration: 2.995s, episode steps: 767, steps per second: 256, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24321/1000000: episode: 34, duration: 2.290s, episode steps: 591, steps per second: 258, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24979/1000000: episode: 35, duration: 2.507s, episode steps: 658, steps per second: 262, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25351/1000000: episode: 36, duration: 1.475s, episode steps: 372, steps per second: 252, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25867/1000000: episode: 37, duration: 1.970s, episode steps: 516, steps per second: 262, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26269/1000000: episode: 38, duration: 1.565s, episode steps: 402, steps per second: 257, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26818/1000000: episode: 39, duration: 2.098s, episode steps: 549, steps per second: 262, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27535/1000000: episode: 40, duration: 2.671s, episode steps: 717, steps per second: 268, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28216/1000000: episode: 41, duration: 2.577s, episode steps: 681, steps per second: 264, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28757/1000000: episode: 42, duration: 2.031s, episode steps: 541, steps per second: 266, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29496/1000000: episode: 43, duration: 2.816s, episode steps: 739, steps per second: 262, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30100/1000000: episode: 44, duration: 2.334s, episode steps: 604, steps per second: 259, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30693/1000000: episode: 45, duration: 2.215s, episode steps: 593, steps per second: 268, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31077/1000000: episode: 46, duration: 1.419s, episode steps: 384, steps per second: 271, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31670/1000000: episode: 47, duration: 2.209s, episode steps: 593, steps per second: 268, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32328/1000000: episode: 48, duration: 2.455s, episode steps: 658, steps per second: 268, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32996/1000000: episode: 49, duration: 2.542s, episode steps: 668, steps per second: 263, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33470/1000000: episode: 50, duration: 1.780s, episode steps: 474, steps per second: 266, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34021/1000000: episode: 51, duration: 2.065s, episode steps: 551, steps per second: 267, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34407/1000000: episode: 52, duration: 1.453s, episode steps: 386, steps per second: 266, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35105/1000000: episode: 53, duration: 2.600s, episode steps: 698, steps per second: 268, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35875/1000000: episode: 54, duration: 2.925s, episode steps: 770, steps per second: 263, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36375/1000000: episode: 55, duration: 1.883s, episode steps: 500, steps per second: 265, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36937/1000000: episode: 56, duration: 2.115s, episode steps: 562, steps per second: 266, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37526/1000000: episode: 57, duration: 2.227s, episode steps: 589, steps per second: 264, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38167/1000000: episode: 58, duration: 2.412s, episode steps: 641, steps per second: 266, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38553/1000000: episode: 59, duration: 1.439s, episode steps: 386, steps per second: 268, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39332/1000000: episode: 60, duration: 3.130s, episode steps: 779, steps per second: 249, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39884/1000000: episode: 61, duration: 2.056s, episode steps: 552, steps per second: 269, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40782/1000000: episode: 62, duration: 3.354s, episode steps: 898, steps per second: 268, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41580/1000000: episode: 63, duration: 2.965s, episode steps: 798, steps per second: 269, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42341/1000000: episode: 64, duration: 2.855s, episode steps: 761, steps per second: 267, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43015/1000000: episode: 65, duration: 2.532s, episode steps: 674, steps per second: 266, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43530/1000000: episode: 66, duration: 1.931s, episode steps: 515, steps per second: 267, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44379/1000000: episode: 67, duration: 3.173s, episode steps: 849, steps per second: 268, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44779/1000000: episode: 68, duration: 1.500s, episode steps: 400, steps per second: 267, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45378/1000000: episode: 69, duration: 2.348s, episode steps: 599, steps per second: 255, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46237/1000000: episode: 70, duration: 3.328s, episode steps: 859, steps per second: 258, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46746/1000000: episode: 71, duration: 1.918s, episode steps: 509, steps per second: 265, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47899/1000000: episode: 72, duration: 4.301s, episode steps: 1153, steps per second: 268, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48556/1000000: episode: 73, duration: 2.505s, episode steps: 657, steps per second: 262, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49491/1000000: episode: 74, duration: 3.545s, episode steps: 935, steps per second: 264, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  50130/1000000: episode: 75, duration: 6.123s, episode steps: 639, steps per second: 104, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.007484, mae: 0.032771, mean_q: 0.059762, mean_eps: 0.954941\n",
            "  50957/1000000: episode: 76, duration: 23.852s, episode steps: 827, steps per second:  35, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006767, mae: 0.032192, mean_q: 0.048410, mean_eps: 0.954510\n",
            "  51564/1000000: episode: 77, duration: 17.559s, episode steps: 607, steps per second:  35, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.006342, mae: 0.034054, mean_q: 0.047790, mean_eps: 0.953866\n",
            "  52419/1000000: episode: 78, duration: 24.849s, episode steps: 855, steps per second:  34, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.007015, mae: 0.034437, mean_q: 0.046772, mean_eps: 0.953209\n",
            "  53200/1000000: episode: 79, duration: 22.666s, episode steps: 781, steps per second:  34, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.006893, mae: 0.035258, mean_q: 0.045567, mean_eps: 0.952473\n",
            "  53888/1000000: episode: 80, duration: 20.080s, episode steps: 688, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.005506, mae: 0.031795, mean_q: 0.041734, mean_eps: 0.951812\n",
            "  54428/1000000: episode: 81, duration: 15.928s, episode steps: 540, steps per second:  34, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.006661, mae: 0.033694, mean_q: 0.044442, mean_eps: 0.951260\n",
            "  55098/1000000: episode: 82, duration: 19.492s, episode steps: 670, steps per second:  34, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.007804, mae: 0.036573, mean_q: 0.046199, mean_eps: 0.950714\n",
            "  55681/1000000: episode: 83, duration: 16.916s, episode steps: 583, steps per second:  34, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.007508, mae: 0.036250, mean_q: 0.047551, mean_eps: 0.950149\n",
            "  56045/1000000: episode: 84, duration: 10.544s, episode steps: 364, steps per second:  35, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.007482, mae: 0.037604, mean_q: 0.047863, mean_eps: 0.949722\n",
            "  56781/1000000: episode: 85, duration: 21.358s, episode steps: 736, steps per second:  34, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.005545, mae: 0.031706, mean_q: 0.042800, mean_eps: 0.949227\n",
            "  57334/1000000: episode: 86, duration: 15.964s, episode steps: 553, steps per second:  35, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.005605, mae: 0.032614, mean_q: 0.040843, mean_eps: 0.948648\n",
            "  58222/1000000: episode: 87, duration: 25.778s, episode steps: 888, steps per second:  34, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.006401, mae: 0.033366, mean_q: 0.043336, mean_eps: 0.948000\n",
            "  58781/1000000: episode: 88, duration: 16.230s, episode steps: 559, steps per second:  34, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.005752, mae: 0.033184, mean_q: 0.042812, mean_eps: 0.947348\n",
            "  60111/1000000: episode: 89, duration: 38.276s, episode steps: 1330, steps per second:  35, episode reward: 24.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.006745, mae: 0.034879, mean_q: 0.043632, mean_eps: 0.946499\n",
            "  61037/1000000: episode: 90, duration: 27.000s, episode steps: 926, steps per second:  34, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006349, mae: 0.050024, mean_q: 0.064337, mean_eps: 0.945483\n",
            "  61680/1000000: episode: 91, duration: 18.594s, episode steps: 643, steps per second:  35, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.007692, mae: 0.054623, mean_q: 0.072932, mean_eps: 0.944778\n",
            "  62206/1000000: episode: 92, duration: 15.253s, episode steps: 526, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.007153, mae: 0.052319, mean_q: 0.064882, mean_eps: 0.944252\n",
            "  62708/1000000: episode: 93, duration: 14.578s, episode steps: 502, steps per second:  34, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.005570, mae: 0.049906, mean_q: 0.063546, mean_eps: 0.943790\n",
            "  63886/1000000: episode: 94, duration: 34.226s, episode steps: 1178, steps per second:  34, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.006161, mae: 0.050608, mean_q: 0.063945, mean_eps: 0.943034\n",
            "  64656/1000000: episode: 95, duration: 22.377s, episode steps: 770, steps per second:  34, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.007846, mae: 0.053974, mean_q: 0.069521, mean_eps: 0.942157\n",
            "  65171/1000000: episode: 96, duration: 14.972s, episode steps: 515, steps per second:  34, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.007359, mae: 0.053693, mean_q: 0.068330, mean_eps: 0.941579\n",
            "  66228/1000000: episode: 97, duration: 30.676s, episode steps: 1057, steps per second:  34, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.006529, mae: 0.051440, mean_q: 0.066635, mean_eps: 0.940872\n",
            "  66624/1000000: episode: 98, duration: 11.658s, episode steps: 396, steps per second:  34, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.005184, mae: 0.048675, mean_q: 0.063552, mean_eps: 0.940218\n",
            "  67087/1000000: episode: 99, duration: 13.496s, episode steps: 463, steps per second:  34, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.008001, mae: 0.054479, mean_q: 0.068154, mean_eps: 0.939831\n",
            "  67712/1000000: episode: 100, duration: 18.153s, episode steps: 625, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.006616, mae: 0.051714, mean_q: 0.065743, mean_eps: 0.939342\n",
            "  68115/1000000: episode: 101, duration: 11.718s, episode steps: 403, steps per second:  34, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006991, mae: 0.054163, mean_q: 0.065746, mean_eps: 0.938879\n",
            "  68602/1000000: episode: 102, duration: 14.137s, episode steps: 487, steps per second:  34, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.007037, mae: 0.051733, mean_q: 0.064195, mean_eps: 0.938478\n",
            "  69115/1000000: episode: 103, duration: 14.818s, episode steps: 513, steps per second:  35, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.006721, mae: 0.052491, mean_q: 0.067374, mean_eps: 0.938028\n",
            "  69912/1000000: episode: 104, duration: 23.164s, episode steps: 797, steps per second:  34, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.007402, mae: 0.053251, mean_q: 0.067693, mean_eps: 0.937439\n",
            "  71016/1000000: episode: 105, duration: 31.936s, episode steps: 1104, steps per second:  35, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.007402, mae: 0.074904, mean_q: 0.095028, mean_eps: 0.936584\n",
            "  71650/1000000: episode: 106, duration: 18.340s, episode steps: 634, steps per second:  35, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.007389, mae: 0.077699, mean_q: 0.097777, mean_eps: 0.935801\n",
            "  72240/1000000: episode: 107, duration: 17.163s, episode steps: 590, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.007322, mae: 0.077462, mean_q: 0.097944, mean_eps: 0.935250\n",
            "  72824/1000000: episode: 108, duration: 17.197s, episode steps: 584, steps per second:  34, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.006572, mae: 0.076514, mean_q: 0.100958, mean_eps: 0.934723\n",
            "  73588/1000000: episode: 109, duration: 22.380s, episode steps: 764, steps per second:  34, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007141, mae: 0.077496, mean_q: 0.100082, mean_eps: 0.934116\n",
            "  74410/1000000: episode: 110, duration: 23.988s, episode steps: 822, steps per second:  34, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.006808, mae: 0.076554, mean_q: 0.096815, mean_eps: 0.933402\n",
            "  75291/1000000: episode: 111, duration: 25.545s, episode steps: 881, steps per second:  34, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.007291, mae: 0.077588, mean_q: 0.097226, mean_eps: 0.932635\n",
            "  76004/1000000: episode: 112, duration: 20.821s, episode steps: 713, steps per second:  34, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006774, mae: 0.077669, mean_q: 0.096957, mean_eps: 0.931919\n",
            "  76660/1000000: episode: 113, duration: 19.402s, episode steps: 656, steps per second:  34, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.007467, mae: 0.078402, mean_q: 0.098439, mean_eps: 0.931303\n",
            "  77082/1000000: episode: 114, duration: 12.415s, episode steps: 422, steps per second:  34, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.007576, mae: 0.079381, mean_q: 0.100941, mean_eps: 0.930817\n",
            "  77631/1000000: episode: 115, duration: 15.950s, episode steps: 549, steps per second:  34, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.005976, mae: 0.073838, mean_q: 0.092954, mean_eps: 0.930380\n",
            "  78758/1000000: episode: 116, duration: 32.772s, episode steps: 1127, steps per second:  34, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.007034, mae: 0.077723, mean_q: 0.097913, mean_eps: 0.929625\n",
            "  79242/1000000: episode: 117, duration: 13.976s, episode steps: 484, steps per second:  35, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.006867, mae: 0.075995, mean_q: 0.093116, mean_eps: 0.928900\n",
            "  79627/1000000: episode: 118, duration: 11.203s, episode steps: 385, steps per second:  34, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.007145, mae: 0.078095, mean_q: 0.097080, mean_eps: 0.928509\n",
            "  80317/1000000: episode: 119, duration: 20.140s, episode steps: 690, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.007358, mae: 0.082500, mean_q: 0.103363, mean_eps: 0.928025\n",
            "  81133/1000000: episode: 120, duration: 23.664s, episode steps: 816, steps per second:  34, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.007063, mae: 0.090303, mean_q: 0.114951, mean_eps: 0.927347\n",
            "  81868/1000000: episode: 121, duration: 21.469s, episode steps: 735, steps per second:  34, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.008881, mae: 0.095885, mean_q: 0.122183, mean_eps: 0.926650\n",
            "  82448/1000000: episode: 122, duration: 16.875s, episode steps: 580, steps per second:  34, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.005803, mae: 0.089362, mean_q: 0.114589, mean_eps: 0.926060\n",
            "  82881/1000000: episode: 123, duration: 12.664s, episode steps: 433, steps per second:  34, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.007120, mae: 0.090771, mean_q: 0.113979, mean_eps: 0.925602\n",
            "  83272/1000000: episode: 124, duration: 11.398s, episode steps: 391, steps per second:  34, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.007909, mae: 0.093008, mean_q: 0.116446, mean_eps: 0.925232\n",
            "  83934/1000000: episode: 125, duration: 19.282s, episode steps: 662, steps per second:  34, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.005695, mae: 0.089237, mean_q: 0.111860, mean_eps: 0.924758\n",
            "  84414/1000000: episode: 126, duration: 13.896s, episode steps: 480, steps per second:  35, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.007034, mae: 0.091638, mean_q: 0.113418, mean_eps: 0.924243\n",
            "  85167/1000000: episode: 127, duration: 21.827s, episode steps: 753, steps per second:  34, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.005974, mae: 0.089170, mean_q: 0.109975, mean_eps: 0.923689\n",
            "  85876/1000000: episode: 128, duration: 20.550s, episode steps: 709, steps per second:  35, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.005986, mae: 0.089314, mean_q: 0.111987, mean_eps: 0.923032\n",
            "  86930/1000000: episode: 129, duration: 30.868s, episode steps: 1054, steps per second:  34, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.006168, mae: 0.089286, mean_q: 0.110431, mean_eps: 0.922238\n",
            "  87675/1000000: episode: 130, duration: 21.559s, episode steps: 745, steps per second:  35, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.007148, mae: 0.091303, mean_q: 0.111428, mean_eps: 0.921428\n",
            "  88218/1000000: episode: 131, duration: 15.764s, episode steps: 543, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.007593, mae: 0.094432, mean_q: 0.118589, mean_eps: 0.920849\n",
            "  88841/1000000: episode: 132, duration: 18.100s, episode steps: 623, steps per second:  34, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007759, mae: 0.093536, mean_q: 0.115289, mean_eps: 0.920323\n",
            "  89543/1000000: episode: 133, duration: 20.244s, episode steps: 702, steps per second:  35, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006493, mae: 0.091347, mean_q: 0.114020, mean_eps: 0.919727\n",
            "  90300/1000000: episode: 134, duration: 22.005s, episode steps: 757, steps per second:  34, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.006970, mae: 0.098240, mean_q: 0.120674, mean_eps: 0.919072\n",
            "  91152/1000000: episode: 135, duration: 24.747s, episode steps: 852, steps per second:  34, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.007336, mae: 0.114000, mean_q: 0.144945, mean_eps: 0.918348\n",
            "  91778/1000000: episode: 136, duration: 18.213s, episode steps: 626, steps per second:  34, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.006769, mae: 0.112607, mean_q: 0.141323, mean_eps: 0.917682\n",
            "  92495/1000000: episode: 137, duration: 20.868s, episode steps: 717, steps per second:  34, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.006808, mae: 0.111288, mean_q: 0.141653, mean_eps: 0.917078\n",
            "  93013/1000000: episode: 138, duration: 15.116s, episode steps: 518, steps per second:  34, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.004948, mae: 0.107658, mean_q: 0.135704, mean_eps: 0.916521\n",
            "  93512/1000000: episode: 139, duration: 14.610s, episode steps: 499, steps per second:  34, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.005650, mae: 0.109206, mean_q: 0.136823, mean_eps: 0.916064\n",
            "  94117/1000000: episode: 140, duration: 17.666s, episode steps: 605, steps per second:  34, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.006210, mae: 0.109598, mean_q: 0.138506, mean_eps: 0.915567\n",
            "  94589/1000000: episode: 141, duration: 13.653s, episode steps: 472, steps per second:  35, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.006601, mae: 0.109567, mean_q: 0.134993, mean_eps: 0.915081\n",
            "  95387/1000000: episode: 142, duration: 23.194s, episode steps: 798, steps per second:  34, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.007211, mae: 0.113471, mean_q: 0.140082, mean_eps: 0.914511\n",
            "  96039/1000000: episode: 143, duration: 18.995s, episode steps: 652, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.006041, mae: 0.110761, mean_q: 0.138385, mean_eps: 0.913859\n",
            "  96765/1000000: episode: 144, duration: 21.099s, episode steps: 726, steps per second:  34, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.006140, mae: 0.109867, mean_q: 0.135879, mean_eps: 0.913238\n",
            "  97697/1000000: episode: 145, duration: 27.401s, episode steps: 932, steps per second:  34, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.006275, mae: 0.110175, mean_q: 0.135779, mean_eps: 0.912491\n",
            "  98482/1000000: episode: 146, duration: 22.955s, episode steps: 785, steps per second:  34, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.006792, mae: 0.112865, mean_q: 0.139676, mean_eps: 0.911719\n",
            "  98944/1000000: episode: 147, duration: 13.481s, episode steps: 462, steps per second:  34, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.007155, mae: 0.112685, mean_q: 0.138645, mean_eps: 0.911159\n",
            "  99548/1000000: episode: 148, duration: 17.666s, episode steps: 604, steps per second:  34, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.742 [0.000, 5.000],  loss: 0.004743, mae: 0.108119, mean_q: 0.137496, mean_eps: 0.910680\n",
            " 100354/1000000: episode: 149, duration: 23.614s, episode steps: 806, steps per second:  34, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.006011, mae: 0.123801, mean_q: 0.155115, mean_eps: 0.910045\n",
            " 100870/1000000: episode: 150, duration: 15.050s, episode steps: 516, steps per second:  34, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.006189, mae: 0.146605, mean_q: 0.181564, mean_eps: 0.909449\n",
            " 101687/1000000: episode: 151, duration: 23.756s, episode steps: 817, steps per second:  34, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.006703, mae: 0.147577, mean_q: 0.182974, mean_eps: 0.908850\n",
            " 102391/1000000: episode: 152, duration: 20.518s, episode steps: 704, steps per second:  34, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.005484, mae: 0.143650, mean_q: 0.179540, mean_eps: 0.908166\n",
            " 103193/1000000: episode: 153, duration: 23.444s, episode steps: 802, steps per second:  34, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.006049, mae: 0.146456, mean_q: 0.181044, mean_eps: 0.907487\n",
            " 103849/1000000: episode: 154, duration: 19.679s, episode steps: 656, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.006778, mae: 0.147883, mean_q: 0.182075, mean_eps: 0.906830\n",
            " 104291/1000000: episode: 155, duration: 12.887s, episode steps: 442, steps per second:  34, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.006497, mae: 0.148791, mean_q: 0.183890, mean_eps: 0.906337\n",
            " 105130/1000000: episode: 156, duration: 24.842s, episode steps: 839, steps per second:  34, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.007277, mae: 0.149330, mean_q: 0.186191, mean_eps: 0.905761\n",
            " 105865/1000000: episode: 157, duration: 21.600s, episode steps: 735, steps per second:  34, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.008040, mae: 0.149991, mean_q: 0.187514, mean_eps: 0.905052\n",
            " 106537/1000000: episode: 158, duration: 19.600s, episode steps: 672, steps per second:  34, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.006768, mae: 0.148140, mean_q: 0.182899, mean_eps: 0.904418\n",
            " 106923/1000000: episode: 159, duration: 11.304s, episode steps: 386, steps per second:  34, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.938 [0.000, 5.000],  loss: 0.007765, mae: 0.151596, mean_q: 0.188893, mean_eps: 0.903943\n",
            " 107300/1000000: episode: 160, duration: 11.186s, episode steps: 377, steps per second:  34, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.740 [0.000, 5.000],  loss: 0.007519, mae: 0.149113, mean_q: 0.184028, mean_eps: 0.903601\n",
            " 108186/1000000: episode: 161, duration: 25.919s, episode steps: 886, steps per second:  34, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.006843, mae: 0.148074, mean_q: 0.183890, mean_eps: 0.903032\n",
            " 108647/1000000: episode: 162, duration: 13.507s, episode steps: 461, steps per second:  34, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.005454, mae: 0.143540, mean_q: 0.175900, mean_eps: 0.902426\n",
            " 109072/1000000: episode: 163, duration: 12.537s, episode steps: 425, steps per second:  34, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.006855, mae: 0.149876, mean_q: 0.183672, mean_eps: 0.902028\n",
            " 109754/1000000: episode: 164, duration: 20.420s, episode steps: 682, steps per second:  33, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007321, mae: 0.149680, mean_q: 0.183643, mean_eps: 0.901529\n",
            " 110552/1000000: episode: 165, duration: 23.888s, episode steps: 798, steps per second:  33, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.006380, mae: 0.155760, mean_q: 0.192000, mean_eps: 0.900863\n",
            " 111348/1000000: episode: 166, duration: 23.691s, episode steps: 796, steps per second:  34, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.006916, mae: 0.163757, mean_q: 0.201199, mean_eps: 0.900147\n",
            " 111957/1000000: episode: 167, duration: 18.122s, episode steps: 609, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.006383, mae: 0.162149, mean_q: 0.202286, mean_eps: 0.899513\n",
            " 112461/1000000: episode: 168, duration: 15.040s, episode steps: 504, steps per second:  34, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006923, mae: 0.165273, mean_q: 0.202857, mean_eps: 0.899011\n",
            " 113018/1000000: episode: 169, duration: 16.419s, episode steps: 557, steps per second:  34, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006126, mae: 0.164177, mean_q: 0.202895, mean_eps: 0.898534\n",
            " 114257/1000000: episode: 170, duration: 36.550s, episode steps: 1239, steps per second:  34, episode reward: 30.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.006452, mae: 0.163637, mean_q: 0.201909, mean_eps: 0.897726\n",
            " 114947/1000000: episode: 171, duration: 20.277s, episode steps: 690, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.006817, mae: 0.163622, mean_q: 0.199977, mean_eps: 0.896858\n",
            " 115677/1000000: episode: 172, duration: 21.402s, episode steps: 730, steps per second:  34, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.006732, mae: 0.165623, mean_q: 0.202321, mean_eps: 0.896219\n",
            " 116350/1000000: episode: 173, duration: 19.854s, episode steps: 673, steps per second:  34, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.007696, mae: 0.166094, mean_q: 0.202788, mean_eps: 0.895587\n",
            " 116759/1000000: episode: 174, duration: 11.954s, episode steps: 409, steps per second:  34, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.006384, mae: 0.167682, mean_q: 0.207435, mean_eps: 0.895101\n",
            " 117329/1000000: episode: 175, duration: 16.830s, episode steps: 570, steps per second:  34, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.006613, mae: 0.161622, mean_q: 0.199587, mean_eps: 0.894660\n",
            " 117900/1000000: episode: 176, duration: 16.765s, episode steps: 571, steps per second:  34, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.007536, mae: 0.171951, mean_q: 0.212126, mean_eps: 0.894147\n",
            " 118853/1000000: episode: 177, duration: 28.196s, episode steps: 953, steps per second:  34, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.006386, mae: 0.162866, mean_q: 0.200697, mean_eps: 0.893462\n",
            " 119223/1000000: episode: 178, duration: 10.833s, episode steps: 370, steps per second:  34, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.005817, mae: 0.165178, mean_q: 0.203327, mean_eps: 0.892866\n",
            " 119658/1000000: episode: 179, duration: 12.808s, episode steps: 435, steps per second:  34, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: 0.006859, mae: 0.160830, mean_q: 0.199663, mean_eps: 0.892504\n",
            " 120299/1000000: episode: 180, duration: 18.813s, episode steps: 641, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.007564, mae: 0.175848, mean_q: 0.214431, mean_eps: 0.892020\n",
            " 121085/1000000: episode: 181, duration: 23.134s, episode steps: 786, steps per second:  34, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006393, mae: 0.183860, mean_q: 0.227623, mean_eps: 0.891377\n",
            " 121486/1000000: episode: 182, duration: 11.967s, episode steps: 401, steps per second:  34, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.007031, mae: 0.185841, mean_q: 0.228442, mean_eps: 0.890843\n",
            " 121998/1000000: episode: 183, duration: 15.340s, episode steps: 512, steps per second:  33, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.006670, mae: 0.180703, mean_q: 0.223504, mean_eps: 0.890432\n",
            " 122513/1000000: episode: 184, duration: 15.140s, episode steps: 515, steps per second:  34, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.007238, mae: 0.187380, mean_q: 0.231405, mean_eps: 0.889970\n",
            " 123004/1000000: episode: 185, duration: 14.432s, episode steps: 491, steps per second:  34, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.007210, mae: 0.187664, mean_q: 0.229751, mean_eps: 0.889518\n",
            " 123692/1000000: episode: 186, duration: 20.561s, episode steps: 688, steps per second:  33, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.006293, mae: 0.183234, mean_q: 0.224461, mean_eps: 0.888989\n",
            " 124079/1000000: episode: 187, duration: 11.563s, episode steps: 387, steps per second:  33, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.007073, mae: 0.187507, mean_q: 0.229002, mean_eps: 0.888504\n",
            " 124491/1000000: episode: 188, duration: 12.181s, episode steps: 412, steps per second:  34, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.007313, mae: 0.188804, mean_q: 0.230512, mean_eps: 0.888144\n",
            " 125105/1000000: episode: 189, duration: 18.082s, episode steps: 614, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.005721, mae: 0.182594, mean_q: 0.221479, mean_eps: 0.887682\n",
            " 125915/1000000: episode: 190, duration: 23.803s, episode steps: 810, steps per second:  34, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.006328, mae: 0.185545, mean_q: 0.227396, mean_eps: 0.887041\n",
            " 126664/1000000: episode: 191, duration: 22.127s, episode steps: 749, steps per second:  34, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.007115, mae: 0.187885, mean_q: 0.228666, mean_eps: 0.886341\n",
            " 127306/1000000: episode: 192, duration: 19.057s, episode steps: 642, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.006835, mae: 0.189048, mean_q: 0.230915, mean_eps: 0.885714\n",
            " 128281/1000000: episode: 193, duration: 28.884s, episode steps: 975, steps per second:  34, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.006500, mae: 0.185218, mean_q: 0.227950, mean_eps: 0.884985\n",
            " 128922/1000000: episode: 194, duration: 19.148s, episode steps: 641, steps per second:  33, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.006474, mae: 0.185383, mean_q: 0.227398, mean_eps: 0.884258\n",
            " 129718/1000000: episode: 195, duration: 23.534s, episode steps: 796, steps per second:  34, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.006859, mae: 0.185573, mean_q: 0.224924, mean_eps: 0.883612\n",
            " 130361/1000000: episode: 196, duration: 18.896s, episode steps: 643, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.006804, mae: 0.199742, mean_q: 0.245046, mean_eps: 0.882964\n",
            " 131132/1000000: episode: 197, duration: 22.921s, episode steps: 771, steps per second:  34, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.007190, mae: 0.209520, mean_q: 0.255538, mean_eps: 0.882329\n",
            " 131751/1000000: episode: 198, duration: 18.407s, episode steps: 619, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.005365, mae: 0.202995, mean_q: 0.252425, mean_eps: 0.881704\n",
            " 132740/1000000: episode: 199, duration: 29.238s, episode steps: 989, steps per second:  34, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.006874, mae: 0.209389, mean_q: 0.255979, mean_eps: 0.880980\n",
            " 133203/1000000: episode: 200, duration: 13.657s, episode steps: 463, steps per second:  34, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.008151, mae: 0.214095, mean_q: 0.260906, mean_eps: 0.880327\n",
            " 133907/1000000: episode: 201, duration: 20.724s, episode steps: 704, steps per second:  34, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.006739, mae: 0.209892, mean_q: 0.256173, mean_eps: 0.879801\n",
            " 134605/1000000: episode: 202, duration: 20.673s, episode steps: 698, steps per second:  34, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.006608, mae: 0.210021, mean_q: 0.259023, mean_eps: 0.879170\n",
            " 135348/1000000: episode: 203, duration: 22.003s, episode steps: 743, steps per second:  34, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.008381, mae: 0.214401, mean_q: 0.260831, mean_eps: 0.878522\n",
            " 136013/1000000: episode: 204, duration: 19.781s, episode steps: 665, steps per second:  34, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.006224, mae: 0.205297, mean_q: 0.248559, mean_eps: 0.877888\n",
            " 136628/1000000: episode: 205, duration: 18.313s, episode steps: 615, steps per second:  34, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.006435, mae: 0.206643, mean_q: 0.250380, mean_eps: 0.877312\n",
            " 137157/1000000: episode: 206, duration: 15.653s, episode steps: 529, steps per second:  34, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.007572, mae: 0.213583, mean_q: 0.264000, mean_eps: 0.876797\n",
            " 137848/1000000: episode: 207, duration: 20.368s, episode steps: 691, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.007283, mae: 0.208556, mean_q: 0.255753, mean_eps: 0.876248\n",
            " 138461/1000000: episode: 208, duration: 18.152s, episode steps: 613, steps per second:  34, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.006610, mae: 0.212210, mean_q: 0.258145, mean_eps: 0.875661\n",
            " 139449/1000000: episode: 209, duration: 29.417s, episode steps: 988, steps per second:  34, episode reward: 25.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.006782, mae: 0.210195, mean_q: 0.254918, mean_eps: 0.874940\n",
            " 140159/1000000: episode: 210, duration: 21.024s, episode steps: 710, steps per second:  34, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.005724, mae: 0.210784, mean_q: 0.258810, mean_eps: 0.874176\n",
            " 140645/1000000: episode: 211, duration: 14.472s, episode steps: 486, steps per second:  34, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.006337, mae: 0.221669, mean_q: 0.270539, mean_eps: 0.873638\n",
            " 141322/1000000: episode: 212, duration: 19.857s, episode steps: 677, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.006160, mae: 0.223646, mean_q: 0.272037, mean_eps: 0.873114\n",
            " 141960/1000000: episode: 213, duration: 19.091s, episode steps: 638, steps per second:  33, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.007248, mae: 0.225576, mean_q: 0.272981, mean_eps: 0.872524\n",
            " 142617/1000000: episode: 214, duration: 19.504s, episode steps: 657, steps per second:  34, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.005977, mae: 0.223410, mean_q: 0.270219, mean_eps: 0.871941\n",
            " 143003/1000000: episode: 215, duration: 11.430s, episode steps: 386, steps per second:  34, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.007388, mae: 0.224007, mean_q: 0.271727, mean_eps: 0.871471\n",
            " 143732/1000000: episode: 216, duration: 21.747s, episode steps: 729, steps per second:  34, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.006090, mae: 0.221937, mean_q: 0.268840, mean_eps: 0.870971\n",
            " 144372/1000000: episode: 217, duration: 19.017s, episode steps: 640, steps per second:  34, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.006953, mae: 0.222702, mean_q: 0.271081, mean_eps: 0.870355\n",
            " 145022/1000000: episode: 218, duration: 19.192s, episode steps: 650, steps per second:  34, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.006579, mae: 0.225812, mean_q: 0.274498, mean_eps: 0.869774\n",
            " 145366/1000000: episode: 219, duration: 10.169s, episode steps: 344, steps per second:  34, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.004695, mae: 0.219393, mean_q: 0.268779, mean_eps: 0.869325\n",
            " 146017/1000000: episode: 220, duration: 19.285s, episode steps: 651, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.006948, mae: 0.222488, mean_q: 0.271782, mean_eps: 0.868877\n",
            " 146783/1000000: episode: 221, duration: 22.552s, episode steps: 766, steps per second:  34, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.006740, mae: 0.225868, mean_q: 0.275745, mean_eps: 0.868240\n",
            " 147304/1000000: episode: 222, duration: 15.451s, episode steps: 521, steps per second:  34, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.007785, mae: 0.231053, mean_q: 0.280639, mean_eps: 0.867662\n",
            " 147795/1000000: episode: 223, duration: 14.582s, episode steps: 491, steps per second:  34, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.007447, mae: 0.226047, mean_q: 0.274353, mean_eps: 0.867207\n",
            " 148328/1000000: episode: 224, duration: 15.761s, episode steps: 533, steps per second:  34, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.007180, mae: 0.225645, mean_q: 0.273921, mean_eps: 0.866746\n",
            " 149232/1000000: episode: 225, duration: 26.861s, episode steps: 904, steps per second:  34, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006796, mae: 0.225538, mean_q: 0.273715, mean_eps: 0.866100\n",
            " 149868/1000000: episode: 226, duration: 19.134s, episode steps: 636, steps per second:  33, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.006704, mae: 0.226777, mean_q: 0.275167, mean_eps: 0.865407\n",
            " 150554/1000000: episode: 227, duration: 20.490s, episode steps: 686, steps per second:  33, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.007175, mae: 0.251649, mean_q: 0.305064, mean_eps: 0.864811\n",
            " 151529/1000000: episode: 228, duration: 29.060s, episode steps: 975, steps per second:  34, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.006494, mae: 0.259911, mean_q: 0.314616, mean_eps: 0.864062\n",
            " 152530/1000000: episode: 229, duration: 29.884s, episode steps: 1001, steps per second:  33, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.006350, mae: 0.256421, mean_q: 0.311804, mean_eps: 0.863173\n",
            " 153242/1000000: episode: 230, duration: 21.290s, episode steps: 712, steps per second:  33, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.007067, mae: 0.264825, mean_q: 0.324728, mean_eps: 0.862403\n",
            " 153841/1000000: episode: 231, duration: 17.945s, episode steps: 599, steps per second:  33, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.006710, mae: 0.256670, mean_q: 0.312348, mean_eps: 0.861812\n",
            " 154218/1000000: episode: 232, duration: 11.223s, episode steps: 377, steps per second:  34, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.007510, mae: 0.258764, mean_q: 0.313561, mean_eps: 0.861373\n",
            " 154788/1000000: episode: 233, duration: 16.960s, episode steps: 570, steps per second:  34, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.006427, mae: 0.255291, mean_q: 0.317344, mean_eps: 0.860948\n",
            " 155293/1000000: episode: 234, duration: 15.201s, episode steps: 505, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.006819, mae: 0.258722, mean_q: 0.315224, mean_eps: 0.860464\n",
            " 156141/1000000: episode: 235, duration: 25.186s, episode steps: 848, steps per second:  34, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.006293, mae: 0.257711, mean_q: 0.314189, mean_eps: 0.859854\n",
            " 156761/1000000: episode: 236, duration: 18.295s, episode steps: 620, steps per second:  34, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.007617, mae: 0.260450, mean_q: 0.315658, mean_eps: 0.859193\n",
            " 157322/1000000: episode: 237, duration: 16.633s, episode steps: 561, steps per second:  34, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.006594, mae: 0.256794, mean_q: 0.313863, mean_eps: 0.858662\n",
            " 158057/1000000: episode: 238, duration: 21.808s, episode steps: 735, steps per second:  34, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.005872, mae: 0.259780, mean_q: 0.315100, mean_eps: 0.858079\n",
            " 158710/1000000: episode: 239, duration: 19.374s, episode steps: 653, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.006427, mae: 0.259815, mean_q: 0.313013, mean_eps: 0.857454\n",
            " 159385/1000000: episode: 240, duration: 20.057s, episode steps: 675, steps per second:  34, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.006433, mae: 0.260854, mean_q: 0.317651, mean_eps: 0.856857\n",
            " 159721/1000000: episode: 241, duration: 9.914s, episode steps: 336, steps per second:  34, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.007214, mae: 0.258138, mean_q: 0.316412, mean_eps: 0.856401\n",
            " 160610/1000000: episode: 242, duration: 26.675s, episode steps: 889, steps per second:  33, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.006726, mae: 0.275265, mean_q: 0.332496, mean_eps: 0.855851\n",
            " 161308/1000000: episode: 243, duration: 20.594s, episode steps: 698, steps per second:  34, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.007326, mae: 0.283654, mean_q: 0.342798, mean_eps: 0.855138\n",
            " 161951/1000000: episode: 244, duration: 19.079s, episode steps: 643, steps per second:  34, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.007275, mae: 0.282965, mean_q: 0.343190, mean_eps: 0.854535\n",
            " 162780/1000000: episode: 245, duration: 24.659s, episode steps: 829, steps per second:  34, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.007697, mae: 0.287286, mean_q: 0.347871, mean_eps: 0.853872\n",
            " 163329/1000000: episode: 246, duration: 16.372s, episode steps: 549, steps per second:  34, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.007621, mae: 0.284374, mean_q: 0.343160, mean_eps: 0.853251\n",
            " 163951/1000000: episode: 247, duration: 18.563s, episode steps: 622, steps per second:  34, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.008006, mae: 0.287160, mean_q: 0.349447, mean_eps: 0.852724\n",
            " 164447/1000000: episode: 248, duration: 14.822s, episode steps: 496, steps per second:  33, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: 0.007332, mae: 0.285555, mean_q: 0.344140, mean_eps: 0.852222\n",
            " 164999/1000000: episode: 249, duration: 16.516s, episode steps: 552, steps per second:  33, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.007424, mae: 0.286581, mean_q: 0.348383, mean_eps: 0.851750\n",
            " 165496/1000000: episode: 250, duration: 15.158s, episode steps: 497, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.007958, mae: 0.290970, mean_q: 0.352056, mean_eps: 0.851279\n",
            " 165903/1000000: episode: 251, duration: 12.251s, episode steps: 407, steps per second:  33, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.008533, mae: 0.288905, mean_q: 0.356439, mean_eps: 0.850872\n",
            " 166290/1000000: episode: 252, duration: 11.549s, episode steps: 387, steps per second:  34, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.007912, mae: 0.295843, mean_q: 0.361034, mean_eps: 0.850514\n",
            " 167265/1000000: episode: 253, duration: 28.997s, episode steps: 975, steps per second:  34, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.007110, mae: 0.285773, mean_q: 0.347118, mean_eps: 0.849900\n",
            " 168334/1000000: episode: 254, duration: 31.756s, episode steps: 1069, steps per second:  34, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.006888, mae: 0.284014, mean_q: 0.343773, mean_eps: 0.848980\n",
            " 168933/1000000: episode: 255, duration: 17.846s, episode steps: 599, steps per second:  34, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.006943, mae: 0.289911, mean_q: 0.349236, mean_eps: 0.848229\n",
            " 169481/1000000: episode: 256, duration: 16.286s, episode steps: 548, steps per second:  34, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.005679, mae: 0.280011, mean_q: 0.337804, mean_eps: 0.847713\n",
            " 170038/1000000: episode: 257, duration: 16.628s, episode steps: 557, steps per second:  33, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.006900, mae: 0.284789, mean_q: 0.344347, mean_eps: 0.847216\n",
            " 170936/1000000: episode: 258, duration: 26.968s, episode steps: 898, steps per second:  33, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: 0.008606, mae: 0.303302, mean_q: 0.367134, mean_eps: 0.846563\n",
            " 171510/1000000: episode: 259, duration: 17.147s, episode steps: 574, steps per second:  33, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.007907, mae: 0.304320, mean_q: 0.366969, mean_eps: 0.845900\n",
            " 172237/1000000: episode: 260, duration: 21.743s, episode steps: 727, steps per second:  33, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.006594, mae: 0.301964, mean_q: 0.365475, mean_eps: 0.845313\n",
            " 173018/1000000: episode: 261, duration: 23.317s, episode steps: 781, steps per second:  33, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.007957, mae: 0.301284, mean_q: 0.366143, mean_eps: 0.844635\n",
            " 173796/1000000: episode: 262, duration: 23.059s, episode steps: 778, steps per second:  34, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007877, mae: 0.298195, mean_q: 0.361025, mean_eps: 0.843935\n",
            " 175125/1000000: episode: 263, duration: 39.732s, episode steps: 1329, steps per second:  33, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.007678, mae: 0.303086, mean_q: 0.367337, mean_eps: 0.842986\n",
            " 175780/1000000: episode: 264, duration: 19.494s, episode steps: 655, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.007839, mae: 0.297958, mean_q: 0.361454, mean_eps: 0.842093\n",
            " 176169/1000000: episode: 265, duration: 11.763s, episode steps: 389, steps per second:  33, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.009132, mae: 0.308822, mean_q: 0.374859, mean_eps: 0.841623\n",
            " 176939/1000000: episode: 266, duration: 22.809s, episode steps: 770, steps per second:  34, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.007058, mae: 0.299463, mean_q: 0.364554, mean_eps: 0.841101\n",
            " 177568/1000000: episode: 267, duration: 18.817s, episode steps: 629, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006615, mae: 0.300039, mean_q: 0.363245, mean_eps: 0.840473\n",
            " 178241/1000000: episode: 268, duration: 20.211s, episode steps: 673, steps per second:  33, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.007452, mae: 0.303010, mean_q: 0.366613, mean_eps: 0.839886\n",
            " 178790/1000000: episode: 269, duration: 16.462s, episode steps: 549, steps per second:  33, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.007926, mae: 0.305162, mean_q: 0.369168, mean_eps: 0.839336\n",
            " 179153/1000000: episode: 270, duration: 10.896s, episode steps: 363, steps per second:  33, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.005555, mae: 0.291578, mean_q: 0.356315, mean_eps: 0.838925\n",
            " 179862/1000000: episode: 271, duration: 21.286s, episode steps: 709, steps per second:  33, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007586, mae: 0.300205, mean_q: 0.364576, mean_eps: 0.838443\n",
            " 180287/1000000: episode: 272, duration: 12.741s, episode steps: 425, steps per second:  33, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.007110, mae: 0.313523, mean_q: 0.381383, mean_eps: 0.837933\n",
            " 181268/1000000: episode: 273, duration: 29.685s, episode steps: 981, steps per second:  33, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.007971, mae: 0.335849, mean_q: 0.407222, mean_eps: 0.837302\n",
            " 182203/1000000: episode: 274, duration: 27.998s, episode steps: 935, steps per second:  33, episode reward: 26.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.007533, mae: 0.335814, mean_q: 0.407145, mean_eps: 0.836439\n",
            " 182566/1000000: episode: 275, duration: 10.884s, episode steps: 363, steps per second:  33, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.006874, mae: 0.332431, mean_q: 0.403099, mean_eps: 0.835854\n",
            " 183246/1000000: episode: 276, duration: 20.449s, episode steps: 680, steps per second:  33, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.007117, mae: 0.333110, mean_q: 0.402723, mean_eps: 0.835385\n",
            " 184204/1000000: episode: 277, duration: 28.714s, episode steps: 958, steps per second:  33, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.008963, mae: 0.334264, mean_q: 0.403667, mean_eps: 0.834648\n",
            " 184864/1000000: episode: 278, duration: 19.930s, episode steps: 660, steps per second:  33, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.008256, mae: 0.333146, mean_q: 0.404961, mean_eps: 0.833921\n",
            " 185575/1000000: episode: 279, duration: 21.270s, episode steps: 711, steps per second:  33, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.007392, mae: 0.335494, mean_q: 0.404277, mean_eps: 0.833304\n",
            " 185983/1000000: episode: 280, duration: 12.242s, episode steps: 408, steps per second:  33, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.691 [0.000, 5.000],  loss: 0.008029, mae: 0.339447, mean_q: 0.409836, mean_eps: 0.832800\n",
            " 186817/1000000: episode: 281, duration: 24.979s, episode steps: 834, steps per second:  33, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.007377, mae: 0.333020, mean_q: 0.402161, mean_eps: 0.832240\n",
            " 187762/1000000: episode: 282, duration: 28.372s, episode steps: 945, steps per second:  33, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007465, mae: 0.338113, mean_q: 0.408126, mean_eps: 0.831439\n",
            " 188249/1000000: episode: 283, duration: 14.605s, episode steps: 487, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.008937, mae: 0.337223, mean_q: 0.406090, mean_eps: 0.830795\n",
            " 188617/1000000: episode: 284, duration: 10.991s, episode steps: 368, steps per second:  33, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.742 [0.000, 5.000],  loss: 0.007329, mae: 0.332844, mean_q: 0.403387, mean_eps: 0.830409\n",
            " 189243/1000000: episode: 285, duration: 18.543s, episode steps: 626, steps per second:  34, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.008225, mae: 0.333827, mean_q: 0.405595, mean_eps: 0.829963\n",
            " 190381/1000000: episode: 286, duration: 34.225s, episode steps: 1138, steps per second:  33, episode reward: 26.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.007176, mae: 0.339517, mean_q: 0.412591, mean_eps: 0.829169\n",
            " 191042/1000000: episode: 287, duration: 19.801s, episode steps: 661, steps per second:  33, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.710 [0.000, 5.000],  loss: 0.009091, mae: 0.360754, mean_q: 0.437103, mean_eps: 0.828359\n",
            " 191667/1000000: episode: 288, duration: 18.944s, episode steps: 625, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.008417, mae: 0.361204, mean_q: 0.438482, mean_eps: 0.827781\n",
            " 192426/1000000: episode: 289, duration: 22.677s, episode steps: 759, steps per second:  33, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.008044, mae: 0.353805, mean_q: 0.427401, mean_eps: 0.827159\n",
            " 192919/1000000: episode: 290, duration: 14.708s, episode steps: 493, steps per second:  34, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.009911, mae: 0.354212, mean_q: 0.427032, mean_eps: 0.826595\n",
            " 193617/1000000: episode: 291, duration: 20.959s, episode steps: 698, steps per second:  33, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.007744, mae: 0.355995, mean_q: 0.431200, mean_eps: 0.826059\n",
            " 194249/1000000: episode: 292, duration: 19.127s, episode steps: 632, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.007354, mae: 0.354495, mean_q: 0.429287, mean_eps: 0.825459\n",
            " 194660/1000000: episode: 293, duration: 12.440s, episode steps: 411, steps per second:  33, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.008531, mae: 0.359713, mean_q: 0.433556, mean_eps: 0.824991\n",
            " 195229/1000000: episode: 294, duration: 17.133s, episode steps: 569, steps per second:  33, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007109, mae: 0.349035, mean_q: 0.423581, mean_eps: 0.824550\n",
            " 196533/1000000: episode: 295, duration: 39.472s, episode steps: 1304, steps per second:  33, episode reward: 27.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.692 [0.000, 5.000],  loss: 0.007971, mae: 0.353259, mean_q: 0.427712, mean_eps: 0.823706\n",
            " 197178/1000000: episode: 296, duration: 19.309s, episode steps: 645, steps per second:  33, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.008100, mae: 0.356588, mean_q: 0.430312, mean_eps: 0.822830\n",
            " 197763/1000000: episode: 297, duration: 17.529s, episode steps: 585, steps per second:  33, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.008273, mae: 0.360829, mean_q: 0.436063, mean_eps: 0.822277\n",
            " 198506/1000000: episode: 298, duration: 22.208s, episode steps: 743, steps per second:  33, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.008724, mae: 0.355728, mean_q: 0.428410, mean_eps: 0.821679\n",
            " 198973/1000000: episode: 299, duration: 14.012s, episode steps: 467, steps per second:  33, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.007276, mae: 0.361434, mean_q: 0.435528, mean_eps: 0.821134\n",
            " 199619/1000000: episode: 300, duration: 19.276s, episode steps: 646, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.007866, mae: 0.355735, mean_q: 0.430724, mean_eps: 0.820634\n",
            " 200008/1000000: episode: 301, duration: 11.881s, episode steps: 389, steps per second:  33, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.008039, mae: 0.360664, mean_q: 0.435337, mean_eps: 0.820169\n",
            " 200876/1000000: episode: 302, duration: 26.224s, episode steps: 868, steps per second:  33, episode reward:  8.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.007827, mae: 0.377101, mean_q: 0.455899, mean_eps: 0.819604\n",
            " 201671/1000000: episode: 303, duration: 23.999s, episode steps: 795, steps per second:  33, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.008060, mae: 0.385816, mean_q: 0.466378, mean_eps: 0.818855\n",
            " 202664/1000000: episode: 304, duration: 30.021s, episode steps: 993, steps per second:  33, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.008409, mae: 0.382722, mean_q: 0.463330, mean_eps: 0.818051\n",
            " 203344/1000000: episode: 305, duration: 20.532s, episode steps: 680, steps per second:  33, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.008950, mae: 0.386845, mean_q: 0.468646, mean_eps: 0.817298\n",
            " 203969/1000000: episode: 306, duration: 18.885s, episode steps: 625, steps per second:  33, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.008608, mae: 0.385276, mean_q: 0.463574, mean_eps: 0.816710\n",
            " 204629/1000000: episode: 307, duration: 19.773s, episode steps: 660, steps per second:  33, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.007872, mae: 0.382068, mean_q: 0.462560, mean_eps: 0.816130\n",
            " 205334/1000000: episode: 308, duration: 21.170s, episode steps: 705, steps per second:  33, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.009207, mae: 0.391744, mean_q: 0.476226, mean_eps: 0.815516\n",
            " 205876/1000000: episode: 309, duration: 16.450s, episode steps: 542, steps per second:  33, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.007955, mae: 0.386579, mean_q: 0.467524, mean_eps: 0.814956\n",
            " 206473/1000000: episode: 310, duration: 17.972s, episode steps: 597, steps per second:  33, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: 0.007596, mae: 0.386507, mean_q: 0.466461, mean_eps: 0.814443\n",
            " 207166/1000000: episode: 311, duration: 20.685s, episode steps: 693, steps per second:  34, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.008184, mae: 0.387531, mean_q: 0.466703, mean_eps: 0.813862\n",
            " 207857/1000000: episode: 312, duration: 20.787s, episode steps: 691, steps per second:  33, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.008759, mae: 0.385958, mean_q: 0.467485, mean_eps: 0.813239\n",
            " 208293/1000000: episode: 313, duration: 13.167s, episode steps: 436, steps per second:  33, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.008512, mae: 0.382625, mean_q: 0.462229, mean_eps: 0.812732\n",
            " 208888/1000000: episode: 314, duration: 17.824s, episode steps: 595, steps per second:  33, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.008849, mae: 0.389394, mean_q: 0.468608, mean_eps: 0.812269\n",
            " 209604/1000000: episode: 315, duration: 21.612s, episode steps: 716, steps per second:  33, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.007528, mae: 0.387183, mean_q: 0.469024, mean_eps: 0.811680\n",
            " 210840/1000000: episode: 316, duration: 37.378s, episode steps: 1236, steps per second:  33, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.009308, mae: 0.392674, mean_q: 0.474711, mean_eps: 0.810802\n",
            " 211470/1000000: episode: 317, duration: 19.062s, episode steps: 630, steps per second:  33, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.007952, mae: 0.391457, mean_q: 0.472333, mean_eps: 0.809961\n",
            " 212337/1000000: episode: 318, duration: 26.299s, episode steps: 867, steps per second:  33, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.008750, mae: 0.395436, mean_q: 0.478674, mean_eps: 0.809286\n",
            " 213857/1000000: episode: 319, duration: 45.673s, episode steps: 1520, steps per second:  33, episode reward: 21.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.007318, mae: 0.390664, mean_q: 0.472336, mean_eps: 0.808212\n",
            " 215052/1000000: episode: 320, duration: 35.917s, episode steps: 1195, steps per second:  33, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.007686, mae: 0.392751, mean_q: 0.472865, mean_eps: 0.806991\n",
            " 216008/1000000: episode: 321, duration: 28.891s, episode steps: 956, steps per second:  33, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.007102, mae: 0.390510, mean_q: 0.472541, mean_eps: 0.806025\n",
            " 216519/1000000: episode: 322, duration: 15.439s, episode steps: 511, steps per second:  33, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.007711, mae: 0.387161, mean_q: 0.468541, mean_eps: 0.805364\n",
            " 217226/1000000: episode: 323, duration: 21.199s, episode steps: 707, steps per second:  33, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.007371, mae: 0.387325, mean_q: 0.469798, mean_eps: 0.804815\n",
            " 217866/1000000: episode: 324, duration: 19.305s, episode steps: 640, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.007680, mae: 0.390327, mean_q: 0.472330, mean_eps: 0.804209\n",
            " 218503/1000000: episode: 325, duration: 19.143s, episode steps: 637, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.007780, mae: 0.384594, mean_q: 0.465773, mean_eps: 0.803634\n",
            " 219672/1000000: episode: 326, duration: 35.298s, episode steps: 1169, steps per second:  33, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.007458, mae: 0.390523, mean_q: 0.473332, mean_eps: 0.802823\n",
            " 220534/1000000: episode: 327, duration: 26.271s, episode steps: 862, steps per second:  33, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.009435, mae: 0.408068, mean_q: 0.497808, mean_eps: 0.801908\n",
            " 221147/1000000: episode: 328, duration: 18.455s, episode steps: 613, steps per second:  33, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.009334, mae: 0.417912, mean_q: 0.506112, mean_eps: 0.801244\n",
            " 221484/1000000: episode: 329, duration: 10.262s, episode steps: 337, steps per second:  33, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.007979, mae: 0.417775, mean_q: 0.504771, mean_eps: 0.800817\n",
            " 221993/1000000: episode: 330, duration: 15.529s, episode steps: 509, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.009449, mae: 0.419003, mean_q: 0.504085, mean_eps: 0.800436\n",
            " 222775/1000000: episode: 331, duration: 23.719s, episode steps: 782, steps per second:  33, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.009279, mae: 0.418024, mean_q: 0.505248, mean_eps: 0.799854\n",
            " 223411/1000000: episode: 332, duration: 19.227s, episode steps: 636, steps per second:  33, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.008276, mae: 0.418414, mean_q: 0.507589, mean_eps: 0.799217\n",
            " 223856/1000000: episode: 333, duration: 13.535s, episode steps: 445, steps per second:  33, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.007727, mae: 0.421053, mean_q: 0.513328, mean_eps: 0.798731\n",
            " 224375/1000000: episode: 334, duration: 15.758s, episode steps: 519, steps per second:  33, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.008659, mae: 0.419898, mean_q: 0.508884, mean_eps: 0.798297\n",
            " 224910/1000000: episode: 335, duration: 16.291s, episode steps: 535, steps per second:  33, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.008723, mae: 0.418888, mean_q: 0.506564, mean_eps: 0.797822\n",
            " 225576/1000000: episode: 336, duration: 20.175s, episode steps: 666, steps per second:  33, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.008430, mae: 0.425875, mean_q: 0.513076, mean_eps: 0.797282\n",
            " 226099/1000000: episode: 337, duration: 15.972s, episode steps: 523, steps per second:  33, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.007892, mae: 0.415188, mean_q: 0.503542, mean_eps: 0.796748\n",
            " 226576/1000000: episode: 338, duration: 14.624s, episode steps: 477, steps per second:  33, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.007719, mae: 0.413313, mean_q: 0.499406, mean_eps: 0.796298\n",
            " 227504/1000000: episode: 339, duration: 28.080s, episode steps: 928, steps per second:  33, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.008858, mae: 0.415411, mean_q: 0.500802, mean_eps: 0.795666\n",
            " 228003/1000000: episode: 340, duration: 15.162s, episode steps: 499, steps per second:  33, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.010194, mae: 0.416164, mean_q: 0.501722, mean_eps: 0.795023\n",
            " 229485/1000000: episode: 341, duration: 44.727s, episode steps: 1482, steps per second:  33, episode reward: 29.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.008687, mae: 0.420315, mean_q: 0.507478, mean_eps: 0.794130\n",
            " 230630/1000000: episode: 342, duration: 34.704s, episode steps: 1145, steps per second:  33, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.008449, mae: 0.424852, mean_q: 0.512867, mean_eps: 0.792948\n",
            " 231128/1000000: episode: 343, duration: 15.218s, episode steps: 498, steps per second:  33, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.009195, mae: 0.435408, mean_q: 0.526822, mean_eps: 0.792210\n",
            " 231651/1000000: episode: 344, duration: 15.984s, episode steps: 523, steps per second:  33, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.009772, mae: 0.448755, mean_q: 0.541858, mean_eps: 0.791751\n",
            " 232299/1000000: episode: 345, duration: 19.684s, episode steps: 648, steps per second:  33, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.008911, mae: 0.439416, mean_q: 0.531970, mean_eps: 0.791223\n",
            " 232700/1000000: episode: 346, duration: 12.367s, episode steps: 401, steps per second:  32, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.009412, mae: 0.449878, mean_q: 0.543161, mean_eps: 0.790752\n",
            " 233238/1000000: episode: 347, duration: 16.384s, episode steps: 538, steps per second:  33, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.009224, mae: 0.426996, mean_q: 0.514907, mean_eps: 0.790329\n",
            " 234006/1000000: episode: 348, duration: 23.352s, episode steps: 768, steps per second:  33, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.008090, mae: 0.433628, mean_q: 0.524542, mean_eps: 0.789740\n",
            " 234392/1000000: episode: 349, duration: 11.781s, episode steps: 386, steps per second:  33, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.009850, mae: 0.436220, mean_q: 0.526636, mean_eps: 0.789222\n",
            " 235547/1000000: episode: 350, duration: 35.051s, episode steps: 1155, steps per second:  33, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.008929, mae: 0.433911, mean_q: 0.525786, mean_eps: 0.788529\n",
            " 236120/1000000: episode: 351, duration: 17.620s, episode steps: 573, steps per second:  33, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.008941, mae: 0.432627, mean_q: 0.522878, mean_eps: 0.787751\n",
            " 236527/1000000: episode: 352, duration: 12.403s, episode steps: 407, steps per second:  33, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.009270, mae: 0.433550, mean_q: 0.525535, mean_eps: 0.787310\n",
            " 237156/1000000: episode: 353, duration: 19.177s, episode steps: 629, steps per second:  33, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.008863, mae: 0.437373, mean_q: 0.529270, mean_eps: 0.786844\n",
            " 237638/1000000: episode: 354, duration: 14.812s, episode steps: 482, steps per second:  33, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.008627, mae: 0.426462, mean_q: 0.516272, mean_eps: 0.786344\n",
            " 238151/1000000: episode: 355, duration: 15.454s, episode steps: 513, steps per second:  33, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.782 [0.000, 5.000],  loss: 0.009018, mae: 0.436848, mean_q: 0.527502, mean_eps: 0.785895\n",
            " 238506/1000000: episode: 356, duration: 10.835s, episode steps: 355, steps per second:  33, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.763 [0.000, 5.000],  loss: 0.009210, mae: 0.429163, mean_q: 0.517860, mean_eps: 0.785505\n",
            " 238883/1000000: episode: 357, duration: 11.418s, episode steps: 377, steps per second:  33, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.010868, mae: 0.443905, mean_q: 0.538422, mean_eps: 0.785175\n",
            " 239561/1000000: episode: 358, duration: 20.711s, episode steps: 678, steps per second:  33, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.010574, mae: 0.440194, mean_q: 0.534640, mean_eps: 0.784700\n",
            " 239914/1000000: episode: 359, duration: 10.735s, episode steps: 353, steps per second:  33, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.008250, mae: 0.433783, mean_q: 0.528041, mean_eps: 0.784236\n",
            " 240828/1000000: episode: 360, duration: 28.004s, episode steps: 914, steps per second:  33, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.009338, mae: 0.460064, mean_q: 0.559165, mean_eps: 0.783667\n",
            " 241405/1000000: episode: 361, duration: 17.674s, episode steps: 577, steps per second:  33, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.010527, mae: 0.469039, mean_q: 0.568951, mean_eps: 0.782996\n",
            " 241860/1000000: episode: 362, duration: 13.971s, episode steps: 455, steps per second:  33, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.008847, mae: 0.459628, mean_q: 0.558605, mean_eps: 0.782531\n",
            " 242907/1000000: episode: 363, duration: 32.164s, episode steps: 1047, steps per second:  33, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.009088, mae: 0.461945, mean_q: 0.560405, mean_eps: 0.781856\n",
            " 244054/1000000: episode: 364, duration: 35.082s, episode steps: 1147, steps per second:  33, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.010052, mae: 0.464672, mean_q: 0.561735, mean_eps: 0.780868\n",
            " 244717/1000000: episode: 365, duration: 20.195s, episode steps: 663, steps per second:  33, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.010573, mae: 0.467571, mean_q: 0.565692, mean_eps: 0.780053\n",
            " 245446/1000000: episode: 366, duration: 22.281s, episode steps: 729, steps per second:  33, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.009124, mae: 0.458144, mean_q: 0.556325, mean_eps: 0.779426\n",
            " 245930/1000000: episode: 367, duration: 14.879s, episode steps: 484, steps per second:  33, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.008274, mae: 0.466374, mean_q: 0.563335, mean_eps: 0.778881\n",
            " 246340/1000000: episode: 368, duration: 12.546s, episode steps: 410, steps per second:  33, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.008414, mae: 0.453177, mean_q: 0.549892, mean_eps: 0.778479\n",
            " 247405/1000000: episode: 369, duration: 32.560s, episode steps: 1065, steps per second:  33, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.009042, mae: 0.464857, mean_q: 0.564228, mean_eps: 0.777815\n",
            " 247950/1000000: episode: 370, duration: 16.681s, episode steps: 545, steps per second:  33, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.008858, mae: 0.459869, mean_q: 0.558106, mean_eps: 0.777090\n",
            " 248506/1000000: episode: 371, duration: 16.968s, episode steps: 556, steps per second:  33, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.009702, mae: 0.469550, mean_q: 0.569526, mean_eps: 0.776595\n",
            " 248889/1000000: episode: 372, duration: 11.711s, episode steps: 383, steps per second:  33, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.439 [0.000, 5.000],  loss: 0.008737, mae: 0.466939, mean_q: 0.567166, mean_eps: 0.776172\n",
            " 249311/1000000: episode: 373, duration: 12.950s, episode steps: 422, steps per second:  33, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.009396, mae: 0.463714, mean_q: 0.562284, mean_eps: 0.775810\n",
            " 250077/1000000: episode: 374, duration: 23.604s, episode steps: 766, steps per second:  32, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.009578, mae: 0.461976, mean_q: 0.559920, mean_eps: 0.775275\n",
            " 250559/1000000: episode: 375, duration: 14.699s, episode steps: 482, steps per second:  33, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.009324, mae: 0.473181, mean_q: 0.575145, mean_eps: 0.774714\n",
            " 251549/1000000: episode: 376, duration: 30.540s, episode steps: 990, steps per second:  32, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.009248, mae: 0.483229, mean_q: 0.587055, mean_eps: 0.774051\n",
            " 252088/1000000: episode: 377, duration: 16.483s, episode steps: 539, steps per second:  33, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.009166, mae: 0.477950, mean_q: 0.581435, mean_eps: 0.773364\n",
            " 252655/1000000: episode: 378, duration: 17.488s, episode steps: 567, steps per second:  32, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.007068, mae: 0.471018, mean_q: 0.573794, mean_eps: 0.772867\n",
            " 253595/1000000: episode: 379, duration: 28.989s, episode steps: 940, steps per second:  32, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.009742, mae: 0.478484, mean_q: 0.580121, mean_eps: 0.772188\n",
            " 253984/1000000: episode: 380, duration: 11.989s, episode steps: 389, steps per second:  32, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.009025, mae: 0.472488, mean_q: 0.571462, mean_eps: 0.771591\n",
            " 254406/1000000: episode: 381, duration: 12.985s, episode steps: 422, steps per second:  32, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.010352, mae: 0.480108, mean_q: 0.581389, mean_eps: 0.771225\n",
            " 255344/1000000: episode: 382, duration: 28.883s, episode steps: 938, steps per second:  32, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.009807, mae: 0.485283, mean_q: 0.587374, mean_eps: 0.770613\n",
            " 256082/1000000: episode: 383, duration: 22.694s, episode steps: 738, steps per second:  33, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.009783, mae: 0.481406, mean_q: 0.585510, mean_eps: 0.769859\n",
            " 257016/1000000: episode: 384, duration: 28.803s, episode steps: 934, steps per second:  32, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.727 [0.000, 5.000],  loss: 0.008633, mae: 0.480662, mean_q: 0.581901, mean_eps: 0.769107\n",
            " 257894/1000000: episode: 385, duration: 27.279s, episode steps: 878, steps per second:  32, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.010415, mae: 0.479607, mean_q: 0.579242, mean_eps: 0.768291\n",
            " 258555/1000000: episode: 386, duration: 20.312s, episode steps: 661, steps per second:  33, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.009962, mae: 0.479672, mean_q: 0.584631, mean_eps: 0.767598\n",
            " 259162/1000000: episode: 387, duration: 18.749s, episode steps: 607, steps per second:  32, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.750 [0.000, 5.000],  loss: 0.009230, mae: 0.481451, mean_q: 0.583473, mean_eps: 0.767028\n",
            " 259827/1000000: episode: 388, duration: 20.560s, episode steps: 665, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.008157, mae: 0.477551, mean_q: 0.578734, mean_eps: 0.766455\n",
            " 260233/1000000: episode: 389, duration: 12.584s, episode steps: 406, steps per second:  32, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.007921, mae: 0.496747, mean_q: 0.604338, mean_eps: 0.765973\n",
            " 261012/1000000: episode: 390, duration: 24.089s, episode steps: 779, steps per second:  32, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.009346, mae: 0.514390, mean_q: 0.624226, mean_eps: 0.765440\n",
            " 261738/1000000: episode: 391, duration: 22.485s, episode steps: 726, steps per second:  32, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.009986, mae: 0.512122, mean_q: 0.621392, mean_eps: 0.764763\n",
            " 262217/1000000: episode: 392, duration: 14.723s, episode steps: 479, steps per second:  33, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.010977, mae: 0.523617, mean_q: 0.633650, mean_eps: 0.764220\n",
            " 262726/1000000: episode: 393, duration: 15.676s, episode steps: 509, steps per second:  32, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.008444, mae: 0.516405, mean_q: 0.624943, mean_eps: 0.763775\n",
            " 263614/1000000: episode: 394, duration: 27.626s, episode steps: 888, steps per second:  32, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.009227, mae: 0.508436, mean_q: 0.617051, mean_eps: 0.763147\n",
            " 264404/1000000: episode: 395, duration: 24.404s, episode steps: 790, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.008933, mae: 0.516672, mean_q: 0.627326, mean_eps: 0.762393\n",
            " 265210/1000000: episode: 396, duration: 24.906s, episode steps: 806, steps per second:  32, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.010580, mae: 0.513893, mean_q: 0.621937, mean_eps: 0.761675\n",
            " 266306/1000000: episode: 397, duration: 33.620s, episode steps: 1096, steps per second:  33, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.008222, mae: 0.514495, mean_q: 0.624774, mean_eps: 0.760818\n",
            " 266832/1000000: episode: 398, duration: 16.256s, episode steps: 526, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.010030, mae: 0.507103, mean_q: 0.617934, mean_eps: 0.760089\n",
            " 267774/1000000: episode: 399, duration: 29.071s, episode steps: 942, steps per second:  32, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.008909, mae: 0.514227, mean_q: 0.626177, mean_eps: 0.759428\n",
            " 268411/1000000: episode: 400, duration: 19.739s, episode steps: 637, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.009220, mae: 0.517346, mean_q: 0.628905, mean_eps: 0.758717\n",
            " 268757/1000000: episode: 401, duration: 10.965s, episode steps: 346, steps per second:  32, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.801 [0.000, 5.000],  loss: 0.009624, mae: 0.516603, mean_q: 0.626130, mean_eps: 0.758274\n",
            " 269366/1000000: episode: 402, duration: 18.941s, episode steps: 609, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.009338, mae: 0.520307, mean_q: 0.631852, mean_eps: 0.757844\n",
            " 269963/1000000: episode: 403, duration: 18.526s, episode steps: 597, steps per second:  32, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.008853, mae: 0.507983, mean_q: 0.615457, mean_eps: 0.757302\n",
            " 270327/1000000: episode: 404, duration: 11.223s, episode steps: 364, steps per second:  32, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.009594, mae: 0.527528, mean_q: 0.639414, mean_eps: 0.756870\n",
            " 271150/1000000: episode: 405, duration: 25.483s, episode steps: 823, steps per second:  32, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.009706, mae: 0.528656, mean_q: 0.639090, mean_eps: 0.756336\n",
            " 271951/1000000: episode: 406, duration: 24.703s, episode steps: 801, steps per second:  32, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.008627, mae: 0.526759, mean_q: 0.638409, mean_eps: 0.755605\n",
            " 272436/1000000: episode: 407, duration: 14.956s, episode steps: 485, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.009645, mae: 0.530530, mean_q: 0.645756, mean_eps: 0.755027\n",
            " 272953/1000000: episode: 408, duration: 16.348s, episode steps: 517, steps per second:  32, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.008706, mae: 0.532808, mean_q: 0.648191, mean_eps: 0.754575\n",
            " 273637/1000000: episode: 409, duration: 21.164s, episode steps: 684, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.008923, mae: 0.526409, mean_q: 0.639969, mean_eps: 0.754034\n",
            " 274716/1000000: episode: 410, duration: 33.488s, episode steps: 1079, steps per second:  32, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.009504, mae: 0.533076, mean_q: 0.647847, mean_eps: 0.753242\n",
            " 275684/1000000: episode: 411, duration: 30.002s, episode steps: 968, steps per second:  32, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.007876, mae: 0.521804, mean_q: 0.634360, mean_eps: 0.752322\n",
            " 276070/1000000: episode: 412, duration: 11.976s, episode steps: 386, steps per second:  32, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.009209, mae: 0.518741, mean_q: 0.631207, mean_eps: 0.751712\n",
            " 276486/1000000: episode: 413, duration: 12.844s, episode steps: 416, steps per second:  32, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.009880, mae: 0.528867, mean_q: 0.644098, mean_eps: 0.751350\n",
            " 276884/1000000: episode: 414, duration: 12.293s, episode steps: 398, steps per second:  32, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.010459, mae: 0.533073, mean_q: 0.646974, mean_eps: 0.750984\n",
            " 277437/1000000: episode: 415, duration: 17.167s, episode steps: 553, steps per second:  32, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.792 [0.000, 5.000],  loss: 0.010649, mae: 0.530124, mean_q: 0.646754, mean_eps: 0.750556\n",
            " 278472/1000000: episode: 416, duration: 32.113s, episode steps: 1035, steps per second:  32, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.009119, mae: 0.533624, mean_q: 0.650529, mean_eps: 0.749841\n",
            " 278999/1000000: episode: 417, duration: 16.333s, episode steps: 527, steps per second:  32, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.008809, mae: 0.521890, mean_q: 0.635537, mean_eps: 0.749139\n",
            " 279682/1000000: episode: 418, duration: 21.193s, episode steps: 683, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.009542, mae: 0.529792, mean_q: 0.647399, mean_eps: 0.748594\n",
            " 280081/1000000: episode: 419, duration: 12.298s, episode steps: 399, steps per second:  32, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.009199, mae: 0.537216, mean_q: 0.654610, mean_eps: 0.748106\n",
            " 281176/1000000: episode: 420, duration: 33.982s, episode steps: 1095, steps per second:  32, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.008791, mae: 0.564388, mean_q: 0.689486, mean_eps: 0.747435\n",
            " 281819/1000000: episode: 421, duration: 19.799s, episode steps: 643, steps per second:  32, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.008747, mae: 0.567284, mean_q: 0.693519, mean_eps: 0.746654\n",
            " 282485/1000000: episode: 422, duration: 20.671s, episode steps: 666, steps per second:  32, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.008534, mae: 0.562115, mean_q: 0.685305, mean_eps: 0.746063\n",
            " 283276/1000000: episode: 423, duration: 24.605s, episode steps: 791, steps per second:  32, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.009800, mae: 0.567550, mean_q: 0.690799, mean_eps: 0.745408\n",
            " 283702/1000000: episode: 424, duration: 13.188s, episode steps: 426, steps per second:  32, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.009135, mae: 0.562754, mean_q: 0.684022, mean_eps: 0.744861\n",
            " 284042/1000000: episode: 425, duration: 10.527s, episode steps: 340, steps per second:  32, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.009722, mae: 0.555057, mean_q: 0.676477, mean_eps: 0.744515\n",
            " 284461/1000000: episode: 426, duration: 13.081s, episode steps: 419, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.009256, mae: 0.565766, mean_q: 0.687205, mean_eps: 0.744173\n",
            " 285565/1000000: episode: 427, duration: 34.096s, episode steps: 1104, steps per second:  32, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.009635, mae: 0.564311, mean_q: 0.686461, mean_eps: 0.743487\n",
            " 286536/1000000: episode: 428, duration: 30.237s, episode steps: 971, steps per second:  32, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.009077, mae: 0.569197, mean_q: 0.691442, mean_eps: 0.742555\n",
            " 287381/1000000: episode: 429, duration: 26.277s, episode steps: 845, steps per second:  32, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.008531, mae: 0.570034, mean_q: 0.694039, mean_eps: 0.741738\n",
            " 287760/1000000: episode: 430, duration: 11.817s, episode steps: 379, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.009759, mae: 0.563413, mean_q: 0.684307, mean_eps: 0.741187\n",
            " 288119/1000000: episode: 431, duration: 11.242s, episode steps: 359, steps per second:  32, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.010950, mae: 0.578432, mean_q: 0.700682, mean_eps: 0.740856\n",
            " 288454/1000000: episode: 432, duration: 10.397s, episode steps: 335, steps per second:  32, episode reward:  6.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.010550, mae: 0.569878, mean_q: 0.688922, mean_eps: 0.740543\n",
            " 288991/1000000: episode: 433, duration: 16.685s, episode steps: 537, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.010189, mae: 0.570736, mean_q: 0.691078, mean_eps: 0.740150\n",
            " 289690/1000000: episode: 434, duration: 21.706s, episode steps: 699, steps per second:  32, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.734 [0.000, 5.000],  loss: 0.009062, mae: 0.559612, mean_q: 0.677724, mean_eps: 0.739594\n",
            " 290308/1000000: episode: 435, duration: 19.308s, episode steps: 618, steps per second:  32, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.008964, mae: 0.578338, mean_q: 0.701169, mean_eps: 0.739002\n",
            " 290697/1000000: episode: 436, duration: 12.276s, episode steps: 389, steps per second:  32, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.007585, mae: 0.588756, mean_q: 0.717143, mean_eps: 0.738548\n",
            " 291043/1000000: episode: 437, duration: 10.695s, episode steps: 346, steps per second:  32, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.725 [0.000, 5.000],  loss: 0.008249, mae: 0.576312, mean_q: 0.701849, mean_eps: 0.738217\n",
            " 291763/1000000: episode: 438, duration: 22.382s, episode steps: 720, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.009734, mae: 0.599080, mean_q: 0.726825, mean_eps: 0.737738\n",
            " 292479/1000000: episode: 439, duration: 22.203s, episode steps: 716, steps per second:  32, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.008705, mae: 0.579737, mean_q: 0.704939, mean_eps: 0.737092\n",
            " 292973/1000000: episode: 440, duration: 15.483s, episode steps: 494, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.008794, mae: 0.583433, mean_q: 0.708067, mean_eps: 0.736547\n",
            " 293356/1000000: episode: 441, duration: 11.936s, episode steps: 383, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.009215, mae: 0.588685, mean_q: 0.718949, mean_eps: 0.736152\n",
            " 294009/1000000: episode: 442, duration: 20.473s, episode steps: 653, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.009044, mae: 0.588036, mean_q: 0.713476, mean_eps: 0.735686\n",
            " 294576/1000000: episode: 443, duration: 17.574s, episode steps: 567, steps per second:  32, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.009054, mae: 0.579550, mean_q: 0.704315, mean_eps: 0.735137\n",
            " 295027/1000000: episode: 444, duration: 14.064s, episode steps: 451, steps per second:  32, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.752 [0.000, 5.000],  loss: 0.008068, mae: 0.589855, mean_q: 0.717442, mean_eps: 0.734680\n",
            " 295986/1000000: episode: 445, duration: 29.929s, episode steps: 959, steps per second:  32, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.704 [0.000, 5.000],  loss: 0.008287, mae: 0.584953, mean_q: 0.711165, mean_eps: 0.734045\n",
            " 297083/1000000: episode: 446, duration: 34.032s, episode steps: 1097, steps per second:  32, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.008389, mae: 0.586393, mean_q: 0.712471, mean_eps: 0.733119\n",
            " 297738/1000000: episode: 447, duration: 20.409s, episode steps: 655, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.007410, mae: 0.582206, mean_q: 0.706870, mean_eps: 0.732331\n",
            " 298076/1000000: episode: 448, duration: 10.581s, episode steps: 338, steps per second:  32, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.796 [0.000, 5.000],  loss: 0.009167, mae: 0.589051, mean_q: 0.714742, mean_eps: 0.731885\n",
            " 298446/1000000: episode: 449, duration: 11.560s, episode steps: 370, steps per second:  32, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.009343, mae: 0.571625, mean_q: 0.695913, mean_eps: 0.731566\n",
            " 299106/1000000: episode: 450, duration: 20.570s, episode steps: 660, steps per second:  32, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.780 [0.000, 5.000],  loss: 0.008656, mae: 0.594884, mean_q: 0.723389, mean_eps: 0.731102\n",
            " 299656/1000000: episode: 451, duration: 17.216s, episode steps: 550, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.009778, mae: 0.590774, mean_q: 0.721297, mean_eps: 0.730558\n",
            " 300141/1000000: episode: 452, duration: 15.236s, episode steps: 485, steps per second:  32, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.759 [0.000, 5.000],  loss: 0.009455, mae: 0.594306, mean_q: 0.724174, mean_eps: 0.730092\n",
            " 301053/1000000: episode: 453, duration: 28.397s, episode steps: 912, steps per second:  32, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.009332, mae: 0.612453, mean_q: 0.744048, mean_eps: 0.729462\n",
            " 302057/1000000: episode: 454, duration: 31.576s, episode steps: 1004, steps per second:  32, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.009449, mae: 0.619540, mean_q: 0.751952, mean_eps: 0.728600\n",
            " 303126/1000000: episode: 455, duration: 33.458s, episode steps: 1069, steps per second:  32, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.009018, mae: 0.612066, mean_q: 0.743247, mean_eps: 0.727667\n",
            " 303632/1000000: episode: 456, duration: 16.061s, episode steps: 506, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.010225, mae: 0.625210, mean_q: 0.759450, mean_eps: 0.726960\n",
            " 304270/1000000: episode: 457, duration: 19.995s, episode steps: 638, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.008170, mae: 0.607554, mean_q: 0.738273, mean_eps: 0.726445\n",
            " 304965/1000000: episode: 458, duration: 21.844s, episode steps: 695, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.009418, mae: 0.615172, mean_q: 0.745789, mean_eps: 0.725844\n",
            " 305623/1000000: episode: 459, duration: 20.632s, episode steps: 658, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.009474, mae: 0.623494, mean_q: 0.757322, mean_eps: 0.725235\n",
            " 306367/1000000: episode: 460, duration: 23.199s, episode steps: 744, steps per second:  32, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.009142, mae: 0.616446, mean_q: 0.749846, mean_eps: 0.724605\n",
            " 307301/1000000: episode: 461, duration: 29.250s, episode steps: 934, steps per second:  32, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.009926, mae: 0.619816, mean_q: 0.755181, mean_eps: 0.723849\n",
            " 307837/1000000: episode: 462, duration: 16.899s, episode steps: 536, steps per second:  32, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.009787, mae: 0.614984, mean_q: 0.746227, mean_eps: 0.723187\n",
            " 308173/1000000: episode: 463, duration: 10.556s, episode steps: 336, steps per second:  32, episode reward:  6.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.009215, mae: 0.625544, mean_q: 0.758281, mean_eps: 0.722795\n",
            " 309332/1000000: episode: 464, duration: 36.643s, episode steps: 1159, steps per second:  32, episode reward: 30.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.008801, mae: 0.613585, mean_q: 0.744617, mean_eps: 0.722123\n",
            " 309854/1000000: episode: 465, duration: 16.446s, episode steps: 522, steps per second:  32, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.009399, mae: 0.619274, mean_q: 0.749701, mean_eps: 0.721367\n",
            " 310601/1000000: episode: 466, duration: 23.510s, episode steps: 747, steps per second:  32, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.241 [0.000, 5.000],  loss: 0.008616, mae: 0.626623, mean_q: 0.758954, mean_eps: 0.720795\n",
            " 311272/1000000: episode: 467, duration: 21.561s, episode steps: 671, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.009660, mae: 0.637794, mean_q: 0.774601, mean_eps: 0.720158\n",
            " 312509/1000000: episode: 468, duration: 39.806s, episode steps: 1237, steps per second:  31, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.009838, mae: 0.632515, mean_q: 0.766930, mean_eps: 0.719299\n",
            " 313381/1000000: episode: 469, duration: 27.936s, episode steps: 872, steps per second:  31, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.009154, mae: 0.634929, mean_q: 0.771074, mean_eps: 0.718349\n",
            " 314217/1000000: episode: 470, duration: 26.501s, episode steps: 836, steps per second:  32, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.009876, mae: 0.636400, mean_q: 0.770698, mean_eps: 0.717580\n",
            " 314630/1000000: episode: 471, duration: 13.083s, episode steps: 413, steps per second:  32, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: 0.009391, mae: 0.643355, mean_q: 0.779891, mean_eps: 0.717018\n",
            " 315155/1000000: episode: 472, duration: 16.694s, episode steps: 525, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.010529, mae: 0.640840, mean_q: 0.775824, mean_eps: 0.716597\n",
            " 315840/1000000: episode: 473, duration: 21.825s, episode steps: 685, steps per second:  31, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.010156, mae: 0.626085, mean_q: 0.758883, mean_eps: 0.716054\n",
            " 316572/1000000: episode: 474, duration: 23.273s, episode steps: 732, steps per second:  31, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.008705, mae: 0.633752, mean_q: 0.768889, mean_eps: 0.715416\n",
            " 317366/1000000: episode: 475, duration: 25.457s, episode steps: 794, steps per second:  31, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.008497, mae: 0.631270, mean_q: 0.768580, mean_eps: 0.714729\n",
            " 318335/1000000: episode: 476, duration: 30.727s, episode steps: 969, steps per second:  32, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.008711, mae: 0.633594, mean_q: 0.770014, mean_eps: 0.713935\n",
            " 319142/1000000: episode: 477, duration: 25.927s, episode steps: 807, steps per second:  31, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.011109, mae: 0.640486, mean_q: 0.777457, mean_eps: 0.713136\n",
            " 319680/1000000: episode: 478, duration: 17.234s, episode steps: 538, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.009278, mae: 0.639254, mean_q: 0.776504, mean_eps: 0.712531\n",
            " 320310/1000000: episode: 479, duration: 20.144s, episode steps: 630, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.008505, mae: 0.638596, mean_q: 0.776896, mean_eps: 0.712005\n",
            " 320664/1000000: episode: 480, duration: 11.405s, episode steps: 354, steps per second:  31, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.009764, mae: 0.664719, mean_q: 0.807876, mean_eps: 0.711563\n",
            " 321136/1000000: episode: 481, duration: 15.168s, episode steps: 472, steps per second:  31, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.009707, mae: 0.664613, mean_q: 0.809059, mean_eps: 0.711192\n",
            " 321671/1000000: episode: 482, duration: 16.970s, episode steps: 535, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.009233, mae: 0.667912, mean_q: 0.814187, mean_eps: 0.710738\n",
            " 322373/1000000: episode: 483, duration: 22.445s, episode steps: 702, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.900 [0.000, 5.000],  loss: 0.010119, mae: 0.663654, mean_q: 0.808272, mean_eps: 0.710180\n",
            " 323248/1000000: episode: 484, duration: 27.935s, episode steps: 875, steps per second:  31, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.009310, mae: 0.665236, mean_q: 0.810313, mean_eps: 0.709471\n",
            " 324034/1000000: episode: 485, duration: 25.021s, episode steps: 786, steps per second:  31, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.008974, mae: 0.667491, mean_q: 0.811190, mean_eps: 0.708724\n",
            " 324489/1000000: episode: 486, duration: 14.552s, episode steps: 455, steps per second:  31, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.009506, mae: 0.667989, mean_q: 0.814781, mean_eps: 0.708164\n",
            " 324998/1000000: episode: 487, duration: 16.051s, episode steps: 509, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.009190, mae: 0.664522, mean_q: 0.807169, mean_eps: 0.707730\n",
            " 325682/1000000: episode: 488, duration: 21.817s, episode steps: 684, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.009699, mae: 0.663684, mean_q: 0.806628, mean_eps: 0.707194\n",
            " 326151/1000000: episode: 489, duration: 14.897s, episode steps: 469, steps per second:  31, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.008458, mae: 0.653381, mean_q: 0.794483, mean_eps: 0.706676\n",
            " 327008/1000000: episode: 490, duration: 27.486s, episode steps: 857, steps per second:  31, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.008418, mae: 0.656411, mean_q: 0.799019, mean_eps: 0.706080\n",
            " 327513/1000000: episode: 491, duration: 16.234s, episode steps: 505, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.009823, mae: 0.668791, mean_q: 0.813287, mean_eps: 0.705466\n",
            " 328016/1000000: episode: 492, duration: 15.942s, episode steps: 503, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.008222, mae: 0.670800, mean_q: 0.813427, mean_eps: 0.705012\n",
            " 328527/1000000: episode: 493, duration: 16.285s, episode steps: 511, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.008461, mae: 0.658700, mean_q: 0.798581, mean_eps: 0.704557\n",
            " 329380/1000000: episode: 494, duration: 27.210s, episode steps: 853, steps per second:  31, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.008475, mae: 0.664395, mean_q: 0.806390, mean_eps: 0.703943\n",
            " 329707/1000000: episode: 495, duration: 10.345s, episode steps: 327, steps per second:  32, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.008942, mae: 0.663744, mean_q: 0.804499, mean_eps: 0.703412\n",
            " 330238/1000000: episode: 496, duration: 16.966s, episode steps: 531, steps per second:  31, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.009207, mae: 0.673152, mean_q: 0.819442, mean_eps: 0.703025\n",
            " 330634/1000000: episode: 497, duration: 12.540s, episode steps: 396, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.009300, mae: 0.683417, mean_q: 0.830931, mean_eps: 0.702608\n",
            " 331279/1000000: episode: 498, duration: 20.463s, episode steps: 645, steps per second:  32, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.008451, mae: 0.686161, mean_q: 0.837667, mean_eps: 0.702140\n",
            " 331916/1000000: episode: 499, duration: 20.268s, episode steps: 637, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.009084, mae: 0.685003, mean_q: 0.833394, mean_eps: 0.701564\n",
            " 332603/1000000: episode: 500, duration: 21.912s, episode steps: 687, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.785 [0.000, 5.000],  loss: 0.008701, mae: 0.687199, mean_q: 0.836258, mean_eps: 0.700968\n",
            " 333188/1000000: episode: 501, duration: 19.058s, episode steps: 585, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.010000, mae: 0.697804, mean_q: 0.846483, mean_eps: 0.700395\n",
            " 333800/1000000: episode: 502, duration: 19.960s, episode steps: 612, steps per second:  31, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.714 [0.000, 5.000],  loss: 0.010381, mae: 0.695633, mean_q: 0.846976, mean_eps: 0.699857\n",
            " 334240/1000000: episode: 503, duration: 14.498s, episode steps: 440, steps per second:  30, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.009946, mae: 0.693466, mean_q: 0.845041, mean_eps: 0.699384\n",
            " 334801/1000000: episode: 504, duration: 18.426s, episode steps: 561, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.008943, mae: 0.694021, mean_q: 0.843769, mean_eps: 0.698932\n",
            " 335468/1000000: episode: 505, duration: 21.932s, episode steps: 667, steps per second:  30, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.008976, mae: 0.691878, mean_q: 0.841793, mean_eps: 0.698379\n",
            " 335981/1000000: episode: 506, duration: 16.603s, episode steps: 513, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.008329, mae: 0.676531, mean_q: 0.825818, mean_eps: 0.697848\n",
            " 336419/1000000: episode: 507, duration: 13.956s, episode steps: 438, steps per second:  31, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.008762, mae: 0.682322, mean_q: 0.831466, mean_eps: 0.697420\n",
            " 337661/1000000: episode: 508, duration: 40.046s, episode steps: 1242, steps per second:  31, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.008396, mae: 0.687400, mean_q: 0.833529, mean_eps: 0.696664\n",
            " 338058/1000000: episode: 509, duration: 12.700s, episode steps: 397, steps per second:  31, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.312 [0.000, 5.000],  loss: 0.009249, mae: 0.686857, mean_q: 0.833284, mean_eps: 0.695926\n",
            " 338740/1000000: episode: 510, duration: 22.037s, episode steps: 682, steps per second:  31, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.009790, mae: 0.685427, mean_q: 0.833443, mean_eps: 0.695442\n",
            " 339324/1000000: episode: 511, duration: 18.963s, episode steps: 584, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.008375, mae: 0.681908, mean_q: 0.832316, mean_eps: 0.694873\n",
            " 340136/1000000: episode: 512, duration: 26.204s, episode steps: 812, steps per second:  31, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.695 [0.000, 5.000],  loss: 0.009158, mae: 0.689397, mean_q: 0.839413, mean_eps: 0.694245\n",
            " 341298/1000000: episode: 513, duration: 37.332s, episode steps: 1162, steps per second:  31, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.008204, mae: 0.717074, mean_q: 0.872810, mean_eps: 0.693356\n",
            " 342152/1000000: episode: 514, duration: 28.105s, episode steps: 854, steps per second:  30, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.010001, mae: 0.719530, mean_q: 0.874626, mean_eps: 0.692448\n",
            " 342655/1000000: episode: 515, duration: 16.310s, episode steps: 503, steps per second:  31, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.009627, mae: 0.725270, mean_q: 0.877960, mean_eps: 0.691838\n",
            " 343129/1000000: episode: 516, duration: 15.437s, episode steps: 474, steps per second:  31, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.011178, mae: 0.736548, mean_q: 0.892509, mean_eps: 0.691397\n",
            " 343743/1000000: episode: 517, duration: 19.882s, episode steps: 614, steps per second:  31, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: 0.010412, mae: 0.719643, mean_q: 0.875131, mean_eps: 0.690908\n",
            " 344552/1000000: episode: 518, duration: 26.099s, episode steps: 809, steps per second:  31, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.008337, mae: 0.716860, mean_q: 0.872940, mean_eps: 0.690269\n",
            " 344998/1000000: episode: 519, duration: 14.478s, episode steps: 446, steps per second:  31, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.009354, mae: 0.716092, mean_q: 0.870943, mean_eps: 0.689703\n",
            " 345510/1000000: episode: 520, duration: 16.643s, episode steps: 512, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.152 [0.000, 5.000],  loss: 0.009925, mae: 0.725257, mean_q: 0.880756, mean_eps: 0.689271\n",
            " 346286/1000000: episode: 521, duration: 25.211s, episode steps: 776, steps per second:  31, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.010364, mae: 0.725825, mean_q: 0.882795, mean_eps: 0.688692\n",
            " 346680/1000000: episode: 522, duration: 12.959s, episode steps: 394, steps per second:  30, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.797 [0.000, 5.000],  loss: 0.008260, mae: 0.704502, mean_q: 0.853483, mean_eps: 0.688166\n",
            " 347067/1000000: episode: 523, duration: 12.613s, episode steps: 387, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: 0.009767, mae: 0.715421, mean_q: 0.868359, mean_eps: 0.687815\n",
            " 347576/1000000: episode: 524, duration: 16.499s, episode steps: 509, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.018 [0.000, 5.000],  loss: 0.009110, mae: 0.724656, mean_q: 0.879777, mean_eps: 0.687412\n",
            " 348153/1000000: episode: 525, duration: 18.790s, episode steps: 577, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.865 [0.000, 5.000],  loss: 0.008544, mae: 0.716310, mean_q: 0.869628, mean_eps: 0.686922\n",
            " 348987/1000000: episode: 526, duration: 27.065s, episode steps: 834, steps per second:  31, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.009971, mae: 0.714364, mean_q: 0.868612, mean_eps: 0.686287\n",
            " 349970/1000000: episode: 527, duration: 31.932s, episode steps: 983, steps per second:  31, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.009176, mae: 0.718498, mean_q: 0.872918, mean_eps: 0.685470\n",
            " 350609/1000000: episode: 528, duration: 20.939s, episode steps: 639, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.009513, mae: 0.752138, mean_q: 0.915741, mean_eps: 0.684739\n",
            " 350945/1000000: episode: 529, duration: 10.999s, episode steps: 336, steps per second:  31, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.161 [0.000, 5.000],  loss: 0.010494, mae: 0.762007, mean_q: 0.927603, mean_eps: 0.684300\n",
            " 351597/1000000: episode: 530, duration: 21.489s, episode steps: 652, steps per second:  30, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.009427, mae: 0.760976, mean_q: 0.925263, mean_eps: 0.683855\n",
            " 352194/1000000: episode: 531, duration: 19.500s, episode steps: 597, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.010283, mae: 0.774796, mean_q: 0.941489, mean_eps: 0.683294\n",
            " 352845/1000000: episode: 532, duration: 21.119s, episode steps: 651, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.010093, mae: 0.775140, mean_q: 0.941974, mean_eps: 0.682732\n",
            " 353264/1000000: episode: 533, duration: 13.655s, episode steps: 419, steps per second:  31, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.862 [0.000, 5.000],  loss: 0.010994, mae: 0.767278, mean_q: 0.931535, mean_eps: 0.682251\n",
            " 353667/1000000: episode: 534, duration: 13.119s, episode steps: 403, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.010626, mae: 0.766792, mean_q: 0.932469, mean_eps: 0.681882\n",
            " 354561/1000000: episode: 535, duration: 29.474s, episode steps: 894, steps per second:  30, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.008193, mae: 0.750048, mean_q: 0.911685, mean_eps: 0.681297\n",
            " 355161/1000000: episode: 536, duration: 19.521s, episode steps: 600, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.011114, mae: 0.768388, mean_q: 0.933774, mean_eps: 0.680624\n",
            " 356157/1000000: episode: 537, duration: 32.260s, episode steps: 996, steps per second:  31, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.010275, mae: 0.767307, mean_q: 0.930766, mean_eps: 0.679906\n",
            " 357236/1000000: episode: 538, duration: 34.830s, episode steps: 1079, steps per second:  31, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.010113, mae: 0.770215, mean_q: 0.934594, mean_eps: 0.678974\n",
            " 357629/1000000: episode: 539, duration: 12.856s, episode steps: 393, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.011177, mae: 0.774192, mean_q: 0.939179, mean_eps: 0.678311\n",
            " 358004/1000000: episode: 540, duration: 12.298s, episode steps: 375, steps per second:  30, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.009214, mae: 0.754446, mean_q: 0.915065, mean_eps: 0.677966\n",
            " 358769/1000000: episode: 541, duration: 25.004s, episode steps: 765, steps per second:  31, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.010623, mae: 0.768522, mean_q: 0.933903, mean_eps: 0.677453\n",
            " 359842/1000000: episode: 542, duration: 34.879s, episode steps: 1073, steps per second:  31, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.010139, mae: 0.772268, mean_q: 0.938427, mean_eps: 0.676625\n",
            " 360384/1000000: episode: 543, duration: 17.950s, episode steps: 542, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.008887, mae: 0.785316, mean_q: 0.958218, mean_eps: 0.675899\n",
            " 360759/1000000: episode: 544, duration: 12.223s, episode steps: 375, steps per second:  31, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.009633, mae: 0.823609, mean_q: 1.004053, mean_eps: 0.675487\n",
            " 361288/1000000: episode: 545, duration: 17.172s, episode steps: 529, steps per second:  31, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.010200, mae: 0.805432, mean_q: 0.977618, mean_eps: 0.675080\n",
            " 361956/1000000: episode: 546, duration: 21.755s, episode steps: 668, steps per second:  31, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.009396, mae: 0.816337, mean_q: 0.993357, mean_eps: 0.674542\n",
            " 362648/1000000: episode: 547, duration: 22.466s, episode steps: 692, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.010335, mae: 0.815749, mean_q: 0.991332, mean_eps: 0.673930\n",
            " 363360/1000000: episode: 548, duration: 23.306s, episode steps: 712, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.010059, mae: 0.811324, mean_q: 0.984754, mean_eps: 0.673298\n",
            " 364409/1000000: episode: 549, duration: 34.213s, episode steps: 1049, steps per second:  31, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.010515, mae: 0.813097, mean_q: 0.989818, mean_eps: 0.672504\n",
            " 364845/1000000: episode: 550, duration: 14.130s, episode steps: 436, steps per second:  31, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.186 [0.000, 5.000],  loss: 0.010599, mae: 0.815574, mean_q: 0.991400, mean_eps: 0.671835\n",
            " 365472/1000000: episode: 551, duration: 20.392s, episode steps: 627, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.009183, mae: 0.808652, mean_q: 0.983769, mean_eps: 0.671358\n",
            " 366170/1000000: episode: 552, duration: 22.864s, episode steps: 698, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.010037, mae: 0.812764, mean_q: 0.986599, mean_eps: 0.670762\n",
            " 367021/1000000: episode: 553, duration: 27.834s, episode steps: 851, steps per second:  31, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.010255, mae: 0.827230, mean_q: 1.004683, mean_eps: 0.670064\n",
            " 367532/1000000: episode: 554, duration: 16.606s, episode steps: 511, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.010149, mae: 0.818128, mean_q: 0.993796, mean_eps: 0.669452\n",
            " 368036/1000000: episode: 555, duration: 16.589s, episode steps: 504, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.010416, mae: 0.810423, mean_q: 0.983147, mean_eps: 0.668996\n",
            " 368902/1000000: episode: 556, duration: 28.418s, episode steps: 866, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.010797, mae: 0.815543, mean_q: 0.992113, mean_eps: 0.668379\n",
            " 370000/1000000: episode: 557, duration: 35.836s, episode steps: 1098, steps per second:  31, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.010840, mae: 0.818699, mean_q: 0.994403, mean_eps: 0.667495\n",
            " 370647/1000000: episode: 558, duration: 21.042s, episode steps: 647, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.008973, mae: 0.834050, mean_q: 1.013777, mean_eps: 0.666710\n",
            " 371271/1000000: episode: 559, duration: 20.383s, episode steps: 624, steps per second:  31, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.010415, mae: 0.821914, mean_q: 0.997538, mean_eps: 0.666138\n",
            " 371866/1000000: episode: 560, duration: 19.531s, episode steps: 595, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.010112, mae: 0.827386, mean_q: 1.004350, mean_eps: 0.665589\n",
            " 372380/1000000: episode: 561, duration: 16.764s, episode steps: 514, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.009679, mae: 0.821474, mean_q: 0.995773, mean_eps: 0.665090\n",
            " 373202/1000000: episode: 562, duration: 26.844s, episode steps: 822, steps per second:  31, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.011566, mae: 0.836725, mean_q: 1.018597, mean_eps: 0.664489\n",
            " 373711/1000000: episode: 563, duration: 16.564s, episode steps: 509, steps per second:  31, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.800 [0.000, 5.000],  loss: 0.010184, mae: 0.812844, mean_q: 0.988548, mean_eps: 0.663890\n",
            " 374218/1000000: episode: 564, duration: 16.511s, episode steps: 507, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.771 [0.000, 5.000],  loss: 0.009895, mae: 0.826277, mean_q: 1.006150, mean_eps: 0.663432\n",
            " 374840/1000000: episode: 565, duration: 20.381s, episode steps: 622, steps per second:  31, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.010012, mae: 0.822373, mean_q: 0.998442, mean_eps: 0.662925\n",
            " 375365/1000000: episode: 566, duration: 17.186s, episode steps: 525, steps per second:  31, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.286 [0.000, 5.000],  loss: 0.010664, mae: 0.832402, mean_q: 1.011076, mean_eps: 0.662408\n",
            " 375948/1000000: episode: 567, duration: 19.002s, episode steps: 583, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.010572, mae: 0.828217, mean_q: 1.004022, mean_eps: 0.661910\n",
            " 376331/1000000: episode: 568, duration: 12.535s, episode steps: 383, steps per second:  31, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.011464, mae: 0.823049, mean_q: 1.002324, mean_eps: 0.661476\n",
            " 377143/1000000: episode: 569, duration: 26.298s, episode steps: 812, steps per second:  31, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.010482, mae: 0.826398, mean_q: 1.003213, mean_eps: 0.660938\n",
            " 377795/1000000: episode: 570, duration: 21.084s, episode steps: 652, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.009312, mae: 0.831894, mean_q: 1.009742, mean_eps: 0.660279\n",
            " 378649/1000000: episode: 571, duration: 27.660s, episode steps: 854, steps per second:  31, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.009116, mae: 0.825790, mean_q: 1.002840, mean_eps: 0.659600\n",
            " 379268/1000000: episode: 572, duration: 20.263s, episode steps: 619, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.009642, mae: 0.816894, mean_q: 0.991984, mean_eps: 0.658938\n",
            " 379777/1000000: episode: 573, duration: 16.684s, episode steps: 509, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.898 [0.000, 5.000],  loss: 0.009645, mae: 0.828987, mean_q: 1.010306, mean_eps: 0.658430\n",
            " 380449/1000000: episode: 574, duration: 21.860s, episode steps: 672, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.799 [0.000, 5.000],  loss: 0.008529, mae: 0.843111, mean_q: 1.025235, mean_eps: 0.657897\n",
            " 380960/1000000: episode: 575, duration: 16.576s, episode steps: 511, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.010809, mae: 0.838130, mean_q: 1.018360, mean_eps: 0.657366\n",
            " 381606/1000000: episode: 576, duration: 21.098s, episode steps: 646, steps per second:  31, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.946 [0.000, 5.000],  loss: 0.010635, mae: 0.846564, mean_q: 1.031936, mean_eps: 0.656846\n",
            " 382424/1000000: episode: 577, duration: 26.724s, episode steps: 818, steps per second:  31, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.259 [0.000, 5.000],  loss: 0.010675, mae: 0.847726, mean_q: 1.031656, mean_eps: 0.656187\n",
            " 382943/1000000: episode: 578, duration: 17.034s, episode steps: 519, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.152 [0.000, 5.000],  loss: 0.012011, mae: 0.847769, mean_q: 1.031938, mean_eps: 0.655586\n",
            " 383479/1000000: episode: 579, duration: 17.360s, episode steps: 536, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.011149, mae: 0.856953, mean_q: 1.040333, mean_eps: 0.655111\n",
            " 384571/1000000: episode: 580, duration: 35.563s, episode steps: 1092, steps per second:  31, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.010399, mae: 0.843822, mean_q: 1.025775, mean_eps: 0.654378\n",
            " 385133/1000000: episode: 581, duration: 18.388s, episode steps: 562, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.011385, mae: 0.857480, mean_q: 1.042033, mean_eps: 0.653633\n",
            " 385609/1000000: episode: 582, duration: 15.490s, episode steps: 476, steps per second:  31, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.009277, mae: 0.842990, mean_q: 1.025838, mean_eps: 0.653165\n",
            " 386082/1000000: episode: 583, duration: 15.360s, episode steps: 473, steps per second:  31, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.010042, mae: 0.839660, mean_q: 1.021319, mean_eps: 0.652739\n",
            " 386881/1000000: episode: 584, duration: 26.090s, episode steps: 799, steps per second:  31, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.009825, mae: 0.848746, mean_q: 1.031098, mean_eps: 0.652166\n",
            " 387639/1000000: episode: 585, duration: 24.641s, episode steps: 758, steps per second:  31, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.010229, mae: 0.839134, mean_q: 1.018878, mean_eps: 0.651466\n",
            " 388599/1000000: episode: 586, duration: 31.407s, episode steps: 960, steps per second:  31, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.011064, mae: 0.844016, mean_q: 1.024843, mean_eps: 0.650694\n",
            " 389494/1000000: episode: 587, duration: 29.261s, episode steps: 895, steps per second:  31, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.009936, mae: 0.837252, mean_q: 1.016828, mean_eps: 0.649859\n",
            " 390128/1000000: episode: 588, duration: 20.781s, episode steps: 634, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.010270, mae: 0.855575, mean_q: 1.039749, mean_eps: 0.649171\n",
            " 390784/1000000: episode: 589, duration: 21.666s, episode steps: 656, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.744 [0.000, 5.000],  loss: 0.010772, mae: 0.881086, mean_q: 1.072765, mean_eps: 0.648591\n",
            " 391439/1000000: episode: 590, duration: 21.675s, episode steps: 655, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.009695, mae: 0.893079, mean_q: 1.087706, mean_eps: 0.648001\n",
            " 391955/1000000: episode: 591, duration: 16.737s, episode steps: 516, steps per second:  31, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.011450, mae: 0.883102, mean_q: 1.072084, mean_eps: 0.647474\n",
            " 392600/1000000: episode: 592, duration: 21.166s, episode steps: 645, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.010278, mae: 0.869189, mean_q: 1.052555, mean_eps: 0.646952\n",
            " 393070/1000000: episode: 593, duration: 15.374s, episode steps: 470, steps per second:  31, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.160 [0.000, 5.000],  loss: 0.011829, mae: 0.886755, mean_q: 1.075162, mean_eps: 0.646449\n",
            " 393826/1000000: episode: 594, duration: 24.667s, episode steps: 756, steps per second:  31, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.011014, mae: 0.883045, mean_q: 1.069228, mean_eps: 0.645897\n",
            " 394364/1000000: episode: 595, duration: 17.708s, episode steps: 538, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.010410, mae: 0.876711, mean_q: 1.063184, mean_eps: 0.645315\n",
            " 395147/1000000: episode: 596, duration: 25.623s, episode steps: 783, steps per second:  31, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.011802, mae: 0.889840, mean_q: 1.080940, mean_eps: 0.644721\n",
            " 395690/1000000: episode: 597, duration: 17.821s, episode steps: 543, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.700 [0.000, 5.000],  loss: 0.010541, mae: 0.882797, mean_q: 1.072916, mean_eps: 0.644124\n",
            " 396471/1000000: episode: 598, duration: 25.733s, episode steps: 781, steps per second:  30, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.198 [0.000, 5.000],  loss: 0.011277, mae: 0.881050, mean_q: 1.068310, mean_eps: 0.643528\n",
            " 397217/1000000: episode: 599, duration: 24.563s, episode steps: 746, steps per second:  30, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.010911, mae: 0.887081, mean_q: 1.076110, mean_eps: 0.642840\n",
            " 397749/1000000: episode: 600, duration: 17.488s, episode steps: 532, steps per second:  30, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.773 [0.000, 5.000],  loss: 0.010420, mae: 0.883038, mean_q: 1.073300, mean_eps: 0.642264\n",
            " 398331/1000000: episode: 601, duration: 19.177s, episode steps: 582, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.011698, mae: 0.888651, mean_q: 1.080448, mean_eps: 0.641764\n",
            " 398978/1000000: episode: 602, duration: 21.505s, episode steps: 647, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.009477, mae: 0.876167, mean_q: 1.063851, mean_eps: 0.641211\n",
            " 399445/1000000: episode: 603, duration: 15.464s, episode steps: 467, steps per second:  30, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.231 [0.000, 5.000],  loss: 0.011540, mae: 0.896753, mean_q: 1.087761, mean_eps: 0.640709\n",
            " 400027/1000000: episode: 604, duration: 19.166s, episode steps: 582, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: 0.011284, mae: 0.886583, mean_q: 1.075034, mean_eps: 0.640238\n",
            " 401729/1000000: episode: 605, duration: 56.148s, episode steps: 1702, steps per second:  30, episode reward: 26.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.010672, mae: 0.908071, mean_q: 1.103467, mean_eps: 0.639210\n",
            " 402251/1000000: episode: 606, duration: 17.058s, episode steps: 522, steps per second:  31, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.011500, mae: 0.901753, mean_q: 1.095651, mean_eps: 0.638209\n",
            " 402922/1000000: episode: 607, duration: 22.123s, episode steps: 671, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.854 [0.000, 5.000],  loss: 0.009358, mae: 0.904650, mean_q: 1.098469, mean_eps: 0.637673\n",
            " 403547/1000000: episode: 608, duration: 20.626s, episode steps: 625, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.011072, mae: 0.912831, mean_q: 1.108350, mean_eps: 0.637089\n",
            " 404123/1000000: episode: 609, duration: 18.900s, episode steps: 576, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.009936, mae: 0.894004, mean_q: 1.087066, mean_eps: 0.636549\n",
            " 404632/1000000: episode: 610, duration: 16.865s, episode steps: 509, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.010859, mae: 0.902660, mean_q: 1.096592, mean_eps: 0.636062\n",
            " 405296/1000000: episode: 611, duration: 21.927s, episode steps: 664, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.008913, mae: 0.902294, mean_q: 1.094028, mean_eps: 0.635534\n",
            " 406071/1000000: episode: 612, duration: 25.616s, episode steps: 775, steps per second:  30, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.011349, mae: 0.909247, mean_q: 1.103084, mean_eps: 0.634886\n",
            " 406660/1000000: episode: 613, duration: 19.419s, episode steps: 589, steps per second:  30, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.011325, mae: 0.912091, mean_q: 1.106176, mean_eps: 0.634272\n",
            " 407147/1000000: episode: 614, duration: 16.098s, episode steps: 487, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.011770, mae: 0.913129, mean_q: 1.107704, mean_eps: 0.633788\n",
            " 407703/1000000: episode: 615, duration: 18.310s, episode steps: 556, steps per second:  30, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.010124, mae: 0.896934, mean_q: 1.088019, mean_eps: 0.633318\n",
            " 408491/1000000: episode: 616, duration: 26.119s, episode steps: 788, steps per second:  30, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.009231, mae: 0.902929, mean_q: 1.096919, mean_eps: 0.632714\n",
            " 409254/1000000: episode: 617, duration: 25.265s, episode steps: 763, steps per second:  30, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: 0.010306, mae: 0.910745, mean_q: 1.106528, mean_eps: 0.632015\n",
            " 410269/1000000: episode: 618, duration: 33.747s, episode steps: 1015, steps per second:  30, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.010801, mae: 0.905719, mean_q: 1.100586, mean_eps: 0.631214\n",
            " 410952/1000000: episode: 619, duration: 22.569s, episode steps: 683, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.009707, mae: 0.915200, mean_q: 1.112176, mean_eps: 0.630451\n",
            " 411339/1000000: episode: 620, duration: 12.786s, episode steps: 387, steps per second:  30, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.010322, mae: 0.915048, mean_q: 1.111323, mean_eps: 0.629970\n",
            " 411853/1000000: episode: 621, duration: 17.047s, episode steps: 514, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.010186, mae: 0.920675, mean_q: 1.117981, mean_eps: 0.629564\n",
            " 412503/1000000: episode: 622, duration: 21.334s, episode steps: 650, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.969 [0.000, 5.000],  loss: 0.008703, mae: 0.923851, mean_q: 1.122667, mean_eps: 0.629040\n",
            " 412902/1000000: episode: 623, duration: 13.243s, episode steps: 399, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.011736, mae: 0.943288, mean_q: 1.145742, mean_eps: 0.628568\n",
            " 413496/1000000: episode: 624, duration: 19.743s, episode steps: 594, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.010638, mae: 0.930323, mean_q: 1.129732, mean_eps: 0.628122\n",
            " 414115/1000000: episode: 625, duration: 20.471s, episode steps: 619, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.010565, mae: 0.918865, mean_q: 1.115328, mean_eps: 0.627576\n",
            " 414652/1000000: episode: 626, duration: 17.872s, episode steps: 537, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.009270, mae: 0.921833, mean_q: 1.118922, mean_eps: 0.627056\n",
            " 415041/1000000: episode: 627, duration: 12.919s, episode steps: 389, steps per second:  30, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.011478, mae: 0.935190, mean_q: 1.133042, mean_eps: 0.626639\n",
            " 415695/1000000: episode: 628, duration: 21.585s, episode steps: 654, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.636 [0.000, 5.000],  loss: 0.010985, mae: 0.929138, mean_q: 1.127414, mean_eps: 0.626169\n",
            " 416253/1000000: episode: 629, duration: 18.589s, episode steps: 558, steps per second:  30, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.009883, mae: 0.934720, mean_q: 1.133940, mean_eps: 0.625623\n",
            " 416953/1000000: episode: 630, duration: 23.078s, episode steps: 700, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.010590, mae: 0.922675, mean_q: 1.122581, mean_eps: 0.625056\n",
            " 417445/1000000: episode: 631, duration: 16.257s, episode steps: 492, steps per second:  30, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.009330, mae: 0.923268, mean_q: 1.121475, mean_eps: 0.624520\n",
            " 417946/1000000: episode: 632, duration: 16.627s, episode steps: 501, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.009687, mae: 0.918546, mean_q: 1.116091, mean_eps: 0.624074\n",
            " 418569/1000000: episode: 633, duration: 20.690s, episode steps: 623, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.009917, mae: 0.916070, mean_q: 1.112141, mean_eps: 0.623568\n",
            " 419099/1000000: episode: 634, duration: 17.554s, episode steps: 530, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.760 [0.000, 5.000],  loss: 0.009575, mae: 0.916724, mean_q: 1.113975, mean_eps: 0.623049\n",
            " 419727/1000000: episode: 635, duration: 20.777s, episode steps: 628, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.010827, mae: 0.915139, mean_q: 1.110135, mean_eps: 0.622529\n",
            " 420214/1000000: episode: 636, duration: 16.181s, episode steps: 487, steps per second:  30, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.009127, mae: 0.936800, mean_q: 1.137549, mean_eps: 0.622027\n",
            " 421273/1000000: episode: 637, duration: 35.351s, episode steps: 1059, steps per second:  30, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.009628, mae: 0.947992, mean_q: 1.151459, mean_eps: 0.621330\n",
            " 421874/1000000: episode: 638, duration: 20.019s, episode steps: 601, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.010407, mae: 0.945529, mean_q: 1.149108, mean_eps: 0.620583\n",
            " 422395/1000000: episode: 639, duration: 17.314s, episode steps: 521, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.011073, mae: 0.948834, mean_q: 1.152649, mean_eps: 0.620079\n",
            " 422986/1000000: episode: 640, duration: 19.695s, episode steps: 591, steps per second:  30, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.010950, mae: 0.953713, mean_q: 1.157824, mean_eps: 0.619579\n",
            " 423391/1000000: episode: 641, duration: 13.403s, episode steps: 405, steps per second:  30, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.010144, mae: 0.942169, mean_q: 1.145833, mean_eps: 0.619131\n",
            " 423944/1000000: episode: 642, duration: 18.498s, episode steps: 553, steps per second:  30, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.011393, mae: 0.962619, mean_q: 1.169707, mean_eps: 0.618701\n",
            " 424578/1000000: episode: 643, duration: 21.051s, episode steps: 634, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.010256, mae: 0.961802, mean_q: 1.167725, mean_eps: 0.618166\n",
            " 424957/1000000: episode: 644, duration: 12.596s, episode steps: 379, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.010413, mae: 0.951688, mean_q: 1.156823, mean_eps: 0.617709\n",
            " 426036/1000000: episode: 645, duration: 35.832s, episode steps: 1079, steps per second:  30, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.811 [0.000, 5.000],  loss: 0.010959, mae: 0.954194, mean_q: 1.158918, mean_eps: 0.617054\n",
            " 426693/1000000: episode: 646, duration: 21.896s, episode steps: 657, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.224 [0.000, 5.000],  loss: 0.010605, mae: 0.938899, mean_q: 1.140369, mean_eps: 0.616272\n",
            " 427080/1000000: episode: 647, duration: 13.112s, episode steps: 387, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.010795, mae: 0.980923, mean_q: 1.189882, mean_eps: 0.615803\n",
            " 427680/1000000: episode: 648, duration: 20.065s, episode steps: 600, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.011243, mae: 0.972646, mean_q: 1.179302, mean_eps: 0.615360\n",
            " 428227/1000000: episode: 649, duration: 18.292s, episode steps: 547, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.010741, mae: 0.956570, mean_q: 1.163550, mean_eps: 0.614843\n",
            " 429178/1000000: episode: 650, duration: 31.545s, episode steps: 951, steps per second:  30, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.011042, mae: 0.954807, mean_q: 1.160022, mean_eps: 0.614168\n",
            " 429665/1000000: episode: 651, duration: 16.245s, episode steps: 487, steps per second:  30, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.144 [0.000, 5.000],  loss: 0.010563, mae: 0.948239, mean_q: 1.151447, mean_eps: 0.613520\n",
            " 430012/1000000: episode: 652, duration: 11.595s, episode steps: 347, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.010393, mae: 0.935243, mean_q: 1.133162, mean_eps: 0.613146\n",
            " 430648/1000000: episode: 653, duration: 21.355s, episode steps: 636, steps per second:  30, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.009813, mae: 0.984931, mean_q: 1.196157, mean_eps: 0.612705\n",
            " 431389/1000000: episode: 654, duration: 24.799s, episode steps: 741, steps per second:  30, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.010429, mae: 0.983573, mean_q: 1.193164, mean_eps: 0.612084\n",
            " 432246/1000000: episode: 655, duration: 28.593s, episode steps: 857, steps per second:  30, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.009465, mae: 0.975530, mean_q: 1.182709, mean_eps: 0.611364\n",
            " 432955/1000000: episode: 656, duration: 23.659s, episode steps: 709, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.010195, mae: 0.966760, mean_q: 1.172880, mean_eps: 0.610660\n",
            " 433595/1000000: episode: 657, duration: 21.281s, episode steps: 640, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.010281, mae: 0.972481, mean_q: 1.178235, mean_eps: 0.610053\n",
            " 434032/1000000: episode: 658, duration: 14.705s, episode steps: 437, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.012136, mae: 0.991963, mean_q: 1.202925, mean_eps: 0.609569\n",
            " 434686/1000000: episode: 659, duration: 21.923s, episode steps: 654, steps per second:  30, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.010132, mae: 0.974205, mean_q: 1.182697, mean_eps: 0.609078\n",
            " 435224/1000000: episode: 660, duration: 18.053s, episode steps: 538, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.010361, mae: 0.973077, mean_q: 1.180469, mean_eps: 0.608541\n",
            " 435796/1000000: episode: 661, duration: 19.185s, episode steps: 572, steps per second:  30, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.011011, mae: 0.986858, mean_q: 1.196913, mean_eps: 0.608043\n",
            " 436183/1000000: episode: 662, duration: 13.091s, episode steps: 387, steps per second:  30, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.011473, mae: 0.974769, mean_q: 1.180534, mean_eps: 0.607611\n",
            " 437088/1000000: episode: 663, duration: 30.297s, episode steps: 905, steps per second:  30, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.011074, mae: 0.979273, mean_q: 1.188941, mean_eps: 0.607029\n",
            " 437648/1000000: episode: 664, duration: 18.892s, episode steps: 560, steps per second:  30, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.010448, mae: 0.976992, mean_q: 1.187372, mean_eps: 0.606371\n",
            " 438877/1000000: episode: 665, duration: 41.252s, episode steps: 1229, steps per second:  30, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.286 [0.000, 5.000],  loss: 0.010526, mae: 0.978331, mean_q: 1.187492, mean_eps: 0.605564\n",
            " 439506/1000000: episode: 666, duration: 21.158s, episode steps: 629, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.008491, mae: 0.967024, mean_q: 1.172601, mean_eps: 0.604727\n",
            " 440023/1000000: episode: 667, duration: 17.361s, episode steps: 517, steps per second:  30, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.010864, mae: 0.980069, mean_q: 1.187435, mean_eps: 0.604212\n",
            " 440651/1000000: episode: 668, duration: 21.162s, episode steps: 628, steps per second:  30, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: 0.010353, mae: 0.984635, mean_q: 1.196399, mean_eps: 0.603698\n",
            " 441272/1000000: episode: 669, duration: 20.894s, episode steps: 621, steps per second:  30, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.010048, mae: 0.993468, mean_q: 1.207083, mean_eps: 0.603136\n",
            " 442529/1000000: episode: 670, duration: 42.184s, episode steps: 1257, steps per second:  30, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.010465, mae: 0.988601, mean_q: 1.199652, mean_eps: 0.602290\n",
            " 443217/1000000: episode: 671, duration: 23.005s, episode steps: 688, steps per second:  30, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.010338, mae: 0.989819, mean_q: 1.201237, mean_eps: 0.601413\n",
            " 443724/1000000: episode: 672, duration: 17.020s, episode steps: 507, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.011224, mae: 0.987723, mean_q: 1.198318, mean_eps: 0.600877\n",
            " 444800/1000000: episode: 673, duration: 35.990s, episode steps: 1076, steps per second:  30, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.706 [0.000, 5.000],  loss: 0.010672, mae: 0.995484, mean_q: 1.211217, mean_eps: 0.600166\n",
            " 445334/1000000: episode: 674, duration: 17.979s, episode steps: 534, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.010347, mae: 0.989896, mean_q: 1.200380, mean_eps: 0.599441\n",
            " 445757/1000000: episode: 675, duration: 14.288s, episode steps: 423, steps per second:  30, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.010051, mae: 0.972578, mean_q: 1.182576, mean_eps: 0.599009\n",
            " 446500/1000000: episode: 676, duration: 24.888s, episode steps: 743, steps per second:  30, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.010255, mae: 0.997421, mean_q: 1.211403, mean_eps: 0.598485\n",
            " 447634/1000000: episode: 677, duration: 37.970s, episode steps: 1134, steps per second:  30, episode reward: 26.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.011278, mae: 0.991931, mean_q: 1.202095, mean_eps: 0.597641\n",
            " 448161/1000000: episode: 678, duration: 17.647s, episode steps: 527, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.009527, mae: 0.986601, mean_q: 1.194733, mean_eps: 0.596892\n",
            " 449096/1000000: episode: 679, duration: 31.401s, episode steps: 935, steps per second:  30, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.010043, mae: 0.985539, mean_q: 1.196323, mean_eps: 0.596235\n",
            " 449836/1000000: episode: 680, duration: 24.872s, episode steps: 740, steps per second:  30, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.011555, mae: 0.996910, mean_q: 1.208082, mean_eps: 0.595482\n",
            " 450410/1000000: episode: 681, duration: 19.198s, episode steps: 574, steps per second:  30, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.009862, mae: 1.005727, mean_q: 1.221173, mean_eps: 0.594890\n",
            " 450870/1000000: episode: 682, duration: 15.401s, episode steps: 460, steps per second:  30, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.774 [0.000, 5.000],  loss: 0.010357, mae: 0.988211, mean_q: 1.198169, mean_eps: 0.594424\n",
            " 451525/1000000: episode: 683, duration: 21.881s, episode steps: 655, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.011193, mae: 1.000067, mean_q: 1.213645, mean_eps: 0.593922\n",
            " 452099/1000000: episode: 684, duration: 19.254s, episode steps: 574, steps per second:  30, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: 0.010711, mae: 0.996444, mean_q: 1.206294, mean_eps: 0.593369\n",
            " 452660/1000000: episode: 685, duration: 18.862s, episode steps: 561, steps per second:  30, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.011367, mae: 0.996794, mean_q: 1.208620, mean_eps: 0.592860\n",
            " 453069/1000000: episode: 686, duration: 13.739s, episode steps: 409, steps per second:  30, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.773 [0.000, 5.000],  loss: 0.009760, mae: 1.001104, mean_q: 1.215754, mean_eps: 0.592422\n",
            " 454338/1000000: episode: 687, duration: 42.445s, episode steps: 1269, steps per second:  30, episode reward: 32.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.011040, mae: 0.989495, mean_q: 1.197791, mean_eps: 0.591666\n",
            " 454966/1000000: episode: 688, duration: 21.232s, episode steps: 628, steps per second:  30, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.815 [0.000, 5.000],  loss: 0.010928, mae: 0.996993, mean_q: 1.208369, mean_eps: 0.590813\n",
            " 455551/1000000: episode: 689, duration: 19.745s, episode steps: 585, steps per second:  30, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.011310, mae: 1.003096, mean_q: 1.218593, mean_eps: 0.590268\n",
            " 456101/1000000: episode: 690, duration: 18.743s, episode steps: 550, steps per second:  29, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.224 [0.000, 5.000],  loss: 0.009852, mae: 1.005841, mean_q: 1.219487, mean_eps: 0.589757\n",
            " 456593/1000000: episode: 691, duration: 16.623s, episode steps: 492, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.945 [0.000, 5.000],  loss: 0.010345, mae: 0.995007, mean_q: 1.204896, mean_eps: 0.589287\n",
            " 456993/1000000: episode: 692, duration: 13.504s, episode steps: 400, steps per second:  30, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.010275, mae: 1.006785, mean_q: 1.220969, mean_eps: 0.588885\n",
            " 457741/1000000: episode: 693, duration: 25.218s, episode steps: 748, steps per second:  30, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.773 [0.000, 5.000],  loss: 0.010942, mae: 1.002157, mean_q: 1.214198, mean_eps: 0.588369\n",
            " 458762/1000000: episode: 694, duration: 34.432s, episode steps: 1021, steps per second:  30, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.011027, mae: 1.001001, mean_q: 1.212256, mean_eps: 0.587573\n",
            " 459436/1000000: episode: 695, duration: 22.692s, episode steps: 674, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.755 [0.000, 5.000],  loss: 0.010333, mae: 1.007286, mean_q: 1.221210, mean_eps: 0.586812\n",
            " 460492/1000000: episode: 696, duration: 35.659s, episode steps: 1056, steps per second:  30, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.008894, mae: 1.003237, mean_q: 1.217359, mean_eps: 0.586034\n",
            " 461148/1000000: episode: 697, duration: 22.210s, episode steps: 656, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.995 [0.000, 5.000],  loss: 0.010983, mae: 1.025699, mean_q: 1.243914, mean_eps: 0.585264\n",
            " 462040/1000000: episode: 698, duration: 30.179s, episode steps: 892, steps per second:  30, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.011243, mae: 1.027381, mean_q: 1.244931, mean_eps: 0.584567\n",
            " 463467/1000000: episode: 699, duration: 48.170s, episode steps: 1427, steps per second:  30, episode reward: 27.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.010564, mae: 1.015630, mean_q: 1.232358, mean_eps: 0.583523\n",
            " 464093/1000000: episode: 700, duration: 21.401s, episode steps: 626, steps per second:  29, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.692 [0.000, 5.000],  loss: 0.011261, mae: 1.019233, mean_q: 1.236645, mean_eps: 0.582598\n",
            " 464850/1000000: episode: 701, duration: 25.859s, episode steps: 757, steps per second:  29, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.061 [0.000, 5.000],  loss: 0.010996, mae: 1.010026, mean_q: 1.225185, mean_eps: 0.581975\n",
            " 465777/1000000: episode: 702, duration: 32.045s, episode steps: 927, steps per second:  29, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.010299, mae: 1.010191, mean_q: 1.223983, mean_eps: 0.581217\n",
            " 466203/1000000: episode: 703, duration: 14.631s, episode steps: 426, steps per second:  29, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.010657, mae: 1.008803, mean_q: 1.221865, mean_eps: 0.580609\n",
            " 466839/1000000: episode: 704, duration: 21.819s, episode steps: 636, steps per second:  29, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.082 [0.000, 5.000],  loss: 0.009844, mae: 1.013807, mean_q: 1.228849, mean_eps: 0.580132\n",
            " 467378/1000000: episode: 705, duration: 18.355s, episode steps: 539, steps per second:  29, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.009202, mae: 1.004636, mean_q: 1.218349, mean_eps: 0.579603\n",
            " 467909/1000000: episode: 706, duration: 17.976s, episode steps: 531, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.011180, mae: 1.024745, mean_q: 1.241222, mean_eps: 0.579120\n",
            " 468346/1000000: episode: 707, duration: 14.892s, episode steps: 437, steps per second:  29, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.703 [0.000, 5.000],  loss: 0.011925, mae: 1.037381, mean_q: 1.264666, mean_eps: 0.578685\n",
            " 469428/1000000: episode: 708, duration: 36.598s, episode steps: 1082, steps per second:  30, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.011435, mae: 1.012820, mean_q: 1.228799, mean_eps: 0.578003\n",
            " 469892/1000000: episode: 709, duration: 15.833s, episode steps: 464, steps per second:  29, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.011732, mae: 1.017733, mean_q: 1.234635, mean_eps: 0.577308\n",
            " 470348/1000000: episode: 710, duration: 15.543s, episode steps: 456, steps per second:  29, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.011227, mae: 1.033270, mean_q: 1.254527, mean_eps: 0.576894\n",
            " 470816/1000000: episode: 711, duration: 15.990s, episode steps: 468, steps per second:  29, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.010122, mae: 1.042529, mean_q: 1.269091, mean_eps: 0.576478\n",
            " 471482/1000000: episode: 712, duration: 22.557s, episode steps: 666, steps per second:  30, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.010874, mae: 1.032878, mean_q: 1.253226, mean_eps: 0.575967\n",
            " 472348/1000000: episode: 713, duration: 29.549s, episode steps: 866, steps per second:  29, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.011220, mae: 1.034767, mean_q: 1.258642, mean_eps: 0.575277\n",
            " 473300/1000000: episode: 714, duration: 32.623s, episode steps: 952, steps per second:  29, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.011704, mae: 1.036967, mean_q: 1.257516, mean_eps: 0.574460\n",
            " 474100/1000000: episode: 715, duration: 27.295s, episode steps: 800, steps per second:  29, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.011311, mae: 1.045298, mean_q: 1.265831, mean_eps: 0.573672\n",
            " 475105/1000000: episode: 716, duration: 34.330s, episode steps: 1005, steps per second:  29, episode reward: 29.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.011195, mae: 1.040481, mean_q: 1.262145, mean_eps: 0.572858\n",
            " 475886/1000000: episode: 717, duration: 26.457s, episode steps: 781, steps per second:  30, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.011728, mae: 1.029491, mean_q: 1.249053, mean_eps: 0.572054\n",
            " 476526/1000000: episode: 718, duration: 21.747s, episode steps: 640, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.009999, mae: 1.031579, mean_q: 1.253086, mean_eps: 0.571415\n",
            " 477442/1000000: episode: 719, duration: 31.146s, episode steps: 916, steps per second:  29, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.010342, mae: 1.041728, mean_q: 1.263919, mean_eps: 0.570714\n",
            " 477957/1000000: episode: 720, duration: 17.470s, episode steps: 515, steps per second:  29, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.010766, mae: 1.019551, mean_q: 1.234074, mean_eps: 0.570070\n",
            " 479099/1000000: episode: 721, duration: 38.654s, episode steps: 1142, steps per second:  30, episode reward: 27.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.743 [0.000, 5.000],  loss: 0.011012, mae: 1.039463, mean_q: 1.261741, mean_eps: 0.569325\n",
            " 479936/1000000: episode: 722, duration: 28.534s, episode steps: 837, steps per second:  29, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.011104, mae: 1.045192, mean_q: 1.267477, mean_eps: 0.568436\n",
            " 481096/1000000: episode: 723, duration: 39.597s, episode steps: 1160, steps per second:  29, episode reward: 25.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.011255, mae: 1.075754, mean_q: 1.304642, mean_eps: 0.567537\n",
            " 482056/1000000: episode: 724, duration: 32.684s, episode steps: 960, steps per second:  29, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.012092, mae: 1.065509, mean_q: 1.292139, mean_eps: 0.566583\n",
            " 482997/1000000: episode: 725, duration: 32.266s, episode steps: 941, steps per second:  29, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.011105, mae: 1.068986, mean_q: 1.297832, mean_eps: 0.565727\n",
            " 483692/1000000: episode: 726, duration: 23.718s, episode steps: 695, steps per second:  29, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.011426, mae: 1.070227, mean_q: 1.299198, mean_eps: 0.564990\n",
            " 484433/1000000: episode: 727, duration: 25.394s, episode steps: 741, steps per second:  29, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.011604, mae: 1.061083, mean_q: 1.284982, mean_eps: 0.564344\n",
            " 484849/1000000: episode: 728, duration: 14.150s, episode steps: 416, steps per second:  29, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.012035, mae: 1.070933, mean_q: 1.299190, mean_eps: 0.563822\n",
            " 485795/1000000: episode: 729, duration: 32.270s, episode steps: 946, steps per second:  29, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.012002, mae: 1.073077, mean_q: 1.299933, mean_eps: 0.563210\n",
            " 486481/1000000: episode: 730, duration: 23.391s, episode steps: 686, steps per second:  29, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.010373, mae: 1.066719, mean_q: 1.294915, mean_eps: 0.562476\n",
            " 486867/1000000: episode: 731, duration: 13.090s, episode steps: 386, steps per second:  29, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.756 [0.000, 5.000],  loss: 0.011393, mae: 1.083425, mean_q: 1.313446, mean_eps: 0.561993\n",
            " 487457/1000000: episode: 732, duration: 20.336s, episode steps: 590, steps per second:  29, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.139 [0.000, 5.000],  loss: 0.010633, mae: 1.063024, mean_q: 1.289134, mean_eps: 0.561554\n",
            " 488136/1000000: episode: 733, duration: 23.077s, episode steps: 679, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.010681, mae: 1.074096, mean_q: 1.303026, mean_eps: 0.560984\n",
            " 488712/1000000: episode: 734, duration: 19.586s, episode steps: 576, steps per second:  29, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.010706, mae: 1.071029, mean_q: 1.299323, mean_eps: 0.560420\n",
            " 489469/1000000: episode: 735, duration: 25.682s, episode steps: 757, steps per second:  29, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.021 [0.000, 5.000],  loss: 0.010585, mae: 1.067093, mean_q: 1.292351, mean_eps: 0.559819\n",
            " 490014/1000000: episode: 736, duration: 18.279s, episode steps: 545, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.758 [0.000, 5.000],  loss: 0.011012, mae: 1.068220, mean_q: 1.297420, mean_eps: 0.559232\n",
            " 490731/1000000: episode: 737, duration: 24.956s, episode steps: 717, steps per second:  29, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.153 [0.000, 5.000],  loss: 0.010104, mae: 1.076562, mean_q: 1.307792, mean_eps: 0.558665\n",
            " 491270/1000000: episode: 738, duration: 18.660s, episode steps: 539, steps per second:  29, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.011281, mae: 1.101089, mean_q: 1.338710, mean_eps: 0.558100\n",
            " 491818/1000000: episode: 739, duration: 18.850s, episode steps: 548, steps per second:  29, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.010983, mae: 1.094888, mean_q: 1.328931, mean_eps: 0.557610\n",
            " 492221/1000000: episode: 740, duration: 13.754s, episode steps: 403, steps per second:  29, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.010175, mae: 1.085147, mean_q: 1.315437, mean_eps: 0.557182\n",
            " 492876/1000000: episode: 741, duration: 22.333s, episode steps: 655, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.010797, mae: 1.090634, mean_q: 1.321652, mean_eps: 0.556707\n",
            " 493781/1000000: episode: 742, duration: 30.819s, episode steps: 905, steps per second:  29, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.010452, mae: 1.081226, mean_q: 1.308045, mean_eps: 0.556005\n",
            " 494247/1000000: episode: 743, duration: 15.902s, episode steps: 466, steps per second:  29, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.811 [0.000, 5.000],  loss: 0.010961, mae: 1.101605, mean_q: 1.336003, mean_eps: 0.555387\n",
            " 495199/1000000: episode: 744, duration: 32.639s, episode steps: 952, steps per second:  29, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.010454, mae: 1.088587, mean_q: 1.319703, mean_eps: 0.554750\n",
            " 495810/1000000: episode: 745, duration: 20.756s, episode steps: 611, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.011645, mae: 1.083444, mean_q: 1.314122, mean_eps: 0.554046\n",
            " 496365/1000000: episode: 746, duration: 19.067s, episode steps: 555, steps per second:  29, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.009952, mae: 1.083291, mean_q: 1.313319, mean_eps: 0.553521\n",
            " 496932/1000000: episode: 747, duration: 19.409s, episode steps: 567, steps per second:  29, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.312 [0.000, 5.000],  loss: 0.011572, mae: 1.099898, mean_q: 1.332498, mean_eps: 0.553017\n",
            " 497411/1000000: episode: 748, duration: 16.470s, episode steps: 479, steps per second:  29, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.203 [0.000, 5.000],  loss: 0.010951, mae: 1.099196, mean_q: 1.332595, mean_eps: 0.552547\n",
            " 498293/1000000: episode: 749, duration: 30.207s, episode steps: 882, steps per second:  29, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.011057, mae: 1.080667, mean_q: 1.308501, mean_eps: 0.551933\n",
            " 498917/1000000: episode: 750, duration: 21.337s, episode steps: 624, steps per second:  29, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.012405, mae: 1.108568, mean_q: 1.343059, mean_eps: 0.551255\n",
            " 499505/1000000: episode: 751, duration: 19.970s, episode steps: 588, steps per second:  29, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.010782, mae: 1.096263, mean_q: 1.328594, mean_eps: 0.550709\n",
            " 501069/1000000: episode: 752, duration: 53.218s, episode steps: 1564, steps per second:  29, episode reward: 35.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.010703, mae: 1.092830, mean_q: 1.323192, mean_eps: 0.549741\n",
            " 502251/1000000: episode: 753, duration: 40.140s, episode steps: 1182, steps per second:  29, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.010980, mae: 1.107417, mean_q: 1.342715, mean_eps: 0.548506\n",
            " 502668/1000000: episode: 754, duration: 14.302s, episode steps: 417, steps per second:  29, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.197 [0.000, 5.000],  loss: 0.010877, mae: 1.128223, mean_q: 1.371442, mean_eps: 0.547788\n",
            " 503303/1000000: episode: 755, duration: 21.719s, episode steps: 635, steps per second:  29, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.831 [0.000, 5.000],  loss: 0.011936, mae: 1.109363, mean_q: 1.345518, mean_eps: 0.547314\n",
            " 504676/1000000: episode: 756, duration: 46.687s, episode steps: 1373, steps per second:  29, episode reward: 34.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.010900, mae: 1.119794, mean_q: 1.357404, mean_eps: 0.546411\n",
            " 505554/1000000: episode: 757, duration: 29.897s, episode steps: 878, steps per second:  29, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.010547, mae: 1.108770, mean_q: 1.341403, mean_eps: 0.545397\n",
            " 506346/1000000: episode: 758, duration: 26.758s, episode steps: 792, steps per second:  30, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.761 [0.000, 5.000],  loss: 0.011522, mae: 1.116679, mean_q: 1.353029, mean_eps: 0.544645\n",
            " 506743/1000000: episode: 759, duration: 13.518s, episode steps: 397, steps per second:  29, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.030 [0.000, 5.000],  loss: 0.011597, mae: 1.116854, mean_q: 1.356984, mean_eps: 0.544110\n",
            " 507289/1000000: episode: 760, duration: 18.601s, episode steps: 546, steps per second:  29, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.200 [0.000, 5.000],  loss: 0.009886, mae: 1.114683, mean_q: 1.352202, mean_eps: 0.543686\n",
            " 507698/1000000: episode: 761, duration: 13.915s, episode steps: 409, steps per second:  29, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.011933, mae: 1.113853, mean_q: 1.349308, mean_eps: 0.543255\n",
            " 508173/1000000: episode: 762, duration: 16.121s, episode steps: 475, steps per second:  29, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.897 [0.000, 5.000],  loss: 0.011905, mae: 1.102503, mean_q: 1.340233, mean_eps: 0.542858\n",
            " 508926/1000000: episode: 763, duration: 25.691s, episode steps: 753, steps per second:  29, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.011874, mae: 1.115595, mean_q: 1.351461, mean_eps: 0.542305\n",
            " 509801/1000000: episode: 764, duration: 30.199s, episode steps: 875, steps per second:  29, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.012594, mae: 1.119286, mean_q: 1.358131, mean_eps: 0.541572\n",
            " 510235/1000000: episode: 765, duration: 14.852s, episode steps: 434, steps per second:  29, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.011442, mae: 1.117207, mean_q: 1.355887, mean_eps: 0.540984\n",
            " 511012/1000000: episode: 766, duration: 26.612s, episode steps: 777, steps per second:  29, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.010502, mae: 1.144476, mean_q: 1.387182, mean_eps: 0.540440\n",
            " 511362/1000000: episode: 767, duration: 12.063s, episode steps: 350, steps per second:  29, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.011216, mae: 1.157388, mean_q: 1.404857, mean_eps: 0.539933\n",
            " 512118/1000000: episode: 768, duration: 25.900s, episode steps: 756, steps per second:  29, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.012108, mae: 1.162233, mean_q: 1.409529, mean_eps: 0.539434\n",
            " 512708/1000000: episode: 769, duration: 20.145s, episode steps: 590, steps per second:  29, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.011437, mae: 1.138487, mean_q: 1.381743, mean_eps: 0.538829\n",
            " 513412/1000000: episode: 770, duration: 24.176s, episode steps: 704, steps per second:  29, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.011543, mae: 1.131047, mean_q: 1.367809, mean_eps: 0.538248\n",
            " 514649/1000000: episode: 771, duration: 42.403s, episode steps: 1237, steps per second:  29, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.108 [0.000, 5.000],  loss: 0.010715, mae: 1.132195, mean_q: 1.372478, mean_eps: 0.537373\n",
            " 515269/1000000: episode: 772, duration: 21.140s, episode steps: 620, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.113 [0.000, 5.000],  loss: 0.011956, mae: 1.142616, mean_q: 1.384513, mean_eps: 0.536536\n",
            " 515796/1000000: episode: 773, duration: 18.189s, episode steps: 527, steps per second:  29, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.011196, mae: 1.138766, mean_q: 1.379673, mean_eps: 0.536021\n",
            " 516418/1000000: episode: 774, duration: 21.316s, episode steps: 622, steps per second:  29, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.124 [0.000, 5.000],  loss: 0.012366, mae: 1.148080, mean_q: 1.392383, mean_eps: 0.535505\n",
            " 516872/1000000: episode: 775, duration: 15.568s, episode steps: 454, steps per second:  29, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.010884, mae: 1.148004, mean_q: 1.388247, mean_eps: 0.535020\n",
            " 517409/1000000: episode: 776, duration: 18.496s, episode steps: 537, steps per second:  29, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.836 [0.000, 5.000],  loss: 0.014122, mae: 1.148039, mean_q: 1.391281, mean_eps: 0.534574\n",
            " 517890/1000000: episode: 777, duration: 16.413s, episode steps: 481, steps per second:  29, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.011922, mae: 1.147277, mean_q: 1.390465, mean_eps: 0.534115\n",
            " 518504/1000000: episode: 778, duration: 21.132s, episode steps: 614, steps per second:  29, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.011576, mae: 1.135322, mean_q: 1.375597, mean_eps: 0.533624\n",
            " 519699/1000000: episode: 779, duration: 40.971s, episode steps: 1195, steps per second:  29, episode reward: 34.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.283 [0.000, 5.000],  loss: 0.011339, mae: 1.145782, mean_q: 1.386903, mean_eps: 0.532810\n",
            " 520261/1000000: episode: 780, duration: 19.426s, episode steps: 562, steps per second:  29, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.012678, mae: 1.147895, mean_q: 1.387141, mean_eps: 0.532018\n",
            " 521051/1000000: episode: 781, duration: 27.063s, episode steps: 790, steps per second:  29, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.010514, mae: 1.135783, mean_q: 1.377205, mean_eps: 0.531410\n",
            " 521767/1000000: episode: 782, duration: 24.499s, episode steps: 716, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.012429, mae: 1.152075, mean_q: 1.394679, mean_eps: 0.530733\n",
            " 522313/1000000: episode: 783, duration: 18.959s, episode steps: 546, steps per second:  29, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.012141, mae: 1.167202, mean_q: 1.415887, mean_eps: 0.530164\n",
            " 522770/1000000: episode: 784, duration: 15.842s, episode steps: 457, steps per second:  29, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.011787, mae: 1.156295, mean_q: 1.402177, mean_eps: 0.529712\n",
            " 523302/1000000: episode: 785, duration: 18.311s, episode steps: 532, steps per second:  29, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.012127, mae: 1.156449, mean_q: 1.399946, mean_eps: 0.529268\n",
            " 523860/1000000: episode: 786, duration: 19.394s, episode steps: 558, steps per second:  29, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.012445, mae: 1.156323, mean_q: 1.402258, mean_eps: 0.528778\n",
            " 524456/1000000: episode: 787, duration: 20.839s, episode steps: 596, steps per second:  29, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.010782, mae: 1.147136, mean_q: 1.388773, mean_eps: 0.528260\n",
            " 525066/1000000: episode: 788, duration: 21.016s, episode steps: 610, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.010282, mae: 1.151741, mean_q: 1.394392, mean_eps: 0.527716\n",
            " 525706/1000000: episode: 789, duration: 22.059s, episode steps: 640, steps per second:  29, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.839 [0.000, 5.000],  loss: 0.012359, mae: 1.145944, mean_q: 1.388607, mean_eps: 0.527153\n",
            " 526350/1000000: episode: 790, duration: 22.348s, episode steps: 644, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.010548, mae: 1.147886, mean_q: 1.390409, mean_eps: 0.526575\n",
            " 526961/1000000: episode: 791, duration: 21.134s, episode steps: 611, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.011920, mae: 1.144313, mean_q: 1.382410, mean_eps: 0.526010\n",
            " 527655/1000000: episode: 792, duration: 24.148s, episode steps: 694, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.012272, mae: 1.148311, mean_q: 1.389010, mean_eps: 0.525423\n",
            " 528218/1000000: episode: 793, duration: 19.502s, episode steps: 563, steps per second:  29, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.014 [0.000, 5.000],  loss: 0.011580, mae: 1.171137, mean_q: 1.416416, mean_eps: 0.524858\n",
            " 528786/1000000: episode: 794, duration: 19.648s, episode steps: 568, steps per second:  29, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.143 [0.000, 5.000],  loss: 0.011751, mae: 1.141419, mean_q: 1.383951, mean_eps: 0.524348\n",
            " 529197/1000000: episode: 795, duration: 14.153s, episode steps: 411, steps per second:  29, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.010744, mae: 1.139225, mean_q: 1.380357, mean_eps: 0.523907\n",
            " 530063/1000000: episode: 796, duration: 29.853s, episode steps: 866, steps per second:  29, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.011442, mae: 1.155849, mean_q: 1.401793, mean_eps: 0.523333\n",
            " 530525/1000000: episode: 797, duration: 16.042s, episode steps: 462, steps per second:  29, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.011811, mae: 1.204399, mean_q: 1.462137, mean_eps: 0.522735\n",
            " 531145/1000000: episode: 798, duration: 21.592s, episode steps: 620, steps per second:  29, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.982 [0.000, 5.000],  loss: 0.010776, mae: 1.208735, mean_q: 1.465971, mean_eps: 0.522248\n",
            " 531930/1000000: episode: 799, duration: 27.199s, episode steps: 785, steps per second:  29, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.013543, mae: 1.199072, mean_q: 1.451853, mean_eps: 0.521616\n",
            " 532728/1000000: episode: 800, duration: 28.241s, episode steps: 798, steps per second:  28, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.306 [0.000, 5.000],  loss: 0.011428, mae: 1.208507, mean_q: 1.463449, mean_eps: 0.520905\n",
            " 533347/1000000: episode: 801, duration: 21.600s, episode steps: 619, steps per second:  29, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.012209, mae: 1.193085, mean_q: 1.443837, mean_eps: 0.520268\n",
            " 533861/1000000: episode: 802, duration: 17.810s, episode steps: 514, steps per second:  29, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.011761, mae: 1.196941, mean_q: 1.450329, mean_eps: 0.519756\n",
            " 534998/1000000: episode: 803, duration: 39.150s, episode steps: 1137, steps per second:  29, episode reward: 27.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.012238, mae: 1.189237, mean_q: 1.440488, mean_eps: 0.519013\n",
            " 535801/1000000: episode: 804, duration: 27.817s, episode steps: 803, steps per second:  29, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.012225, mae: 1.197250, mean_q: 1.450705, mean_eps: 0.518140\n",
            " 536425/1000000: episode: 805, duration: 21.770s, episode steps: 624, steps per second:  29, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.881 [0.000, 5.000],  loss: 0.012539, mae: 1.192098, mean_q: 1.442424, mean_eps: 0.517497\n",
            " 536987/1000000: episode: 806, duration: 19.536s, episode steps: 562, steps per second:  29, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.012629, mae: 1.206755, mean_q: 1.462477, mean_eps: 0.516965\n",
            " 537680/1000000: episode: 807, duration: 24.104s, episode steps: 693, steps per second:  29, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.011340, mae: 1.210686, mean_q: 1.468776, mean_eps: 0.516401\n",
            " 538555/1000000: episode: 808, duration: 30.541s, episode steps: 875, steps per second:  29, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.152 [0.000, 5.000],  loss: 0.011883, mae: 1.206288, mean_q: 1.460123, mean_eps: 0.515696\n",
            " 539308/1000000: episode: 809, duration: 26.222s, episode steps: 753, steps per second:  29, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.012858, mae: 1.210229, mean_q: 1.464150, mean_eps: 0.514963\n",
            " 540182/1000000: episode: 810, duration: 30.425s, episode steps: 874, steps per second:  29, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.771 [0.000, 5.000],  loss: 0.013531, mae: 1.208079, mean_q: 1.463640, mean_eps: 0.514230\n",
            " 540868/1000000: episode: 811, duration: 23.732s, episode steps: 686, steps per second:  29, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.159 [0.000, 5.000],  loss: 0.011627, mae: 1.225892, mean_q: 1.484753, mean_eps: 0.513528\n",
            " 541542/1000000: episode: 812, duration: 23.509s, episode steps: 674, steps per second:  29, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.012133, mae: 1.226213, mean_q: 1.488253, mean_eps: 0.512916\n",
            " 542290/1000000: episode: 813, duration: 25.991s, episode steps: 748, steps per second:  29, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.012986, mae: 1.228763, mean_q: 1.490116, mean_eps: 0.512276\n",
            " 543237/1000000: episode: 814, duration: 32.937s, episode steps: 947, steps per second:  29, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.012576, mae: 1.237004, mean_q: 1.497687, mean_eps: 0.511512\n",
            " 544192/1000000: episode: 815, duration: 33.240s, episode steps: 955, steps per second:  29, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.011419, mae: 1.230853, mean_q: 1.489393, mean_eps: 0.510657\n",
            " 544850/1000000: episode: 816, duration: 22.860s, episode steps: 658, steps per second:  29, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.011788, mae: 1.226260, mean_q: 1.486103, mean_eps: 0.509932\n",
            " 545438/1000000: episode: 817, duration: 20.446s, episode steps: 588, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.012553, mae: 1.234815, mean_q: 1.493467, mean_eps: 0.509370\n",
            " 546312/1000000: episode: 818, duration: 30.291s, episode steps: 874, steps per second:  29, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.669 [0.000, 5.000],  loss: 0.012155, mae: 1.230358, mean_q: 1.489395, mean_eps: 0.508713\n",
            " 547134/1000000: episode: 819, duration: 28.630s, episode steps: 822, steps per second:  29, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.011503, mae: 1.216758, mean_q: 1.472305, mean_eps: 0.507950\n",
            " 547848/1000000: episode: 820, duration: 24.785s, episode steps: 714, steps per second:  29, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.010882, mae: 1.231491, mean_q: 1.490352, mean_eps: 0.507259\n",
            " 548260/1000000: episode: 821, duration: 14.368s, episode steps: 412, steps per second:  29, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.011855, mae: 1.228977, mean_q: 1.487911, mean_eps: 0.506753\n",
            " 549137/1000000: episode: 822, duration: 30.570s, episode steps: 877, steps per second:  29, episode reward: 25.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: 0.012815, mae: 1.230133, mean_q: 1.487407, mean_eps: 0.506172\n",
            " 549734/1000000: episode: 823, duration: 20.715s, episode steps: 597, steps per second:  29, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.754 [0.000, 5.000],  loss: 0.013012, mae: 1.226653, mean_q: 1.482450, mean_eps: 0.505508\n",
            " 550169/1000000: episode: 824, duration: 15.251s, episode steps: 435, steps per second:  29, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.012804, mae: 1.254493, mean_q: 1.518877, mean_eps: 0.505043\n",
            " 551192/1000000: episode: 825, duration: 35.585s, episode steps: 1023, steps per second:  29, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.288 [0.000, 5.000],  loss: 0.012025, mae: 1.260306, mean_q: 1.524989, mean_eps: 0.504388\n",
            " 551568/1000000: episode: 826, duration: 13.217s, episode steps: 376, steps per second:  28, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.013592, mae: 1.288286, mean_q: 1.555879, mean_eps: 0.503760\n",
            " 552179/1000000: episode: 827, duration: 21.318s, episode steps: 611, steps per second:  29, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.012518, mae: 1.276208, mean_q: 1.546421, mean_eps: 0.503315\n",
            " 552820/1000000: episode: 828, duration: 22.408s, episode steps: 641, steps per second:  29, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.013078, mae: 1.266754, mean_q: 1.533902, mean_eps: 0.502752\n",
            " 553654/1000000: episode: 829, duration: 29.146s, episode steps: 834, steps per second:  29, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.013370, mae: 1.292355, mean_q: 1.563495, mean_eps: 0.502088\n",
            " 554361/1000000: episode: 830, duration: 24.731s, episode steps: 707, steps per second:  29, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.012962, mae: 1.258703, mean_q: 1.523090, mean_eps: 0.501393\n",
            " 554790/1000000: episode: 831, duration: 14.977s, episode steps: 429, steps per second:  29, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.013190, mae: 1.276046, mean_q: 1.544225, mean_eps: 0.500882\n",
            " 555398/1000000: episode: 832, duration: 21.150s, episode steps: 608, steps per second:  29, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.013132, mae: 1.269643, mean_q: 1.537689, mean_eps: 0.500415\n",
            " 556344/1000000: episode: 833, duration: 33.084s, episode steps: 946, steps per second:  29, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.131 [0.000, 5.000],  loss: 0.012975, mae: 1.275853, mean_q: 1.545633, mean_eps: 0.499717\n",
            " 557482/1000000: episode: 834, duration: 39.888s, episode steps: 1138, steps per second:  29, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.013567, mae: 1.281712, mean_q: 1.552739, mean_eps: 0.498779\n",
            " 558237/1000000: episode: 835, duration: 26.391s, episode steps: 755, steps per second:  29, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.111 [0.000, 5.000],  loss: 0.012980, mae: 1.292724, mean_q: 1.562575, mean_eps: 0.497926\n",
            " 558743/1000000: episode: 836, duration: 17.711s, episode steps: 506, steps per second:  29, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.810 [0.000, 5.000],  loss: 0.010917, mae: 1.264318, mean_q: 1.530688, mean_eps: 0.497359\n",
            " 559248/1000000: episode: 837, duration: 17.671s, episode steps: 505, steps per second:  29, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.013051, mae: 1.278108, mean_q: 1.547150, mean_eps: 0.496905\n",
            " 559977/1000000: episode: 838, duration: 25.492s, episode steps: 729, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.007 [0.000, 5.000],  loss: 0.012525, mae: 1.263350, mean_q: 1.527701, mean_eps: 0.496349\n",
            " 560917/1000000: episode: 839, duration: 33.121s, episode steps: 940, steps per second:  28, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.012819, mae: 1.304783, mean_q: 1.580701, mean_eps: 0.495597\n",
            " 561595/1000000: episode: 840, duration: 23.705s, episode steps: 678, steps per second:  29, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.012611, mae: 1.307783, mean_q: 1.581975, mean_eps: 0.494870\n",
            " 562248/1000000: episode: 841, duration: 23.057s, episode steps: 653, steps per second:  28, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.012653, mae: 1.325126, mean_q: 1.603275, mean_eps: 0.494272\n",
            " 562919/1000000: episode: 842, duration: 23.549s, episode steps: 671, steps per second:  28, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.012776, mae: 1.315823, mean_q: 1.591534, mean_eps: 0.493676\n",
            " 563360/1000000: episode: 843, duration: 15.669s, episode steps: 441, steps per second:  28, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.012356, mae: 1.294715, mean_q: 1.566786, mean_eps: 0.493176\n",
            " 564009/1000000: episode: 844, duration: 23.033s, episode steps: 649, steps per second:  28, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.012304, mae: 1.316056, mean_q: 1.591576, mean_eps: 0.492684\n",
            " 564674/1000000: episode: 845, duration: 23.284s, episode steps: 665, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.012332, mae: 1.302367, mean_q: 1.575212, mean_eps: 0.492092\n",
            " 565254/1000000: episode: 846, duration: 20.295s, episode steps: 580, steps per second:  29, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.013638, mae: 1.301758, mean_q: 1.573413, mean_eps: 0.491532\n",
            " 566058/1000000: episode: 847, duration: 28.106s, episode steps: 804, steps per second:  29, episode reward: 25.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.012777, mae: 1.306064, mean_q: 1.580381, mean_eps: 0.490910\n",
            " 566778/1000000: episode: 848, duration: 25.113s, episode steps: 720, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.012250, mae: 1.293410, mean_q: 1.566212, mean_eps: 0.490224\n",
            " 567981/1000000: episode: 849, duration: 42.287s, episode steps: 1203, steps per second:  28, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.254 [0.000, 5.000],  loss: 0.012021, mae: 1.301221, mean_q: 1.575888, mean_eps: 0.489358\n",
            " 568713/1000000: episode: 850, duration: 25.629s, episode steps: 732, steps per second:  29, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.011859, mae: 1.318439, mean_q: 1.595570, mean_eps: 0.488487\n",
            " 569087/1000000: episode: 851, duration: 13.098s, episode steps: 374, steps per second:  29, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.013595, mae: 1.298410, mean_q: 1.571176, mean_eps: 0.487990\n",
            " 569766/1000000: episode: 852, duration: 23.868s, episode steps: 679, steps per second:  28, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.012670, mae: 1.315209, mean_q: 1.591490, mean_eps: 0.487517\n",
            " 570411/1000000: episode: 853, duration: 22.659s, episode steps: 645, steps per second:  28, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.011745, mae: 1.299536, mean_q: 1.573378, mean_eps: 0.486921\n",
            " 570906/1000000: episode: 854, duration: 17.467s, episode steps: 495, steps per second:  28, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.011892, mae: 1.305349, mean_q: 1.581576, mean_eps: 0.486408\n",
            " 571451/1000000: episode: 855, duration: 19.124s, episode steps: 545, steps per second:  28, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.012901, mae: 1.308659, mean_q: 1.583401, mean_eps: 0.485940\n",
            " 572161/1000000: episode: 856, duration: 25.128s, episode steps: 710, steps per second:  28, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.012046, mae: 1.289910, mean_q: 1.565185, mean_eps: 0.485375\n",
            " 573639/1000000: episode: 857, duration: 51.759s, episode steps: 1478, steps per second:  29, episode reward: 32.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.012279, mae: 1.305073, mean_q: 1.580621, mean_eps: 0.484390\n",
            " 574356/1000000: episode: 858, duration: 25.446s, episode steps: 717, steps per second:  28, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.013860, mae: 1.297323, mean_q: 1.569772, mean_eps: 0.483404\n",
            " 575202/1000000: episode: 859, duration: 29.800s, episode steps: 846, steps per second:  28, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.013579, mae: 1.295248, mean_q: 1.568089, mean_eps: 0.482700\n",
            " 575744/1000000: episode: 860, duration: 19.222s, episode steps: 542, steps per second:  28, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.014490, mae: 1.309211, mean_q: 1.585899, mean_eps: 0.482075\n",
            " 576274/1000000: episode: 861, duration: 18.816s, episode steps: 530, steps per second:  28, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.817 [0.000, 5.000],  loss: 0.011472, mae: 1.314030, mean_q: 1.591220, mean_eps: 0.481593\n",
            " 576818/1000000: episode: 862, duration: 19.238s, episode steps: 544, steps per second:  28, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.160 [0.000, 5.000],  loss: 0.013435, mae: 1.306445, mean_q: 1.580827, mean_eps: 0.481109\n",
            " 577479/1000000: episode: 863, duration: 23.401s, episode steps: 661, steps per second:  28, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.012618, mae: 1.291799, mean_q: 1.563883, mean_eps: 0.480567\n",
            " 577871/1000000: episode: 864, duration: 13.893s, episode steps: 392, steps per second:  28, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.010461, mae: 1.292191, mean_q: 1.565681, mean_eps: 0.480093\n",
            " 578407/1000000: episode: 865, duration: 18.757s, episode steps: 536, steps per second:  29, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.012996, mae: 1.296810, mean_q: 1.570930, mean_eps: 0.479676\n",
            " 579112/1000000: episode: 866, duration: 24.947s, episode steps: 705, steps per second:  28, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.740 [0.000, 5.000],  loss: 0.012680, mae: 1.315929, mean_q: 1.592132, mean_eps: 0.479118\n",
            " 579663/1000000: episode: 867, duration: 19.647s, episode steps: 551, steps per second:  28, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.013114, mae: 1.311932, mean_q: 1.588154, mean_eps: 0.478553\n",
            " 580178/1000000: episode: 868, duration: 18.239s, episode steps: 515, steps per second:  28, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.231 [0.000, 5.000],  loss: 0.011647, mae: 1.320249, mean_q: 1.600635, mean_eps: 0.478072\n",
            " 580694/1000000: episode: 869, duration: 18.232s, episode steps: 516, steps per second:  28, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.012486, mae: 1.325278, mean_q: 1.605822, mean_eps: 0.477608\n",
            " 581104/1000000: episode: 870, duration: 14.736s, episode steps: 410, steps per second:  28, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.095 [0.000, 5.000],  loss: 0.011590, mae: 1.341904, mean_q: 1.626335, mean_eps: 0.477192\n",
            " 581619/1000000: episode: 871, duration: 18.212s, episode steps: 515, steps per second:  28, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.013418, mae: 1.351167, mean_q: 1.637170, mean_eps: 0.476776\n",
            " 582138/1000000: episode: 872, duration: 18.305s, episode steps: 519, steps per second:  28, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.013847, mae: 1.325337, mean_q: 1.608082, mean_eps: 0.476310\n",
            " 583039/1000000: episode: 873, duration: 31.893s, episode steps: 901, steps per second:  28, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.013154, mae: 1.346316, mean_q: 1.631715, mean_eps: 0.475671\n",
            " 583819/1000000: episode: 874, duration: 27.448s, episode steps: 780, steps per second:  28, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.012314, mae: 1.345457, mean_q: 1.629961, mean_eps: 0.474915\n",
            " 584680/1000000: episode: 875, duration: 30.554s, episode steps: 861, steps per second:  28, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.883 [0.000, 5.000],  loss: 0.012939, mae: 1.348443, mean_q: 1.634853, mean_eps: 0.474177\n",
            " 585200/1000000: episode: 876, duration: 18.392s, episode steps: 520, steps per second:  28, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.012546, mae: 1.340407, mean_q: 1.626273, mean_eps: 0.473556\n",
            " 585655/1000000: episode: 877, duration: 16.209s, episode steps: 455, steps per second:  28, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.013162, mae: 1.333397, mean_q: 1.616237, mean_eps: 0.473117\n",
            " 586250/1000000: episode: 878, duration: 21.144s, episode steps: 595, steps per second:  28, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.012314, mae: 1.332132, mean_q: 1.611067, mean_eps: 0.472643\n",
            " 587289/1000000: episode: 879, duration: 36.852s, episode steps: 1039, steps per second:  28, episode reward: 27.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.012755, mae: 1.335263, mean_q: 1.614768, mean_eps: 0.471907\n",
            " 587958/1000000: episode: 880, duration: 23.706s, episode steps: 669, steps per second:  28, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.011033, mae: 1.326943, mean_q: 1.606762, mean_eps: 0.471138\n",
            " 588386/1000000: episode: 881, duration: 15.164s, episode steps: 428, steps per second:  28, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.012947, mae: 1.317794, mean_q: 1.593627, mean_eps: 0.470645\n",
            " 589299/1000000: episode: 882, duration: 32.200s, episode steps: 913, steps per second:  28, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.013418, mae: 1.345590, mean_q: 1.627815, mean_eps: 0.470042\n",
            " 590209/1000000: episode: 883, duration: 32.595s, episode steps: 910, steps per second:  28, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.013400, mae: 1.348474, mean_q: 1.629736, mean_eps: 0.469221\n",
            " 591033/1000000: episode: 884, duration: 29.136s, episode steps: 824, steps per second:  28, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.011608, mae: 1.345730, mean_q: 1.627461, mean_eps: 0.468440\n",
            " 591665/1000000: episode: 885, duration: 22.537s, episode steps: 632, steps per second:  28, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.014069, mae: 1.371946, mean_q: 1.659397, mean_eps: 0.467785\n",
            " 592417/1000000: episode: 886, duration: 26.860s, episode steps: 752, steps per second:  28, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.013188, mae: 1.338924, mean_q: 1.619714, mean_eps: 0.467162\n",
            " 593032/1000000: episode: 887, duration: 22.043s, episode steps: 615, steps per second:  28, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.127 [0.000, 5.000],  loss: 0.012679, mae: 1.349471, mean_q: 1.632816, mean_eps: 0.466548\n",
            " 593822/1000000: episode: 888, duration: 28.335s, episode steps: 790, steps per second:  28, episode reward: 21.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.014269, mae: 1.349934, mean_q: 1.633212, mean_eps: 0.465917\n",
            " 594682/1000000: episode: 889, duration: 30.584s, episode steps: 860, steps per second:  28, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.014070, mae: 1.360278, mean_q: 1.648787, mean_eps: 0.465173\n",
            " 595068/1000000: episode: 890, duration: 13.859s, episode steps: 386, steps per second:  28, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.015246, mae: 1.362044, mean_q: 1.645888, mean_eps: 0.464613\n",
            " 595471/1000000: episode: 891, duration: 14.379s, episode steps: 403, steps per second:  28, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.077 [0.000, 5.000],  loss: 0.012641, mae: 1.343350, mean_q: 1.625192, mean_eps: 0.464259\n",
            " 596542/1000000: episode: 892, duration: 38.245s, episode steps: 1071, steps per second:  28, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.164 [0.000, 5.000],  loss: 0.011765, mae: 1.347257, mean_q: 1.631085, mean_eps: 0.463595\n",
            " 597010/1000000: episode: 893, duration: 16.595s, episode steps: 468, steps per second:  28, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.013200, mae: 1.357479, mean_q: 1.644026, mean_eps: 0.462902\n",
            " 597863/1000000: episode: 894, duration: 30.240s, episode steps: 853, steps per second:  28, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.014626, mae: 1.361615, mean_q: 1.647342, mean_eps: 0.462308\n",
            " 598719/1000000: episode: 895, duration: 30.392s, episode steps: 856, steps per second:  28, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.014306, mae: 1.354020, mean_q: 1.638163, mean_eps: 0.461539\n",
            " 599157/1000000: episode: 896, duration: 15.717s, episode steps: 438, steps per second:  28, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: 0.015421, mae: 1.333303, mean_q: 1.612809, mean_eps: 0.460956\n",
            " 599722/1000000: episode: 897, duration: 20.053s, episode steps: 565, steps per second:  28, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.013535, mae: 1.337280, mean_q: 1.617743, mean_eps: 0.460504\n",
            " 600143/1000000: episode: 898, duration: 15.057s, episode steps: 421, steps per second:  28, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.900 [0.000, 5.000],  loss: 0.012692, mae: 1.360059, mean_q: 1.643660, mean_eps: 0.460061\n",
            " 600807/1000000: episode: 899, duration: 23.630s, episode steps: 664, steps per second:  28, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.128 [0.000, 5.000],  loss: 0.011434, mae: 1.360748, mean_q: 1.644301, mean_eps: 0.459573\n",
            " 601851/1000000: episode: 900, duration: 37.317s, episode steps: 1044, steps per second:  28, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.848 [0.000, 5.000],  loss: 0.013325, mae: 1.360269, mean_q: 1.645107, mean_eps: 0.458805\n",
            " 602580/1000000: episode: 901, duration: 26.081s, episode steps: 729, steps per second:  28, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.013195, mae: 1.375274, mean_q: 1.663891, mean_eps: 0.458007\n",
            " 603232/1000000: episode: 902, duration: 23.453s, episode steps: 652, steps per second:  28, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.014923, mae: 1.370909, mean_q: 1.658772, mean_eps: 0.457386\n",
            " 603608/1000000: episode: 903, duration: 13.602s, episode steps: 376, steps per second:  28, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.761 [0.000, 5.000],  loss: 0.013100, mae: 1.368682, mean_q: 1.657293, mean_eps: 0.456924\n",
            " 604260/1000000: episode: 904, duration: 23.345s, episode steps: 652, steps per second:  28, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.683 [0.000, 5.000],  loss: 0.014128, mae: 1.365666, mean_q: 1.654487, mean_eps: 0.456461\n",
            " 604659/1000000: episode: 905, duration: 14.275s, episode steps: 399, steps per second:  28, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.012116, mae: 1.364652, mean_q: 1.651953, mean_eps: 0.455988\n",
            " 605397/1000000: episode: 906, duration: 26.474s, episode steps: 738, steps per second:  28, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.141 [0.000, 5.000],  loss: 0.013881, mae: 1.376412, mean_q: 1.665288, mean_eps: 0.455475\n",
            " 606230/1000000: episode: 907, duration: 29.837s, episode steps: 833, steps per second:  28, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.012415, mae: 1.359389, mean_q: 1.643000, mean_eps: 0.454767\n",
            " 607169/1000000: episode: 908, duration: 33.634s, episode steps: 939, steps per second:  28, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.013502, mae: 1.365386, mean_q: 1.651497, mean_eps: 0.453970\n",
            " 607907/1000000: episode: 909, duration: 26.426s, episode steps: 738, steps per second:  28, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.014105, mae: 1.363926, mean_q: 1.650699, mean_eps: 0.453216\n",
            " 608470/1000000: episode: 910, duration: 20.105s, episode steps: 563, steps per second:  28, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.854 [0.000, 5.000],  loss: 0.012960, mae: 1.381866, mean_q: 1.672135, mean_eps: 0.452631\n",
            " 609039/1000000: episode: 911, duration: 20.324s, episode steps: 569, steps per second:  28, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.013080, mae: 1.385785, mean_q: 1.677144, mean_eps: 0.452121\n",
            " 609489/1000000: episode: 912, duration: 16.236s, episode steps: 450, steps per second:  28, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.012802, mae: 1.352884, mean_q: 1.634970, mean_eps: 0.451662\n",
            " 610425/1000000: episode: 913, duration: 33.508s, episode steps: 936, steps per second:  28, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.012712, mae: 1.376627, mean_q: 1.667145, mean_eps: 0.451038\n",
            " 610996/1000000: episode: 914, duration: 20.564s, episode steps: 571, steps per second:  28, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.014713, mae: 1.390900, mean_q: 1.684069, mean_eps: 0.450361\n",
            " 611677/1000000: episode: 915, duration: 24.583s, episode steps: 681, steps per second:  28, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.891 [0.000, 5.000],  loss: 0.012913, mae: 1.375177, mean_q: 1.664411, mean_eps: 0.449798\n",
            " 612032/1000000: episode: 916, duration: 12.748s, episode steps: 355, steps per second:  28, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.023 [0.000, 5.000],  loss: 0.014864, mae: 1.370435, mean_q: 1.659139, mean_eps: 0.449331\n",
            " 612396/1000000: episode: 917, duration: 13.141s, episode steps: 364, steps per second:  28, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.926 [0.000, 5.000],  loss: 0.014308, mae: 1.378910, mean_q: 1.665969, mean_eps: 0.449009\n",
            " 612810/1000000: episode: 918, duration: 14.980s, episode steps: 414, steps per second:  28, episode reward: 12.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.013110, mae: 1.373868, mean_q: 1.662866, mean_eps: 0.448658\n",
            " 613693/1000000: episode: 919, duration: 31.671s, episode steps: 883, steps per second:  28, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.112 [0.000, 5.000],  loss: 0.013331, mae: 1.394818, mean_q: 1.688050, mean_eps: 0.448073\n",
            " 614273/1000000: episode: 920, duration: 20.699s, episode steps: 580, steps per second:  28, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.013517, mae: 1.381855, mean_q: 1.670451, mean_eps: 0.447414\n",
            " 614803/1000000: episode: 921, duration: 18.887s, episode steps: 530, steps per second:  28, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.711 [0.000, 5.000],  loss: 0.012739, mae: 1.382808, mean_q: 1.671089, mean_eps: 0.446916\n",
            " 615513/1000000: episode: 922, duration: 25.553s, episode steps: 710, steps per second:  28, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.014032, mae: 1.391328, mean_q: 1.682102, mean_eps: 0.446358\n",
            " 616025/1000000: episode: 923, duration: 18.544s, episode steps: 512, steps per second:  28, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.012963, mae: 1.387077, mean_q: 1.675547, mean_eps: 0.445807\n",
            " 616555/1000000: episode: 924, duration: 18.936s, episode steps: 530, steps per second:  28, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.909 [0.000, 5.000],  loss: 0.014139, mae: 1.389647, mean_q: 1.678055, mean_eps: 0.445339\n",
            " 617055/1000000: episode: 925, duration: 17.934s, episode steps: 500, steps per second:  28, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.013596, mae: 1.379162, mean_q: 1.666160, mean_eps: 0.444876\n",
            " 617672/1000000: episode: 926, duration: 22.332s, episode steps: 617, steps per second:  28, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.107 [0.000, 5.000],  loss: 0.015472, mae: 1.382358, mean_q: 1.674040, mean_eps: 0.444374\n",
            " 618054/1000000: episode: 927, duration: 13.825s, episode steps: 382, steps per second:  28, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.005 [0.000, 5.000],  loss: 0.013300, mae: 1.390824, mean_q: 1.685985, mean_eps: 0.443924\n",
            " 618605/1000000: episode: 928, duration: 19.902s, episode steps: 551, steps per second:  28, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.085 [0.000, 5.000],  loss: 0.013722, mae: 1.381712, mean_q: 1.669834, mean_eps: 0.443503\n",
            " 618971/1000000: episode: 929, duration: 13.067s, episode steps: 366, steps per second:  28, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.014330, mae: 1.407478, mean_q: 1.698491, mean_eps: 0.443091\n",
            " 619612/1000000: episode: 930, duration: 23.195s, episode steps: 641, steps per second:  28, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.020 [0.000, 5.000],  loss: 0.013190, mae: 1.375810, mean_q: 1.660758, mean_eps: 0.442639\n",
            " 620143/1000000: episode: 931, duration: 19.167s, episode steps: 531, steps per second:  28, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.012191, mae: 1.398001, mean_q: 1.690812, mean_eps: 0.442112\n",
            " 620893/1000000: episode: 932, duration: 26.998s, episode steps: 750, steps per second:  28, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.012025, mae: 1.397066, mean_q: 1.690557, mean_eps: 0.441534\n",
            " 621560/1000000: episode: 933, duration: 24.099s, episode steps: 667, steps per second:  28, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.013058, mae: 1.419308, mean_q: 1.716387, mean_eps: 0.440897\n",
            " 622531/1000000: episode: 934, duration: 34.865s, episode steps: 971, steps per second:  28, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.014746, mae: 1.408620, mean_q: 1.701226, mean_eps: 0.440160\n",
            " 622894/1000000: episode: 935, duration: 13.247s, episode steps: 363, steps per second:  27, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.793 [0.000, 5.000],  loss: 0.014455, mae: 1.394523, mean_q: 1.685623, mean_eps: 0.439559\n",
            " 623234/1000000: episode: 936, duration: 12.319s, episode steps: 340, steps per second:  28, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.850 [0.000, 5.000],  loss: 0.013429, mae: 1.425519, mean_q: 1.724736, mean_eps: 0.439242\n",
            " 623674/1000000: episode: 937, duration: 15.779s, episode steps: 440, steps per second:  28, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.164 [0.000, 5.000],  loss: 0.014963, mae: 1.417483, mean_q: 1.715159, mean_eps: 0.438891\n",
            " 624195/1000000: episode: 938, duration: 18.883s, episode steps: 521, steps per second:  28, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: 0.013505, mae: 1.419584, mean_q: 1.716307, mean_eps: 0.438459\n",
            " 624639/1000000: episode: 939, duration: 16.256s, episode steps: 444, steps per second:  27, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.014388, mae: 1.426349, mean_q: 1.728234, mean_eps: 0.438026\n",
            " 625584/1000000: episode: 940, duration: 34.493s, episode steps: 945, steps per second:  27, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.013002, mae: 1.401664, mean_q: 1.695844, mean_eps: 0.437401\n",
            " 626495/1000000: episode: 941, duration: 32.882s, episode steps: 911, steps per second:  28, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.012922, mae: 1.411788, mean_q: 1.710119, mean_eps: 0.436566\n",
            " 627238/1000000: episode: 942, duration: 26.794s, episode steps: 743, steps per second:  28, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.013626, mae: 1.410293, mean_q: 1.709472, mean_eps: 0.435821\n",
            " 627802/1000000: episode: 943, duration: 20.203s, episode steps: 564, steps per second:  28, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.957 [0.000, 5.000],  loss: 0.013567, mae: 1.401016, mean_q: 1.695944, mean_eps: 0.435232\n",
            " 628801/1000000: episode: 944, duration: 35.969s, episode steps: 999, steps per second:  28, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: 0.013384, mae: 1.415593, mean_q: 1.714183, mean_eps: 0.434528\n",
            " 629650/1000000: episode: 945, duration: 30.698s, episode steps: 849, steps per second:  28, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.013159, mae: 1.406332, mean_q: 1.699660, mean_eps: 0.433697\n",
            " 630470/1000000: episode: 946, duration: 29.531s, episode steps: 820, steps per second:  28, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.012561, mae: 1.425489, mean_q: 1.724148, mean_eps: 0.432946\n",
            " 631405/1000000: episode: 947, duration: 33.980s, episode steps: 935, steps per second:  28, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.013888, mae: 1.431477, mean_q: 1.730913, mean_eps: 0.432156\n",
            " 632155/1000000: episode: 948, duration: 27.032s, episode steps: 750, steps per second:  28, episode reward: 21.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.011909, mae: 1.447092, mean_q: 1.751631, mean_eps: 0.431398\n",
            " 632880/1000000: episode: 949, duration: 26.443s, episode steps: 725, steps per second:  27, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.012716, mae: 1.425669, mean_q: 1.722919, mean_eps: 0.430736\n",
            " 633960/1000000: episode: 950, duration: 38.979s, episode steps: 1080, steps per second:  28, episode reward: 26.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.825 [0.000, 5.000],  loss: 0.013390, mae: 1.443472, mean_q: 1.744102, mean_eps: 0.429924\n",
            " 635045/1000000: episode: 951, duration: 39.303s, episode steps: 1085, steps per second:  28, episode reward: 33.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.076 [0.000, 5.000],  loss: 0.013560, mae: 1.437827, mean_q: 1.740467, mean_eps: 0.428948\n",
            " 635903/1000000: episode: 952, duration: 31.154s, episode steps: 858, steps per second:  28, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.014559, mae: 1.442845, mean_q: 1.745215, mean_eps: 0.428073\n",
            " 636642/1000000: episode: 953, duration: 27.212s, episode steps: 739, steps per second:  27, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.013067, mae: 1.434386, mean_q: 1.737318, mean_eps: 0.427355\n",
            " 637614/1000000: episode: 954, duration: 35.376s, episode steps: 972, steps per second:  27, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.014134, mae: 1.429648, mean_q: 1.730985, mean_eps: 0.426585\n",
            " 638506/1000000: episode: 955, duration: 32.600s, episode steps: 892, steps per second:  27, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.013045, mae: 1.433026, mean_q: 1.733583, mean_eps: 0.425746\n",
            " 639106/1000000: episode: 956, duration: 21.877s, episode steps: 600, steps per second:  27, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.013702, mae: 1.426147, mean_q: 1.721590, mean_eps: 0.425075\n",
            " 640054/1000000: episode: 957, duration: 34.625s, episode steps: 948, steps per second:  27, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.013675, mae: 1.439895, mean_q: 1.741795, mean_eps: 0.424378\n",
            " 640868/1000000: episode: 958, duration: 29.894s, episode steps: 814, steps per second:  27, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.012618, mae: 1.443695, mean_q: 1.744792, mean_eps: 0.423586\n",
            " 641375/1000000: episode: 959, duration: 18.719s, episode steps: 507, steps per second:  27, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: 0.013787, mae: 1.457362, mean_q: 1.761712, mean_eps: 0.422992\n",
            " 641938/1000000: episode: 960, duration: 20.673s, episode steps: 563, steps per second:  27, episode reward: 14.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.060 [0.000, 5.000],  loss: 0.012767, mae: 1.445320, mean_q: 1.746959, mean_eps: 0.422510\n",
            " 642772/1000000: episode: 961, duration: 30.392s, episode steps: 834, steps per second:  27, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.012850, mae: 1.439938, mean_q: 1.741594, mean_eps: 0.421881\n",
            " 643559/1000000: episode: 962, duration: 28.568s, episode steps: 787, steps per second:  28, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.013449, mae: 1.439746, mean_q: 1.742726, mean_eps: 0.421152\n",
            " 644473/1000000: episode: 963, duration: 33.512s, episode steps: 914, steps per second:  27, episode reward: 26.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.933 [0.000, 5.000],  loss: 0.013190, mae: 1.441600, mean_q: 1.743002, mean_eps: 0.420386\n",
            " 644995/1000000: episode: 964, duration: 19.008s, episode steps: 522, steps per second:  27, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.013241, mae: 1.444460, mean_q: 1.745751, mean_eps: 0.419739\n",
            " 645963/1000000: episode: 965, duration: 35.405s, episode steps: 968, steps per second:  27, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.807 [0.000, 5.000],  loss: 0.013975, mae: 1.457397, mean_q: 1.764769, mean_eps: 0.419070\n",
            " 646961/1000000: episode: 966, duration: 36.796s, episode steps: 998, steps per second:  27, episode reward: 28.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.085 [0.000, 5.000],  loss: 0.013536, mae: 1.449923, mean_q: 1.753352, mean_eps: 0.418184\n",
            " 647945/1000000: episode: 967, duration: 36.009s, episode steps: 984, steps per second:  27, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.091 [0.000, 5.000],  loss: 0.013020, mae: 1.458678, mean_q: 1.763752, mean_eps: 0.417291\n",
            " 649076/1000000: episode: 968, duration: 41.620s, episode steps: 1131, steps per second:  27, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.013994, mae: 1.449560, mean_q: 1.752870, mean_eps: 0.416341\n",
            " 649556/1000000: episode: 969, duration: 17.798s, episode steps: 480, steps per second:  27, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.012588, mae: 1.462420, mean_q: 1.771086, mean_eps: 0.415617\n",
            " 650209/1000000: episode: 970, duration: 24.125s, episode steps: 653, steps per second:  27, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.012143, mae: 1.446305, mean_q: 1.746986, mean_eps: 0.415106\n",
            " 651249/1000000: episode: 971, duration: 38.279s, episode steps: 1040, steps per second:  27, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.967 [0.000, 5.000],  loss: 0.012017, mae: 1.478916, mean_q: 1.787902, mean_eps: 0.414343\n",
            " 651784/1000000: episode: 972, duration: 19.601s, episode steps: 535, steps per second:  27, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.013643, mae: 1.474012, mean_q: 1.781867, mean_eps: 0.413636\n",
            " 652230/1000000: episode: 973, duration: 16.443s, episode steps: 446, steps per second:  27, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.785 [0.000, 5.000],  loss: 0.012706, mae: 1.484443, mean_q: 1.795865, mean_eps: 0.413195\n",
            " 652921/1000000: episode: 974, duration: 25.473s, episode steps: 691, steps per second:  27, episode reward: 19.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.014541, mae: 1.484587, mean_q: 1.791348, mean_eps: 0.412682\n",
            " 653694/1000000: episode: 975, duration: 28.360s, episode steps: 773, steps per second:  27, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.065 [0.000, 5.000],  loss: 0.012783, mae: 1.480972, mean_q: 1.790697, mean_eps: 0.412023\n",
            " 654340/1000000: episode: 976, duration: 23.994s, episode steps: 646, steps per second:  27, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.015546, mae: 1.476010, mean_q: 1.784744, mean_eps: 0.411386\n",
            " 655267/1000000: episode: 977, duration: 34.181s, episode steps: 927, steps per second:  27, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.810 [0.000, 5.000],  loss: 0.013641, mae: 1.481290, mean_q: 1.791914, mean_eps: 0.410678\n",
            " 656301/1000000: episode: 978, duration: 38.570s, episode steps: 1034, steps per second:  27, episode reward: 26.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.014118, mae: 1.485403, mean_q: 1.795183, mean_eps: 0.409794\n",
            " 656935/1000000: episode: 979, duration: 23.421s, episode steps: 634, steps per second:  27, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.013195, mae: 1.493341, mean_q: 1.806643, mean_eps: 0.409044\n",
            " 657615/1000000: episode: 980, duration: 25.602s, episode steps: 680, steps per second:  27, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.013137, mae: 1.479417, mean_q: 1.790539, mean_eps: 0.408453\n",
            " 658470/1000000: episode: 981, duration: 32.217s, episode steps: 855, steps per second:  27, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.813 [0.000, 5.000],  loss: 0.014091, mae: 1.488562, mean_q: 1.801219, mean_eps: 0.407762\n",
            " 659299/1000000: episode: 982, duration: 30.972s, episode steps: 829, steps per second:  27, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.014237, mae: 1.478544, mean_q: 1.786940, mean_eps: 0.407004\n",
            " 660150/1000000: episode: 983, duration: 31.995s, episode steps: 851, steps per second:  27, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.014335, mae: 1.465373, mean_q: 1.771459, mean_eps: 0.406248\n",
            " 661246/1000000: episode: 984, duration: 41.043s, episode steps: 1096, steps per second:  27, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.862 [0.000, 5.000],  loss: 0.013419, mae: 1.477792, mean_q: 1.787321, mean_eps: 0.405372\n",
            " 661616/1000000: episode: 985, duration: 13.911s, episode steps: 370, steps per second:  27, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.692 [0.000, 5.000],  loss: 0.013883, mae: 1.492786, mean_q: 1.803850, mean_eps: 0.404713\n",
            " 662504/1000000: episode: 986, duration: 33.460s, episode steps: 888, steps per second:  27, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.012648, mae: 1.479224, mean_q: 1.789473, mean_eps: 0.404148\n",
            " 663323/1000000: episode: 987, duration: 30.685s, episode steps: 819, steps per second:  27, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.012890, mae: 1.495780, mean_q: 1.810395, mean_eps: 0.403379\n",
            " 664178/1000000: episode: 988, duration: 32.165s, episode steps: 855, steps per second:  27, episode reward: 22.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.013248, mae: 1.508235, mean_q: 1.823668, mean_eps: 0.402625\n",
            " 664999/1000000: episode: 989, duration: 30.719s, episode steps: 821, steps per second:  27, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.013995, mae: 1.486907, mean_q: 1.799476, mean_eps: 0.401871\n",
            " 665998/1000000: episode: 990, duration: 37.317s, episode steps: 999, steps per second:  27, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.015352, mae: 1.509394, mean_q: 1.825514, mean_eps: 0.401052\n",
            " 666968/1000000: episode: 991, duration: 36.011s, episode steps: 970, steps per second:  27, episode reward: 29.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: 0.013646, mae: 1.486212, mean_q: 1.794744, mean_eps: 0.400166\n",
            " 667881/1000000: episode: 992, duration: 33.790s, episode steps: 913, steps per second:  27, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.013435, mae: 1.502235, mean_q: 1.818644, mean_eps: 0.399318\n",
            " 668627/1000000: episode: 993, duration: 27.443s, episode steps: 746, steps per second:  27, episode reward: 19.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.012500, mae: 1.484575, mean_q: 1.796228, mean_eps: 0.398571\n",
            " 669410/1000000: episode: 994, duration: 28.884s, episode steps: 783, steps per second:  27, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.013794, mae: 1.497119, mean_q: 1.808810, mean_eps: 0.397884\n",
            " 669878/1000000: episode: 995, duration: 17.176s, episode steps: 468, steps per second:  27, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.014724, mae: 1.515867, mean_q: 1.832487, mean_eps: 0.397320\n",
            " 670806/1000000: episode: 996, duration: 34.480s, episode steps: 928, steps per second:  27, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: 0.013545, mae: 1.507258, mean_q: 1.824139, mean_eps: 0.396692\n",
            " 671734/1000000: episode: 997, duration: 34.968s, episode steps: 928, steps per second:  27, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.012759, mae: 1.500033, mean_q: 1.814115, mean_eps: 0.395857\n",
            " 672219/1000000: episode: 998, duration: 18.188s, episode steps: 485, steps per second:  27, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: 0.010759, mae: 1.499662, mean_q: 1.811699, mean_eps: 0.395222\n",
            " 673291/1000000: episode: 999, duration: 40.436s, episode steps: 1072, steps per second:  27, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.013675, mae: 1.516218, mean_q: 1.832669, mean_eps: 0.394521\n",
            " 674187/1000000: episode: 1000, duration: 33.294s, episode steps: 896, steps per second:  27, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.011400, mae: 1.494817, mean_q: 1.807967, mean_eps: 0.393636\n",
            " 674884/1000000: episode: 1001, duration: 26.162s, episode steps: 697, steps per second:  27, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.013703, mae: 1.522577, mean_q: 1.839626, mean_eps: 0.392919\n",
            " 675716/1000000: episode: 1002, duration: 30.968s, episode steps: 832, steps per second:  27, episode reward: 23.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.014111, mae: 1.498169, mean_q: 1.809806, mean_eps: 0.392232\n",
            " 676391/1000000: episode: 1003, duration: 24.928s, episode steps: 675, steps per second:  27, episode reward: 18.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.012379, mae: 1.514764, mean_q: 1.829324, mean_eps: 0.391553\n",
            " 677522/1000000: episode: 1004, duration: 41.631s, episode steps: 1131, steps per second:  27, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.013856, mae: 1.506408, mean_q: 1.821404, mean_eps: 0.390740\n",
            " 678483/1000000: episode: 1005, duration: 35.471s, episode steps: 961, steps per second:  27, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.013014, mae: 1.501651, mean_q: 1.816937, mean_eps: 0.389798\n",
            " 679302/1000000: episode: 1006, duration: 30.319s, episode steps: 819, steps per second:  27, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.328 [0.000, 5.000],  loss: 0.012509, mae: 1.504133, mean_q: 1.815531, mean_eps: 0.388997\n",
            " 680044/1000000: episode: 1007, duration: 27.415s, episode steps: 742, steps per second:  27, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: 0.014768, mae: 1.512828, mean_q: 1.828303, mean_eps: 0.388295\n",
            " 680433/1000000: episode: 1008, duration: 14.593s, episode steps: 389, steps per second:  27, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.440 [0.000, 5.000],  loss: 0.013237, mae: 1.545972, mean_q: 1.870510, mean_eps: 0.387786\n",
            " 681614/1000000: episode: 1009, duration: 43.414s, episode steps: 1181, steps per second:  27, episode reward: 32.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.013768, mae: 1.540118, mean_q: 1.862843, mean_eps: 0.387078\n",
            " 682835/1000000: episode: 1010, duration: 45.192s, episode steps: 1221, steps per second:  27, episode reward: 31.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.042 [0.000, 5.000],  loss: 0.012857, mae: 1.541580, mean_q: 1.863632, mean_eps: 0.385998\n",
            " 683353/1000000: episode: 1011, duration: 19.676s, episode steps: 518, steps per second:  26, episode reward: 14.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.011324, mae: 1.553747, mean_q: 1.881250, mean_eps: 0.385215\n",
            " 683890/1000000: episode: 1012, duration: 20.135s, episode steps: 537, steps per second:  27, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.013846, mae: 1.533044, mean_q: 1.851665, mean_eps: 0.384740\n",
            " 684268/1000000: episode: 1013, duration: 14.288s, episode steps: 378, steps per second:  26, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.013516, mae: 1.533947, mean_q: 1.851993, mean_eps: 0.384330\n",
            " 684846/1000000: episode: 1014, duration: 22.142s, episode steps: 578, steps per second:  26, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.013573, mae: 1.548344, mean_q: 1.867494, mean_eps: 0.383900\n",
            " 685480/1000000: episode: 1015, duration: 24.006s, episode steps: 634, steps per second:  26, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 3.033 [0.000, 5.000],  loss: 0.013977, mae: 1.539122, mean_q: 1.860026, mean_eps: 0.383354\n",
            " 686376/1000000: episode: 1016, duration: 33.711s, episode steps: 896, steps per second:  27, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.760 [0.000, 5.000],  loss: 0.013539, mae: 1.537468, mean_q: 1.857243, mean_eps: 0.382667\n",
            " 687229/1000000: episode: 1017, duration: 32.130s, episode steps: 853, steps per second:  27, episode reward: 24.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.014216, mae: 1.545782, mean_q: 1.870101, mean_eps: 0.381878\n",
            " 688191/1000000: episode: 1018, duration: 36.079s, episode steps: 962, steps per second:  27, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.013281, mae: 1.538673, mean_q: 1.858381, mean_eps: 0.381061\n",
            " 688731/1000000: episode: 1019, duration: 20.032s, episode steps: 540, steps per second:  27, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.012783, mae: 1.530932, mean_q: 1.849980, mean_eps: 0.380386\n",
            " 689109/1000000: episode: 1020, duration: 14.147s, episode steps: 378, steps per second:  27, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.013699, mae: 1.547930, mean_q: 1.869059, mean_eps: 0.379972\n",
            " 689758/1000000: episode: 1021, duration: 24.290s, episode steps: 649, steps per second:  27, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.014566, mae: 1.561343, mean_q: 1.888408, mean_eps: 0.379509\n",
            " 690252/1000000: episode: 1022, duration: 18.742s, episode steps: 494, steps per second:  26, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.012636, mae: 1.547422, mean_q: 1.871960, mean_eps: 0.378996\n",
            " 691220/1000000: episode: 1023, duration: 36.448s, episode steps: 968, steps per second:  27, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.074 [0.000, 5.000],  loss: 0.013080, mae: 1.553148, mean_q: 1.877069, mean_eps: 0.378339\n",
            " 691849/1000000: episode: 1024, duration: 24.041s, episode steps: 629, steps per second:  26, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.012935, mae: 1.559651, mean_q: 1.882582, mean_eps: 0.377619\n",
            " 692319/1000000: episode: 1025, duration: 17.655s, episode steps: 470, steps per second:  27, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.632 [0.000, 5.000],  loss: 0.014401, mae: 1.553384, mean_q: 1.878020, mean_eps: 0.377124\n",
            " 692763/1000000: episode: 1026, duration: 17.046s, episode steps: 444, steps per second:  26, episode reward: 11.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.012646, mae: 1.543074, mean_q: 1.867703, mean_eps: 0.376714\n",
            " 694050/1000000: episode: 1027, duration: 48.099s, episode steps: 1287, steps per second:  27, episode reward: 30.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.013019, mae: 1.550317, mean_q: 1.873489, mean_eps: 0.375935\n",
            " 695092/1000000: episode: 1028, duration: 38.640s, episode steps: 1042, steps per second:  27, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.013465, mae: 1.542700, mean_q: 1.862487, mean_eps: 0.374887\n",
            " 696095/1000000: episode: 1029, duration: 37.112s, episode steps: 1003, steps per second:  27, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: 0.013506, mae: 1.569784, mean_q: 1.895364, mean_eps: 0.373967\n",
            " 697457/1000000: episode: 1030, duration: 52.436s, episode steps: 1362, steps per second:  26, episode reward: 35.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.013404, mae: 1.556850, mean_q: 1.881149, mean_eps: 0.372902\n",
            " 698259/1000000: episode: 1031, duration: 30.626s, episode steps: 802, steps per second:  26, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.744 [0.000, 5.000],  loss: 0.012937, mae: 1.567929, mean_q: 1.893745, mean_eps: 0.371928\n",
            " 699313/1000000: episode: 1032, duration: 40.135s, episode steps: 1054, steps per second:  26, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.013916, mae: 1.546956, mean_q: 1.867457, mean_eps: 0.371093\n",
            " 699854/1000000: episode: 1033, duration: 20.697s, episode steps: 541, steps per second:  26, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.014099, mae: 1.541198, mean_q: 1.862835, mean_eps: 0.370374\n",
            " 700557/1000000: episode: 1034, duration: 26.786s, episode steps: 703, steps per second:  26, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.068 [0.000, 5.000],  loss: 0.013005, mae: 1.585186, mean_q: 1.915257, mean_eps: 0.369815\n",
            " 700998/1000000: episode: 1035, duration: 16.972s, episode steps: 441, steps per second:  26, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.013678, mae: 1.599882, mean_q: 1.934591, mean_eps: 0.369300\n",
            " 701869/1000000: episode: 1036, duration: 33.034s, episode steps: 871, steps per second:  26, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.014262, mae: 1.600189, mean_q: 1.934607, mean_eps: 0.368709\n",
            " 702933/1000000: episode: 1037, duration: 40.407s, episode steps: 1064, steps per second:  26, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.013510, mae: 1.591124, mean_q: 1.920519, mean_eps: 0.367838\n",
            " 703534/1000000: episode: 1038, duration: 22.468s, episode steps: 601, steps per second:  27, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: 0.014784, mae: 1.607326, mean_q: 1.941551, mean_eps: 0.367089\n",
            " 704078/1000000: episode: 1039, duration: 20.674s, episode steps: 544, steps per second:  26, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: 0.014360, mae: 1.605022, mean_q: 1.935907, mean_eps: 0.366575\n",
            " 704862/1000000: episode: 1040, duration: 29.553s, episode steps: 784, steps per second:  27, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.015042, mae: 1.624366, mean_q: 1.960337, mean_eps: 0.365977\n",
            " 705482/1000000: episode: 1041, duration: 23.514s, episode steps: 620, steps per second:  26, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.753 [0.000, 5.000],  loss: 0.014266, mae: 1.600515, mean_q: 1.932208, mean_eps: 0.365345\n",
            " 706121/1000000: episode: 1042, duration: 24.037s, episode steps: 639, steps per second:  27, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.014453, mae: 1.593733, mean_q: 1.924189, mean_eps: 0.364778\n",
            " 706778/1000000: episode: 1043, duration: 24.687s, episode steps: 657, steps per second:  27, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.921 [0.000, 5.000],  loss: 0.013489, mae: 1.594010, mean_q: 1.923004, mean_eps: 0.364195\n",
            " 707286/1000000: episode: 1044, duration: 19.150s, episode steps: 508, steps per second:  27, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.886 [0.000, 5.000],  loss: 0.015067, mae: 1.590706, mean_q: 1.920491, mean_eps: 0.363671\n",
            " 708011/1000000: episode: 1045, duration: 27.544s, episode steps: 725, steps per second:  26, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.942 [0.000, 5.000],  loss: 0.014289, mae: 1.609638, mean_q: 1.943502, mean_eps: 0.363117\n",
            " 708747/1000000: episode: 1046, duration: 27.647s, episode steps: 736, steps per second:  27, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.781 [0.000, 5.000],  loss: 0.012992, mae: 1.590296, mean_q: 1.920458, mean_eps: 0.362460\n",
            " 709143/1000000: episode: 1047, duration: 14.881s, episode steps: 396, steps per second:  27, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.788 [0.000, 5.000],  loss: 0.012483, mae: 1.620925, mean_q: 1.959249, mean_eps: 0.361950\n",
            " 709645/1000000: episode: 1048, duration: 19.030s, episode steps: 502, steps per second:  26, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.012690, mae: 1.585870, mean_q: 1.915936, mean_eps: 0.361545\n",
            " 710611/1000000: episode: 1049, duration: 36.418s, episode steps: 966, steps per second:  27, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.014039, mae: 1.607473, mean_q: 1.941432, mean_eps: 0.360885\n",
            " 711279/1000000: episode: 1050, duration: 25.261s, episode steps: 668, steps per second:  26, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.808 [0.000, 5.000],  loss: 0.013055, mae: 1.629912, mean_q: 1.969515, mean_eps: 0.360150\n",
            " 711883/1000000: episode: 1051, duration: 22.868s, episode steps: 604, steps per second:  26, episode reward: 15.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.014465, mae: 1.622782, mean_q: 1.958543, mean_eps: 0.359578\n",
            " 712726/1000000: episode: 1052, duration: 31.789s, episode steps: 843, steps per second:  27, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.014075, mae: 1.631777, mean_q: 1.975510, mean_eps: 0.358926\n",
            " 713363/1000000: episode: 1053, duration: 24.107s, episode steps: 637, steps per second:  26, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.014520, mae: 1.609383, mean_q: 1.944525, mean_eps: 0.358260\n",
            " 714006/1000000: episode: 1054, duration: 24.461s, episode steps: 643, steps per second:  26, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.013668, mae: 1.646048, mean_q: 1.985382, mean_eps: 0.357684\n",
            " 714451/1000000: episode: 1055, duration: 16.764s, episode steps: 445, steps per second:  27, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.969 [0.000, 5.000],  loss: 0.013551, mae: 1.614721, mean_q: 1.952968, mean_eps: 0.357195\n",
            " 715114/1000000: episode: 1056, duration: 25.204s, episode steps: 663, steps per second:  26, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.831 [0.000, 5.000],  loss: 0.013482, mae: 1.615479, mean_q: 1.951801, mean_eps: 0.356696\n",
            " 716053/1000000: episode: 1057, duration: 35.658s, episode steps: 939, steps per second:  26, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.047 [0.000, 5.000],  loss: 0.014443, mae: 1.620031, mean_q: 1.954646, mean_eps: 0.355974\n",
            " 716843/1000000: episode: 1058, duration: 29.993s, episode steps: 790, steps per second:  26, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.014334, mae: 1.634483, mean_q: 1.973905, mean_eps: 0.355197\n",
            " 717484/1000000: episode: 1059, duration: 24.216s, episode steps: 641, steps per second:  26, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.875 [0.000, 5.000],  loss: 0.014919, mae: 1.636499, mean_q: 1.979066, mean_eps: 0.354554\n",
            " 718081/1000000: episode: 1060, duration: 22.811s, episode steps: 597, steps per second:  26, episode reward: 15.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.013156, mae: 1.629580, mean_q: 1.968653, mean_eps: 0.353996\n",
            " 718707/1000000: episode: 1061, duration: 23.576s, episode steps: 626, steps per second:  27, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.014579, mae: 1.631886, mean_q: 1.972124, mean_eps: 0.353445\n",
            " 719332/1000000: episode: 1062, duration: 23.751s, episode steps: 625, steps per second:  26, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.015147, mae: 1.650280, mean_q: 1.993828, mean_eps: 0.352884\n",
            " 719830/1000000: episode: 1063, duration: 19.059s, episode steps: 498, steps per second:  26, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.926 [0.000, 5.000],  loss: 0.013454, mae: 1.634666, mean_q: 1.976421, mean_eps: 0.352378\n",
            " 720457/1000000: episode: 1064, duration: 23.776s, episode steps: 627, steps per second:  26, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.013602, mae: 1.655115, mean_q: 2.001210, mean_eps: 0.351870\n",
            " 721143/1000000: episode: 1065, duration: 26.171s, episode steps: 686, steps per second:  26, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.224 [0.000, 5.000],  loss: 0.013662, mae: 1.659455, mean_q: 2.002555, mean_eps: 0.351280\n",
            " 721682/1000000: episode: 1066, duration: 20.690s, episode steps: 539, steps per second:  26, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.012877, mae: 1.650284, mean_q: 1.993402, mean_eps: 0.350729\n",
            " 722127/1000000: episode: 1067, duration: 16.841s, episode steps: 445, steps per second:  26, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.015560, mae: 1.656697, mean_q: 1.999994, mean_eps: 0.350286\n",
            " 723357/1000000: episode: 1068, duration: 46.876s, episode steps: 1230, steps per second:  26, episode reward: 30.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.015038, mae: 1.657512, mean_q: 2.003154, mean_eps: 0.349532\n",
            " 724218/1000000: episode: 1069, duration: 32.990s, episode steps: 861, steps per second:  26, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.012867, mae: 1.674507, mean_q: 2.023317, mean_eps: 0.348591\n",
            " 725028/1000000: episode: 1070, duration: 31.419s, episode steps: 810, steps per second:  26, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.784 [0.000, 5.000],  loss: 0.013940, mae: 1.642147, mean_q: 1.982882, mean_eps: 0.347840\n",
            " 725651/1000000: episode: 1071, duration: 23.929s, episode steps: 623, steps per second:  26, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.770 [0.000, 5.000],  loss: 0.015088, mae: 1.655485, mean_q: 1.998735, mean_eps: 0.347196\n",
            " 726487/1000000: episode: 1072, duration: 32.152s, episode steps: 836, steps per second:  26, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.014339, mae: 1.663688, mean_q: 2.009051, mean_eps: 0.346539\n",
            " 727406/1000000: episode: 1073, duration: 35.286s, episode steps: 919, steps per second:  26, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.153 [0.000, 5.000],  loss: 0.014356, mae: 1.645968, mean_q: 1.988756, mean_eps: 0.345749\n",
            " 728043/1000000: episode: 1074, duration: 24.294s, episode steps: 637, steps per second:  26, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.014720, mae: 1.653223, mean_q: 2.000974, mean_eps: 0.345048\n",
            " 728601/1000000: episode: 1075, duration: 21.378s, episode steps: 558, steps per second:  26, episode reward: 14.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.013938, mae: 1.663587, mean_q: 2.009396, mean_eps: 0.344510\n",
            " 729383/1000000: episode: 1076, duration: 30.101s, episode steps: 782, steps per second:  26, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.093 [0.000, 5.000],  loss: 0.013990, mae: 1.676893, mean_q: 2.027268, mean_eps: 0.343907\n",
            " 730016/1000000: episode: 1077, duration: 24.384s, episode steps: 633, steps per second:  26, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.088 [0.000, 5.000],  loss: 0.013201, mae: 1.650054, mean_q: 1.993609, mean_eps: 0.343272\n",
            " 730891/1000000: episode: 1078, duration: 33.680s, episode steps: 875, steps per second:  26, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.013593, mae: 1.678994, mean_q: 2.030768, mean_eps: 0.342593\n",
            " 731555/1000000: episode: 1079, duration: 25.290s, episode steps: 664, steps per second:  26, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.895 [0.000, 5.000],  loss: 0.015009, mae: 1.688177, mean_q: 2.040479, mean_eps: 0.341900\n",
            " 732447/1000000: episode: 1080, duration: 34.170s, episode steps: 892, steps per second:  26, episode reward: 24.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.058 [0.000, 5.000],  loss: 0.015502, mae: 1.688626, mean_q: 2.041838, mean_eps: 0.341200\n",
            " 733406/1000000: episode: 1081, duration: 36.705s, episode steps: 959, steps per second:  26, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.137 [0.000, 5.000],  loss: 0.014424, mae: 1.669445, mean_q: 2.018084, mean_eps: 0.340367\n",
            " 734198/1000000: episode: 1082, duration: 30.382s, episode steps: 792, steps per second:  26, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.012764, mae: 1.675198, mean_q: 2.026785, mean_eps: 0.339578\n",
            " 734837/1000000: episode: 1083, duration: 24.332s, episode steps: 639, steps per second:  26, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.189 [0.000, 5.000],  loss: 0.013696, mae: 1.704325, mean_q: 2.059331, mean_eps: 0.338934\n",
            " 735352/1000000: episode: 1084, duration: 19.774s, episode steps: 515, steps per second:  26, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.200 [0.000, 5.000],  loss: 0.014773, mae: 1.684901, mean_q: 2.035285, mean_eps: 0.338415\n",
            " 736034/1000000: episode: 1085, duration: 26.058s, episode steps: 682, steps per second:  26, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.063 [0.000, 5.000],  loss: 0.014109, mae: 1.665736, mean_q: 2.012348, mean_eps: 0.337877\n",
            " 736678/1000000: episode: 1086, duration: 24.765s, episode steps: 644, steps per second:  26, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.015013, mae: 1.703502, mean_q: 2.058649, mean_eps: 0.337280\n",
            " 737462/1000000: episode: 1087, duration: 30.261s, episode steps: 784, steps per second:  26, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.013068, mae: 1.696410, mean_q: 2.050635, mean_eps: 0.336637\n",
            " 737894/1000000: episode: 1088, duration: 16.598s, episode steps: 432, steps per second:  26, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.736 [0.000, 5.000],  loss: 0.015021, mae: 1.704425, mean_q: 2.058799, mean_eps: 0.336090\n",
            " 738922/1000000: episode: 1089, duration: 39.584s, episode steps: 1028, steps per second:  26, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.013957, mae: 1.683402, mean_q: 2.033504, mean_eps: 0.335433\n",
            " 739728/1000000: episode: 1090, duration: 30.951s, episode steps: 806, steps per second:  26, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.015027, mae: 1.686008, mean_q: 2.034964, mean_eps: 0.334608\n",
            " 740309/1000000: episode: 1091, duration: 22.586s, episode steps: 581, steps per second:  26, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.038 [0.000, 5.000],  loss: 0.014799, mae: 1.685358, mean_q: 2.035225, mean_eps: 0.333984\n",
            " 740838/1000000: episode: 1092, duration: 20.447s, episode steps: 529, steps per second:  26, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.960 [0.000, 5.000],  loss: 0.013118, mae: 1.687006, mean_q: 2.040892, mean_eps: 0.333483\n",
            " 741782/1000000: episode: 1093, duration: 36.288s, episode steps: 944, steps per second:  26, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.014941, mae: 1.710817, mean_q: 2.068990, mean_eps: 0.332821\n",
            " 742717/1000000: episode: 1094, duration: 35.932s, episode steps: 935, steps per second:  26, episode reward: 26.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.852 [0.000, 5.000],  loss: 0.014335, mae: 1.688682, mean_q: 2.041274, mean_eps: 0.331975\n",
            " 743187/1000000: episode: 1095, duration: 18.117s, episode steps: 470, steps per second:  26, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.881 [0.000, 5.000],  loss: 0.016039, mae: 1.693391, mean_q: 2.046728, mean_eps: 0.331343\n",
            " 743748/1000000: episode: 1096, duration: 21.944s, episode steps: 561, steps per second:  26, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.014582, mae: 1.713755, mean_q: 2.071612, mean_eps: 0.330881\n",
            " 744921/1000000: episode: 1097, duration: 45.472s, episode steps: 1173, steps per second:  26, episode reward: 28.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: 0.015279, mae: 1.707100, mean_q: 2.061170, mean_eps: 0.330099\n",
            " 745417/1000000: episode: 1098, duration: 18.985s, episode steps: 496, steps per second:  26, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.736 [0.000, 5.000],  loss: 0.015320, mae: 1.705581, mean_q: 2.057923, mean_eps: 0.329347\n",
            " 746524/1000000: episode: 1099, duration: 42.867s, episode steps: 1107, steps per second:  26, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.014732, mae: 1.718212, mean_q: 2.075914, mean_eps: 0.328627\n",
            " 747081/1000000: episode: 1100, duration: 21.701s, episode steps: 557, steps per second:  26, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.016123, mae: 1.701343, mean_q: 2.058031, mean_eps: 0.327878\n",
            " 747839/1000000: episode: 1101, duration: 29.311s, episode steps: 758, steps per second:  26, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.014241, mae: 1.698473, mean_q: 2.054412, mean_eps: 0.327286\n",
            " 749109/1000000: episode: 1102, duration: 49.238s, episode steps: 1270, steps per second:  26, episode reward: 27.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.015044, mae: 1.709793, mean_q: 2.068655, mean_eps: 0.326373\n",
            " 749643/1000000: episode: 1103, duration: 20.720s, episode steps: 534, steps per second:  26, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.043 [0.000, 5.000],  loss: 0.014926, mae: 1.706890, mean_q: 2.061762, mean_eps: 0.325562\n",
            " 750745/1000000: episode: 1104, duration: 42.839s, episode steps: 1102, steps per second:  26, episode reward: 32.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.013080, mae: 1.705874, mean_q: 2.061508, mean_eps: 0.324825\n",
            " 751184/1000000: episode: 1105, duration: 17.203s, episode steps: 439, steps per second:  26, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.984 [0.000, 5.000],  loss: 0.016177, mae: 1.723156, mean_q: 2.079763, mean_eps: 0.324132\n",
            " 751870/1000000: episode: 1106, duration: 26.530s, episode steps: 686, steps per second:  26, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.014517, mae: 1.749238, mean_q: 2.113471, mean_eps: 0.323627\n",
            " 753029/1000000: episode: 1107, duration: 45.074s, episode steps: 1159, steps per second:  26, episode reward: 30.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.013565, mae: 1.724021, mean_q: 2.082709, mean_eps: 0.322795\n",
            " 754183/1000000: episode: 1108, duration: 44.889s, episode steps: 1154, steps per second:  26, episode reward: 31.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.016050, mae: 1.724511, mean_q: 2.082524, mean_eps: 0.321755\n",
            " 754899/1000000: episode: 1109, duration: 27.861s, episode steps: 716, steps per second:  26, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.003 [0.000, 5.000],  loss: 0.015752, mae: 1.745396, mean_q: 2.112028, mean_eps: 0.320914\n",
            " 755940/1000000: episode: 1110, duration: 40.815s, episode steps: 1041, steps per second:  26, episode reward: 28.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.014467, mae: 1.735016, mean_q: 2.097999, mean_eps: 0.320124\n",
            " 757168/1000000: episode: 1111, duration: 48.566s, episode steps: 1228, steps per second:  25, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.014381, mae: 1.739753, mean_q: 2.103983, mean_eps: 0.319103\n",
            " 757556/1000000: episode: 1112, duration: 15.349s, episode steps: 388, steps per second:  25, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.515 [0.000, 5.000],  loss: 0.014928, mae: 1.717604, mean_q: 2.074765, mean_eps: 0.318376\n",
            " 759039/1000000: episode: 1113, duration: 58.570s, episode steps: 1483, steps per second:  25, episode reward: 33.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.707 [0.000, 5.000],  loss: 0.015518, mae: 1.728576, mean_q: 2.087496, mean_eps: 0.317534\n",
            " 759667/1000000: episode: 1114, duration: 24.722s, episode steps: 628, steps per second:  25, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.013476, mae: 1.734353, mean_q: 2.096502, mean_eps: 0.316583\n",
            " 760453/1000000: episode: 1115, duration: 31.191s, episode steps: 786, steps per second:  25, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.014951, mae: 1.750515, mean_q: 2.115514, mean_eps: 0.315946\n",
            " 761134/1000000: episode: 1116, duration: 26.737s, episode steps: 681, steps per second:  25, episode reward: 20.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.014040, mae: 1.768761, mean_q: 2.137439, mean_eps: 0.315285\n",
            " 761512/1000000: episode: 1117, duration: 15.087s, episode steps: 378, steps per second:  25, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.013839, mae: 1.762802, mean_q: 2.129438, mean_eps: 0.314810\n",
            " 762239/1000000: episode: 1118, duration: 28.716s, episode steps: 727, steps per second:  25, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.014028, mae: 1.748361, mean_q: 2.109934, mean_eps: 0.314313\n",
            " 762681/1000000: episode: 1119, duration: 17.419s, episode steps: 442, steps per second:  25, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.188 [0.000, 5.000],  loss: 0.014674, mae: 1.766900, mean_q: 2.133260, mean_eps: 0.313786\n",
            " 763932/1000000: episode: 1120, duration: 49.292s, episode steps: 1251, steps per second:  25, episode reward: 29.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.015428, mae: 1.762050, mean_q: 2.126676, mean_eps: 0.313025\n",
            " 764629/1000000: episode: 1121, duration: 27.827s, episode steps: 697, steps per second:  25, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.073 [0.000, 5.000],  loss: 0.015481, mae: 1.748675, mean_q: 2.112991, mean_eps: 0.312148\n",
            " 765601/1000000: episode: 1122, duration: 38.148s, episode steps: 972, steps per second:  25, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.015376, mae: 1.752049, mean_q: 2.118307, mean_eps: 0.311396\n",
            " 766122/1000000: episode: 1123, duration: 20.573s, episode steps: 521, steps per second:  25, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.797 [0.000, 5.000],  loss: 0.020934, mae: 1.775428, mean_q: 2.145097, mean_eps: 0.310724\n",
            " 767108/1000000: episode: 1124, duration: 38.678s, episode steps: 986, steps per second:  25, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.017006, mae: 1.783355, mean_q: 2.154326, mean_eps: 0.310047\n",
            " 767756/1000000: episode: 1125, duration: 25.759s, episode steps: 648, steps per second:  25, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.904 [0.000, 5.000],  loss: 0.015522, mae: 1.741344, mean_q: 2.103622, mean_eps: 0.309313\n",
            " 768882/1000000: episode: 1126, duration: 44.188s, episode steps: 1126, steps per second:  25, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.014438, mae: 1.769050, mean_q: 2.136725, mean_eps: 0.308514\n",
            " 769528/1000000: episode: 1127, duration: 25.510s, episode steps: 646, steps per second:  25, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.015348, mae: 1.762840, mean_q: 2.128671, mean_eps: 0.307716\n",
            " 770028/1000000: episode: 1128, duration: 19.920s, episode steps: 500, steps per second:  25, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.020521, mae: 1.768500, mean_q: 2.139470, mean_eps: 0.307202\n",
            " 770972/1000000: episode: 1129, duration: 37.672s, episode steps: 944, steps per second:  25, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.082 [0.000, 5.000],  loss: 0.014458, mae: 1.803086, mean_q: 2.180282, mean_eps: 0.306552\n",
            " 771658/1000000: episode: 1130, duration: 27.366s, episode steps: 686, steps per second:  25, episode reward: 17.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.636 [0.000, 5.000],  loss: 0.014517, mae: 1.793637, mean_q: 2.167558, mean_eps: 0.305817\n",
            " 772171/1000000: episode: 1131, duration: 20.391s, episode steps: 513, steps per second:  25, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.715 [0.000, 5.000],  loss: 0.014950, mae: 1.823479, mean_q: 2.199542, mean_eps: 0.305277\n",
            " 773056/1000000: episode: 1132, duration: 35.095s, episode steps: 885, steps per second:  25, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.014283, mae: 1.793757, mean_q: 2.165585, mean_eps: 0.304649\n",
            " 773891/1000000: episode: 1133, duration: 33.215s, episode steps: 835, steps per second:  25, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.013883, mae: 1.790633, mean_q: 2.164373, mean_eps: 0.303875\n",
            " 774998/1000000: episode: 1134, duration: 43.597s, episode steps: 1107, steps per second:  25, episode reward: 30.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.016548, mae: 1.806912, mean_q: 2.184304, mean_eps: 0.303000\n",
            " 775878/1000000: episode: 1135, duration: 34.700s, episode steps: 880, steps per second:  25, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.015800, mae: 1.820929, mean_q: 2.200665, mean_eps: 0.302106\n",
            " 776713/1000000: episode: 1136, duration: 33.204s, episode steps: 835, steps per second:  25, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.015045, mae: 1.802755, mean_q: 2.180880, mean_eps: 0.301334\n",
            " 777566/1000000: episode: 1137, duration: 33.764s, episode steps: 853, steps per second:  25, episode reward: 22.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.145 [0.000, 5.000],  loss: 0.015353, mae: 1.787180, mean_q: 2.162780, mean_eps: 0.300574\n",
            " 778309/1000000: episode: 1138, duration: 29.794s, episode steps: 743, steps per second:  25, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.016225, mae: 1.810655, mean_q: 2.186176, mean_eps: 0.299856\n",
            " 778709/1000000: episode: 1139, duration: 15.938s, episode steps: 400, steps per second:  25, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.988 [0.000, 5.000],  loss: 0.014308, mae: 1.791972, mean_q: 2.164883, mean_eps: 0.299341\n",
            " 779691/1000000: episode: 1140, duration: 38.881s, episode steps: 982, steps per second:  25, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.193 [0.000, 5.000],  loss: 0.016189, mae: 1.810148, mean_q: 2.188891, mean_eps: 0.298720\n",
            " 780049/1000000: episode: 1141, duration: 14.365s, episode steps: 358, steps per second:  25, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.015260, mae: 1.834593, mean_q: 2.216542, mean_eps: 0.298117\n",
            " 780773/1000000: episode: 1142, duration: 28.725s, episode steps: 724, steps per second:  25, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.822 [0.000, 5.000],  loss: 0.014554, mae: 1.809246, mean_q: 2.185827, mean_eps: 0.297629\n",
            " 781819/1000000: episode: 1143, duration: 41.540s, episode steps: 1046, steps per second:  25, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.802 [0.000, 5.000],  loss: 0.014746, mae: 1.810699, mean_q: 2.189640, mean_eps: 0.296834\n",
            " 782737/1000000: episode: 1144, duration: 36.629s, episode steps: 918, steps per second:  25, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.015262, mae: 1.811439, mean_q: 2.187950, mean_eps: 0.295950\n",
            " 783371/1000000: episode: 1145, duration: 25.249s, episode steps: 634, steps per second:  25, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.035 [0.000, 5.000],  loss: 0.017031, mae: 1.828778, mean_q: 2.208549, mean_eps: 0.295251\n",
            " 784410/1000000: episode: 1146, duration: 41.704s, episode steps: 1039, steps per second:  25, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.948 [0.000, 5.000],  loss: 0.016356, mae: 1.819503, mean_q: 2.200315, mean_eps: 0.294499\n",
            " 785307/1000000: episode: 1147, duration: 35.706s, episode steps: 897, steps per second:  25, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.015054, mae: 1.814979, mean_q: 2.195424, mean_eps: 0.293628\n",
            " 786026/1000000: episode: 1148, duration: 28.755s, episode steps: 719, steps per second:  25, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.962 [0.000, 5.000],  loss: 0.014631, mae: 1.805806, mean_q: 2.180997, mean_eps: 0.292901\n",
            " 787294/1000000: episode: 1149, duration: 50.554s, episode steps: 1268, steps per second:  25, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.144 [0.000, 5.000],  loss: 0.015673, mae: 1.835820, mean_q: 2.218825, mean_eps: 0.292006\n",
            " 788149/1000000: episode: 1150, duration: 34.334s, episode steps: 855, steps per second:  25, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.017038, mae: 1.806598, mean_q: 2.185429, mean_eps: 0.291050\n",
            " 789150/1000000: episode: 1151, duration: 40.396s, episode steps: 1001, steps per second:  25, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.185 [0.000, 5.000],  loss: 0.015277, mae: 1.798133, mean_q: 2.172960, mean_eps: 0.290215\n",
            " 790300/1000000: episode: 1152, duration: 46.584s, episode steps: 1150, steps per second:  25, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.016815, mae: 1.819173, mean_q: 2.200183, mean_eps: 0.289248\n",
            " 791247/1000000: episode: 1153, duration: 38.058s, episode steps: 947, steps per second:  25, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.099 [0.000, 5.000],  loss: 0.014833, mae: 1.831266, mean_q: 2.211150, mean_eps: 0.288305\n",
            " 791962/1000000: episode: 1154, duration: 28.999s, episode steps: 715, steps per second:  25, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.136 [0.000, 5.000],  loss: 0.013841, mae: 1.831003, mean_q: 2.215009, mean_eps: 0.287556\n",
            " 792470/1000000: episode: 1155, duration: 20.306s, episode steps: 508, steps per second:  25, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.015500, mae: 1.839636, mean_q: 2.221263, mean_eps: 0.287006\n",
            " 793420/1000000: episode: 1156, duration: 38.609s, episode steps: 950, steps per second:  25, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.015989, mae: 1.843097, mean_q: 2.228625, mean_eps: 0.286350\n",
            " 794176/1000000: episode: 1157, duration: 30.535s, episode steps: 756, steps per second:  25, episode reward: 21.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.014356, mae: 1.843137, mean_q: 2.229668, mean_eps: 0.285584\n",
            " 795062/1000000: episode: 1158, duration: 35.651s, episode steps: 886, steps per second:  25, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.017575, mae: 1.839594, mean_q: 2.221634, mean_eps: 0.284844\n",
            " 795741/1000000: episode: 1159, duration: 27.571s, episode steps: 679, steps per second:  25, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.014605, mae: 1.833856, mean_q: 2.214148, mean_eps: 0.284138\n",
            " 796980/1000000: episode: 1160, duration: 50.309s, episode steps: 1239, steps per second:  25, episode reward: 28.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.033 [0.000, 5.000],  loss: 0.015500, mae: 1.841781, mean_q: 2.227009, mean_eps: 0.283276\n",
            " 797643/1000000: episode: 1161, duration: 26.734s, episode steps: 663, steps per second:  25, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.127 [0.000, 5.000],  loss: 0.015807, mae: 1.860524, mean_q: 2.248631, mean_eps: 0.282421\n",
            " 798435/1000000: episode: 1162, duration: 31.544s, episode steps: 792, steps per second:  25, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.016798, mae: 1.850646, mean_q: 2.238188, mean_eps: 0.281766\n",
            " 799140/1000000: episode: 1163, duration: 28.110s, episode steps: 705, steps per second:  25, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.015388, mae: 1.846014, mean_q: 2.232638, mean_eps: 0.281093\n",
            " 799838/1000000: episode: 1164, duration: 27.700s, episode steps: 698, steps per second:  25, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.799 [0.000, 5.000],  loss: 0.013808, mae: 1.850259, mean_q: 2.236545, mean_eps: 0.280461\n",
            " 800518/1000000: episode: 1165, duration: 26.986s, episode steps: 680, steps per second:  25, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.015112, mae: 1.852261, mean_q: 2.238492, mean_eps: 0.279840\n",
            " 801019/1000000: episode: 1166, duration: 20.058s, episode steps: 501, steps per second:  25, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.014713, mae: 1.871955, mean_q: 2.263793, mean_eps: 0.279309\n",
            " 801864/1000000: episode: 1167, duration: 34.257s, episode steps: 845, steps per second:  25, episode reward: 27.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.015819, mae: 1.864823, mean_q: 2.253936, mean_eps: 0.278704\n",
            " 802398/1000000: episode: 1168, duration: 21.600s, episode steps: 534, steps per second:  25, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.015054, mae: 1.884171, mean_q: 2.276221, mean_eps: 0.278083\n",
            " 803073/1000000: episode: 1169, duration: 27.203s, episode steps: 675, steps per second:  25, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.015373, mae: 1.882561, mean_q: 2.272255, mean_eps: 0.277538\n",
            " 803748/1000000: episode: 1170, duration: 27.360s, episode steps: 675, steps per second:  25, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.939 [0.000, 5.000],  loss: 0.015515, mae: 1.848623, mean_q: 2.235630, mean_eps: 0.276931\n",
            " 804783/1000000: episode: 1171, duration: 41.225s, episode steps: 1035, steps per second:  25, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.887 [0.000, 5.000],  loss: 0.015758, mae: 1.862233, mean_q: 2.250065, mean_eps: 0.276162\n",
            " 805463/1000000: episode: 1172, duration: 27.206s, episode steps: 680, steps per second:  25, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.838 [0.000, 5.000],  loss: 0.017848, mae: 1.870532, mean_q: 2.258870, mean_eps: 0.275390\n",
            " 806524/1000000: episode: 1173, duration: 42.382s, episode steps: 1061, steps per second:  25, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.016666, mae: 1.860199, mean_q: 2.249004, mean_eps: 0.274607\n",
            " 807372/1000000: episode: 1174, duration: 34.283s, episode steps: 848, steps per second:  25, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.058 [0.000, 5.000],  loss: 0.016307, mae: 1.855740, mean_q: 2.244644, mean_eps: 0.273749\n",
            " 807827/1000000: episode: 1175, duration: 18.476s, episode steps: 455, steps per second:  25, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.015909, mae: 1.874703, mean_q: 2.264938, mean_eps: 0.273162\n",
            " 808360/1000000: episode: 1176, duration: 21.824s, episode steps: 533, steps per second:  24, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.017698, mae: 1.854682, mean_q: 2.238563, mean_eps: 0.272717\n",
            " 809747/1000000: episode: 1177, duration: 56.422s, episode steps: 1387, steps per second:  25, episode reward: 30.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: 0.015784, mae: 1.873988, mean_q: 2.261747, mean_eps: 0.271853\n",
            " 810384/1000000: episode: 1178, duration: 25.705s, episode steps: 637, steps per second:  25, episode reward: 19.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 3.060 [0.000, 5.000],  loss: 0.014362, mae: 1.862612, mean_q: 2.251787, mean_eps: 0.270942\n",
            " 811220/1000000: episode: 1179, duration: 34.281s, episode steps: 836, steps per second:  24, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.017785, mae: 1.891271, mean_q: 2.284820, mean_eps: 0.270280\n",
            " 812189/1000000: episode: 1180, duration: 39.478s, episode steps: 969, steps per second:  25, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.991 [0.000, 5.000],  loss: 0.016387, mae: 1.869273, mean_q: 2.258391, mean_eps: 0.269466\n",
            " 813065/1000000: episode: 1181, duration: 35.576s, episode steps: 876, steps per second:  25, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: 0.017034, mae: 1.884706, mean_q: 2.278725, mean_eps: 0.268635\n",
            " 813786/1000000: episode: 1182, duration: 29.195s, episode steps: 721, steps per second:  25, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.016186, mae: 1.883121, mean_q: 2.274915, mean_eps: 0.267917\n",
            " 814417/1000000: episode: 1183, duration: 25.825s, episode steps: 631, steps per second:  24, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.864 [0.000, 5.000],  loss: 0.015765, mae: 1.867170, mean_q: 2.253816, mean_eps: 0.267308\n",
            " 815491/1000000: episode: 1184, duration: 43.126s, episode steps: 1074, steps per second:  25, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.017284, mae: 1.877342, mean_q: 2.267744, mean_eps: 0.266541\n",
            " 816427/1000000: episode: 1185, duration: 38.074s, episode steps: 936, steps per second:  25, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.016260, mae: 1.889198, mean_q: 2.283127, mean_eps: 0.265638\n",
            " 817056/1000000: episode: 1186, duration: 25.765s, episode steps: 629, steps per second:  24, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: 0.017787, mae: 1.892550, mean_q: 2.285052, mean_eps: 0.264934\n",
            " 817953/1000000: episode: 1187, duration: 36.604s, episode steps: 897, steps per second:  25, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.016044, mae: 1.890426, mean_q: 2.283738, mean_eps: 0.264246\n",
            " 818869/1000000: episode: 1188, duration: 37.812s, episode steps: 916, steps per second:  24, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: 0.016229, mae: 1.868713, mean_q: 2.256573, mean_eps: 0.263429\n",
            " 819406/1000000: episode: 1189, duration: 21.852s, episode steps: 537, steps per second:  25, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.016608, mae: 1.904045, mean_q: 2.301702, mean_eps: 0.262776\n",
            " 820099/1000000: episode: 1190, duration: 28.092s, episode steps: 693, steps per second:  25, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.072 [0.000, 5.000],  loss: 0.016262, mae: 1.862779, mean_q: 2.251178, mean_eps: 0.262223\n",
            " 820464/1000000: episode: 1191, duration: 14.883s, episode steps: 365, steps per second:  25, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.016590, mae: 1.924818, mean_q: 2.324652, mean_eps: 0.261748\n",
            " 821024/1000000: episode: 1192, duration: 22.817s, episode steps: 560, steps per second:  25, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.911 [0.000, 5.000],  loss: 0.017979, mae: 1.900570, mean_q: 2.297255, mean_eps: 0.261332\n",
            " 822255/1000000: episode: 1193, duration: 51.807s, episode steps: 1231, steps per second:  24, episode reward: 29.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.906 [0.000, 5.000],  loss: 0.017049, mae: 1.927707, mean_q: 2.329167, mean_eps: 0.260526\n",
            " 823184/1000000: episode: 1194, duration: 39.223s, episode steps: 929, steps per second:  24, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.079 [0.000, 5.000],  loss: 0.016790, mae: 1.902998, mean_q: 2.299212, mean_eps: 0.259554\n",
            " 823955/1000000: episode: 1195, duration: 32.075s, episode steps: 771, steps per second:  24, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.018652, mae: 1.943348, mean_q: 2.347941, mean_eps: 0.258789\n",
            " 824478/1000000: episode: 1196, duration: 21.841s, episode steps: 523, steps per second:  24, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.018991, mae: 1.931082, mean_q: 2.337163, mean_eps: 0.258206\n",
            " 825100/1000000: episode: 1197, duration: 25.651s, episode steps: 622, steps per second:  24, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.017214, mae: 1.928982, mean_q: 2.331709, mean_eps: 0.257691\n",
            " 825616/1000000: episode: 1198, duration: 21.308s, episode steps: 516, steps per second:  24, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.017056, mae: 1.915777, mean_q: 2.319919, mean_eps: 0.257180\n",
            " 826114/1000000: episode: 1199, duration: 20.566s, episode steps: 498, steps per second:  24, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.016414, mae: 1.904162, mean_q: 2.301749, mean_eps: 0.256722\n",
            " 826751/1000000: episode: 1200, duration: 26.813s, episode steps: 637, steps per second:  24, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.018795, mae: 1.902035, mean_q: 2.301813, mean_eps: 0.256211\n",
            " 827277/1000000: episode: 1201, duration: 21.742s, episode steps: 526, steps per second:  24, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.932 [0.000, 5.000],  loss: 0.018625, mae: 1.912538, mean_q: 2.309758, mean_eps: 0.255687\n",
            " 827845/1000000: episode: 1202, duration: 23.344s, episode steps: 568, steps per second:  24, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: 0.016331, mae: 1.894352, mean_q: 2.288961, mean_eps: 0.255194\n",
            " 828489/1000000: episode: 1203, duration: 26.301s, episode steps: 644, steps per second:  24, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 3.061 [0.000, 5.000],  loss: 0.017184, mae: 1.891751, mean_q: 2.285452, mean_eps: 0.254649\n",
            " 829001/1000000: episode: 1204, duration: 20.735s, episode steps: 512, steps per second:  25, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.015660, mae: 1.898452, mean_q: 2.296753, mean_eps: 0.254129\n",
            " 829656/1000000: episode: 1205, duration: 26.335s, episode steps: 655, steps per second:  25, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.867 [0.000, 5.000],  loss: 0.017513, mae: 1.907323, mean_q: 2.307541, mean_eps: 0.253605\n",
            " 831192/1000000: episode: 1206, duration: 62.253s, episode steps: 1536, steps per second:  25, episode reward: 35.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.016179, mae: 1.931899, mean_q: 2.335731, mean_eps: 0.252620\n",
            " 832183/1000000: episode: 1207, duration: 39.830s, episode steps: 991, steps per second:  25, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.017165, mae: 1.934166, mean_q: 2.340103, mean_eps: 0.251483\n",
            " 832862/1000000: episode: 1208, duration: 27.287s, episode steps: 679, steps per second:  25, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.215 [0.000, 5.000],  loss: 0.016002, mae: 1.920027, mean_q: 2.320170, mean_eps: 0.250730\n",
            " 834604/1000000: episode: 1209, duration: 70.003s, episode steps: 1742, steps per second:  25, episode reward: 38.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.016363, mae: 1.927239, mean_q: 2.329370, mean_eps: 0.249641\n",
            " 835536/1000000: episode: 1210, duration: 37.350s, episode steps: 932, steps per second:  25, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.016049, mae: 1.932642, mean_q: 2.340786, mean_eps: 0.248439\n",
            " 836328/1000000: episode: 1211, duration: 32.238s, episode steps: 792, steps per second:  25, episode reward: 21.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.015255, mae: 1.948587, mean_q: 2.354536, mean_eps: 0.247663\n",
            " 836991/1000000: episode: 1212, duration: 26.693s, episode steps: 663, steps per second:  25, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.017349, mae: 1.916744, mean_q: 2.316959, mean_eps: 0.247008\n",
            " 837831/1000000: episode: 1213, duration: 33.920s, episode steps: 840, steps per second:  25, episode reward: 22.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.095 [0.000, 5.000],  loss: 0.016498, mae: 1.935035, mean_q: 2.336246, mean_eps: 0.246331\n",
            " 838737/1000000: episode: 1214, duration: 36.427s, episode steps: 906, steps per second:  25, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.015418, mae: 1.923917, mean_q: 2.323589, mean_eps: 0.245544\n",
            " 839519/1000000: episode: 1215, duration: 31.502s, episode steps: 782, steps per second:  25, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.017388, mae: 1.943815, mean_q: 2.346623, mean_eps: 0.244785\n",
            " 840363/1000000: episode: 1216, duration: 33.954s, episode steps: 844, steps per second:  25, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.016853, mae: 1.971279, mean_q: 2.380844, mean_eps: 0.244054\n",
            " 840987/1000000: episode: 1217, duration: 25.256s, episode steps: 624, steps per second:  25, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.016502, mae: 1.956219, mean_q: 2.362762, mean_eps: 0.243393\n",
            " 841810/1000000: episode: 1218, duration: 33.240s, episode steps: 823, steps per second:  25, episode reward: 24.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.015847, mae: 1.952615, mean_q: 2.357957, mean_eps: 0.242742\n",
            " 842584/1000000: episode: 1219, duration: 31.465s, episode steps: 774, steps per second:  25, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.239 [0.000, 5.000],  loss: 0.015730, mae: 1.938971, mean_q: 2.342651, mean_eps: 0.242024\n",
            " 843221/1000000: episode: 1220, duration: 25.739s, episode steps: 637, steps per second:  25, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.922 [0.000, 5.000],  loss: 0.016316, mae: 1.938219, mean_q: 2.342663, mean_eps: 0.241388\n",
            " 843752/1000000: episode: 1221, duration: 21.643s, episode steps: 531, steps per second:  25, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.016112, mae: 1.969669, mean_q: 2.381625, mean_eps: 0.240863\n",
            " 844376/1000000: episode: 1222, duration: 25.252s, episode steps: 624, steps per second:  25, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.970 [0.000, 5.000],  loss: 0.015821, mae: 1.931627, mean_q: 2.336119, mean_eps: 0.240344\n",
            " 845141/1000000: episode: 1223, duration: 31.226s, episode steps: 765, steps per second:  24, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.017417, mae: 1.955624, mean_q: 2.363014, mean_eps: 0.239718\n",
            " 845680/1000000: episode: 1224, duration: 21.771s, episode steps: 539, steps per second:  25, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.549 [0.000, 5.000],  loss: 0.014985, mae: 1.952935, mean_q: 2.355452, mean_eps: 0.239131\n",
            " 846900/1000000: episode: 1225, duration: 49.544s, episode steps: 1220, steps per second:  25, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.015859, mae: 1.960901, mean_q: 2.367412, mean_eps: 0.238341\n",
            " 847830/1000000: episode: 1226, duration: 37.522s, episode steps: 930, steps per second:  25, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.016671, mae: 1.947930, mean_q: 2.351350, mean_eps: 0.237372\n",
            " 849523/1000000: episode: 1227, duration: 67.743s, episode steps: 1693, steps per second:  25, episode reward: 31.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: 0.016735, mae: 1.967585, mean_q: 2.375248, mean_eps: 0.236192\n",
            " 850610/1000000: episode: 1228, duration: 43.836s, episode steps: 1087, steps per second:  25, episode reward: 29.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.016668, mae: 1.954356, mean_q: 2.360086, mean_eps: 0.234941\n",
            " 851138/1000000: episode: 1229, duration: 21.305s, episode steps: 528, steps per second:  25, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 3.125 [0.000, 5.000],  loss: 0.015247, mae: 1.953413, mean_q: 2.360643, mean_eps: 0.234213\n",
            " 852574/1000000: episode: 1230, duration: 57.879s, episode steps: 1436, steps per second:  25, episode reward: 34.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.015754, mae: 1.941848, mean_q: 2.344676, mean_eps: 0.233330\n",
            " 853509/1000000: episode: 1231, duration: 37.823s, episode steps: 935, steps per second:  25, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.017055, mae: 1.948730, mean_q: 2.355319, mean_eps: 0.232262\n",
            " 854624/1000000: episode: 1232, duration: 45.297s, episode steps: 1115, steps per second:  25, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.960 [0.000, 5.000],  loss: 0.016796, mae: 1.956534, mean_q: 2.366871, mean_eps: 0.231341\n",
            " 855304/1000000: episode: 1233, duration: 27.434s, episode steps: 680, steps per second:  25, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.016626, mae: 1.960443, mean_q: 2.368851, mean_eps: 0.230534\n",
            " 856228/1000000: episode: 1234, duration: 37.016s, episode steps: 924, steps per second:  25, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.745 [0.000, 5.000],  loss: 0.015517, mae: 1.952025, mean_q: 2.356948, mean_eps: 0.229812\n",
            " 856604/1000000: episode: 1235, duration: 15.274s, episode steps: 376, steps per second:  25, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.835 [0.000, 5.000],  loss: 0.015890, mae: 1.965564, mean_q: 2.374406, mean_eps: 0.229227\n",
            " 857360/1000000: episode: 1236, duration: 31.584s, episode steps: 756, steps per second:  24, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: 0.017115, mae: 1.950275, mean_q: 2.357798, mean_eps: 0.228718\n",
            " 858024/1000000: episode: 1237, duration: 28.164s, episode steps: 664, steps per second:  24, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.018607, mae: 1.974845, mean_q: 2.383978, mean_eps: 0.228079\n",
            " 858734/1000000: episode: 1238, duration: 30.866s, episode steps: 710, steps per second:  23, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.017501, mae: 1.955773, mean_q: 2.360705, mean_eps: 0.227460\n",
            " 859686/1000000: episode: 1239, duration: 39.542s, episode steps: 952, steps per second:  24, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.017319, mae: 1.942528, mean_q: 2.346138, mean_eps: 0.226711\n",
            " 860469/1000000: episode: 1240, duration: 32.157s, episode steps: 783, steps per second:  24, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.255 [0.000, 5.000],  loss: 0.015939, mae: 1.979195, mean_q: 2.392359, mean_eps: 0.225930\n",
            " 861129/1000000: episode: 1241, duration: 27.182s, episode steps: 660, steps per second:  24, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.016161, mae: 1.998950, mean_q: 2.415916, mean_eps: 0.225280\n",
            " 861844/1000000: episode: 1242, duration: 29.270s, episode steps: 715, steps per second:  24, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 3.070 [0.000, 5.000],  loss: 0.014730, mae: 1.969720, mean_q: 2.382849, mean_eps: 0.224663\n",
            " 862423/1000000: episode: 1243, duration: 23.650s, episode steps: 579, steps per second:  24, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.164 [0.000, 5.000],  loss: 0.017709, mae: 1.962556, mean_q: 2.368252, mean_eps: 0.224081\n",
            " 863296/1000000: episode: 1244, duration: 35.507s, episode steps: 873, steps per second:  25, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.015790, mae: 2.004182, mean_q: 2.423089, mean_eps: 0.223428\n",
            " 864213/1000000: episode: 1245, duration: 37.529s, episode steps: 917, steps per second:  24, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.016085, mae: 1.974581, mean_q: 2.385855, mean_eps: 0.222621\n",
            " 864947/1000000: episode: 1246, duration: 29.988s, episode steps: 734, steps per second:  24, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.079 [0.000, 5.000],  loss: 0.015810, mae: 1.964242, mean_q: 2.373104, mean_eps: 0.221878\n",
            " 865830/1000000: episode: 1247, duration: 36.106s, episode steps: 883, steps per second:  24, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.016018, mae: 1.966338, mean_q: 2.374680, mean_eps: 0.221151\n",
            " 866445/1000000: episode: 1248, duration: 25.327s, episode steps: 615, steps per second:  24, episode reward: 20.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 3.198 [0.000, 5.000],  loss: 0.015149, mae: 1.963581, mean_q: 2.371505, mean_eps: 0.220476\n",
            " 866816/1000000: episode: 1249, duration: 15.176s, episode steps: 371, steps per second:  24, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 3.232 [0.000, 5.000],  loss: 0.017712, mae: 1.999899, mean_q: 2.413942, mean_eps: 0.220033\n",
            " 867703/1000000: episode: 1250, duration: 36.686s, episode steps: 887, steps per second:  24, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.016510, mae: 1.976293, mean_q: 2.385737, mean_eps: 0.219468\n",
            " 868419/1000000: episode: 1251, duration: 29.531s, episode steps: 716, steps per second:  24, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.113 [0.000, 5.000],  loss: 0.017730, mae: 1.978040, mean_q: 2.389917, mean_eps: 0.218746\n",
            " 869276/1000000: episode: 1252, duration: 35.492s, episode steps: 857, steps per second:  24, episode reward: 25.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.758 [0.000, 5.000],  loss: 0.015048, mae: 1.981137, mean_q: 2.393468, mean_eps: 0.218039\n",
            " 869951/1000000: episode: 1253, duration: 27.926s, episode steps: 675, steps per second:  24, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.019363, mae: 2.001526, mean_q: 2.417903, mean_eps: 0.217349\n",
            " 870599/1000000: episode: 1254, duration: 26.787s, episode steps: 648, steps per second:  24, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.032 [0.000, 5.000],  loss: 0.016404, mae: 1.959281, mean_q: 2.367128, mean_eps: 0.216753\n",
            " 871400/1000000: episode: 1255, duration: 33.272s, episode steps: 801, steps per second:  24, episode reward: 21.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.018472, mae: 1.983859, mean_q: 2.395784, mean_eps: 0.216102\n",
            " 872167/1000000: episode: 1256, duration: 31.535s, episode steps: 767, steps per second:  24, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.742 [0.000, 5.000],  loss: 0.015941, mae: 1.965510, mean_q: 2.372874, mean_eps: 0.215396\n",
            " 873041/1000000: episode: 1257, duration: 37.288s, episode steps: 874, steps per second:  23, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: 0.015835, mae: 1.957795, mean_q: 2.364699, mean_eps: 0.214656\n",
            " 873757/1000000: episode: 1258, duration: 30.424s, episode steps: 716, steps per second:  24, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.017899, mae: 1.981687, mean_q: 2.394022, mean_eps: 0.213940\n",
            " 874813/1000000: episode: 1259, duration: 43.391s, episode steps: 1056, steps per second:  24, episode reward: 26.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.068 [0.000, 5.000],  loss: 0.015884, mae: 1.965833, mean_q: 2.372544, mean_eps: 0.213143\n",
            " 875522/1000000: episode: 1260, duration: 29.331s, episode steps: 709, steps per second:  24, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.921 [0.000, 5.000],  loss: 0.016763, mae: 1.968283, mean_q: 2.375000, mean_eps: 0.212349\n",
            " 876828/1000000: episode: 1261, duration: 53.981s, episode steps: 1306, steps per second:  24, episode reward: 31.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.017631, mae: 1.982253, mean_q: 2.395461, mean_eps: 0.211443\n",
            " 877801/1000000: episode: 1262, duration: 40.421s, episode steps: 973, steps per second:  24, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.017786, mae: 1.957713, mean_q: 2.365336, mean_eps: 0.210417\n",
            " 878545/1000000: episode: 1263, duration: 30.722s, episode steps: 744, steps per second:  24, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.902 [0.000, 5.000],  loss: 0.017200, mae: 1.976820, mean_q: 2.386441, mean_eps: 0.209643\n",
            " 879005/1000000: episode: 1264, duration: 18.983s, episode steps: 460, steps per second:  24, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.972 [0.000, 5.000],  loss: 0.016021, mae: 1.962034, mean_q: 2.372333, mean_eps: 0.209102\n",
            " 879916/1000000: episode: 1265, duration: 37.674s, episode steps: 911, steps per second:  24, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.086 [0.000, 5.000],  loss: 0.016982, mae: 1.967905, mean_q: 2.381350, mean_eps: 0.208486\n",
            " 880666/1000000: episode: 1266, duration: 30.909s, episode steps: 750, steps per second:  24, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 3.307 [0.000, 5.000],  loss: 0.015965, mae: 2.003799, mean_q: 2.423496, mean_eps: 0.207739\n",
            " 881186/1000000: episode: 1267, duration: 21.298s, episode steps: 520, steps per second:  24, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.016460, mae: 1.980652, mean_q: 2.394823, mean_eps: 0.207167\n",
            " 881834/1000000: episode: 1268, duration: 26.556s, episode steps: 648, steps per second:  24, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.648 [0.000, 5.000],  loss: 0.018691, mae: 1.990323, mean_q: 2.404596, mean_eps: 0.206641\n",
            " 882362/1000000: episode: 1269, duration: 21.722s, episode steps: 528, steps per second:  24, episode reward: 13.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.015312, mae: 1.977776, mean_q: 2.387118, mean_eps: 0.206112\n",
            " 883074/1000000: episode: 1270, duration: 29.520s, episode steps: 712, steps per second:  24, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.772 [0.000, 5.000],  loss: 0.017268, mae: 1.982404, mean_q: 2.394894, mean_eps: 0.205554\n",
            " 883988/1000000: episode: 1271, duration: 37.567s, episode steps: 914, steps per second:  24, episode reward: 29.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.017190, mae: 1.994562, mean_q: 2.408706, mean_eps: 0.204823\n",
            " 884861/1000000: episode: 1272, duration: 36.178s, episode steps: 873, steps per second:  24, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.923 [0.000, 5.000],  loss: 0.017394, mae: 1.991318, mean_q: 2.402749, mean_eps: 0.204018\n",
            " 885586/1000000: episode: 1273, duration: 29.880s, episode steps: 725, steps per second:  24, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.018063, mae: 1.984449, mean_q: 2.395080, mean_eps: 0.203298\n",
            " 886530/1000000: episode: 1274, duration: 39.078s, episode steps: 944, steps per second:  24, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.016049, mae: 1.995307, mean_q: 2.411164, mean_eps: 0.202548\n",
            " 887411/1000000: episode: 1275, duration: 36.539s, episode steps: 881, steps per second:  24, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.732 [0.000, 5.000],  loss: 0.016469, mae: 2.010771, mean_q: 2.427673, mean_eps: 0.201727\n",
            " 888392/1000000: episode: 1276, duration: 40.651s, episode steps: 981, steps per second:  24, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.149 [0.000, 5.000],  loss: 0.018085, mae: 1.993421, mean_q: 2.406168, mean_eps: 0.200890\n",
            " 889205/1000000: episode: 1277, duration: 33.913s, episode steps: 813, steps per second:  24, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.017326, mae: 1.992413, mean_q: 2.406669, mean_eps: 0.200082\n",
            " 890137/1000000: episode: 1278, duration: 38.503s, episode steps: 932, steps per second:  24, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.027 [0.000, 5.000],  loss: 0.017189, mae: 2.001080, mean_q: 2.419161, mean_eps: 0.199295\n",
            " 890814/1000000: episode: 1279, duration: 28.110s, episode steps: 677, steps per second:  24, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.016050, mae: 2.005060, mean_q: 2.422519, mean_eps: 0.198572\n",
            " 891539/1000000: episode: 1280, duration: 29.905s, episode steps: 725, steps per second:  24, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.017103, mae: 1.994403, mean_q: 2.409219, mean_eps: 0.197942\n",
            " 892125/1000000: episode: 1281, duration: 24.455s, episode steps: 586, steps per second:  24, episode reward: 19.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 3.026 [0.000, 5.000],  loss: 0.015672, mae: 2.015812, mean_q: 2.434011, mean_eps: 0.197351\n",
            " 893024/1000000: episode: 1282, duration: 37.466s, episode steps: 899, steps per second:  24, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.899 [0.000, 5.000],  loss: 0.017154, mae: 2.030805, mean_q: 2.454868, mean_eps: 0.196683\n",
            " 893890/1000000: episode: 1283, duration: 36.252s, episode steps: 866, steps per second:  24, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.940 [0.000, 5.000],  loss: 0.019401, mae: 2.034277, mean_q: 2.457306, mean_eps: 0.195890\n",
            " 894681/1000000: episode: 1284, duration: 33.317s, episode steps: 791, steps per second:  24, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.019029, mae: 2.022341, mean_q: 2.439023, mean_eps: 0.195143\n",
            " 895440/1000000: episode: 1285, duration: 31.402s, episode steps: 759, steps per second:  24, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.017851, mae: 2.005249, mean_q: 2.423250, mean_eps: 0.194446\n",
            " 896365/1000000: episode: 1286, duration: 38.600s, episode steps: 925, steps per second:  24, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.840 [0.000, 5.000],  loss: 0.015860, mae: 2.021829, mean_q: 2.443255, mean_eps: 0.193688\n",
            " 897148/1000000: episode: 1287, duration: 32.795s, episode steps: 783, steps per second:  24, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.034 [0.000, 5.000],  loss: 0.017564, mae: 2.021483, mean_q: 2.439667, mean_eps: 0.192920\n",
            " 898177/1000000: episode: 1288, duration: 42.989s, episode steps: 1029, steps per second:  24, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.017611, mae: 2.006589, mean_q: 2.420807, mean_eps: 0.192104\n",
            " 898654/1000000: episode: 1289, duration: 20.343s, episode steps: 477, steps per second:  23, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.016914, mae: 2.031522, mean_q: 2.451093, mean_eps: 0.191426\n",
            " 899396/1000000: episode: 1290, duration: 31.691s, episode steps: 742, steps per second:  23, episode reward: 22.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 1.965 [0.000, 5.000],  loss: 0.017643, mae: 2.037725, mean_q: 2.461453, mean_eps: 0.190878\n",
            " 899953/1000000: episode: 1291, duration: 23.568s, episode steps: 557, steps per second:  24, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.016585, mae: 2.033716, mean_q: 2.457151, mean_eps: 0.190293\n",
            " 900996/1000000: episode: 1292, duration: 43.355s, episode steps: 1043, steps per second:  24, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.015705, mae: 2.059188, mean_q: 2.490835, mean_eps: 0.189573\n",
            " 901456/1000000: episode: 1293, duration: 19.493s, episode steps: 460, steps per second:  24, episode reward: 11.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.943 [0.000, 5.000],  loss: 0.016618, mae: 2.069722, mean_q: 2.503290, mean_eps: 0.188898\n",
            " 901937/1000000: episode: 1294, duration: 20.471s, episode steps: 481, steps per second:  23, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.917 [0.000, 5.000],  loss: 0.017712, mae: 2.050231, mean_q: 2.477356, mean_eps: 0.188474\n",
            " 902406/1000000: episode: 1295, duration: 19.530s, episode steps: 469, steps per second:  24, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.015811, mae: 2.044757, mean_q: 2.470818, mean_eps: 0.188045\n",
            " 903140/1000000: episode: 1296, duration: 30.807s, episode steps: 734, steps per second:  24, episode reward: 24.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.756 [0.000, 5.000],  loss: 0.018049, mae: 2.076090, mean_q: 2.509513, mean_eps: 0.187505\n",
            " 903905/1000000: episode: 1297, duration: 31.994s, episode steps: 765, steps per second:  24, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.016709, mae: 2.054517, mean_q: 2.481465, mean_eps: 0.186830\n",
            " 904572/1000000: episode: 1298, duration: 28.191s, episode steps: 667, steps per second:  24, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.018880, mae: 2.073854, mean_q: 2.507193, mean_eps: 0.186186\n",
            " 905101/1000000: episode: 1299, duration: 22.191s, episode steps: 529, steps per second:  24, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.234 [0.000, 5.000],  loss: 0.017450, mae: 2.069158, mean_q: 2.501108, mean_eps: 0.185648\n",
            " 905745/1000000: episode: 1300, duration: 26.850s, episode steps: 644, steps per second:  24, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.770 [0.000, 5.000],  loss: 0.019091, mae: 2.044033, mean_q: 2.469228, mean_eps: 0.185118\n",
            " 906402/1000000: episode: 1301, duration: 27.432s, episode steps: 657, steps per second:  24, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.728 [0.000, 5.000],  loss: 0.018481, mae: 2.046257, mean_q: 2.472676, mean_eps: 0.184533\n",
            " 907514/1000000: episode: 1302, duration: 46.601s, episode steps: 1112, steps per second:  24, episode reward: 26.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.112 [0.000, 5.000],  loss: 0.017472, mae: 2.054191, mean_q: 2.481800, mean_eps: 0.183738\n",
            " 907992/1000000: episode: 1303, duration: 20.139s, episode steps: 478, steps per second:  24, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.017205, mae: 2.071115, mean_q: 2.501897, mean_eps: 0.183023\n",
            " 908601/1000000: episode: 1304, duration: 25.696s, episode steps: 609, steps per second:  24, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.019335, mae: 2.061746, mean_q: 2.490558, mean_eps: 0.182534\n",
            " 909223/1000000: episode: 1305, duration: 26.507s, episode steps: 622, steps per second:  23, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.018123, mae: 2.054906, mean_q: 2.486892, mean_eps: 0.181979\n",
            " 909756/1000000: episode: 1306, duration: 22.759s, episode steps: 533, steps per second:  23, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.977 [0.000, 5.000],  loss: 0.019393, mae: 2.046891, mean_q: 2.472276, mean_eps: 0.181461\n",
            " 910537/1000000: episode: 1307, duration: 32.859s, episode steps: 781, steps per second:  24, episode reward: 22.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.895 [0.000, 5.000],  loss: 0.017385, mae: 2.086940, mean_q: 2.520423, mean_eps: 0.180869\n",
            " 911305/1000000: episode: 1308, duration: 32.139s, episode steps: 768, steps per second:  24, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.019306, mae: 2.086823, mean_q: 2.523323, mean_eps: 0.180170\n",
            " 912020/1000000: episode: 1309, duration: 30.363s, episode steps: 715, steps per second:  24, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.019338, mae: 2.096550, mean_q: 2.532595, mean_eps: 0.179504\n",
            " 912988/1000000: episode: 1310, duration: 41.055s, episode steps: 968, steps per second:  24, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.018917, mae: 2.076419, mean_q: 2.508598, mean_eps: 0.178748\n",
            " 913919/1000000: episode: 1311, duration: 39.195s, episode steps: 931, steps per second:  24, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.190 [0.000, 5.000],  loss: 0.017508, mae: 2.078925, mean_q: 2.510024, mean_eps: 0.177893\n",
            " 914699/1000000: episode: 1312, duration: 32.808s, episode steps: 780, steps per second:  24, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.744 [0.000, 5.000],  loss: 0.018298, mae: 2.108526, mean_q: 2.547052, mean_eps: 0.177123\n",
            " 915209/1000000: episode: 1313, duration: 21.539s, episode steps: 510, steps per second:  24, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.018962, mae: 2.091691, mean_q: 2.528496, mean_eps: 0.176541\n",
            " 916251/1000000: episode: 1314, duration: 43.938s, episode steps: 1042, steps per second:  24, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.050 [0.000, 5.000],  loss: 0.019636, mae: 2.074955, mean_q: 2.506594, mean_eps: 0.175843\n",
            " 916807/1000000: episode: 1315, duration: 23.376s, episode steps: 556, steps per second:  24, episode reward: 15.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.088 [0.000, 5.000],  loss: 0.020647, mae: 2.096123, mean_q: 2.530727, mean_eps: 0.175125\n",
            " 917532/1000000: episode: 1316, duration: 30.448s, episode steps: 725, steps per second:  24, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.016424, mae: 2.092374, mean_q: 2.529226, mean_eps: 0.174549\n",
            " 918463/1000000: episode: 1317, duration: 38.699s, episode steps: 931, steps per second:  24, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.467 [0.000, 5.000],  loss: 0.019334, mae: 2.091640, mean_q: 2.525249, mean_eps: 0.173804\n",
            " 919518/1000000: episode: 1318, duration: 44.546s, episode steps: 1055, steps per second:  24, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.018357, mae: 2.095059, mean_q: 2.531910, mean_eps: 0.172909\n",
            " 920503/1000000: episode: 1319, duration: 41.551s, episode steps: 985, steps per second:  24, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.017734, mae: 2.085722, mean_q: 2.521853, mean_eps: 0.171991\n",
            " 921428/1000000: episode: 1320, duration: 38.936s, episode steps: 925, steps per second:  24, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.018501, mae: 2.111352, mean_q: 2.549428, mean_eps: 0.171132\n",
            " 922345/1000000: episode: 1321, duration: 38.379s, episode steps: 917, steps per second:  24, episode reward: 25.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 3.110 [0.000, 5.000],  loss: 0.019234, mae: 2.122363, mean_q: 2.567972, mean_eps: 0.170303\n",
            " 923219/1000000: episode: 1322, duration: 36.680s, episode steps: 874, steps per second:  24, episode reward: 26.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.772 [0.000, 5.000],  loss: 0.019904, mae: 2.113444, mean_q: 2.555328, mean_eps: 0.169496\n",
            " 924078/1000000: episode: 1323, duration: 35.999s, episode steps: 859, steps per second:  24, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.659 [0.000, 5.000],  loss: 0.016673, mae: 2.103291, mean_q: 2.543109, mean_eps: 0.168717\n",
            " 924701/1000000: episode: 1324, duration: 26.243s, episode steps: 623, steps per second:  24, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.017859, mae: 2.114526, mean_q: 2.554695, mean_eps: 0.168049\n",
            " 925343/1000000: episode: 1325, duration: 26.705s, episode steps: 642, steps per second:  24, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.018164, mae: 2.117148, mean_q: 2.557439, mean_eps: 0.167480\n",
            " 925946/1000000: episode: 1326, duration: 25.523s, episode steps: 603, steps per second:  24, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.021011, mae: 2.115474, mean_q: 2.558054, mean_eps: 0.166920\n",
            " 926505/1000000: episode: 1327, duration: 23.472s, episode steps: 559, steps per second:  24, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.063 [0.000, 5.000],  loss: 0.019744, mae: 2.105089, mean_q: 2.542363, mean_eps: 0.166397\n",
            " 927467/1000000: episode: 1328, duration: 40.707s, episode steps: 962, steps per second:  24, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.019487, mae: 2.122803, mean_q: 2.561829, mean_eps: 0.165713\n",
            " 928204/1000000: episode: 1329, duration: 31.484s, episode steps: 737, steps per second:  23, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.017570, mae: 2.115836, mean_q: 2.558629, mean_eps: 0.164949\n",
            " 929103/1000000: episode: 1330, duration: 38.131s, episode steps: 899, steps per second:  24, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.033 [0.000, 5.000],  loss: 0.019357, mae: 2.144706, mean_q: 2.589305, mean_eps: 0.164213\n",
            " 930075/1000000: episode: 1331, duration: 41.211s, episode steps: 972, steps per second:  24, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.017164, mae: 2.117404, mean_q: 2.558495, mean_eps: 0.163371\n",
            " 931002/1000000: episode: 1332, duration: 39.113s, episode steps: 927, steps per second:  24, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.172 [0.000, 5.000],  loss: 0.015967, mae: 2.144583, mean_q: 2.597602, mean_eps: 0.162516\n",
            " 931610/1000000: episode: 1333, duration: 25.999s, episode steps: 608, steps per second:  23, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.018966, mae: 2.170092, mean_q: 2.621496, mean_eps: 0.161825\n",
            " 932594/1000000: episode: 1334, duration: 41.716s, episode steps: 984, steps per second:  24, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.018872, mae: 2.166866, mean_q: 2.616629, mean_eps: 0.161108\n",
            " 933106/1000000: episode: 1335, duration: 21.676s, episode steps: 512, steps per second:  24, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.984 [0.000, 5.000],  loss: 0.018020, mae: 2.149981, mean_q: 2.597491, mean_eps: 0.160435\n",
            " 934034/1000000: episode: 1336, duration: 39.146s, episode steps: 928, steps per second:  24, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.024 [0.000, 5.000],  loss: 0.016886, mae: 2.148865, mean_q: 2.598850, mean_eps: 0.159787\n",
            " 934878/1000000: episode: 1337, duration: 35.854s, episode steps: 844, steps per second:  24, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.017382, mae: 2.151161, mean_q: 2.599457, mean_eps: 0.158990\n",
            " 935567/1000000: episode: 1338, duration: 29.016s, episode steps: 689, steps per second:  24, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.017582, mae: 2.168358, mean_q: 2.621102, mean_eps: 0.158300\n",
            " 936388/1000000: episode: 1339, duration: 34.911s, episode steps: 821, steps per second:  24, episode reward: 23.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.875 [0.000, 5.000],  loss: 0.016824, mae: 2.166218, mean_q: 2.614921, mean_eps: 0.157622\n",
            " 937666/1000000: episode: 1340, duration: 54.053s, episode steps: 1278, steps per second:  24, episode reward: 31.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.018174, mae: 2.157666, mean_q: 2.606473, mean_eps: 0.156677\n",
            " 938567/1000000: episode: 1341, duration: 38.071s, episode steps: 901, steps per second:  24, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.019356, mae: 2.169551, mean_q: 2.624820, mean_eps: 0.155696\n",
            " 939298/1000000: episode: 1342, duration: 31.071s, episode steps: 731, steps per second:  24, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.017528, mae: 2.164232, mean_q: 2.612832, mean_eps: 0.154961\n",
            " 939917/1000000: episode: 1343, duration: 26.213s, episode steps: 619, steps per second:  24, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.018264, mae: 2.161002, mean_q: 2.611641, mean_eps: 0.154353\n",
            " 940419/1000000: episode: 1344, duration: 21.346s, episode steps: 502, steps per second:  24, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.015788, mae: 2.166030, mean_q: 2.619617, mean_eps: 0.153849\n",
            " 940960/1000000: episode: 1345, duration: 23.356s, episode steps: 541, steps per second:  23, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.068 [0.000, 5.000],  loss: 0.017058, mae: 2.160496, mean_q: 2.610367, mean_eps: 0.153381\n",
            " 941381/1000000: episode: 1346, duration: 18.484s, episode steps: 421, steps per second:  23, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.017171, mae: 2.163137, mean_q: 2.613399, mean_eps: 0.152947\n",
            " 941930/1000000: episode: 1347, duration: 23.521s, episode steps: 549, steps per second:  23, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.018592, mae: 2.191054, mean_q: 2.651087, mean_eps: 0.152510\n",
            " 942365/1000000: episode: 1348, duration: 18.650s, episode steps: 435, steps per second:  23, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.949 [0.000, 5.000],  loss: 0.019217, mae: 2.176129, mean_q: 2.626166, mean_eps: 0.152067\n",
            " 943006/1000000: episode: 1349, duration: 27.692s, episode steps: 641, steps per second:  23, episode reward: 19.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.016764, mae: 2.197215, mean_q: 2.654453, mean_eps: 0.151583\n",
            " 943612/1000000: episode: 1350, duration: 25.688s, episode steps: 606, steps per second:  24, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.018863, mae: 2.196682, mean_q: 2.651672, mean_eps: 0.151023\n",
            " 944441/1000000: episode: 1351, duration: 35.300s, episode steps: 829, steps per second:  23, episode reward: 23.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.020225, mae: 2.187306, mean_q: 2.644097, mean_eps: 0.150377\n",
            " 945160/1000000: episode: 1352, duration: 30.722s, episode steps: 719, steps per second:  23, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.019895, mae: 2.186730, mean_q: 2.646846, mean_eps: 0.149680\n",
            " 946119/1000000: episode: 1353, duration: 40.751s, episode steps: 959, steps per second:  24, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.021108, mae: 2.194173, mean_q: 2.652191, mean_eps: 0.148926\n",
            " 946725/1000000: episode: 1354, duration: 25.768s, episode steps: 606, steps per second:  24, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.785 [0.000, 5.000],  loss: 0.017559, mae: 2.178263, mean_q: 2.631584, mean_eps: 0.148220\n",
            " 947392/1000000: episode: 1355, duration: 28.427s, episode steps: 667, steps per second:  23, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.020349, mae: 2.181903, mean_q: 2.635615, mean_eps: 0.147648\n",
            " 948005/1000000: episode: 1356, duration: 26.081s, episode steps: 613, steps per second:  24, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.949 [0.000, 5.000],  loss: 0.016696, mae: 2.189221, mean_q: 2.647113, mean_eps: 0.147072\n",
            " 948414/1000000: episode: 1357, duration: 17.311s, episode steps: 409, steps per second:  24, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.021323, mae: 2.200266, mean_q: 2.659479, mean_eps: 0.146611\n",
            " 949434/1000000: episode: 1358, duration: 43.414s, episode steps: 1020, steps per second:  23, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.017907, mae: 2.190263, mean_q: 2.645278, mean_eps: 0.145968\n",
            " 950216/1000000: episode: 1359, duration: 33.224s, episode steps: 782, steps per second:  24, episode reward: 21.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.847 [0.000, 5.000],  loss: 0.015727, mae: 2.168997, mean_q: 2.620816, mean_eps: 0.145158\n",
            " 951033/1000000: episode: 1360, duration: 34.793s, episode steps: 817, steps per second:  23, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.018401, mae: 2.212327, mean_q: 2.674153, mean_eps: 0.144438\n",
            " 951473/1000000: episode: 1361, duration: 18.802s, episode steps: 440, steps per second:  23, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.973 [0.000, 5.000],  loss: 0.017978, mae: 2.201197, mean_q: 2.664548, mean_eps: 0.143871\n",
            " 952291/1000000: episode: 1362, duration: 34.791s, episode steps: 818, steps per second:  24, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.019115, mae: 2.211146, mean_q: 2.672620, mean_eps: 0.143306\n",
            " 952938/1000000: episode: 1363, duration: 27.497s, episode steps: 647, steps per second:  24, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.019384, mae: 2.244110, mean_q: 2.713969, mean_eps: 0.142647\n",
            " 953817/1000000: episode: 1364, duration: 37.165s, episode steps: 879, steps per second:  24, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.017849, mae: 2.203160, mean_q: 2.662655, mean_eps: 0.141960\n",
            " 954748/1000000: episode: 1365, duration: 39.467s, episode steps: 931, steps per second:  24, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.828 [0.000, 5.000],  loss: 0.018901, mae: 2.201001, mean_q: 2.661763, mean_eps: 0.141146\n",
            " 955712/1000000: episode: 1366, duration: 41.108s, episode steps: 964, steps per second:  23, episode reward: 28.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.193 [0.000, 5.000],  loss: 0.019901, mae: 2.197181, mean_q: 2.654662, mean_eps: 0.140295\n",
            " 956241/1000000: episode: 1367, duration: 22.686s, episode steps: 529, steps per second:  23, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.877 [0.000, 5.000],  loss: 0.020398, mae: 2.201080, mean_q: 2.660218, mean_eps: 0.139622\n",
            " 957024/1000000: episode: 1368, duration: 33.452s, episode steps: 783, steps per second:  23, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.018930, mae: 2.218079, mean_q: 2.680223, mean_eps: 0.139031\n",
            " 957597/1000000: episode: 1369, duration: 24.411s, episode steps: 573, steps per second:  23, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.049 [0.000, 5.000],  loss: 0.017064, mae: 2.224882, mean_q: 2.689431, mean_eps: 0.138421\n",
            " 958164/1000000: episode: 1370, duration: 24.089s, episode steps: 567, steps per second:  24, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.019363, mae: 2.227409, mean_q: 2.692402, mean_eps: 0.137908\n",
            " 959130/1000000: episode: 1371, duration: 41.161s, episode steps: 966, steps per second:  23, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.017871, mae: 2.212016, mean_q: 2.674167, mean_eps: 0.137219\n",
            " 959691/1000000: episode: 1372, duration: 24.132s, episode steps: 561, steps per second:  23, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.706 [0.000, 5.000],  loss: 0.018701, mae: 2.202388, mean_q: 2.662466, mean_eps: 0.136531\n",
            " 960357/1000000: episode: 1373, duration: 28.974s, episode steps: 666, steps per second:  23, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.017680, mae: 2.236401, mean_q: 2.706403, mean_eps: 0.135978\n",
            " 960885/1000000: episode: 1374, duration: 22.922s, episode steps: 528, steps per second:  23, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.016964, mae: 2.250995, mean_q: 2.723564, mean_eps: 0.135440\n",
            " 961447/1000000: episode: 1375, duration: 24.244s, episode steps: 562, steps per second:  23, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.900 [0.000, 5.000],  loss: 0.020100, mae: 2.226981, mean_q: 2.690094, mean_eps: 0.134951\n",
            " 962075/1000000: episode: 1376, duration: 26.783s, episode steps: 628, steps per second:  23, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.989 [0.000, 5.000],  loss: 0.017701, mae: 2.241450, mean_q: 2.707625, mean_eps: 0.134416\n",
            " 963283/1000000: episode: 1377, duration: 51.623s, episode steps: 1208, steps per second:  23, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.018138, mae: 2.233798, mean_q: 2.699260, mean_eps: 0.133590\n",
            " 963804/1000000: episode: 1378, duration: 22.323s, episode steps: 521, steps per second:  23, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.019989, mae: 2.224580, mean_q: 2.691652, mean_eps: 0.132812\n",
            " 964767/1000000: episode: 1379, duration: 41.319s, episode steps: 963, steps per second:  23, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 3.334 [0.000, 5.000],  loss: 0.020566, mae: 2.249404, mean_q: 2.717869, mean_eps: 0.132144\n",
            " 965976/1000000: episode: 1380, duration: 51.385s, episode steps: 1209, steps per second:  24, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: 0.021503, mae: 2.232744, mean_q: 2.696403, mean_eps: 0.131167\n",
            " 966678/1000000: episode: 1381, duration: 29.878s, episode steps: 702, steps per second:  23, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.056 [0.000, 5.000],  loss: 0.018911, mae: 2.237746, mean_q: 2.703298, mean_eps: 0.130307\n",
            " 967387/1000000: episode: 1382, duration: 30.065s, episode steps: 709, steps per second:  24, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.157 [0.000, 5.000],  loss: 0.021685, mae: 2.231843, mean_q: 2.695827, mean_eps: 0.129671\n",
            " 967960/1000000: episode: 1383, duration: 24.737s, episode steps: 573, steps per second:  23, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.019706, mae: 2.251305, mean_q: 2.722071, mean_eps: 0.129095\n",
            " 968309/1000000: episode: 1384, duration: 15.080s, episode steps: 349, steps per second:  23, episode reward:  8.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.019860, mae: 2.223878, mean_q: 2.690563, mean_eps: 0.128679\n",
            " 969087/1000000: episode: 1385, duration: 33.073s, episode steps: 778, steps per second:  24, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.850 [0.000, 5.000],  loss: 0.019535, mae: 2.229944, mean_q: 2.690304, mean_eps: 0.128172\n",
            " 970001/1000000: episode: 1386, duration: 39.189s, episode steps: 914, steps per second:  23, episode reward: 25.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.809 [0.000, 5.000],  loss: 0.018260, mae: 2.243220, mean_q: 2.708815, mean_eps: 0.127410\n",
            " 970642/1000000: episode: 1387, duration: 27.136s, episode steps: 641, steps per second:  24, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.020242, mae: 2.258300, mean_q: 2.734043, mean_eps: 0.126710\n",
            " 971635/1000000: episode: 1388, duration: 43.040s, episode steps: 993, steps per second:  23, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.065 [0.000, 5.000],  loss: 0.019323, mae: 2.254995, mean_q: 2.726850, mean_eps: 0.125976\n",
            " 972781/1000000: episode: 1389, duration: 49.418s, episode steps: 1146, steps per second:  23, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.245 [0.000, 5.000],  loss: 0.018380, mae: 2.260394, mean_q: 2.731795, mean_eps: 0.125013\n",
            " 973442/1000000: episode: 1390, duration: 28.190s, episode steps: 661, steps per second:  23, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.113 [0.000, 5.000],  loss: 0.018860, mae: 2.260686, mean_q: 2.731456, mean_eps: 0.124199\n",
            " 974187/1000000: episode: 1391, duration: 31.947s, episode steps: 745, steps per second:  23, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.019162, mae: 2.258837, mean_q: 2.731213, mean_eps: 0.123567\n",
            " 974993/1000000: episode: 1392, duration: 34.612s, episode steps: 806, steps per second:  23, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.833 [0.000, 5.000],  loss: 0.020784, mae: 2.267666, mean_q: 2.739719, mean_eps: 0.122869\n",
            " 975683/1000000: episode: 1393, duration: 29.364s, episode steps: 690, steps per second:  23, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.018863, mae: 2.253666, mean_q: 2.722921, mean_eps: 0.122196\n",
            " 976387/1000000: episode: 1394, duration: 30.292s, episode steps: 704, steps per second:  23, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.189 [0.000, 5.000],  loss: 0.021028, mae: 2.264789, mean_q: 2.737121, mean_eps: 0.121569\n",
            " 976786/1000000: episode: 1395, duration: 17.223s, episode steps: 399, steps per second:  23, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.017084, mae: 2.245425, mean_q: 2.718410, mean_eps: 0.121073\n",
            " 977335/1000000: episode: 1396, duration: 23.497s, episode steps: 549, steps per second:  23, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.803 [0.000, 5.000],  loss: 0.019247, mae: 2.274708, mean_q: 2.748222, mean_eps: 0.120646\n",
            " 978100/1000000: episode: 1397, duration: 32.954s, episode steps: 765, steps per second:  23, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.021176, mae: 2.258848, mean_q: 2.734471, mean_eps: 0.120056\n",
            " 979098/1000000: episode: 1398, duration: 42.919s, episode steps: 998, steps per second:  23, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.955 [0.000, 5.000],  loss: 0.018957, mae: 2.269052, mean_q: 2.744158, mean_eps: 0.119262\n",
            " 979770/1000000: episode: 1399, duration: 29.091s, episode steps: 672, steps per second:  23, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.079 [0.000, 5.000],  loss: 0.016844, mae: 2.264793, mean_q: 2.741061, mean_eps: 0.118509\n",
            " 980721/1000000: episode: 1400, duration: 41.072s, episode steps: 951, steps per second:  23, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.017351, mae: 2.257413, mean_q: 2.733722, mean_eps: 0.117779\n",
            " 981446/1000000: episode: 1401, duration: 31.179s, episode steps: 725, steps per second:  23, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.019108, mae: 2.244461, mean_q: 2.714725, mean_eps: 0.117024\n",
            " 982084/1000000: episode: 1402, duration: 27.874s, episode steps: 638, steps per second:  23, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.094 [0.000, 5.000],  loss: 0.016219, mae: 2.236065, mean_q: 2.704855, mean_eps: 0.116412\n",
            " 982700/1000000: episode: 1403, duration: 26.720s, episode steps: 616, steps per second:  23, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.706 [0.000, 5.000],  loss: 0.019327, mae: 2.270293, mean_q: 2.748887, mean_eps: 0.115849\n",
            " 983061/1000000: episode: 1404, duration: 15.761s, episode steps: 361, steps per second:  23, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.023091, mae: 2.267924, mean_q: 2.739846, mean_eps: 0.115408\n",
            " 983848/1000000: episode: 1405, duration: 34.377s, episode steps: 787, steps per second:  23, episode reward: 23.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.019668, mae: 2.253324, mean_q: 2.724057, mean_eps: 0.114891\n",
            " 984350/1000000: episode: 1406, duration: 21.765s, episode steps: 502, steps per second:  23, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: 0.019373, mae: 2.274949, mean_q: 2.749238, mean_eps: 0.114312\n",
            " 985987/1000000: episode: 1407, duration: 70.914s, episode steps: 1637, steps per second:  23, episode reward: 34.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.888 [0.000, 5.000],  loss: 0.019284, mae: 2.262600, mean_q: 2.735998, mean_eps: 0.113349\n",
            " 986948/1000000: episode: 1408, duration: 42.050s, episode steps: 961, steps per second:  23, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.017618, mae: 2.269555, mean_q: 2.744934, mean_eps: 0.112181\n",
            " 987438/1000000: episode: 1409, duration: 21.502s, episode steps: 490, steps per second:  23, episode reward: 13.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.021630, mae: 2.272822, mean_q: 2.747967, mean_eps: 0.111527\n",
            " 988591/1000000: episode: 1410, duration: 50.152s, episode steps: 1153, steps per second:  23, episode reward: 26.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.004 [0.000, 5.000],  loss: 0.018787, mae: 2.265108, mean_q: 2.737611, mean_eps: 0.110787\n",
            " 989546/1000000: episode: 1411, duration: 41.890s, episode steps: 955, steps per second:  23, episode reward: 27.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.169 [0.000, 5.000],  loss: 0.018717, mae: 2.264884, mean_q: 2.738008, mean_eps: 0.109839\n",
            " 990554/1000000: episode: 1412, duration: 44.283s, episode steps: 1008, steps per second:  23, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.932 [0.000, 5.000],  loss: 0.018654, mae: 2.271841, mean_q: 2.747506, mean_eps: 0.108955\n",
            " 991482/1000000: episode: 1413, duration: 40.752s, episode steps: 928, steps per second:  23, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.675 [0.000, 5.000],  loss: 0.018839, mae: 2.260434, mean_q: 2.734229, mean_eps: 0.108084\n",
            " 991915/1000000: episode: 1414, duration: 19.161s, episode steps: 433, steps per second:  23, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.018852, mae: 2.264765, mean_q: 2.739002, mean_eps: 0.107472\n",
            " 992892/1000000: episode: 1415, duration: 42.560s, episode steps: 977, steps per second:  23, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.861 [0.000, 5.000],  loss: 0.020698, mae: 2.282752, mean_q: 2.763335, mean_eps: 0.106838\n",
            " 993385/1000000: episode: 1416, duration: 21.854s, episode steps: 493, steps per second:  23, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.858 [0.000, 5.000],  loss: 0.018731, mae: 2.266154, mean_q: 2.735052, mean_eps: 0.106176\n",
            " 994324/1000000: episode: 1417, duration: 41.013s, episode steps: 939, steps per second:  23, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.018702, mae: 2.276846, mean_q: 2.750824, mean_eps: 0.105531\n",
            " 995016/1000000: episode: 1418, duration: 30.394s, episode steps: 692, steps per second:  23, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.679 [0.000, 5.000],  loss: 0.020119, mae: 2.282158, mean_q: 2.757615, mean_eps: 0.104799\n",
            " 995839/1000000: episode: 1419, duration: 36.052s, episode steps: 823, steps per second:  23, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.851 [0.000, 5.000],  loss: 0.018791, mae: 2.276409, mean_q: 2.748204, mean_eps: 0.104117\n",
            " 996346/1000000: episode: 1420, duration: 22.218s, episode steps: 507, steps per second:  23, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.753 [0.000, 5.000],  loss: 0.021759, mae: 2.245347, mean_q: 2.714291, mean_eps: 0.103517\n",
            " 996991/1000000: episode: 1421, duration: 28.038s, episode steps: 645, steps per second:  23, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.800 [0.000, 5.000],  loss: 0.022212, mae: 2.298427, mean_q: 2.778456, mean_eps: 0.102999\n",
            " 998020/1000000: episode: 1422, duration: 45.116s, episode steps: 1029, steps per second:  23, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.216 [0.000, 5.000],  loss: 0.019909, mae: 2.270966, mean_q: 2.745352, mean_eps: 0.102246\n",
            " 998909/1000000: episode: 1423, duration: 39.009s, episode steps: 889, steps per second:  23, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.957 [0.000, 5.000],  loss: 0.019854, mae: 2.276001, mean_q: 2.751970, mean_eps: 0.101382\n",
            " 999774/1000000: episode: 1424, duration: 37.843s, episode steps: 865, steps per second:  23, episode reward: 26.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.020441, mae: 2.259337, mean_q: 2.731868, mean_eps: 0.100592\n",
            "done, took 33721.255 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 5.000, steps: 717\n",
            "Episode 2: reward: 15.000, steps: 1083\n",
            "Episode 3: reward: 11.000, steps: 889\n",
            "Episode 4: reward: 13.000, steps: 935\n",
            "Episode 5: reward: 13.000, steps: 831\n",
            "Episode 6: reward: 8.000, steps: 511\n",
            "Episode 7: reward: 20.000, steps: 997\n",
            "Episode 8: reward: 20.000, steps: 823\n",
            "Episode 9: reward: 18.000, steps: 1078\n",
            "Episode 10: reward: 6.000, steps: 516\n",
            "Episode 11: reward: 10.000, steps: 905\n",
            "Episode 12: reward: 10.000, steps: 975\n",
            "Episode 13: reward: 9.000, steps: 647\n",
            "Episode 14: reward: 9.000, steps: 495\n",
            "Episode 15: reward: 11.000, steps: 821\n",
            "Episode 16: reward: 8.000, steps: 919\n",
            "Episode 17: reward: 10.000, steps: 673\n",
            "Episode 18: reward: 8.000, steps: 639\n",
            "Episode 19: reward: 16.000, steps: 1249\n",
            "Episode 20: reward: 5.000, steps: 643\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f907d165a50>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam  # ✅ IMPORTANTE: usar legacy\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# ==== Constantes ====\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "\n",
        "# ==== Procesador para observaciones ====\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3\n",
        "        img = Image.fromarray(observation)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        return batch.astype('float32') / 255.\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "# ==== Preparar entorno ====\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "# ==== Modelo CNN tipo DeepMind ====\n",
        "#input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "#model = Sequential()\n",
        "#model.add(Permute((2, 3, 1), input_shape=input_shape))  # (4, 84, 84) → (84, 84, 4)\n",
        "#model.add(Conv2D(32, kernel_size=8, strides=4, activation='relu'))\n",
        "#model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
        "#model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu'))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(512, activation='relu'))\n",
        "#model.add(Dense(nb_actions, activation='linear'))\n",
        "\n",
        "\n",
        "# ==== Modelo CNN Mejorado ====\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 3, 1), input_shape=input_shape))  # (4, 84, 84) → (84, 84, 4)\n",
        "\n",
        "# Capas convolucionales\n",
        "model.add(Conv2D(32, kernel_size=8, strides=4, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu'))  # Nueva capa\n",
        "\n",
        "# Capa densa más profunda\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))  # Mayor capacidad\n",
        "model.add(Dense(nb_actions, activation='linear'))  # Salida\n",
        "\n",
        "\n",
        "# ==== Memoria y política ====\n",
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=1.0, value_min=0.1, value_test=0.05,\n",
        "                              nb_steps=1000000)\n",
        "\n",
        "# ==== Agente DQN ====\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               memory=memory,\n",
        "               processor=AtariProcessor(),\n",
        "               nb_steps_warmup=50000,\n",
        "               target_model_update=10000,\n",
        "               train_interval=4,\n",
        "               gamma=0.99,\n",
        "               policy=policy)\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.00025), metrics=['mae'])\n",
        "\n",
        "# ==== Callbacks ====\n",
        "checkpoint_weights_filename = 'dqn_{}_weights_{{step}}.h5f'.format(ENV_NAME)\n",
        "log_filename = 'dqn_{}_log.json'.format(ENV_NAME)\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000),\n",
        "    FileLogger(log_filename, interval=100)\n",
        "]\n",
        "\n",
        "# ==== Entrenamiento ====\n",
        "dqn.fit(env,\n",
        "        nb_steps=1000000,  # ENTRENAMIENTO EXTENDIDO\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "# ==== Guardar pesos finales ====\n",
        "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
        "\n",
        "# ==== Evaluación ====\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "KTLa_uXIyuf6",
        "outputId": "5d0bb36d-9969-4c49-c253-e072e46ccd2d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Leer los logs guardados\n",
        "with open(log_filename) as f:\n",
        "    log_data = json.load(f)\n",
        "\n",
        "# Extraer rewards y episodios\n",
        "episode_rewards = log_data['episode_reward']\n",
        "episodes = list(range(1, len(episode_rewards) + 1))  # Episodios desde 1\n",
        "\n",
        "# (Opcional) Suavizar la curva con media móvil\n",
        "def moving_average(data, window_size=10):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "smoothed_rewards = moving_average(episode_rewards, window_size=10)\n",
        "\n",
        "# Graficar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(episodes, episode_rewards, alpha=0.3, label='Reward por episodio')\n",
        "plt.plot(episodes[:len(smoothed_rewards)], smoothed_rewards, color='red', label='Media móvil (10)')\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Reward')\n",
        "plt.title('Evolución del reward durante el entrenamiento')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NAlu8b1Gb2b"
      },
      "source": [
        "3. Justificación de los parámetros seleccionados y de los resultados obtenidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANFQiicXK3sO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glbMpbKSKcVp"
      },
      "source": [
        "Implementación de Boltzmann Policy\n",
        "\n",
        "\n",
        "En lugar de una política ε-greedy (donde tomas la acción con el máximo Q o una aleatoria), usarías una distribución softmax sobre los Q-values para elegir la acción:\n",
        "\n",
        "Ventajas:\n",
        "\n",
        "Mejor exploración: elige buenas acciones con más probabilidad, incluso si no son la mejor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "12qZPtaoKZaD",
        "outputId": "496a8c33-756d-43b7-a0d5-d548ed9feab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 1000000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    652/1000000: episode: 1, duration: 2.637s, episode steps: 652, steps per second: 247, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   1241/1000000: episode: 2, duration: 2.295s, episode steps: 589, steps per second: 257, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   1842/1000000: episode: 3, duration: 2.449s, episode steps: 601, steps per second: 245, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   2480/1000000: episode: 4, duration: 2.578s, episode steps: 638, steps per second: 247, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   3167/1000000: episode: 5, duration: 2.671s, episode steps: 687, steps per second: 257, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   3792/1000000: episode: 6, duration: 2.418s, episode steps: 625, steps per second: 258, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   4310/1000000: episode: 7, duration: 2.028s, episode steps: 518, steps per second: 255, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   4692/1000000: episode: 8, duration: 1.505s, episode steps: 382, steps per second: 254, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   5084/1000000: episode: 9, duration: 1.567s, episode steps: 392, steps per second: 250, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   5952/1000000: episode: 10, duration: 3.383s, episode steps: 868, steps per second: 257, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   6345/1000000: episode: 11, duration: 1.523s, episode steps: 393, steps per second: 258, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   6743/1000000: episode: 12, duration: 1.526s, episode steps: 398, steps per second: 261, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   7713/1000000: episode: 13, duration: 3.722s, episode steps: 970, steps per second: 261, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   8119/1000000: episode: 14, duration: 1.590s, episode steps: 406, steps per second: 255, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   8807/1000000: episode: 15, duration: 2.677s, episode steps: 688, steps per second: 257, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   9684/1000000: episode: 16, duration: 3.311s, episode steps: 877, steps per second: 265, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  10385/1000000: episode: 17, duration: 2.682s, episode steps: 701, steps per second: 261, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  10961/1000000: episode: 18, duration: 2.209s, episode steps: 576, steps per second: 261, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  11540/1000000: episode: 19, duration: 2.265s, episode steps: 579, steps per second: 256, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  12203/1000000: episode: 20, duration: 2.526s, episode steps: 663, steps per second: 263, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  12817/1000000: episode: 21, duration: 2.309s, episode steps: 614, steps per second: 266, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  13641/1000000: episode: 22, duration: 3.106s, episode steps: 824, steps per second: 265, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  14268/1000000: episode: 23, duration: 2.405s, episode steps: 627, steps per second: 261, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  14842/1000000: episode: 24, duration: 2.227s, episode steps: 574, steps per second: 258, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  15371/1000000: episode: 25, duration: 1.977s, episode steps: 529, steps per second: 268, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  16604/1000000: episode: 26, duration: 4.636s, episode steps: 1233, steps per second: 266, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  17220/1000000: episode: 27, duration: 2.336s, episode steps: 616, steps per second: 264, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  17763/1000000: episode: 28, duration: 2.100s, episode steps: 543, steps per second: 259, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  18453/1000000: episode: 29, duration: 2.613s, episode steps: 690, steps per second: 264, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  19418/1000000: episode: 30, duration: 3.636s, episode steps: 965, steps per second: 265, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  20482/1000000: episode: 31, duration: 4.125s, episode steps: 1064, steps per second: 258, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  20907/1000000: episode: 32, duration: 1.710s, episode steps: 425, steps per second: 249, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  21345/1000000: episode: 33, duration: 1.734s, episode steps: 438, steps per second: 253, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  21961/1000000: episode: 34, duration: 2.381s, episode steps: 616, steps per second: 259, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  22672/1000000: episode: 35, duration: 2.763s, episode steps: 711, steps per second: 257, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  23083/1000000: episode: 36, duration: 1.608s, episode steps: 411, steps per second: 256, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  23449/1000000: episode: 37, duration: 1.434s, episode steps: 366, steps per second: 255, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  24436/1000000: episode: 38, duration: 3.881s, episode steps: 987, steps per second: 254, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  25086/1000000: episode: 39, duration: 2.554s, episode steps: 650, steps per second: 254, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  25903/1000000: episode: 40, duration: 3.117s, episode steps: 817, steps per second: 262, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  26511/1000000: episode: 41, duration: 2.389s, episode steps: 608, steps per second: 254, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  27531/1000000: episode: 42, duration: 4.076s, episode steps: 1020, steps per second: 250, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  27920/1000000: episode: 43, duration: 1.547s, episode steps: 389, steps per second: 251, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  28697/1000000: episode: 44, duration: 3.087s, episode steps: 777, steps per second: 252, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  29778/1000000: episode: 45, duration: 4.201s, episode steps: 1081, steps per second: 257, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  30670/1000000: episode: 46, duration: 3.424s, episode steps: 892, steps per second: 260, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  31108/1000000: episode: 47, duration: 1.660s, episode steps: 438, steps per second: 264, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  31552/1000000: episode: 48, duration: 1.673s, episode steps: 444, steps per second: 265, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  32171/1000000: episode: 49, duration: 2.330s, episode steps: 619, steps per second: 266, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  32970/1000000: episode: 50, duration: 3.022s, episode steps: 799, steps per second: 264, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  33723/1000000: episode: 51, duration: 2.897s, episode steps: 753, steps per second: 260, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  34363/1000000: episode: 52, duration: 2.426s, episode steps: 640, steps per second: 264, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  35013/1000000: episode: 53, duration: 2.441s, episode steps: 650, steps per second: 266, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  35574/1000000: episode: 54, duration: 2.164s, episode steps: 561, steps per second: 259, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  36523/1000000: episode: 55, duration: 3.603s, episode steps: 949, steps per second: 263, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  37353/1000000: episode: 56, duration: 3.209s, episode steps: 830, steps per second: 259, episode reward:  6.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  38337/1000000: episode: 57, duration: 3.677s, episode steps: 984, steps per second: 268, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  38973/1000000: episode: 58, duration: 2.364s, episode steps: 636, steps per second: 269, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  39736/1000000: episode: 59, duration: 2.862s, episode steps: 763, steps per second: 267, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  40801/1000000: episode: 60, duration: 3.971s, episode steps: 1065, steps per second: 268, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  41308/1000000: episode: 61, duration: 1.911s, episode steps: 507, steps per second: 265, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  42076/1000000: episode: 62, duration: 2.881s, episode steps: 768, steps per second: 267, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  42591/1000000: episode: 63, duration: 1.936s, episode steps: 515, steps per second: 266, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  43682/1000000: episode: 64, duration: 4.144s, episode steps: 1091, steps per second: 263, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  44360/1000000: episode: 65, duration: 2.620s, episode steps: 678, steps per second: 259, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  45114/1000000: episode: 66, duration: 2.937s, episode steps: 754, steps per second: 257, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  46260/1000000: episode: 67, duration: 4.500s, episode steps: 1146, steps per second: 255, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  47052/1000000: episode: 68, duration: 3.094s, episode steps: 792, steps per second: 256, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  48339/1000000: episode: 69, duration: 4.845s, episode steps: 1287, steps per second: 266, episode reward: 17.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  48759/1000000: episode: 70, duration: 1.597s, episode steps: 420, steps per second: 263, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  49279/1000000: episode: 71, duration: 1.990s, episode steps: 520, steps per second: 261, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  49964/1000000: episode: 72, duration: 2.615s, episode steps: 685, steps per second: 262, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  50551/1000000: episode: 73, duration: 2.201s, episode steps: 587, steps per second: 267, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  51199/1000000: episode: 74, duration: 2.438s, episode steps: 648, steps per second: 266, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  52274/1000000: episode: 75, duration: 4.134s, episode steps: 1075, steps per second: 260, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  53146/1000000: episode: 76, duration: 3.377s, episode steps: 872, steps per second: 258, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  54515/1000000: episode: 77, duration: 5.151s, episode steps: 1369, steps per second: 266, episode reward: 20.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  55112/1000000: episode: 78, duration: 2.274s, episode steps: 597, steps per second: 263, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  56154/1000000: episode: 79, duration: 4.038s, episode steps: 1042, steps per second: 258, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  57715/1000000: episode: 80, duration: 5.869s, episode steps: 1561, steps per second: 266, episode reward: 16.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  58207/1000000: episode: 81, duration: 1.859s, episode steps: 492, steps per second: 265, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  59062/1000000: episode: 82, duration: 3.271s, episode steps: 855, steps per second: 261, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  59566/1000000: episode: 83, duration: 1.869s, episode steps: 504, steps per second: 270, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  60561/1000000: episode: 84, duration: 3.672s, episode steps: 995, steps per second: 271, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  61269/1000000: episode: 85, duration: 2.640s, episode steps: 708, steps per second: 268, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  61997/1000000: episode: 86, duration: 2.734s, episode steps: 728, steps per second: 266, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  62958/1000000: episode: 87, duration: 3.624s, episode steps: 961, steps per second: 265, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  63570/1000000: episode: 88, duration: 2.300s, episode steps: 612, steps per second: 266, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  64296/1000000: episode: 89, duration: 2.725s, episode steps: 726, steps per second: 266, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  64916/1000000: episode: 90, duration: 2.353s, episode steps: 620, steps per second: 263, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  65953/1000000: episode: 91, duration: 3.974s, episode steps: 1037, steps per second: 261, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  66646/1000000: episode: 92, duration: 2.580s, episode steps: 693, steps per second: 269, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  67343/1000000: episode: 93, duration: 2.591s, episode steps: 697, steps per second: 269, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  68141/1000000: episode: 94, duration: 3.011s, episode steps: 798, steps per second: 265, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  68736/1000000: episode: 95, duration: 2.326s, episode steps: 595, steps per second: 256, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  69166/1000000: episode: 96, duration: 1.638s, episode steps: 430, steps per second: 262, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  70233/1000000: episode: 97, duration: 3.986s, episode steps: 1067, steps per second: 268, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  70848/1000000: episode: 98, duration: 2.310s, episode steps: 615, steps per second: 266, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  71656/1000000: episode: 99, duration: 3.059s, episode steps: 808, steps per second: 264, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  72181/1000000: episode: 100, duration: 2.029s, episode steps: 525, steps per second: 259, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  72989/1000000: episode: 101, duration: 3.030s, episode steps: 808, steps per second: 267, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  73546/1000000: episode: 102, duration: 2.095s, episode steps: 557, steps per second: 266, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  74294/1000000: episode: 103, duration: 2.801s, episode steps: 748, steps per second: 267, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  74931/1000000: episode: 104, duration: 2.429s, episode steps: 637, steps per second: 262, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  75976/1000000: episode: 105, duration: 3.898s, episode steps: 1045, steps per second: 268, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  76990/1000000: episode: 106, duration: 3.791s, episode steps: 1014, steps per second: 267, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  77525/1000000: episode: 107, duration: 2.003s, episode steps: 535, steps per second: 267, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  78325/1000000: episode: 108, duration: 3.058s, episode steps: 800, steps per second: 262, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  78797/1000000: episode: 109, duration: 1.760s, episode steps: 472, steps per second: 268, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  79291/1000000: episode: 110, duration: 1.876s, episode steps: 494, steps per second: 263, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  79912/1000000: episode: 111, duration: 2.355s, episode steps: 621, steps per second: 264, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  80590/1000000: episode: 112, duration: 2.534s, episode steps: 678, steps per second: 268, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  81411/1000000: episode: 113, duration: 3.192s, episode steps: 821, steps per second: 257, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  81817/1000000: episode: 114, duration: 1.504s, episode steps: 406, steps per second: 270, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  82527/1000000: episode: 115, duration: 2.607s, episode steps: 710, steps per second: 272, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  83508/1000000: episode: 116, duration: 3.624s, episode steps: 981, steps per second: 271, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  84237/1000000: episode: 117, duration: 2.746s, episode steps: 729, steps per second: 265, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  84868/1000000: episode: 118, duration: 2.432s, episode steps: 631, steps per second: 259, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  85847/1000000: episode: 119, duration: 3.657s, episode steps: 979, steps per second: 268, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  86461/1000000: episode: 120, duration: 2.299s, episode steps: 614, steps per second: 267, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  86965/1000000: episode: 121, duration: 1.868s, episode steps: 504, steps per second: 270, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  87505/1000000: episode: 122, duration: 2.054s, episode steps: 540, steps per second: 263, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  87905/1000000: episode: 123, duration: 1.582s, episode steps: 400, steps per second: 253, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  88427/1000000: episode: 124, duration: 1.957s, episode steps: 522, steps per second: 267, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  89199/1000000: episode: 125, duration: 2.892s, episode steps: 772, steps per second: 267, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  89712/1000000: episode: 126, duration: 1.936s, episode steps: 513, steps per second: 265, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  90440/1000000: episode: 127, duration: 2.735s, episode steps: 728, steps per second: 266, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  91067/1000000: episode: 128, duration: 2.362s, episode steps: 627, steps per second: 265, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  91625/1000000: episode: 129, duration: 2.095s, episode steps: 558, steps per second: 266, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  92154/1000000: episode: 130, duration: 1.981s, episode steps: 529, steps per second: 267, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  93279/1000000: episode: 131, duration: 4.188s, episode steps: 1125, steps per second: 269, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  93677/1000000: episode: 132, duration: 1.506s, episode steps: 398, steps per second: 264, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  94327/1000000: episode: 133, duration: 2.494s, episode steps: 650, steps per second: 261, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  94955/1000000: episode: 134, duration: 2.345s, episode steps: 628, steps per second: 268, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  95324/1000000: episode: 135, duration: 1.383s, episode steps: 369, steps per second: 267, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  96077/1000000: episode: 136, duration: 2.803s, episode steps: 753, steps per second: 269, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  96579/1000000: episode: 137, duration: 1.894s, episode steps: 502, steps per second: 265, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  97112/1000000: episode: 138, duration: 2.031s, episode steps: 533, steps per second: 262, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  97757/1000000: episode: 139, duration: 2.429s, episode steps: 645, steps per second: 266, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  98396/1000000: episode: 140, duration: 2.389s, episode steps: 639, steps per second: 267, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  98904/1000000: episode: 141, duration: 1.892s, episode steps: 508, steps per second: 268, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  99419/1000000: episode: 142, duration: 1.937s, episode steps: 515, steps per second: 266, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100539/1000000: episode: 143, duration: 60.704s, episode steps: 1120, steps per second:  18, episode reward:  9.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.006602, mae: 0.019897, mean_q: 0.027568\n",
            " 101140/1000000: episode: 144, duration: 65.299s, episode steps: 601, steps per second:   9, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.007076, mae: 0.022712, mean_q: 0.028241\n",
            " 101772/1000000: episode: 145, duration: 68.756s, episode steps: 632, steps per second:   9, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.007462, mae: 0.027476, mean_q: 0.035330\n",
            " 102779/1000000: episode: 146, duration: 110.085s, episode steps: 1007, steps per second:   9, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.007127, mae: 0.023465, mean_q: 0.028036\n",
            " 103439/1000000: episode: 147, duration: 72.022s, episode steps: 660, steps per second:   9, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.007123, mae: 0.019659, mean_q: 0.022232\n",
            " 104248/1000000: episode: 148, duration: 89.008s, episode steps: 809, steps per second:   9, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.007273, mae: 0.024041, mean_q: 0.028629\n",
            " 104747/1000000: episode: 149, duration: 54.129s, episode steps: 499, steps per second:   9, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.007718, mae: 0.027544, mean_q: 0.033450\n",
            " 105485/1000000: episode: 150, duration: 79.992s, episode steps: 738, steps per second:   9, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.006739, mae: 0.024851, mean_q: 0.029001\n",
            " 106369/1000000: episode: 151, duration: 96.471s, episode steps: 884, steps per second:   9, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.007103, mae: 0.025820, mean_q: 0.029161\n",
            " 106814/1000000: episode: 152, duration: 48.885s, episode steps: 445, steps per second:   9, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.006982, mae: 0.018095, mean_q: 0.019761\n",
            " 107320/1000000: episode: 153, duration: 55.256s, episode steps: 506, steps per second:   9, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.006309, mae: 0.022558, mean_q: 0.027391\n",
            " 108081/1000000: episode: 154, duration: 82.313s, episode steps: 761, steps per second:   9, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.006623, mae: 0.020485, mean_q: 0.022913\n",
            " 108698/1000000: episode: 155, duration: 67.199s, episode steps: 617, steps per second:   9, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.006686, mae: 0.021266, mean_q: 0.026399\n",
            " 109366/1000000: episode: 156, duration: 72.495s, episode steps: 668, steps per second:   9, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.007581, mae: 0.030191, mean_q: 0.035253\n",
            " 109925/1000000: episode: 157, duration: 61.360s, episode steps: 559, steps per second:   9, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.006851, mae: 0.029483, mean_q: 0.033814\n",
            " 110731/1000000: episode: 158, duration: 88.086s, episode steps: 806, steps per second:   9, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.007247, mae: 0.039563, mean_q: 0.047706\n",
            " 111534/1000000: episode: 159, duration: 86.910s, episode steps: 803, steps per second:   9, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.006714, mae: 0.041185, mean_q: 0.050634\n",
            " 112230/1000000: episode: 160, duration: 75.541s, episode steps: 696, steps per second:   9, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006878, mae: 0.040705, mean_q: 0.049059\n",
            " 112911/1000000: episode: 161, duration: 73.934s, episode steps: 681, steps per second:   9, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.007215, mae: 0.042810, mean_q: 0.051354\n",
            " 113557/1000000: episode: 162, duration: 69.706s, episode steps: 646, steps per second:   9, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.006505, mae: 0.040654, mean_q: 0.049255\n",
            " 113958/1000000: episode: 163, duration: 43.349s, episode steps: 401, steps per second:   9, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.007222, mae: 0.042871, mean_q: 0.052082\n",
            " 114553/1000000: episode: 164, duration: 64.360s, episode steps: 595, steps per second:   9, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006971, mae: 0.042188, mean_q: 0.051786\n",
            " 115088/1000000: episode: 165, duration: 58.289s, episode steps: 535, steps per second:   9, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007350, mae: 0.041911, mean_q: 0.051440\n",
            " 115784/1000000: episode: 166, duration: 75.738s, episode steps: 696, steps per second:   9, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006846, mae: 0.041838, mean_q: 0.051146\n",
            " 116367/1000000: episode: 167, duration: 63.067s, episode steps: 583, steps per second:   9, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.007036, mae: 0.042568, mean_q: 0.053018\n",
            " 116863/1000000: episode: 168, duration: 53.627s, episode steps: 496, steps per second:   9, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.007345, mae: 0.042929, mean_q: 0.053454\n",
            " 117588/1000000: episode: 169, duration: 78.245s, episode steps: 725, steps per second:   9, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006902, mae: 0.041915, mean_q: 0.052556\n",
            " 118697/1000000: episode: 170, duration: 120.283s, episode steps: 1109, steps per second:   9, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006177, mae: 0.040266, mean_q: 0.050088\n",
            " 119523/1000000: episode: 171, duration: 89.122s, episode steps: 826, steps per second:   9, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.006166, mae: 0.040530, mean_q: 0.051261\n",
            " 120237/1000000: episode: 172, duration: 81.136s, episode steps: 714, steps per second:   9, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.007018, mae: 0.046275, mean_q: 0.059610\n",
            " 121482/1000000: episode: 173, duration: 144.265s, episode steps: 1245, steps per second:   9, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006650, mae: 0.053749, mean_q: 0.070270\n",
            " 121997/1000000: episode: 174, duration: 55.939s, episode steps: 515, steps per second:   9, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.007091, mae: 0.055318, mean_q: 0.071591\n",
            " 122516/1000000: episode: 175, duration: 56.080s, episode steps: 519, steps per second:   9, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006709, mae: 0.052375, mean_q: 0.068799\n",
            " 123152/1000000: episode: 176, duration: 69.108s, episode steps: 636, steps per second:   9, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.006973, mae: 0.054726, mean_q: 0.070799\n",
            " 124158/1000000: episode: 177, duration: 108.853s, episode steps: 1006, steps per second:   9, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.006447, mae: 0.053526, mean_q: 0.068459\n",
            " 125274/1000000: episode: 178, duration: 121.145s, episode steps: 1116, steps per second:   9, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006194, mae: 0.052150, mean_q: 0.067876\n",
            " 126066/1000000: episode: 179, duration: 86.691s, episode steps: 792, steps per second:   9, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006463, mae: 0.053387, mean_q: 0.069759\n",
            " 126815/1000000: episode: 180, duration: 81.263s, episode steps: 749, steps per second:   9, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.006614, mae: 0.054251, mean_q: 0.070243\n",
            " 127385/1000000: episode: 181, duration: 61.603s, episode steps: 570, steps per second:   9, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.006032, mae: 0.052896, mean_q: 0.069709\n",
            " 127994/1000000: episode: 182, duration: 65.839s, episode steps: 609, steps per second:   9, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.006855, mae: 0.054723, mean_q: 0.070424\n",
            " 128627/1000000: episode: 183, duration: 68.725s, episode steps: 633, steps per second:   9, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.005723, mae: 0.052402, mean_q: 0.068855\n",
            " 129341/1000000: episode: 184, duration: 77.241s, episode steps: 714, steps per second:   9, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.006159, mae: 0.052964, mean_q: 0.069736\n",
            " 130385/1000000: episode: 185, duration: 112.862s, episode steps: 1044, steps per second:   9, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.006164, mae: 0.058301, mean_q: 0.076130\n",
            " 130775/1000000: episode: 186, duration: 42.343s, episode steps: 390, steps per second:   9, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.005855, mae: 0.065161, mean_q: 0.084546\n",
            " 131363/1000000: episode: 187, duration: 63.767s, episode steps: 588, steps per second:   9, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.006207, mae: 0.065895, mean_q: 0.086453\n",
            " 131977/1000000: episode: 188, duration: 65.860s, episode steps: 614, steps per second:   9, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006402, mae: 0.066357, mean_q: 0.087003\n",
            " 132402/1000000: episode: 189, duration: 45.949s, episode steps: 425, steps per second:   9, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.005330, mae: 0.063226, mean_q: 0.083142\n",
            " 132864/1000000: episode: 190, duration: 49.836s, episode steps: 462, steps per second:   9, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.005618, mae: 0.064548, mean_q: 0.085799\n",
            " 133280/1000000: episode: 191, duration: 44.898s, episode steps: 416, steps per second:   9, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.006545, mae: 0.066166, mean_q: 0.087090\n",
            " 133973/1000000: episode: 192, duration: 74.556s, episode steps: 693, steps per second:   9, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.005603, mae: 0.064383, mean_q: 0.084574\n",
            " 135166/1000000: episode: 193, duration: 128.383s, episode steps: 1193, steps per second:   9, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.005987, mae: 0.065938, mean_q: 0.086014\n",
            " 135556/1000000: episode: 194, duration: 42.404s, episode steps: 390, steps per second:   9, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.005770, mae: 0.065642, mean_q: 0.086073\n",
            " 136236/1000000: episode: 195, duration: 73.561s, episode steps: 680, steps per second:   9, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.005898, mae: 0.065247, mean_q: 0.085938\n",
            " 136874/1000000: episode: 196, duration: 68.607s, episode steps: 638, steps per second:   9, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.005911, mae: 0.065121, mean_q: 0.086128\n",
            " 137656/1000000: episode: 197, duration: 84.576s, episode steps: 782, steps per second:   9, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.006044, mae: 0.064846, mean_q: 0.086881\n",
            " 138349/1000000: episode: 198, duration: 75.099s, episode steps: 693, steps per second:   9, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.005749, mae: 0.065398, mean_q: 0.087111\n",
            " 138923/1000000: episode: 199, duration: 61.906s, episode steps: 574, steps per second:   9, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.005541, mae: 0.065489, mean_q: 0.087563\n",
            " 139590/1000000: episode: 200, duration: 72.142s, episode steps: 667, steps per second:   9, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.005718, mae: 0.064863, mean_q: 0.086815\n",
            " 139948/1000000: episode: 201, duration: 38.925s, episode steps: 358, steps per second:   9, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.005021, mae: 0.062502, mean_q: 0.083047\n",
            " 140446/1000000: episode: 202, duration: 56.375s, episode steps: 498, steps per second:   9, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.006451, mae: 0.080039, mean_q: 0.104873\n",
            " 140993/1000000: episode: 203, duration: 59.622s, episode steps: 547, steps per second:   9, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.005704, mae: 0.081914, mean_q: 0.107783\n",
            " 141491/1000000: episode: 204, duration: 54.268s, episode steps: 498, steps per second:   9, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.005653, mae: 0.080667, mean_q: 0.106220\n",
            " 142129/1000000: episode: 205, duration: 69.599s, episode steps: 638, steps per second:   9, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.006156, mae: 0.081159, mean_q: 0.107317\n",
            " 142825/1000000: episode: 206, duration: 75.888s, episode steps: 696, steps per second:   9, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.005747, mae: 0.081222, mean_q: 0.106504\n",
            " 143609/1000000: episode: 207, duration: 85.176s, episode steps: 784, steps per second:   9, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.006073, mae: 0.081349, mean_q: 0.107922\n",
            " 144313/1000000: episode: 208, duration: 76.675s, episode steps: 704, steps per second:   9, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.005707, mae: 0.082259, mean_q: 0.108577\n",
            " 144829/1000000: episode: 209, duration: 55.966s, episode steps: 516, steps per second:   9, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.005515, mae: 0.080014, mean_q: 0.105973\n",
            " 145255/1000000: episode: 210, duration: 46.294s, episode steps: 426, steps per second:   9, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.005582, mae: 0.081105, mean_q: 0.106778\n",
            " 146037/1000000: episode: 211, duration: 84.294s, episode steps: 782, steps per second:   9, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.005579, mae: 0.080020, mean_q: 0.105689\n",
            " 147025/1000000: episode: 212, duration: 106.412s, episode steps: 988, steps per second:   9, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.005495, mae: 0.078319, mean_q: 0.103974\n",
            " 148279/1000000: episode: 213, duration: 136.071s, episode steps: 1254, steps per second:   9, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.005802, mae: 0.080762, mean_q: 0.107373\n",
            " 148936/1000000: episode: 214, duration: 71.546s, episode steps: 657, steps per second:   9, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.005561, mae: 0.080077, mean_q: 0.106358\n",
            " 149586/1000000: episode: 215, duration: 71.241s, episode steps: 650, steps per second:   9, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.005558, mae: 0.078779, mean_q: 0.104602\n",
            " 150227/1000000: episode: 216, duration: 70.208s, episode steps: 641, steps per second:   9, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.006144, mae: 0.089190, mean_q: 0.119379\n",
            " 150908/1000000: episode: 217, duration: 74.421s, episode steps: 681, steps per second:   9, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.006016, mae: 0.101291, mean_q: 0.133329\n",
            " 151500/1000000: episode: 218, duration: 64.728s, episode steps: 592, steps per second:   9, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.006538, mae: 0.103028, mean_q: 0.135056\n",
            " 151950/1000000: episode: 219, duration: 49.180s, episode steps: 450, steps per second:   9, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.005527, mae: 0.100701, mean_q: 0.132203\n",
            " 153246/1000000: episode: 220, duration: 141.252s, episode steps: 1296, steps per second:   9, episode reward: 20.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.005769, mae: 0.099594, mean_q: 0.131540\n",
            " 153997/1000000: episode: 221, duration: 81.761s, episode steps: 751, steps per second:   9, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.005500, mae: 0.101347, mean_q: 0.134347\n",
            " 154825/1000000: episode: 222, duration: 90.119s, episode steps: 828, steps per second:   9, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.005585, mae: 0.100070, mean_q: 0.132836\n",
            " 155404/1000000: episode: 223, duration: 63.362s, episode steps: 579, steps per second:   9, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.005403, mae: 0.101203, mean_q: 0.133661\n",
            " 156225/1000000: episode: 224, duration: 88.718s, episode steps: 821, steps per second:   9, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.004990, mae: 0.097753, mean_q: 0.129739\n",
            " 156858/1000000: episode: 225, duration: 68.764s, episode steps: 633, steps per second:   9, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.005379, mae: 0.100775, mean_q: 0.133873\n",
            " 157531/1000000: episode: 226, duration: 72.902s, episode steps: 673, steps per second:   9, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.005515, mae: 0.097883, mean_q: 0.130416\n",
            " 158169/1000000: episode: 227, duration: 69.238s, episode steps: 638, steps per second:   9, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.005386, mae: 0.097314, mean_q: 0.129298\n",
            " 159086/1000000: episode: 228, duration: 99.140s, episode steps: 917, steps per second:   9, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.004807, mae: 0.095850, mean_q: 0.127139\n",
            " 159934/1000000: episode: 229, duration: 91.731s, episode steps: 848, steps per second:   9, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.005020, mae: 0.097743, mean_q: 0.130084\n",
            " 160427/1000000: episode: 230, duration: 53.730s, episode steps: 493, steps per second:   9, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.006488, mae: 0.124132, mean_q: 0.163292\n",
            " 160973/1000000: episode: 231, duration: 59.376s, episode steps: 546, steps per second:   9, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.006166, mae: 0.125523, mean_q: 0.164043\n",
            " 161930/1000000: episode: 232, duration: 103.668s, episode steps: 957, steps per second:   9, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.005738, mae: 0.124318, mean_q: 0.162447\n",
            " 162929/1000000: episode: 233, duration: 108.259s, episode steps: 999, steps per second:   9, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.005919, mae: 0.125721, mean_q: 0.164415\n",
            " 163412/1000000: episode: 234, duration: 52.428s, episode steps: 483, steps per second:   9, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.005788, mae: 0.123276, mean_q: 0.161815\n",
            " 164388/1000000: episode: 235, duration: 105.466s, episode steps: 976, steps per second:   9, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006112, mae: 0.123513, mean_q: 0.162531\n",
            " 164978/1000000: episode: 236, duration: 63.811s, episode steps: 590, steps per second:   9, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.005837, mae: 0.123090, mean_q: 0.162379\n",
            " 166002/1000000: episode: 237, duration: 111.018s, episode steps: 1024, steps per second:   9, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.005318, mae: 0.119998, mean_q: 0.158361\n",
            " 166579/1000000: episode: 238, duration: 62.536s, episode steps: 577, steps per second:   9, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.005565, mae: 0.125020, mean_q: 0.164171\n",
            " 167539/1000000: episode: 239, duration: 104.596s, episode steps: 960, steps per second:   9, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.005604, mae: 0.124797, mean_q: 0.164489\n",
            " 168226/1000000: episode: 240, duration: 74.717s, episode steps: 687, steps per second:   9, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.005630, mae: 0.123289, mean_q: 0.162931\n",
            " 168928/1000000: episode: 241, duration: 76.431s, episode steps: 702, steps per second:   9, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.005482, mae: 0.123863, mean_q: 0.164580\n",
            " 169733/1000000: episode: 242, duration: 87.675s, episode steps: 805, steps per second:   9, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.005105, mae: 0.121615, mean_q: 0.160548\n",
            " 170514/1000000: episode: 243, duration: 85.011s, episode steps: 781, steps per second:   9, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.006040, mae: 0.137618, mean_q: 0.181762\n",
            " 171479/1000000: episode: 244, duration: 105.211s, episode steps: 965, steps per second:   9, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.005965, mae: 0.146801, mean_q: 0.190484\n",
            " 172174/1000000: episode: 245, duration: 75.757s, episode steps: 695, steps per second:   9, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.006097, mae: 0.145239, mean_q: 0.189736\n",
            " 172706/1000000: episode: 246, duration: 58.354s, episode steps: 532, steps per second:   9, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.005878, mae: 0.146550, mean_q: 0.191874\n",
            " 173320/1000000: episode: 247, duration: 66.862s, episode steps: 614, steps per second:   9, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.005228, mae: 0.142930, mean_q: 0.187136\n",
            " 173975/1000000: episode: 248, duration: 71.600s, episode steps: 655, steps per second:   9, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.005363, mae: 0.142828, mean_q: 0.186619\n",
            " 174986/1000000: episode: 249, duration: 110.512s, episode steps: 1011, steps per second:   9, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.005596, mae: 0.144930, mean_q: 0.190015\n",
            " 176164/1000000: episode: 250, duration: 128.587s, episode steps: 1178, steps per second:   9, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.005417, mae: 0.143318, mean_q: 0.188429\n",
            " 176817/1000000: episode: 251, duration: 71.259s, episode steps: 653, steps per second:   9, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.005402, mae: 0.145882, mean_q: 0.192217\n",
            " 177607/1000000: episode: 252, duration: 86.672s, episode steps: 790, steps per second:   9, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.005492, mae: 0.144326, mean_q: 0.189146\n",
            " 178406/1000000: episode: 253, duration: 87.942s, episode steps: 799, steps per second:   9, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.005449, mae: 0.144046, mean_q: 0.190075\n",
            " 179125/1000000: episode: 254, duration: 78.543s, episode steps: 719, steps per second:   9, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.005258, mae: 0.143803, mean_q: 0.189306\n",
            " 180090/1000000: episode: 255, duration: 105.994s, episode steps: 965, steps per second:   9, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.005270, mae: 0.147792, mean_q: 0.194718\n",
            " 180740/1000000: episode: 256, duration: 71.481s, episode steps: 650, steps per second:   9, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.006739, mae: 0.173732, mean_q: 0.227543\n",
            " 181412/1000000: episode: 257, duration: 73.752s, episode steps: 672, steps per second:   9, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.006505, mae: 0.171543, mean_q: 0.224690\n",
            " 182057/1000000: episode: 258, duration: 71.103s, episode steps: 645, steps per second:   9, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.006496, mae: 0.172218, mean_q: 0.225571\n",
            " 182555/1000000: episode: 259, duration: 54.986s, episode steps: 498, steps per second:   9, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.006289, mae: 0.171607, mean_q: 0.224561\n",
            " 183175/1000000: episode: 260, duration: 68.296s, episode steps: 620, steps per second:   9, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.005560, mae: 0.171718, mean_q: 0.224781\n",
            " 183561/1000000: episode: 261, duration: 42.820s, episode steps: 386, steps per second:   9, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.005461, mae: 0.164741, mean_q: 0.215016\n",
            " 184194/1000000: episode: 262, duration: 70.170s, episode steps: 633, steps per second:   9, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.005795, mae: 0.166483, mean_q: 0.217502\n",
            " 185173/1000000: episode: 263, duration: 107.510s, episode steps: 979, steps per second:   9, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.005744, mae: 0.171371, mean_q: 0.225153\n",
            " 185798/1000000: episode: 264, duration: 68.706s, episode steps: 625, steps per second:   9, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.005754, mae: 0.166530, mean_q: 0.217975\n",
            " 187146/1000000: episode: 265, duration: 149.193s, episode steps: 1348, steps per second:   9, episode reward: 14.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.005508, mae: 0.169747, mean_q: 0.223336\n",
            " 187524/1000000: episode: 266, duration: 41.884s, episode steps: 378, steps per second:   9, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.005555, mae: 0.170065, mean_q: 0.223899\n",
            " 188111/1000000: episode: 267, duration: 64.786s, episode steps: 587, steps per second:   9, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.005581, mae: 0.170765, mean_q: 0.223404\n",
            "done, took 10014.145 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 1.000, steps: 566\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3000545209.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# ==== Evaluación ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rl/core.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Select an action.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_recent_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompute_q_values\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_batch_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompute_batch_q_values\u001b[0;34m(self, state_batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_batch_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_state_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4606\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4608\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4609\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4610\u001b[0m         output_structure = tf.nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1482\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                                                run_metadata_ptr)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy  # Inclusión de nueva Policy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# ==== Constantes ====\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "\n",
        "# ==== Procesador para observaciones ====\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3\n",
        "        img = Image.fromarray(observation)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        return batch.astype('float32') / 255.\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "# ==== Preparar entorno ====\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "# ==== Modelo CNN tipo DeepMind ====\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 3, 1), input_shape=input_shape))  # (4, 84, 84) → (84, 84, 4)\n",
        "model.add(Conv2D(32, kernel_size=8, strides=4, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(nb_actions, activation='linear'))\n",
        "\n",
        "# ==== Memoria y política ====\n",
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "policy = BoltzmannQPolicy()\n",
        "\n",
        "# ==== Agente DQN ====\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               memory=memory,\n",
        "               processor=AtariProcessor(),\n",
        "               nb_steps_warmup=100000,\n",
        "               target_model_update=10000,\n",
        "               train_interval=1,\n",
        "               gamma=0.99,\n",
        "               policy=policy , enable_double_dqn= True)\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.00025), metrics=['mae'])\n",
        "\n",
        "# ==== Callbacks ====\n",
        "checkpoint_weights_filename = 'dqn_{}_weights_{{step}}.h5f'.format(ENV_NAME)\n",
        "log_filename = 'dqn_{}_log.json'.format(ENV_NAME)\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000),\n",
        "    FileLogger(log_filename, interval=100)\n",
        "]\n",
        "\n",
        "# ==== Entrenamiento ====\n",
        "dqn.fit(env,\n",
        "        nb_steps=1000000,\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "# ==== Guardar pesos finales ====\n",
        "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
        "\n",
        "# ==== Evaluación ====\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il-LRDGmxZdd",
        "outputId": "84f79724-0a0f-46d2-c881-b705ad2ee75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 1000000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    853/1000000: episode: 1, duration: 4.092s, episode steps: 853, steps per second: 208, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   1373/1000000: episode: 2, duration: 2.421s, episode steps: 520, steps per second: 215, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   1934/1000000: episode: 3, duration: 2.669s, episode steps: 561, steps per second: 210, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   2840/1000000: episode: 4, duration: 4.220s, episode steps: 906, steps per second: 215, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   3464/1000000: episode: 5, duration: 2.921s, episode steps: 624, steps per second: 214, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   4152/1000000: episode: 6, duration: 3.248s, episode steps: 688, steps per second: 212, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   4878/1000000: episode: 7, duration: 3.400s, episode steps: 726, steps per second: 214, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   5755/1000000: episode: 8, duration: 4.081s, episode steps: 877, steps per second: 215, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   6463/1000000: episode: 9, duration: 3.286s, episode steps: 708, steps per second: 215, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   7168/1000000: episode: 10, duration: 3.308s, episode steps: 705, steps per second: 213, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   7628/1000000: episode: 11, duration: 2.147s, episode steps: 460, steps per second: 214, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   8353/1000000: episode: 12, duration: 3.365s, episode steps: 725, steps per second: 215, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   9016/1000000: episode: 13, duration: 3.148s, episode steps: 663, steps per second: 211, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   9846/1000000: episode: 14, duration: 3.931s, episode steps: 830, steps per second: 211, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  10241/1000000: episode: 15, duration: 1.864s, episode steps: 395, steps per second: 212, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  10917/1000000: episode: 16, duration: 3.131s, episode steps: 676, steps per second: 216, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  11627/1000000: episode: 17, duration: 3.288s, episode steps: 710, steps per second: 216, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  12766/1000000: episode: 18, duration: 5.268s, episode steps: 1139, steps per second: 216, episode reward:  9.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  13722/1000000: episode: 19, duration: 4.409s, episode steps: 956, steps per second: 217, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  14473/1000000: episode: 20, duration: 3.528s, episode steps: 751, steps per second: 213, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  15274/1000000: episode: 21, duration: 3.789s, episode steps: 801, steps per second: 211, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  15896/1000000: episode: 22, duration: 2.908s, episode steps: 622, steps per second: 214, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  16380/1000000: episode: 23, duration: 2.240s, episode steps: 484, steps per second: 216, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  16999/1000000: episode: 24, duration: 2.952s, episode steps: 619, steps per second: 210, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  17766/1000000: episode: 25, duration: 3.615s, episode steps: 767, steps per second: 212, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  18494/1000000: episode: 26, duration: 3.401s, episode steps: 728, steps per second: 214, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  19369/1000000: episode: 27, duration: 4.036s, episode steps: 875, steps per second: 217, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  19918/1000000: episode: 28, duration: 2.575s, episode steps: 549, steps per second: 213, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  20441/1000000: episode: 29, duration: 2.418s, episode steps: 523, steps per second: 216, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  21103/1000000: episode: 30, duration: 3.040s, episode steps: 662, steps per second: 218, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  22034/1000000: episode: 31, duration: 4.273s, episode steps: 931, steps per second: 218, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  23158/1000000: episode: 32, duration: 5.215s, episode steps: 1124, steps per second: 216, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  23944/1000000: episode: 33, duration: 3.589s, episode steps: 786, steps per second: 219, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  24511/1000000: episode: 34, duration: 2.636s, episode steps: 567, steps per second: 215, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  25159/1000000: episode: 35, duration: 3.047s, episode steps: 648, steps per second: 213, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  25710/1000000: episode: 36, duration: 2.543s, episode steps: 551, steps per second: 217, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  26504/1000000: episode: 37, duration: 3.647s, episode steps: 794, steps per second: 218, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  27234/1000000: episode: 38, duration: 3.358s, episode steps: 730, steps per second: 217, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  28134/1000000: episode: 39, duration: 4.211s, episode steps: 900, steps per second: 214, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  28840/1000000: episode: 40, duration: 3.205s, episode steps: 706, steps per second: 220, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  29506/1000000: episode: 41, duration: 3.010s, episode steps: 666, steps per second: 221, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  30288/1000000: episode: 42, duration: 3.584s, episode steps: 782, steps per second: 218, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  30970/1000000: episode: 43, duration: 3.154s, episode steps: 682, steps per second: 216, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  31479/1000000: episode: 44, duration: 2.323s, episode steps: 509, steps per second: 219, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  32047/1000000: episode: 45, duration: 2.609s, episode steps: 568, steps per second: 218, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  32442/1000000: episode: 46, duration: 1.813s, episode steps: 395, steps per second: 218, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  33106/1000000: episode: 47, duration: 3.103s, episode steps: 664, steps per second: 214, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  33614/1000000: episode: 48, duration: 2.341s, episode steps: 508, steps per second: 217, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  34117/1000000: episode: 49, duration: 2.306s, episode steps: 503, steps per second: 218, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  35551/1000000: episode: 50, duration: 6.556s, episode steps: 1434, steps per second: 219, episode reward: 12.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  36161/1000000: episode: 51, duration: 2.790s, episode steps: 610, steps per second: 219, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  36615/1000000: episode: 52, duration: 2.072s, episode steps: 454, steps per second: 219, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  37009/1000000: episode: 53, duration: 1.803s, episode steps: 394, steps per second: 219, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  37614/1000000: episode: 54, duration: 2.775s, episode steps: 605, steps per second: 218, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  38236/1000000: episode: 55, duration: 2.974s, episode steps: 622, steps per second: 209, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  38871/1000000: episode: 56, duration: 2.920s, episode steps: 635, steps per second: 217, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  39608/1000000: episode: 57, duration: 3.365s, episode steps: 737, steps per second: 219, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  40386/1000000: episode: 58, duration: 3.585s, episode steps: 778, steps per second: 217, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  41145/1000000: episode: 59, duration: 3.532s, episode steps: 759, steps per second: 215, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  41827/1000000: episode: 60, duration: 3.101s, episode steps: 682, steps per second: 220, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  42202/1000000: episode: 61, duration: 1.709s, episode steps: 375, steps per second: 219, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  43096/1000000: episode: 62, duration: 4.107s, episode steps: 894, steps per second: 218, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  43709/1000000: episode: 63, duration: 2.861s, episode steps: 613, steps per second: 214, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  44328/1000000: episode: 64, duration: 2.853s, episode steps: 619, steps per second: 217, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  45059/1000000: episode: 65, duration: 3.330s, episode steps: 731, steps per second: 219, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  46147/1000000: episode: 66, duration: 5.023s, episode steps: 1088, steps per second: 217, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  46647/1000000: episode: 67, duration: 2.274s, episode steps: 500, steps per second: 220, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  47607/1000000: episode: 68, duration: 4.295s, episode steps: 960, steps per second: 224, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  48447/1000000: episode: 69, duration: 3.929s, episode steps: 840, steps per second: 214, episode reward:  4.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  49438/1000000: episode: 70, duration: 4.523s, episode steps: 991, steps per second: 219, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  49835/1000000: episode: 71, duration: 1.812s, episode steps: 397, steps per second: 219, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  51168/1000000: episode: 72, duration: 50.369s, episode steps: 1333, steps per second:  26, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.006327, mae: 0.012898, mean_q: 0.017487\n",
            "  52134/1000000: episode: 73, duration: 40.793s, episode steps: 966, steps per second:  24, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.006161, mae: 0.010764, mean_q: 0.006768\n",
            "  52624/1000000: episode: 74, duration: 20.605s, episode steps: 490, steps per second:  24, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.005821, mae: 0.009911, mean_q: 0.006173\n",
            "  53390/1000000: episode: 75, duration: 32.405s, episode steps: 766, steps per second:  24, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.008093, mae: 0.012189, mean_q: 0.006051\n",
            "  53915/1000000: episode: 76, duration: 22.288s, episode steps: 525, steps per second:  24, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.006770, mae: 0.011618, mean_q: 0.009969\n",
            "  54703/1000000: episode: 77, duration: 33.518s, episode steps: 788, steps per second:  24, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.007831, mae: 0.011632, mean_q: 0.009493\n",
            "  55201/1000000: episode: 78, duration: 21.246s, episode steps: 498, steps per second:  23, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.005744, mae: 0.010054, mean_q: 0.004503\n",
            "  55851/1000000: episode: 79, duration: 27.648s, episode steps: 650, steps per second:  24, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.006964, mae: 0.013065, mean_q: 0.004815\n",
            "  56345/1000000: episode: 80, duration: 21.221s, episode steps: 494, steps per second:  23, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.007240, mae: 0.011670, mean_q: 0.009353\n",
            "  56945/1000000: episode: 81, duration: 25.763s, episode steps: 600, steps per second:  23, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.007261, mae: 0.011038, mean_q: 0.011220\n",
            "  57361/1000000: episode: 82, duration: 17.743s, episode steps: 416, steps per second:  23, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.005550, mae: 0.015109, mean_q: 0.007984\n",
            "  57986/1000000: episode: 83, duration: 26.792s, episode steps: 625, steps per second:  23, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.006197, mae: 0.012178, mean_q: 0.008001\n",
            "  58366/1000000: episode: 84, duration: 16.532s, episode steps: 380, steps per second:  23, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.007648, mae: 0.010544, mean_q: 0.007181\n",
            "  58908/1000000: episode: 85, duration: 23.683s, episode steps: 542, steps per second:  23, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.007688, mae: 0.013680, mean_q: 0.004403\n",
            "  59311/1000000: episode: 86, duration: 17.466s, episode steps: 403, steps per second:  23, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.008701, mae: 0.011872, mean_q: 0.010505\n",
            "  59820/1000000: episode: 87, duration: 22.121s, episode steps: 509, steps per second:  23, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.006827, mae: 0.011803, mean_q: 0.012018\n",
            "  60303/1000000: episode: 88, duration: 21.010s, episode steps: 483, steps per second:  23, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.008445, mae: 0.016631, mean_q: 0.014009\n",
            "  60816/1000000: episode: 89, duration: 22.401s, episode steps: 513, steps per second:  23, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.005446, mae: 0.015215, mean_q: 0.015225\n",
            "  61362/1000000: episode: 90, duration: 23.815s, episode steps: 546, steps per second:  23, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.007635, mae: 0.017625, mean_q: 0.021449\n",
            "  61998/1000000: episode: 91, duration: 27.745s, episode steps: 636, steps per second:  23, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.006974, mae: 0.016765, mean_q: 0.017574\n",
            "  62623/1000000: episode: 92, duration: 27.133s, episode steps: 625, steps per second:  23, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.006744, mae: 0.018986, mean_q: 0.021315\n",
            "  63384/1000000: episode: 93, duration: 33.347s, episode steps: 761, steps per second:  23, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007132, mae: 0.019933, mean_q: 0.018876\n",
            "  64192/1000000: episode: 94, duration: 35.405s, episode steps: 808, steps per second:  23, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.006120, mae: 0.017988, mean_q: 0.017990\n",
            "  64835/1000000: episode: 95, duration: 28.061s, episode steps: 643, steps per second:  23, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.006027, mae: 0.018171, mean_q: 0.017420\n",
            "  65489/1000000: episode: 96, duration: 28.898s, episode steps: 654, steps per second:  23, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.005553, mae: 0.015901, mean_q: 0.014950\n",
            "  65884/1000000: episode: 97, duration: 17.413s, episode steps: 395, steps per second:  23, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.006432, mae: 0.017402, mean_q: 0.015982\n",
            "  66560/1000000: episode: 98, duration: 29.950s, episode steps: 676, steps per second:  23, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.005893, mae: 0.017697, mean_q: 0.017247\n",
            "  67110/1000000: episode: 99, duration: 24.311s, episode steps: 550, steps per second:  23, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.005464, mae: 0.016386, mean_q: 0.016284\n",
            "  67909/1000000: episode: 100, duration: 35.162s, episode steps: 799, steps per second:  23, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.007349, mae: 0.020180, mean_q: 0.019777\n",
            "  68628/1000000: episode: 101, duration: 31.584s, episode steps: 719, steps per second:  23, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.007667, mae: 0.018693, mean_q: 0.021457\n",
            "  69687/1000000: episode: 102, duration: 46.696s, episode steps: 1059, steps per second:  23, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.006711, mae: 0.019417, mean_q: 0.021066\n",
            "  70391/1000000: episode: 103, duration: 31.109s, episode steps: 704, steps per second:  23, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.005117, mae: 0.019655, mean_q: 0.024323\n",
            "  70781/1000000: episode: 104, duration: 17.246s, episode steps: 390, steps per second:  23, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007543, mae: 0.029660, mean_q: 0.037376\n",
            "  71986/1000000: episode: 105, duration: 53.268s, episode steps: 1205, steps per second:  23, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.007235, mae: 0.029945, mean_q: 0.039344\n",
            "  72789/1000000: episode: 106, duration: 35.737s, episode steps: 803, steps per second:  22, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.007071, mae: 0.028820, mean_q: 0.040129\n",
            "  73296/1000000: episode: 107, duration: 22.492s, episode steps: 507, steps per second:  23, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.007313, mae: 0.030174, mean_q: 0.038538\n",
            "  74124/1000000: episode: 108, duration: 36.973s, episode steps: 828, steps per second:  22, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.007129, mae: 0.030718, mean_q: 0.038761\n",
            "  74716/1000000: episode: 109, duration: 26.495s, episode steps: 592, steps per second:  22, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.006971, mae: 0.029312, mean_q: 0.037545\n",
            "  75119/1000000: episode: 110, duration: 17.859s, episode steps: 403, steps per second:  23, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.007548, mae: 0.028509, mean_q: 0.035646\n",
            "  75929/1000000: episode: 111, duration: 36.213s, episode steps: 810, steps per second:  22, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.007024, mae: 0.028012, mean_q: 0.035476\n",
            "  76499/1000000: episode: 112, duration: 25.244s, episode steps: 570, steps per second:  23, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.006152, mae: 0.027754, mean_q: 0.036405\n",
            "  77070/1000000: episode: 113, duration: 25.350s, episode steps: 571, steps per second:  23, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.007880, mae: 0.030548, mean_q: 0.038601\n",
            "  77820/1000000: episode: 114, duration: 33.528s, episode steps: 750, steps per second:  22, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.005696, mae: 0.027225, mean_q: 0.036123\n",
            "  78489/1000000: episode: 115, duration: 30.152s, episode steps: 669, steps per second:  22, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.007088, mae: 0.029270, mean_q: 0.036220\n",
            "  79270/1000000: episode: 116, duration: 34.996s, episode steps: 781, steps per second:  22, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.006745, mae: 0.028331, mean_q: 0.037384\n",
            "  79845/1000000: episode: 117, duration: 26.014s, episode steps: 575, steps per second:  22, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006892, mae: 0.029679, mean_q: 0.038321\n",
            "  80908/1000000: episode: 118, duration: 47.627s, episode steps: 1063, steps per second:  22, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.006248, mae: 0.036182, mean_q: 0.046584\n",
            "  82062/1000000: episode: 119, duration: 51.576s, episode steps: 1154, steps per second:  22, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.005430, mae: 0.036504, mean_q: 0.047874\n",
            "  82751/1000000: episode: 120, duration: 30.840s, episode steps: 689, steps per second:  22, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.007257, mae: 0.041666, mean_q: 0.053857\n",
            "  83230/1000000: episode: 121, duration: 21.452s, episode steps: 479, steps per second:  22, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.006085, mae: 0.037147, mean_q: 0.050951\n",
            "  83941/1000000: episode: 122, duration: 32.017s, episode steps: 711, steps per second:  22, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.006778, mae: 0.037996, mean_q: 0.050351\n",
            "  84510/1000000: episode: 123, duration: 25.505s, episode steps: 569, steps per second:  22, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.008158, mae: 0.042903, mean_q: 0.053964\n",
            "  85264/1000000: episode: 124, duration: 34.117s, episode steps: 754, steps per second:  22, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.006465, mae: 0.038038, mean_q: 0.052976\n",
            "  85927/1000000: episode: 125, duration: 29.943s, episode steps: 663, steps per second:  22, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.007192, mae: 0.039725, mean_q: 0.051943\n",
            "  86434/1000000: episode: 126, duration: 23.010s, episode steps: 507, steps per second:  22, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.006108, mae: 0.037494, mean_q: 0.050883\n",
            "  86918/1000000: episode: 127, duration: 21.901s, episode steps: 484, steps per second:  22, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.006336, mae: 0.039577, mean_q: 0.051830\n",
            "  87438/1000000: episode: 128, duration: 23.396s, episode steps: 520, steps per second:  22, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.007553, mae: 0.040809, mean_q: 0.052823\n",
            "  88226/1000000: episode: 129, duration: 35.349s, episode steps: 788, steps per second:  22, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.006934, mae: 0.040906, mean_q: 0.054131\n",
            "  88962/1000000: episode: 130, duration: 33.069s, episode steps: 736, steps per second:  22, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.006666, mae: 0.039717, mean_q: 0.051086\n",
            "  89943/1000000: episode: 131, duration: 43.909s, episode steps: 981, steps per second:  22, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.006910, mae: 0.040600, mean_q: 0.054986\n",
            "  90461/1000000: episode: 132, duration: 23.394s, episode steps: 518, steps per second:  22, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.006633, mae: 0.056998, mean_q: 0.075899\n",
            "  91161/1000000: episode: 133, duration: 31.578s, episode steps: 700, steps per second:  22, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.005640, mae: 0.056274, mean_q: 0.075949\n",
            "  91859/1000000: episode: 134, duration: 31.552s, episode steps: 698, steps per second:  22, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.006122, mae: 0.057216, mean_q: 0.078604\n",
            "  92593/1000000: episode: 135, duration: 33.222s, episode steps: 734, steps per second:  22, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.005222, mae: 0.054646, mean_q: 0.074644\n",
            "  93512/1000000: episode: 136, duration: 41.573s, episode steps: 919, steps per second:  22, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006843, mae: 0.058248, mean_q: 0.077624\n",
            "  94124/1000000: episode: 137, duration: 27.803s, episode steps: 612, steps per second:  22, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.006042, mae: 0.054353, mean_q: 0.071748\n",
            "  94604/1000000: episode: 138, duration: 21.782s, episode steps: 480, steps per second:  22, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.005495, mae: 0.054946, mean_q: 0.074044\n",
            "  95097/1000000: episode: 139, duration: 22.309s, episode steps: 493, steps per second:  22, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.005110, mae: 0.052824, mean_q: 0.069838\n",
            "  95879/1000000: episode: 140, duration: 35.310s, episode steps: 782, steps per second:  22, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.005858, mae: 0.054088, mean_q: 0.071576\n",
            "  96286/1000000: episode: 141, duration: 18.359s, episode steps: 407, steps per second:  22, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.004785, mae: 0.051903, mean_q: 0.070686\n",
            "  97187/1000000: episode: 142, duration: 40.722s, episode steps: 901, steps per second:  22, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.005646, mae: 0.054860, mean_q: 0.073881\n",
            "  97702/1000000: episode: 143, duration: 23.290s, episode steps: 515, steps per second:  22, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.005202, mae: 0.054377, mean_q: 0.074740\n",
            "  98607/1000000: episode: 144, duration: 40.907s, episode steps: 905, steps per second:  22, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006366, mae: 0.056920, mean_q: 0.073530\n",
            "  99313/1000000: episode: 145, duration: 32.143s, episode steps: 706, steps per second:  22, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.005727, mae: 0.051722, mean_q: 0.069100\n",
            "  99993/1000000: episode: 146, duration: 30.867s, episode steps: 680, steps per second:  22, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.005513, mae: 0.055872, mean_q: 0.073194\n",
            " 100518/1000000: episode: 147, duration: 23.936s, episode steps: 525, steps per second:  22, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.006039, mae: 0.068564, mean_q: 0.088927\n",
            " 100935/1000000: episode: 148, duration: 18.960s, episode steps: 417, steps per second:  22, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.007641, mae: 0.072284, mean_q: 0.093680\n",
            " 101767/1000000: episode: 149, duration: 37.769s, episode steps: 832, steps per second:  22, episode reward:  6.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006714, mae: 0.069250, mean_q: 0.091634\n",
            " 102613/1000000: episode: 150, duration: 38.605s, episode steps: 846, steps per second:  22, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.007032, mae: 0.069403, mean_q: 0.091157\n",
            " 103163/1000000: episode: 151, duration: 25.101s, episode steps: 550, steps per second:  22, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.008023, mae: 0.074307, mean_q: 0.098240\n",
            " 103545/1000000: episode: 152, duration: 17.535s, episode steps: 382, steps per second:  22, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.006247, mae: 0.069420, mean_q: 0.091518\n",
            " 104074/1000000: episode: 153, duration: 23.874s, episode steps: 529, steps per second:  22, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.005529, mae: 0.066832, mean_q: 0.090015\n",
            " 104918/1000000: episode: 154, duration: 38.484s, episode steps: 844, steps per second:  22, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.007442, mae: 0.071115, mean_q: 0.095766\n",
            " 105555/1000000: episode: 155, duration: 29.801s, episode steps: 637, steps per second:  21, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.006014, mae: 0.069551, mean_q: 0.093885\n",
            " 106127/1000000: episode: 156, duration: 26.972s, episode steps: 572, steps per second:  21, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.006530, mae: 0.069154, mean_q: 0.091968\n",
            " 106762/1000000: episode: 157, duration: 29.543s, episode steps: 635, steps per second:  21, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.006766, mae: 0.071096, mean_q: 0.096741\n",
            " 107322/1000000: episode: 158, duration: 25.856s, episode steps: 560, steps per second:  22, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.005664, mae: 0.068728, mean_q: 0.093760\n",
            " 108243/1000000: episode: 159, duration: 42.636s, episode steps: 921, steps per second:  22, episode reward:  6.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.006441, mae: 0.069932, mean_q: 0.094378\n",
            " 108642/1000000: episode: 160, duration: 18.321s, episode steps: 399, steps per second:  22, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.006276, mae: 0.069401, mean_q: 0.091852\n",
            " 109357/1000000: episode: 161, duration: 32.931s, episode steps: 715, steps per second:  22, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006420, mae: 0.068284, mean_q: 0.091875\n",
            " 110363/1000000: episode: 162, duration: 46.067s, episode steps: 1006, steps per second:  22, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.006757, mae: 0.082656, mean_q: 0.109695\n",
            " 111368/1000000: episode: 163, duration: 46.389s, episode steps: 1005, steps per second:  22, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.007371, mae: 0.104083, mean_q: 0.139037\n",
            " 112102/1000000: episode: 164, duration: 33.831s, episode steps: 734, steps per second:  22, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006080, mae: 0.098449, mean_q: 0.130930\n",
            " 112775/1000000: episode: 165, duration: 30.822s, episode steps: 673, steps per second:  22, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.006546, mae: 0.100638, mean_q: 0.132775\n",
            " 113272/1000000: episode: 166, duration: 22.974s, episode steps: 497, steps per second:  22, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006349, mae: 0.097958, mean_q: 0.128270\n",
            " 113968/1000000: episode: 167, duration: 32.709s, episode steps: 696, steps per second:  21, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.005243, mae: 0.097539, mean_q: 0.127223\n",
            " 114722/1000000: episode: 168, duration: 35.095s, episode steps: 754, steps per second:  21, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.006075, mae: 0.097745, mean_q: 0.125742\n",
            " 115218/1000000: episode: 169, duration: 23.069s, episode steps: 496, steps per second:  22, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.005918, mae: 0.097313, mean_q: 0.125651\n",
            " 116169/1000000: episode: 170, duration: 44.654s, episode steps: 951, steps per second:  21, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.006454, mae: 0.098910, mean_q: 0.127591\n",
            " 117457/1000000: episode: 171, duration: 59.995s, episode steps: 1288, steps per second:  21, episode reward: 21.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.006131, mae: 0.098457, mean_q: 0.128387\n",
            " 118007/1000000: episode: 172, duration: 25.388s, episode steps: 550, steps per second:  22, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.006558, mae: 0.099508, mean_q: 0.129007\n",
            " 118716/1000000: episode: 173, duration: 32.660s, episode steps: 709, steps per second:  22, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006332, mae: 0.101295, mean_q: 0.130623\n",
            " 119084/1000000: episode: 174, duration: 17.087s, episode steps: 368, steps per second:  22, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.005567, mae: 0.094986, mean_q: 0.124036\n",
            " 119830/1000000: episode: 175, duration: 34.325s, episode steps: 746, steps per second:  22, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.005513, mae: 0.100272, mean_q: 0.130726\n",
            " 120392/1000000: episode: 176, duration: 26.039s, episode steps: 562, steps per second:  22, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.006210, mae: 0.107714, mean_q: 0.138835\n",
            " 120768/1000000: episode: 177, duration: 17.476s, episode steps: 376, steps per second:  22, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.008130, mae: 0.114256, mean_q: 0.146770\n",
            " 121329/1000000: episode: 178, duration: 26.076s, episode steps: 561, steps per second:  22, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.006263, mae: 0.111718, mean_q: 0.145103\n",
            " 121981/1000000: episode: 179, duration: 30.121s, episode steps: 652, steps per second:  22, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.006836, mae: 0.110185, mean_q: 0.142866\n",
            " 122698/1000000: episode: 180, duration: 32.978s, episode steps: 717, steps per second:  22, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.006172, mae: 0.110751, mean_q: 0.145456\n",
            " 123384/1000000: episode: 181, duration: 31.801s, episode steps: 686, steps per second:  22, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.006201, mae: 0.109345, mean_q: 0.141951\n",
            " 124162/1000000: episode: 182, duration: 36.075s, episode steps: 778, steps per second:  22, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.006391, mae: 0.112834, mean_q: 0.145889\n",
            " 125089/1000000: episode: 183, duration: 42.872s, episode steps: 927, steps per second:  22, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.005531, mae: 0.106944, mean_q: 0.138937\n",
            " 125479/1000000: episode: 184, duration: 17.926s, episode steps: 390, steps per second:  22, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007530, mae: 0.112146, mean_q: 0.142948\n",
            " 125982/1000000: episode: 185, duration: 23.328s, episode steps: 503, steps per second:  22, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.006830, mae: 0.112682, mean_q: 0.146922\n",
            " 126786/1000000: episode: 186, duration: 37.133s, episode steps: 804, steps per second:  22, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.006118, mae: 0.110376, mean_q: 0.143008\n",
            " 127343/1000000: episode: 187, duration: 26.000s, episode steps: 557, steps per second:  21, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.005300, mae: 0.107523, mean_q: 0.138896\n",
            " 127949/1000000: episode: 188, duration: 28.107s, episode steps: 606, steps per second:  22, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.006676, mae: 0.108873, mean_q: 0.140332\n",
            " 128334/1000000: episode: 189, duration: 17.770s, episode steps: 385, steps per second:  22, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.006187, mae: 0.112328, mean_q: 0.144080\n",
            " 128825/1000000: episode: 190, duration: 22.828s, episode steps: 491, steps per second:  22, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.007009, mae: 0.110568, mean_q: 0.144661\n",
            " 129218/1000000: episode: 191, duration: 18.219s, episode steps: 393, steps per second:  22, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.005372, mae: 0.105198, mean_q: 0.138768\n",
            " 130026/1000000: episode: 192, duration: 37.480s, episode steps: 808, steps per second:  22, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.005903, mae: 0.108648, mean_q: 0.139499\n",
            " 130533/1000000: episode: 193, duration: 23.580s, episode steps: 507, steps per second:  22, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.006605, mae: 0.135906, mean_q: 0.173501\n",
            " 131371/1000000: episode: 194, duration: 38.858s, episode steps: 838, steps per second:  22, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006329, mae: 0.132378, mean_q: 0.168232\n",
            " 132041/1000000: episode: 195, duration: 31.331s, episode steps: 670, steps per second:  21, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.006167, mae: 0.131828, mean_q: 0.167774\n",
            " 132562/1000000: episode: 196, duration: 24.124s, episode steps: 521, steps per second:  22, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.005935, mae: 0.133647, mean_q: 0.168735\n",
            " 133523/1000000: episode: 197, duration: 44.575s, episode steps: 961, steps per second:  22, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.006296, mae: 0.133035, mean_q: 0.170159\n",
            " 134236/1000000: episode: 198, duration: 33.217s, episode steps: 713, steps per second:  21, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.005872, mae: 0.132996, mean_q: 0.170324\n",
            " 134888/1000000: episode: 199, duration: 30.486s, episode steps: 652, steps per second:  21, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.006594, mae: 0.135223, mean_q: 0.173784\n",
            " 135367/1000000: episode: 200, duration: 22.313s, episode steps: 479, steps per second:  21, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.008289, mae: 0.141836, mean_q: 0.181888\n",
            " 135885/1000000: episode: 201, duration: 24.210s, episode steps: 518, steps per second:  21, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.005831, mae: 0.132892, mean_q: 0.170429\n",
            " 137282/1000000: episode: 202, duration: 65.005s, episode steps: 1397, steps per second:  21, episode reward: 14.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.005588, mae: 0.134886, mean_q: 0.173031\n",
            " 137705/1000000: episode: 203, duration: 19.844s, episode steps: 423, steps per second:  21, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.005018, mae: 0.127970, mean_q: 0.166421\n",
            " 138282/1000000: episode: 204, duration: 26.832s, episode steps: 577, steps per second:  22, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.005766, mae: 0.130268, mean_q: 0.169088\n",
            " 139004/1000000: episode: 205, duration: 33.912s, episode steps: 722, steps per second:  21, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.006179, mae: 0.132847, mean_q: 0.171470\n",
            " 139785/1000000: episode: 206, duration: 36.549s, episode steps: 781, steps per second:  21, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.006877, mae: 0.133359, mean_q: 0.171704\n",
            " 140371/1000000: episode: 207, duration: 27.375s, episode steps: 586, steps per second:  21, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.005252, mae: 0.144214, mean_q: 0.186057\n",
            " 141083/1000000: episode: 208, duration: 33.359s, episode steps: 712, steps per second:  21, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.006643, mae: 0.151967, mean_q: 0.194525\n",
            " 141993/1000000: episode: 209, duration: 42.657s, episode steps: 910, steps per second:  21, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006680, mae: 0.145714, mean_q: 0.190034\n",
            " 142997/1000000: episode: 210, duration: 47.082s, episode steps: 1004, steps per second:  21, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006423, mae: 0.152430, mean_q: 0.196676\n",
            " 143417/1000000: episode: 211, duration: 19.788s, episode steps: 420, steps per second:  21, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.005812, mae: 0.148300, mean_q: 0.188409\n",
            " 143837/1000000: episode: 212, duration: 19.715s, episode steps: 420, steps per second:  21, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.005882, mae: 0.148345, mean_q: 0.189496\n",
            " 145018/1000000: episode: 213, duration: 55.302s, episode steps: 1181, steps per second:  21, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.006434, mae: 0.147735, mean_q: 0.188810\n",
            " 145418/1000000: episode: 214, duration: 18.785s, episode steps: 400, steps per second:  21, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.005877, mae: 0.147459, mean_q: 0.189278\n",
            " 146394/1000000: episode: 215, duration: 45.607s, episode steps: 976, steps per second:  21, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.005652, mae: 0.148458, mean_q: 0.189450\n",
            " 147277/1000000: episode: 216, duration: 41.546s, episode steps: 883, steps per second:  21, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.004675, mae: 0.148289, mean_q: 0.190147\n",
            " 147912/1000000: episode: 217, duration: 29.845s, episode steps: 635, steps per second:  21, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.006745, mae: 0.151814, mean_q: 0.192419\n",
            " 148454/1000000: episode: 218, duration: 25.617s, episode steps: 542, steps per second:  21, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.005884, mae: 0.145916, mean_q: 0.186559\n",
            " 149317/1000000: episode: 219, duration: 40.726s, episode steps: 863, steps per second:  21, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.006740, mae: 0.151045, mean_q: 0.193177\n",
            " 149773/1000000: episode: 220, duration: 21.406s, episode steps: 456, steps per second:  21, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.005096, mae: 0.145549, mean_q: 0.187254\n",
            " 150577/1000000: episode: 221, duration: 37.568s, episode steps: 804, steps per second:  21, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.006400, mae: 0.160274, mean_q: 0.206933\n",
            " 151662/1000000: episode: 222, duration: 51.089s, episode steps: 1085, steps per second:  21, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.006596, mae: 0.162479, mean_q: 0.208406\n",
            " 152287/1000000: episode: 223, duration: 29.569s, episode steps: 625, steps per second:  21, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.006228, mae: 0.160100, mean_q: 0.206538\n",
            " 152649/1000000: episode: 224, duration: 17.089s, episode steps: 362, steps per second:  21, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.005200, mae: 0.156062, mean_q: 0.198938\n",
            " 153288/1000000: episode: 225, duration: 30.222s, episode steps: 639, steps per second:  21, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.006133, mae: 0.160563, mean_q: 0.205142\n",
            " 153885/1000000: episode: 226, duration: 28.351s, episode steps: 597, steps per second:  21, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.005600, mae: 0.158086, mean_q: 0.200756\n",
            " 154280/1000000: episode: 227, duration: 18.793s, episode steps: 395, steps per second:  21, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.008775, mae: 0.168692, mean_q: 0.215218\n",
            " 155085/1000000: episode: 228, duration: 38.212s, episode steps: 805, steps per second:  21, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.007640, mae: 0.168637, mean_q: 0.213741\n",
            " 155605/1000000: episode: 229, duration: 24.654s, episode steps: 520, steps per second:  21, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.006498, mae: 0.157132, mean_q: 0.199576\n",
            " 156465/1000000: episode: 230, duration: 40.741s, episode steps: 860, steps per second:  21, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006291, mae: 0.159227, mean_q: 0.203537\n",
            " 157211/1000000: episode: 231, duration: 35.415s, episode steps: 746, steps per second:  21, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006946, mae: 0.158383, mean_q: 0.202323\n",
            " 157772/1000000: episode: 232, duration: 27.079s, episode steps: 561, steps per second:  21, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.006095, mae: 0.157917, mean_q: 0.201201\n",
            " 158243/1000000: episode: 233, duration: 22.470s, episode steps: 471, steps per second:  21, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.005712, mae: 0.160049, mean_q: 0.205438\n",
            " 159163/1000000: episode: 234, duration: 44.076s, episode steps: 920, steps per second:  21, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.006424, mae: 0.162339, mean_q: 0.208065\n",
            " 159999/1000000: episode: 235, duration: 39.891s, episode steps: 836, steps per second:  21, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.007144, mae: 0.162482, mean_q: 0.207459\n",
            " 160640/1000000: episode: 236, duration: 31.089s, episode steps: 641, steps per second:  21, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.007614, mae: 0.178751, mean_q: 0.228348\n",
            " 161603/1000000: episode: 237, duration: 46.302s, episode steps: 963, steps per second:  21, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.005265, mae: 0.172707, mean_q: 0.220959\n",
            " 162260/1000000: episode: 238, duration: 31.482s, episode steps: 657, steps per second:  21, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006006, mae: 0.181157, mean_q: 0.230504\n",
            " 162805/1000000: episode: 239, duration: 26.140s, episode steps: 545, steps per second:  21, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.007731, mae: 0.183426, mean_q: 0.233630\n",
            " 163677/1000000: episode: 240, duration: 41.481s, episode steps: 872, steps per second:  21, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.006816, mae: 0.175881, mean_q: 0.223538\n",
            " 164507/1000000: episode: 241, duration: 39.551s, episode steps: 830, steps per second:  21, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006191, mae: 0.175310, mean_q: 0.223167\n",
            " 165207/1000000: episode: 242, duration: 33.231s, episode steps: 700, steps per second:  21, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.005915, mae: 0.175118, mean_q: 0.222482\n",
            " 165897/1000000: episode: 243, duration: 33.087s, episode steps: 690, steps per second:  21, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.005263, mae: 0.169310, mean_q: 0.214136\n",
            " 166429/1000000: episode: 244, duration: 25.422s, episode steps: 532, steps per second:  21, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.006246, mae: 0.171310, mean_q: 0.216830\n",
            " 167116/1000000: episode: 245, duration: 33.117s, episode steps: 687, steps per second:  21, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006387, mae: 0.177364, mean_q: 0.223921\n",
            " 167993/1000000: episode: 246, duration: 42.092s, episode steps: 877, steps per second:  21, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.007287, mae: 0.174917, mean_q: 0.222238\n",
            " 168591/1000000: episode: 247, duration: 28.502s, episode steps: 598, steps per second:  21, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.006650, mae: 0.175084, mean_q: 0.222626\n",
            " 169169/1000000: episode: 248, duration: 27.724s, episode steps: 578, steps per second:  21, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.005642, mae: 0.171016, mean_q: 0.217145\n",
            " 170099/1000000: episode: 249, duration: 44.349s, episode steps: 930, steps per second:  21, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.005717, mae: 0.174269, mean_q: 0.219656\n",
            " 170759/1000000: episode: 250, duration: 31.437s, episode steps: 660, steps per second:  21, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.005719, mae: 0.187736, mean_q: 0.236653\n",
            " 171439/1000000: episode: 251, duration: 32.622s, episode steps: 680, steps per second:  21, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.008026, mae: 0.191122, mean_q: 0.242394\n",
            " 172253/1000000: episode: 252, duration: 38.913s, episode steps: 814, steps per second:  21, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.006640, mae: 0.185152, mean_q: 0.234909\n",
            " 172914/1000000: episode: 253, duration: 31.626s, episode steps: 661, steps per second:  21, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006599, mae: 0.191245, mean_q: 0.241774\n",
            " 173608/1000000: episode: 254, duration: 33.479s, episode steps: 694, steps per second:  21, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.005804, mae: 0.188319, mean_q: 0.239442\n",
            " 174567/1000000: episode: 255, duration: 46.147s, episode steps: 959, steps per second:  21, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.005258, mae: 0.182456, mean_q: 0.232145\n",
            " 174973/1000000: episode: 256, duration: 19.673s, episode steps: 406, steps per second:  21, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.006865, mae: 0.187072, mean_q: 0.238034\n",
            " 175543/1000000: episode: 257, duration: 27.353s, episode steps: 570, steps per second:  21, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.006615, mae: 0.185232, mean_q: 0.234831\n",
            " 176147/1000000: episode: 258, duration: 28.983s, episode steps: 604, steps per second:  21, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.005743, mae: 0.184620, mean_q: 0.234425\n",
            " 177101/1000000: episode: 259, duration: 45.948s, episode steps: 954, steps per second:  21, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.005543, mae: 0.183796, mean_q: 0.233964\n",
            " 177880/1000000: episode: 260, duration: 37.441s, episode steps: 779, steps per second:  21, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.006640, mae: 0.189282, mean_q: 0.239335\n",
            " 178925/1000000: episode: 261, duration: 50.699s, episode steps: 1045, steps per second:  21, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.005943, mae: 0.188755, mean_q: 0.239696\n",
            " 180078/1000000: episode: 262, duration: 55.495s, episode steps: 1153, steps per second:  21, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.005903, mae: 0.187339, mean_q: 0.239017\n",
            " 180665/1000000: episode: 263, duration: 28.213s, episode steps: 587, steps per second:  21, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006224, mae: 0.216082, mean_q: 0.273217\n",
            " 181290/1000000: episode: 264, duration: 29.967s, episode steps: 625, steps per second:  21, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.006783, mae: 0.208521, mean_q: 0.264789\n",
            " 181967/1000000: episode: 265, duration: 32.615s, episode steps: 677, steps per second:  21, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006695, mae: 0.211179, mean_q: 0.267466\n",
            " 182350/1000000: episode: 266, duration: 18.522s, episode steps: 383, steps per second:  21, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.006244, mae: 0.205925, mean_q: 0.261806\n",
            " 183651/1000000: episode: 267, duration: 62.606s, episode steps: 1301, steps per second:  21, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.006581, mae: 0.206432, mean_q: 0.260921\n",
            " 184444/1000000: episode: 268, duration: 39.069s, episode steps: 793, steps per second:  20, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.005437, mae: 0.203901, mean_q: 0.258127\n",
            " 184844/1000000: episode: 269, duration: 19.887s, episode steps: 400, steps per second:  20, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.005786, mae: 0.207906, mean_q: 0.262440\n",
            " 185670/1000000: episode: 270, duration: 40.316s, episode steps: 826, steps per second:  20, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.007306, mae: 0.212242, mean_q: 0.266708\n",
            " 186368/1000000: episode: 271, duration: 34.203s, episode steps: 698, steps per second:  20, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.006766, mae: 0.212301, mean_q: 0.266651\n",
            " 186756/1000000: episode: 272, duration: 19.080s, episode steps: 388, steps per second:  20, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.006567, mae: 0.205660, mean_q: 0.258844\n",
            " 187439/1000000: episode: 273, duration: 33.064s, episode steps: 683, steps per second:  21, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.006253, mae: 0.204249, mean_q: 0.257246\n",
            " 188206/1000000: episode: 274, duration: 37.252s, episode steps: 767, steps per second:  21, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.007885, mae: 0.212481, mean_q: 0.269840\n",
            " 188773/1000000: episode: 275, duration: 27.572s, episode steps: 567, steps per second:  21, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.006015, mae: 0.202903, mean_q: 0.257773\n",
            " 189171/1000000: episode: 276, duration: 19.160s, episode steps: 398, steps per second:  21, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.007723, mae: 0.207828, mean_q: 0.263351\n",
            " 189779/1000000: episode: 277, duration: 29.493s, episode steps: 608, steps per second:  21, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.694 [0.000, 5.000],  loss: 0.006915, mae: 0.208400, mean_q: 0.265243\n",
            " 190388/1000000: episode: 278, duration: 29.719s, episode steps: 609, steps per second:  20, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.006389, mae: 0.225545, mean_q: 0.285438\n",
            " 191145/1000000: episode: 279, duration: 36.739s, episode steps: 757, steps per second:  21, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.007451, mae: 0.238237, mean_q: 0.300091\n",
            " 192362/1000000: episode: 280, duration: 58.942s, episode steps: 1217, steps per second:  21, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006616, mae: 0.234886, mean_q: 0.296422\n",
            " 193147/1000000: episode: 281, duration: 37.993s, episode steps: 785, steps per second:  21, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006487, mae: 0.234796, mean_q: 0.296092\n",
            " 193541/1000000: episode: 282, duration: 19.185s, episode steps: 394, steps per second:  21, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.006392, mae: 0.225878, mean_q: 0.285307\n",
            " 194015/1000000: episode: 283, duration: 22.970s, episode steps: 474, steps per second:  21, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.006960, mae: 0.231684, mean_q: 0.292650\n",
            " 194707/1000000: episode: 284, duration: 33.602s, episode steps: 692, steps per second:  21, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.007070, mae: 0.234365, mean_q: 0.295293\n",
            " 195484/1000000: episode: 285, duration: 37.825s, episode steps: 777, steps per second:  21, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.007195, mae: 0.232746, mean_q: 0.292946\n",
            " 195984/1000000: episode: 286, duration: 24.415s, episode steps: 500, steps per second:  20, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.006337, mae: 0.229234, mean_q: 0.288464\n",
            " 196573/1000000: episode: 287, duration: 28.818s, episode steps: 589, steps per second:  20, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.006466, mae: 0.228779, mean_q: 0.287964\n",
            " 197249/1000000: episode: 288, duration: 32.722s, episode steps: 676, steps per second:  21, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.007056, mae: 0.233287, mean_q: 0.293556\n",
            " 197708/1000000: episode: 289, duration: 22.348s, episode steps: 459, steps per second:  21, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.007423, mae: 0.238807, mean_q: 0.302203\n",
            " 198261/1000000: episode: 290, duration: 27.015s, episode steps: 553, steps per second:  20, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.007305, mae: 0.232768, mean_q: 0.294169\n",
            " 199155/1000000: episode: 291, duration: 43.642s, episode steps: 894, steps per second:  20, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006976, mae: 0.232855, mean_q: 0.293916\n",
            " 199770/1000000: episode: 292, duration: 29.909s, episode steps: 615, steps per second:  21, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.006681, mae: 0.235279, mean_q: 0.297393\n",
            " 200573/1000000: episode: 293, duration: 39.199s, episode steps: 803, steps per second:  20, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.006590, mae: 0.254886, mean_q: 0.321312\n",
            " 201191/1000000: episode: 294, duration: 29.893s, episode steps: 618, steps per second:  21, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006967, mae: 0.262627, mean_q: 0.329572\n",
            " 201720/1000000: episode: 295, duration: 25.852s, episode steps: 529, steps per second:  20, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.006718, mae: 0.262886, mean_q: 0.330996\n",
            " 202477/1000000: episode: 296, duration: 36.848s, episode steps: 757, steps per second:  21, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.008302, mae: 0.263728, mean_q: 0.330990\n",
            " 203108/1000000: episode: 297, duration: 30.869s, episode steps: 631, steps per second:  20, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.008500, mae: 0.265320, mean_q: 0.332132\n",
            " 203600/1000000: episode: 298, duration: 24.124s, episode steps: 492, steps per second:  20, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.007675, mae: 0.266003, mean_q: 0.333838\n",
            " 204249/1000000: episode: 299, duration: 31.838s, episode steps: 649, steps per second:  20, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.006613, mae: 0.254575, mean_q: 0.321466\n",
            " 205356/1000000: episode: 300, duration: 53.997s, episode steps: 1107, steps per second:  21, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.007769, mae: 0.263467, mean_q: 0.330999\n",
            " 206179/1000000: episode: 301, duration: 40.125s, episode steps: 823, steps per second:  21, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.007693, mae: 0.263535, mean_q: 0.329859\n",
            " 206993/1000000: episode: 302, duration: 40.000s, episode steps: 814, steps per second:  20, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.007591, mae: 0.263473, mean_q: 0.329882\n",
            " 207770/1000000: episode: 303, duration: 37.770s, episode steps: 777, steps per second:  21, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.007631, mae: 0.261675, mean_q: 0.328469\n",
            " 208853/1000000: episode: 304, duration: 52.822s, episode steps: 1083, steps per second:  21, episode reward: 29.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.007355, mae: 0.256445, mean_q: 0.322168\n",
            " 209349/1000000: episode: 305, duration: 24.243s, episode steps: 496, steps per second:  20, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.007752, mae: 0.261261, mean_q: 0.328525\n",
            " 210050/1000000: episode: 306, duration: 34.028s, episode steps: 701, steps per second:  21, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.006938, mae: 0.256800, mean_q: 0.322287\n",
            " 210997/1000000: episode: 307, duration: 46.335s, episode steps: 947, steps per second:  20, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007804, mae: 0.273364, mean_q: 0.343824\n",
            " 211572/1000000: episode: 308, duration: 28.485s, episode steps: 575, steps per second:  20, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.007124, mae: 0.276713, mean_q: 0.347673\n",
            " 212003/1000000: episode: 309, duration: 21.174s, episode steps: 431, steps per second:  20, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.006395, mae: 0.271766, mean_q: 0.342428\n",
            " 212697/1000000: episode: 310, duration: 34.142s, episode steps: 694, steps per second:  20, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007745, mae: 0.272086, mean_q: 0.340648\n",
            " 213329/1000000: episode: 311, duration: 31.147s, episode steps: 632, steps per second:  20, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.008037, mae: 0.273556, mean_q: 0.342732\n",
            " 214144/1000000: episode: 312, duration: 40.165s, episode steps: 815, steps per second:  20, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.007728, mae: 0.274262, mean_q: 0.344190\n",
            " 214636/1000000: episode: 313, duration: 24.280s, episode steps: 492, steps per second:  20, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007025, mae: 0.263978, mean_q: 0.331308\n",
            " 215352/1000000: episode: 314, duration: 35.150s, episode steps: 716, steps per second:  20, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.007106, mae: 0.269129, mean_q: 0.338615\n",
            " 216637/1000000: episode: 315, duration: 62.892s, episode steps: 1285, steps per second:  20, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.007036, mae: 0.270068, mean_q: 0.340214\n",
            " 217187/1000000: episode: 316, duration: 26.765s, episode steps: 550, steps per second:  21, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.008455, mae: 0.274822, mean_q: 0.345147\n",
            " 217726/1000000: episode: 317, duration: 26.597s, episode steps: 539, steps per second:  20, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.007181, mae: 0.269352, mean_q: 0.337581\n",
            " 218671/1000000: episode: 318, duration: 46.390s, episode steps: 945, steps per second:  20, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.006385, mae: 0.265305, mean_q: 0.333070\n",
            " 219425/1000000: episode: 319, duration: 37.111s, episode steps: 754, steps per second:  20, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.006209, mae: 0.263112, mean_q: 0.330505\n",
            " 220078/1000000: episode: 320, duration: 32.062s, episode steps: 653, steps per second:  20, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.006245, mae: 0.262581, mean_q: 0.329897\n",
            " 220821/1000000: episode: 321, duration: 36.741s, episode steps: 743, steps per second:  20, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007534, mae: 0.286152, mean_q: 0.360018\n",
            " 221354/1000000: episode: 322, duration: 26.250s, episode steps: 533, steps per second:  20, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.007868, mae: 0.285170, mean_q: 0.357323\n",
            " 221962/1000000: episode: 323, duration: 29.737s, episode steps: 608, steps per second:  20, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.008087, mae: 0.275705, mean_q: 0.345844\n",
            " 222505/1000000: episode: 324, duration: 26.614s, episode steps: 543, steps per second:  20, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.007234, mae: 0.281885, mean_q: 0.353733\n",
            " 223059/1000000: episode: 325, duration: 27.226s, episode steps: 554, steps per second:  20, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.007290, mae: 0.271643, mean_q: 0.340095\n",
            " 223760/1000000: episode: 326, duration: 34.623s, episode steps: 701, steps per second:  20, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.007406, mae: 0.276788, mean_q: 0.346663\n",
            " 224205/1000000: episode: 327, duration: 22.043s, episode steps: 445, steps per second:  20, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.006496, mae: 0.280271, mean_q: 0.351431\n",
            " 224884/1000000: episode: 328, duration: 33.518s, episode steps: 679, steps per second:  20, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.008155, mae: 0.280402, mean_q: 0.350483\n",
            " 225667/1000000: episode: 329, duration: 38.723s, episode steps: 783, steps per second:  20, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.007381, mae: 0.280842, mean_q: 0.352777\n",
            " 226080/1000000: episode: 330, duration: 20.534s, episode steps: 413, steps per second:  20, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.008196, mae: 0.279766, mean_q: 0.350740\n",
            " 227438/1000000: episode: 331, duration: 67.078s, episode steps: 1358, steps per second:  20, episode reward: 17.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.007253, mae: 0.278724, mean_q: 0.348108\n",
            " 228049/1000000: episode: 332, duration: 30.145s, episode steps: 611, steps per second:  20, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.007797, mae: 0.285018, mean_q: 0.357765\n",
            " 228661/1000000: episode: 333, duration: 30.204s, episode steps: 612, steps per second:  20, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.007102, mae: 0.283537, mean_q: 0.354447\n",
            " 229439/1000000: episode: 334, duration: 38.317s, episode steps: 778, steps per second:  20, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.007606, mae: 0.276862, mean_q: 0.346089\n",
            " 230025/1000000: episode: 335, duration: 29.063s, episode steps: 586, steps per second:  20, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006479, mae: 0.282163, mean_q: 0.352084\n",
            " 230686/1000000: episode: 336, duration: 32.813s, episode steps: 661, steps per second:  20, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.007657, mae: 0.301528, mean_q: 0.375805\n",
            " 231195/1000000: episode: 337, duration: 25.160s, episode steps: 509, steps per second:  20, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.007234, mae: 0.296945, mean_q: 0.369165\n",
            " 231855/1000000: episode: 338, duration: 32.653s, episode steps: 660, steps per second:  20, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.006868, mae: 0.292311, mean_q: 0.363814\n",
            " 232523/1000000: episode: 339, duration: 33.143s, episode steps: 668, steps per second:  20, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.006896, mae: 0.301377, mean_q: 0.376558\n",
            " 232979/1000000: episode: 340, duration: 22.595s, episode steps: 456, steps per second:  20, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.007181, mae: 0.298757, mean_q: 0.373436\n",
            " 233590/1000000: episode: 341, duration: 30.154s, episode steps: 611, steps per second:  20, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.007667, mae: 0.298930, mean_q: 0.372383\n",
            " 234418/1000000: episode: 342, duration: 40.751s, episode steps: 828, steps per second:  20, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007317, mae: 0.295033, mean_q: 0.368442\n",
            " 235415/1000000: episode: 343, duration: 49.188s, episode steps: 997, steps per second:  20, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.007778, mae: 0.298517, mean_q: 0.372916\n",
            " 235974/1000000: episode: 344, duration: 27.630s, episode steps: 559, steps per second:  20, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.007341, mae: 0.298433, mean_q: 0.373585\n",
            " 236651/1000000: episode: 345, duration: 33.586s, episode steps: 677, steps per second:  20, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.007427, mae: 0.297299, mean_q: 0.371609\n",
            " 237627/1000000: episode: 346, duration: 48.461s, episode steps: 976, steps per second:  20, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.007057, mae: 0.295481, mean_q: 0.369465\n",
            " 238411/1000000: episode: 347, duration: 38.979s, episode steps: 784, steps per second:  20, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.008542, mae: 0.301725, mean_q: 0.375710\n",
            " 238968/1000000: episode: 348, duration: 27.712s, episode steps: 557, steps per second:  20, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.006704, mae: 0.296522, mean_q: 0.369558\n",
            " 239927/1000000: episode: 349, duration: 47.736s, episode steps: 959, steps per second:  20, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.006977, mae: 0.292862, mean_q: 0.365828\n",
            " 240648/1000000: episode: 350, duration: 35.901s, episode steps: 721, steps per second:  20, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.007126, mae: 0.317694, mean_q: 0.397753\n",
            " 241352/1000000: episode: 351, duration: 35.212s, episode steps: 704, steps per second:  20, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.007895, mae: 0.318031, mean_q: 0.396540\n",
            " 242094/1000000: episode: 352, duration: 36.902s, episode steps: 742, steps per second:  20, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.007711, mae: 0.320951, mean_q: 0.400941\n",
            " 242885/1000000: episode: 353, duration: 39.389s, episode steps: 791, steps per second:  20, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.007719, mae: 0.322252, mean_q: 0.402519\n",
            " 243516/1000000: episode: 354, duration: 31.522s, episode steps: 631, steps per second:  20, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.007764, mae: 0.311578, mean_q: 0.389211\n",
            " 244297/1000000: episode: 355, duration: 39.103s, episode steps: 781, steps per second:  20, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.008460, mae: 0.321192, mean_q: 0.400782\n",
            " 244937/1000000: episode: 356, duration: 31.966s, episode steps: 640, steps per second:  20, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.007075, mae: 0.315273, mean_q: 0.394357\n",
            " 245634/1000000: episode: 357, duration: 34.635s, episode steps: 697, steps per second:  20, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.007227, mae: 0.318286, mean_q: 0.397735\n",
            " 246837/1000000: episode: 358, duration: 59.878s, episode steps: 1203, steps per second:  20, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.007563, mae: 0.315523, mean_q: 0.393841\n",
            " 247348/1000000: episode: 359, duration: 25.495s, episode steps: 511, steps per second:  20, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.008614, mae: 0.320956, mean_q: 0.401409\n",
            " 248448/1000000: episode: 360, duration: 55.124s, episode steps: 1100, steps per second:  20, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007105, mae: 0.314791, mean_q: 0.392563\n",
            " 249331/1000000: episode: 361, duration: 44.200s, episode steps: 883, steps per second:  20, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007501, mae: 0.317612, mean_q: 0.394968\n",
            " 249974/1000000: episode: 362, duration: 32.237s, episode steps: 643, steps per second:  20, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.007680, mae: 0.316388, mean_q: 0.394023\n",
            " 250377/1000000: episode: 363, duration: 20.328s, episode steps: 403, steps per second:  20, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.008690, mae: 0.349688, mean_q: 0.435689\n",
            " 251091/1000000: episode: 364, duration: 35.757s, episode steps: 714, steps per second:  20, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.008432, mae: 0.354951, mean_q: 0.442938\n",
            " 251723/1000000: episode: 365, duration: 31.517s, episode steps: 632, steps per second:  20, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.009208, mae: 0.343379, mean_q: 0.427162\n",
            " 252535/1000000: episode: 366, duration: 40.678s, episode steps: 812, steps per second:  20, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.008667, mae: 0.345824, mean_q: 0.430248\n",
            " 253152/1000000: episode: 367, duration: 30.966s, episode steps: 617, steps per second:  20, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.007401, mae: 0.351557, mean_q: 0.439480\n",
            " 254329/1000000: episode: 368, duration: 59.128s, episode steps: 1177, steps per second:  20, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.008611, mae: 0.347373, mean_q: 0.433399\n",
            " 254804/1000000: episode: 369, duration: 23.886s, episode steps: 475, steps per second:  20, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.008313, mae: 0.343234, mean_q: 0.426608\n",
            " 255382/1000000: episode: 370, duration: 29.217s, episode steps: 578, steps per second:  20, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.008956, mae: 0.348054, mean_q: 0.433842\n",
            " 256180/1000000: episode: 371, duration: 41.235s, episode steps: 798, steps per second:  19, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.008620, mae: 0.351724, mean_q: 0.438667\n",
            " 256880/1000000: episode: 372, duration: 35.740s, episode steps: 700, steps per second:  20, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.008379, mae: 0.348630, mean_q: 0.436553\n",
            " 257499/1000000: episode: 373, duration: 31.023s, episode steps: 619, steps per second:  20, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.007924, mae: 0.346996, mean_q: 0.433019\n",
            " 258303/1000000: episode: 374, duration: 40.358s, episode steps: 804, steps per second:  20, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.008244, mae: 0.347880, mean_q: 0.434423\n",
            " 259343/1000000: episode: 375, duration: 52.409s, episode steps: 1040, steps per second:  20, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.008503, mae: 0.352881, mean_q: 0.441136\n",
            " 259834/1000000: episode: 376, duration: 24.712s, episode steps: 491, steps per second:  20, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.008242, mae: 0.339643, mean_q: 0.423187\n",
            " 260779/1000000: episode: 377, duration: 47.489s, episode steps: 945, steps per second:  20, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.008548, mae: 0.376646, mean_q: 0.470479\n",
            " 261901/1000000: episode: 378, duration: 56.900s, episode steps: 1122, steps per second:  20, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.009147, mae: 0.376501, mean_q: 0.468590\n",
            " 262534/1000000: episode: 379, duration: 31.981s, episode steps: 633, steps per second:  20, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.008606, mae: 0.380510, mean_q: 0.476336\n",
            " 262935/1000000: episode: 380, duration: 20.213s, episode steps: 401, steps per second:  20, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.008461, mae: 0.393039, mean_q: 0.489948\n",
            " 263388/1000000: episode: 381, duration: 22.987s, episode steps: 453, steps per second:  20, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.007778, mae: 0.375695, mean_q: 0.470474\n",
            " 264244/1000000: episode: 382, duration: 43.407s, episode steps: 856, steps per second:  20, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.008559, mae: 0.372896, mean_q: 0.464541\n",
            " 265053/1000000: episode: 383, duration: 41.056s, episode steps: 809, steps per second:  20, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.009872, mae: 0.380793, mean_q: 0.474033\n",
            " 265950/1000000: episode: 384, duration: 45.178s, episode steps: 897, steps per second:  20, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.009114, mae: 0.373488, mean_q: 0.465682\n",
            " 266994/1000000: episode: 385, duration: 52.647s, episode steps: 1044, steps per second:  20, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.008413, mae: 0.372916, mean_q: 0.464768\n",
            " 267914/1000000: episode: 386, duration: 46.543s, episode steps: 920, steps per second:  20, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.008578, mae: 0.373601, mean_q: 0.464758\n",
            " 268337/1000000: episode: 387, duration: 21.377s, episode steps: 423, steps per second:  20, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.008151, mae: 0.381303, mean_q: 0.475640\n",
            " 269147/1000000: episode: 388, duration: 40.739s, episode steps: 810, steps per second:  20, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007874, mae: 0.377480, mean_q: 0.470107\n",
            " 269966/1000000: episode: 389, duration: 41.323s, episode steps: 819, steps per second:  20, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.008486, mae: 0.371562, mean_q: 0.461774\n",
            " 270904/1000000: episode: 390, duration: 47.402s, episode steps: 938, steps per second:  20, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.009506, mae: 0.412833, mean_q: 0.513889\n",
            " 271856/1000000: episode: 391, duration: 48.388s, episode steps: 952, steps per second:  20, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.008276, mae: 0.403855, mean_q: 0.503436\n",
            " 272446/1000000: episode: 392, duration: 30.027s, episode steps: 590, steps per second:  20, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.009747, mae: 0.413826, mean_q: 0.518012\n",
            " 273485/1000000: episode: 393, duration: 52.464s, episode steps: 1039, steps per second:  20, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.008958, mae: 0.405496, mean_q: 0.505657\n",
            " 274090/1000000: episode: 394, duration: 30.809s, episode steps: 605, steps per second:  20, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.009676, mae: 0.404926, mean_q: 0.504132\n",
            " 274896/1000000: episode: 395, duration: 40.820s, episode steps: 806, steps per second:  20, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.009338, mae: 0.401776, mean_q: 0.498791\n",
            " 275355/1000000: episode: 396, duration: 23.224s, episode steps: 459, steps per second:  20, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.008941, mae: 0.404361, mean_q: 0.502428\n",
            " 275946/1000000: episode: 397, duration: 29.929s, episode steps: 591, steps per second:  20, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.009113, mae: 0.407916, mean_q: 0.506319\n",
            " 276710/1000000: episode: 398, duration: 38.696s, episode steps: 764, steps per second:  20, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.009252, mae: 0.406979, mean_q: 0.504950\n",
            " 277309/1000000: episode: 399, duration: 30.554s, episode steps: 599, steps per second:  20, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.008619, mae: 0.401730, mean_q: 0.498361\n",
            " 277910/1000000: episode: 400, duration: 30.399s, episode steps: 601, steps per second:  20, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.009808, mae: 0.401431, mean_q: 0.498144\n",
            " 278350/1000000: episode: 401, duration: 22.141s, episode steps: 440, steps per second:  20, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.008313, mae: 0.410288, mean_q: 0.510948\n",
            " 279038/1000000: episode: 402, duration: 34.735s, episode steps: 688, steps per second:  20, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.008341, mae: 0.409266, mean_q: 0.508978\n",
            " 279640/1000000: episode: 403, duration: 30.538s, episode steps: 602, steps per second:  20, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.008030, mae: 0.401854, mean_q: 0.500182\n",
            " 280605/1000000: episode: 404, duration: 49.090s, episode steps: 965, steps per second:  20, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.009086, mae: 0.423808, mean_q: 0.526883\n",
            " 281384/1000000: episode: 405, duration: 39.260s, episode steps: 779, steps per second:  20, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.007609, mae: 0.427412, mean_q: 0.532577\n",
            " 282245/1000000: episode: 406, duration: 43.526s, episode steps: 861, steps per second:  20, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.008678, mae: 0.425651, mean_q: 0.529121\n",
            " 282741/1000000: episode: 407, duration: 25.113s, episode steps: 496, steps per second:  20, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.008207, mae: 0.412825, mean_q: 0.512358\n",
            " 283545/1000000: episode: 408, duration: 40.605s, episode steps: 804, steps per second:  20, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.009139, mae: 0.430883, mean_q: 0.535885\n",
            " 284178/1000000: episode: 409, duration: 32.006s, episode steps: 633, steps per second:  20, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.008810, mae: 0.427137, mean_q: 0.532003\n",
            " 284909/1000000: episode: 410, duration: 37.157s, episode steps: 731, steps per second:  20, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.008425, mae: 0.423787, mean_q: 0.527324\n",
            " 285718/1000000: episode: 411, duration: 41.189s, episode steps: 809, steps per second:  20, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.007912, mae: 0.421579, mean_q: 0.523654\n",
            " 286286/1000000: episode: 412, duration: 28.929s, episode steps: 568, steps per second:  20, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.007888, mae: 0.415395, mean_q: 0.516381\n",
            " 286719/1000000: episode: 413, duration: 21.906s, episode steps: 433, steps per second:  20, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.009179, mae: 0.423595, mean_q: 0.527481\n",
            " 287371/1000000: episode: 414, duration: 33.212s, episode steps: 652, steps per second:  20, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.009306, mae: 0.426582, mean_q: 0.532779\n",
            " 288136/1000000: episode: 415, duration: 39.034s, episode steps: 765, steps per second:  20, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.009362, mae: 0.427900, mean_q: 0.531710\n",
            " 288956/1000000: episode: 416, duration: 41.772s, episode steps: 820, steps per second:  20, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.008725, mae: 0.421213, mean_q: 0.524730\n",
            " 289936/1000000: episode: 417, duration: 49.833s, episode steps: 980, steps per second:  20, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.007949, mae: 0.429943, mean_q: 0.535576\n",
            " 290712/1000000: episode: 418, duration: 39.652s, episode steps: 776, steps per second:  20, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.008816, mae: 0.463882, mean_q: 0.578620\n",
            " 291452/1000000: episode: 419, duration: 37.746s, episode steps: 740, steps per second:  20, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.009473, mae: 0.462185, mean_q: 0.574628\n",
            " 292088/1000000: episode: 420, duration: 32.569s, episode steps: 636, steps per second:  20, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.009760, mae: 0.469686, mean_q: 0.585640\n",
            " 292591/1000000: episode: 421, duration: 25.715s, episode steps: 503, steps per second:  20, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.010630, mae: 0.477379, mean_q: 0.594453\n",
            " 293351/1000000: episode: 422, duration: 38.673s, episode steps: 760, steps per second:  20, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.009313, mae: 0.460919, mean_q: 0.573073\n",
            " 293991/1000000: episode: 423, duration: 33.196s, episode steps: 640, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.010004, mae: 0.469943, mean_q: 0.583443\n",
            " 294634/1000000: episode: 424, duration: 32.908s, episode steps: 643, steps per second:  20, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.008842, mae: 0.459502, mean_q: 0.571689\n",
            " 295443/1000000: episode: 425, duration: 41.128s, episode steps: 809, steps per second:  20, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.009292, mae: 0.466129, mean_q: 0.579982\n",
            " 296493/1000000: episode: 426, duration: 53.413s, episode steps: 1050, steps per second:  20, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.008987, mae: 0.459085, mean_q: 0.570557\n",
            " 297450/1000000: episode: 427, duration: 48.442s, episode steps: 957, steps per second:  20, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.008931, mae: 0.465273, mean_q: 0.577563\n",
            " 297998/1000000: episode: 428, duration: 27.776s, episode steps: 548, steps per second:  20, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.010221, mae: 0.463149, mean_q: 0.574132\n",
            " 298399/1000000: episode: 429, duration: 20.530s, episode steps: 401, steps per second:  20, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.009427, mae: 0.462325, mean_q: 0.574422\n",
            " 298938/1000000: episode: 430, duration: 27.564s, episode steps: 539, steps per second:  20, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.010057, mae: 0.468559, mean_q: 0.582098\n",
            " 299698/1000000: episode: 431, duration: 38.701s, episode steps: 760, steps per second:  20, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.010044, mae: 0.461189, mean_q: 0.573688\n",
            " 300377/1000000: episode: 432, duration: 34.774s, episode steps: 679, steps per second:  20, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.009969, mae: 0.483351, mean_q: 0.601430\n",
            " 301375/1000000: episode: 433, duration: 50.759s, episode steps: 998, steps per second:  20, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.009636, mae: 0.498059, mean_q: 0.619834\n",
            " 301756/1000000: episode: 434, duration: 19.597s, episode steps: 381, steps per second:  19, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.011554, mae: 0.485607, mean_q: 0.606030\n",
            " 302557/1000000: episode: 435, duration: 40.788s, episode steps: 801, steps per second:  20, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.009753, mae: 0.495973, mean_q: 0.615940\n",
            " 303120/1000000: episode: 436, duration: 28.841s, episode steps: 563, steps per second:  20, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.010816, mae: 0.488826, mean_q: 0.607345\n",
            " 304106/1000000: episode: 437, duration: 50.350s, episode steps: 986, steps per second:  20, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.009583, mae: 0.497244, mean_q: 0.619717\n",
            " 304558/1000000: episode: 438, duration: 23.202s, episode steps: 452, steps per second:  19, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.010084, mae: 0.486088, mean_q: 0.604661\n",
            " 305493/1000000: episode: 439, duration: 47.652s, episode steps: 935, steps per second:  20, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.010180, mae: 0.497462, mean_q: 0.619319\n",
            " 306573/1000000: episode: 440, duration: 55.180s, episode steps: 1080, steps per second:  20, episode reward:  9.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.009945, mae: 0.490710, mean_q: 0.610046\n",
            " 307136/1000000: episode: 441, duration: 28.930s, episode steps: 563, steps per second:  19, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.010541, mae: 0.490215, mean_q: 0.607385\n",
            " 307984/1000000: episode: 442, duration: 43.534s, episode steps: 848, steps per second:  19, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.008830, mae: 0.487218, mean_q: 0.604720\n",
            " 308381/1000000: episode: 443, duration: 20.389s, episode steps: 397, steps per second:  19, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.009112, mae: 0.490086, mean_q: 0.607123\n",
            " 309135/1000000: episode: 444, duration: 38.421s, episode steps: 754, steps per second:  20, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.009680, mae: 0.492547, mean_q: 0.611012\n",
            " 310044/1000000: episode: 445, duration: 46.669s, episode steps: 909, steps per second:  19, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.009886, mae: 0.485937, mean_q: 0.603486\n",
            " 310783/1000000: episode: 446, duration: 38.093s, episode steps: 739, steps per second:  19, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.010504, mae: 0.552777, mean_q: 0.685456\n",
            " 311309/1000000: episode: 447, duration: 27.184s, episode steps: 526, steps per second:  19, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.011927, mae: 0.543548, mean_q: 0.675322\n",
            " 311922/1000000: episode: 448, duration: 31.406s, episode steps: 613, steps per second:  20, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.010660, mae: 0.547257, mean_q: 0.682684\n",
            " 312738/1000000: episode: 449, duration: 42.083s, episode steps: 816, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.010476, mae: 0.541222, mean_q: 0.672977\n",
            " 313229/1000000: episode: 450, duration: 25.189s, episode steps: 491, steps per second:  19, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.011334, mae: 0.540061, mean_q: 0.671443\n",
            " 313911/1000000: episode: 451, duration: 34.981s, episode steps: 682, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.011333, mae: 0.545623, mean_q: 0.678845\n",
            " 314422/1000000: episode: 452, duration: 26.387s, episode steps: 511, steps per second:  19, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.010222, mae: 0.551476, mean_q: 0.687289\n",
            " 314941/1000000: episode: 453, duration: 26.758s, episode steps: 519, steps per second:  19, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.009393, mae: 0.547247, mean_q: 0.682817\n",
            " 316519/1000000: episode: 454, duration: 80.979s, episode steps: 1578, steps per second:  19, episode reward: 24.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.010546, mae: 0.549744, mean_q: 0.684493\n",
            " 317008/1000000: episode: 455, duration: 25.202s, episode steps: 489, steps per second:  19, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.010654, mae: 0.538651, mean_q: 0.669579\n",
            " 317502/1000000: episode: 456, duration: 25.437s, episode steps: 494, steps per second:  19, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.011298, mae: 0.546785, mean_q: 0.678019\n",
            " 318031/1000000: episode: 457, duration: 27.224s, episode steps: 529, steps per second:  19, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.010738, mae: 0.539985, mean_q: 0.671186\n",
            " 318432/1000000: episode: 458, duration: 20.680s, episode steps: 401, steps per second:  19, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.010446, mae: 0.538136, mean_q: 0.668360\n",
            " 319054/1000000: episode: 459, duration: 32.129s, episode steps: 622, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.011073, mae: 0.548954, mean_q: 0.680857\n",
            " 319571/1000000: episode: 460, duration: 26.507s, episode steps: 517, steps per second:  20, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.010072, mae: 0.547653, mean_q: 0.680503\n",
            " 320201/1000000: episode: 461, duration: 32.577s, episode steps: 630, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.010701, mae: 0.545080, mean_q: 0.678219\n",
            " 320728/1000000: episode: 462, duration: 27.180s, episode steps: 527, steps per second:  19, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.010964, mae: 0.571558, mean_q: 0.710170\n",
            " 321490/1000000: episode: 463, duration: 39.323s, episode steps: 762, steps per second:  19, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.010633, mae: 0.577170, mean_q: 0.717871\n",
            " 322151/1000000: episode: 464, duration: 33.874s, episode steps: 661, steps per second:  20, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.010675, mae: 0.573343, mean_q: 0.713345\n",
            " 323259/1000000: episode: 465, duration: 57.216s, episode steps: 1108, steps per second:  19, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.011260, mae: 0.569304, mean_q: 0.709728\n",
            " 323843/1000000: episode: 466, duration: 30.147s, episode steps: 584, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.010574, mae: 0.564960, mean_q: 0.701748\n",
            " 324695/1000000: episode: 467, duration: 43.788s, episode steps: 852, steps per second:  19, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.010549, mae: 0.564661, mean_q: 0.702123\n",
            " 325653/1000000: episode: 468, duration: 49.438s, episode steps: 958, steps per second:  19, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.010606, mae: 0.559173, mean_q: 0.695557\n",
            " 326031/1000000: episode: 469, duration: 19.420s, episode steps: 378, steps per second:  19, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.010737, mae: 0.565029, mean_q: 0.701116\n",
            " 326575/1000000: episode: 470, duration: 28.112s, episode steps: 544, steps per second:  19, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.009703, mae: 0.573642, mean_q: 0.712361\n",
            " 328024/1000000: episode: 471, duration: 75.124s, episode steps: 1449, steps per second:  19, episode reward: 14.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.010997, mae: 0.566246, mean_q: 0.704533\n",
            " 328630/1000000: episode: 472, duration: 31.671s, episode steps: 606, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.011051, mae: 0.553406, mean_q: 0.690197\n",
            " 329397/1000000: episode: 473, duration: 39.823s, episode steps: 767, steps per second:  19, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.010238, mae: 0.565660, mean_q: 0.702675\n",
            " 330671/1000000: episode: 474, duration: 65.703s, episode steps: 1274, steps per second:  19, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.010400, mae: 0.576682, mean_q: 0.716741\n",
            " 331155/1000000: episode: 475, duration: 25.292s, episode steps: 484, steps per second:  19, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.011537, mae: 0.593553, mean_q: 0.737611\n",
            " 331774/1000000: episode: 476, duration: 32.131s, episode steps: 619, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.011174, mae: 0.605617, mean_q: 0.751371\n",
            " 332485/1000000: episode: 477, duration: 36.904s, episode steps: 711, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.010461, mae: 0.594222, mean_q: 0.739383\n",
            " 332859/1000000: episode: 478, duration: 19.132s, episode steps: 374, steps per second:  20, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.010942, mae: 0.604015, mean_q: 0.750380\n",
            " 333422/1000000: episode: 479, duration: 29.215s, episode steps: 563, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.011342, mae: 0.597500, mean_q: 0.740745\n",
            " 333906/1000000: episode: 480, duration: 24.873s, episode steps: 484, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.011645, mae: 0.593509, mean_q: 0.735467\n",
            " 334337/1000000: episode: 481, duration: 22.306s, episode steps: 431, steps per second:  19, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.011443, mae: 0.609247, mean_q: 0.757132\n",
            " 334730/1000000: episode: 482, duration: 20.395s, episode steps: 393, steps per second:  19, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.011028, mae: 0.606782, mean_q: 0.752442\n",
            " 335367/1000000: episode: 483, duration: 32.803s, episode steps: 637, steps per second:  19, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.011624, mae: 0.594209, mean_q: 0.737465\n",
            " 335810/1000000: episode: 484, duration: 22.852s, episode steps: 443, steps per second:  19, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.011125, mae: 0.602312, mean_q: 0.747307\n",
            " 336568/1000000: episode: 485, duration: 39.138s, episode steps: 758, steps per second:  19, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.011781, mae: 0.606250, mean_q: 0.751493\n",
            " 337110/1000000: episode: 486, duration: 28.048s, episode steps: 542, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.010553, mae: 0.589402, mean_q: 0.730907\n",
            " 338082/1000000: episode: 487, duration: 50.199s, episode steps: 972, steps per second:  19, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.011449, mae: 0.599490, mean_q: 0.745237\n",
            " 338671/1000000: episode: 488, duration: 30.314s, episode steps: 589, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.010005, mae: 0.598127, mean_q: 0.743227\n",
            " 339394/1000000: episode: 489, duration: 37.473s, episode steps: 723, steps per second:  19, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.010819, mae: 0.601121, mean_q: 0.744382\n",
            " 340216/1000000: episode: 490, duration: 42.216s, episode steps: 822, steps per second:  19, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.011819, mae: 0.616883, mean_q: 0.765826\n",
            " 340822/1000000: episode: 491, duration: 31.458s, episode steps: 606, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.012293, mae: 0.661167, mean_q: 0.822156\n",
            " 341402/1000000: episode: 492, duration: 29.858s, episode steps: 580, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.012229, mae: 0.654523, mean_q: 0.815265\n",
            " 342352/1000000: episode: 493, duration: 49.303s, episode steps: 950, steps per second:  19, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.011868, mae: 0.651724, mean_q: 0.810506\n",
            " 342932/1000000: episode: 494, duration: 30.119s, episode steps: 580, steps per second:  19, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.011558, mae: 0.646367, mean_q: 0.801421\n",
            " 343649/1000000: episode: 495, duration: 37.070s, episode steps: 717, steps per second:  19, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.012000, mae: 0.659949, mean_q: 0.820177\n",
            " 343997/1000000: episode: 496, duration: 18.111s, episode steps: 348, steps per second:  19, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.010529, mae: 0.649569, mean_q: 0.807999\n",
            " 345108/1000000: episode: 497, duration: 57.332s, episode steps: 1111, steps per second:  19, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.011116, mae: 0.643195, mean_q: 0.799571\n",
            " 346040/1000000: episode: 498, duration: 48.139s, episode steps: 932, steps per second:  19, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.012009, mae: 0.653779, mean_q: 0.810704\n",
            " 346679/1000000: episode: 499, duration: 33.124s, episode steps: 639, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.011484, mae: 0.635714, mean_q: 0.786864\n",
            " 347404/1000000: episode: 500, duration: 37.451s, episode steps: 725, steps per second:  19, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.011647, mae: 0.633880, mean_q: 0.787374\n",
            " 348064/1000000: episode: 501, duration: 34.306s, episode steps: 660, steps per second:  19, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.012996, mae: 0.658510, mean_q: 0.818614\n",
            " 348469/1000000: episode: 502, duration: 20.981s, episode steps: 405, steps per second:  19, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.011801, mae: 0.649467, mean_q: 0.807094\n",
            " 349240/1000000: episode: 503, duration: 39.863s, episode steps: 771, steps per second:  19, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.012380, mae: 0.653462, mean_q: 0.811256\n",
            " 350497/1000000: episode: 504, duration: 64.952s, episode steps: 1257, steps per second:  19, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.011700, mae: 0.673789, mean_q: 0.836367\n",
            " 351750/1000000: episode: 505, duration: 64.391s, episode steps: 1253, steps per second:  19, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.011526, mae: 0.697781, mean_q: 0.865177\n",
            " 352125/1000000: episode: 506, duration: 19.370s, episode steps: 375, steps per second:  19, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.012356, mae: 0.688082, mean_q: 0.854661\n",
            " 352703/1000000: episode: 507, duration: 29.879s, episode steps: 578, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.011408, mae: 0.696231, mean_q: 0.866560\n",
            " 353437/1000000: episode: 508, duration: 38.142s, episode steps: 734, steps per second:  19, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.011137, mae: 0.689228, mean_q: 0.856066\n",
            " 354031/1000000: episode: 509, duration: 30.427s, episode steps: 594, steps per second:  20, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.011178, mae: 0.698626, mean_q: 0.866957\n",
            " 354676/1000000: episode: 510, duration: 33.371s, episode steps: 645, steps per second:  19, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.011681, mae: 0.686444, mean_q: 0.851758\n",
            " 355444/1000000: episode: 511, duration: 39.899s, episode steps: 768, steps per second:  19, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.011156, mae: 0.688086, mean_q: 0.853580\n",
            " 355986/1000000: episode: 512, duration: 28.153s, episode steps: 542, steps per second:  19, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.010391, mae: 0.684327, mean_q: 0.851109\n",
            " 356560/1000000: episode: 513, duration: 29.850s, episode steps: 574, steps per second:  19, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.011227, mae: 0.690895, mean_q: 0.858560\n",
            " 357001/1000000: episode: 514, duration: 22.942s, episode steps: 441, steps per second:  19, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.010422, mae: 0.691621, mean_q: 0.857514\n",
            " 357580/1000000: episode: 515, duration: 29.915s, episode steps: 579, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.012385, mae: 0.701427, mean_q: 0.870939\n",
            " 357946/1000000: episode: 516, duration: 19.045s, episode steps: 366, steps per second:  19, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.013091, mae: 0.699089, mean_q: 0.866605\n",
            " 358438/1000000: episode: 517, duration: 25.467s, episode steps: 492, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.012988, mae: 0.681246, mean_q: 0.843216\n",
            " 358999/1000000: episode: 518, duration: 28.895s, episode steps: 561, steps per second:  19, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.011803, mae: 0.692355, mean_q: 0.858889\n",
            " 360604/1000000: episode: 519, duration: 82.820s, episode steps: 1605, steps per second:  19, episode reward: 27.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.011504, mae: 0.707149, mean_q: 0.877414\n",
            " 361209/1000000: episode: 520, duration: 31.380s, episode steps: 605, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.012222, mae: 0.715226, mean_q: 0.890487\n",
            " 361804/1000000: episode: 521, duration: 30.666s, episode steps: 595, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.012391, mae: 0.720955, mean_q: 0.895914\n",
            " 362312/1000000: episode: 522, duration: 26.415s, episode steps: 508, steps per second:  19, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.011630, mae: 0.711830, mean_q: 0.883143\n",
            " 362765/1000000: episode: 523, duration: 23.514s, episode steps: 453, steps per second:  19, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.011424, mae: 0.706764, mean_q: 0.876967\n",
            " 363408/1000000: episode: 524, duration: 33.159s, episode steps: 643, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.010800, mae: 0.712344, mean_q: 0.884461\n",
            " 363788/1000000: episode: 525, duration: 19.855s, episode steps: 380, steps per second:  19, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.011670, mae: 0.698618, mean_q: 0.869608\n",
            " 364361/1000000: episode: 526, duration: 29.809s, episode steps: 573, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.012022, mae: 0.725923, mean_q: 0.898727\n",
            " 364909/1000000: episode: 527, duration: 28.664s, episode steps: 548, steps per second:  19, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.012301, mae: 0.711941, mean_q: 0.882857\n",
            " 365338/1000000: episode: 528, duration: 22.125s, episode steps: 429, steps per second:  19, episode reward: 10.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.012845, mae: 0.722487, mean_q: 0.895250\n",
            " 366082/1000000: episode: 529, duration: 38.469s, episode steps: 744, steps per second:  19, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.011059, mae: 0.717100, mean_q: 0.887290\n",
            " 366807/1000000: episode: 530, duration: 37.373s, episode steps: 725, steps per second:  19, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.011125, mae: 0.713985, mean_q: 0.884434\n",
            " 367573/1000000: episode: 531, duration: 39.671s, episode steps: 766, steps per second:  19, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.011506, mae: 0.699714, mean_q: 0.866362\n",
            " 368518/1000000: episode: 532, duration: 48.919s, episode steps: 945, steps per second:  19, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.012017, mae: 0.717311, mean_q: 0.889549\n",
            " 369244/1000000: episode: 533, duration: 37.813s, episode steps: 726, steps per second:  19, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.011264, mae: 0.714771, mean_q: 0.883490\n",
            " 370061/1000000: episode: 534, duration: 42.632s, episode steps: 817, steps per second:  19, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.012182, mae: 0.722894, mean_q: 0.898018\n",
            " 370696/1000000: episode: 535, duration: 33.099s, episode steps: 635, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.011152, mae: 0.744432, mean_q: 0.924545\n",
            " 371463/1000000: episode: 536, duration: 39.792s, episode steps: 767, steps per second:  19, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.011200, mae: 0.743895, mean_q: 0.923326\n",
            " 371966/1000000: episode: 537, duration: 26.085s, episode steps: 503, steps per second:  19, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.011184, mae: 0.729948, mean_q: 0.904472\n",
            " 372894/1000000: episode: 538, duration: 47.853s, episode steps: 928, steps per second:  19, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.011701, mae: 0.742691, mean_q: 0.922263\n",
            " 373633/1000000: episode: 539, duration: 38.398s, episode steps: 739, steps per second:  19, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.011270, mae: 0.742996, mean_q: 0.922758\n",
            " 374248/1000000: episode: 540, duration: 31.939s, episode steps: 615, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.012947, mae: 0.738074, mean_q: 0.914188\n",
            " 374737/1000000: episode: 541, duration: 25.488s, episode steps: 489, steps per second:  19, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.011621, mae: 0.742776, mean_q: 0.919283\n",
            " 375262/1000000: episode: 542, duration: 27.163s, episode steps: 525, steps per second:  19, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.011594, mae: 0.749336, mean_q: 0.929746\n",
            " 376044/1000000: episode: 543, duration: 40.701s, episode steps: 782, steps per second:  19, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.011522, mae: 0.740941, mean_q: 0.919548\n",
            " 376689/1000000: episode: 544, duration: 33.947s, episode steps: 645, steps per second:  19, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.011673, mae: 0.723292, mean_q: 0.895398\n",
            " 377204/1000000: episode: 545, duration: 26.733s, episode steps: 515, steps per second:  19, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.011046, mae: 0.749902, mean_q: 0.927554\n",
            " 378650/1000000: episode: 546, duration: 74.945s, episode steps: 1446, steps per second:  19, episode reward: 15.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.011575, mae: 0.734128, mean_q: 0.909487\n",
            " 379337/1000000: episode: 547, duration: 35.731s, episode steps: 687, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.011165, mae: 0.731566, mean_q: 0.905421\n",
            " 379957/1000000: episode: 548, duration: 32.199s, episode steps: 620, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.011212, mae: 0.736210, mean_q: 0.912615\n",
            " 380619/1000000: episode: 549, duration: 34.259s, episode steps: 662, steps per second:  19, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.011856, mae: 0.791259, mean_q: 0.981654\n",
            " 381122/1000000: episode: 550, duration: 26.070s, episode steps: 503, steps per second:  19, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.011317, mae: 0.797828, mean_q: 0.989691\n",
            " 381859/1000000: episode: 551, duration: 38.237s, episode steps: 737, steps per second:  19, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.012301, mae: 0.792893, mean_q: 0.982440\n",
            " 382506/1000000: episode: 552, duration: 33.812s, episode steps: 647, steps per second:  19, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.011812, mae: 0.807603, mean_q: 1.001135\n",
            " 383050/1000000: episode: 553, duration: 28.387s, episode steps: 544, steps per second:  19, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.011932, mae: 0.786061, mean_q: 0.974070\n",
            " 383711/1000000: episode: 554, duration: 34.319s, episode steps: 661, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.010773, mae: 0.786927, mean_q: 0.973886\n",
            " 384189/1000000: episode: 555, duration: 24.908s, episode steps: 478, steps per second:  19, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.012905, mae: 0.790922, mean_q: 0.976074\n",
            " 385498/1000000: episode: 556, duration: 67.730s, episode steps: 1309, steps per second:  19, episode reward: 17.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.012199, mae: 0.791922, mean_q: 0.979201\n",
            " 386386/1000000: episode: 557, duration: 46.139s, episode steps: 888, steps per second:  19, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.011788, mae: 0.789487, mean_q: 0.975811\n",
            " 386802/1000000: episode: 558, duration: 21.660s, episode steps: 416, steps per second:  19, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.012030, mae: 0.801492, mean_q: 0.990669\n",
            " 387199/1000000: episode: 559, duration: 20.589s, episode steps: 397, steps per second:  19, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.013375, mae: 0.808039, mean_q: 1.000093\n",
            " 387864/1000000: episode: 560, duration: 34.698s, episode steps: 665, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.011596, mae: 0.792361, mean_q: 0.978566\n",
            " 388866/1000000: episode: 561, duration: 52.389s, episode steps: 1002, steps per second:  19, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.012151, mae: 0.784561, mean_q: 0.969967\n",
            " 389483/1000000: episode: 562, duration: 31.907s, episode steps: 617, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.010443, mae: 0.783180, mean_q: 0.968112\n",
            " 389941/1000000: episode: 563, duration: 24.014s, episode steps: 458, steps per second:  19, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.012544, mae: 0.784497, mean_q: 0.971016\n",
            " 390640/1000000: episode: 564, duration: 36.537s, episode steps: 699, steps per second:  19, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.012450, mae: 0.861578, mean_q: 1.066107\n",
            " 391583/1000000: episode: 565, duration: 49.018s, episode steps: 943, steps per second:  19, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.012384, mae: 0.866034, mean_q: 1.071345\n",
            " 392198/1000000: episode: 566, duration: 32.025s, episode steps: 615, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.012581, mae: 0.857574, mean_q: 1.060058\n",
            " 392850/1000000: episode: 567, duration: 33.952s, episode steps: 652, steps per second:  19, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.012729, mae: 0.845272, mean_q: 1.042836\n",
            " 393547/1000000: episode: 568, duration: 36.182s, episode steps: 697, steps per second:  19, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.012977, mae: 0.866652, mean_q: 1.071361\n",
            " 394336/1000000: episode: 569, duration: 41.253s, episode steps: 789, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.013271, mae: 0.850022, mean_q: 1.051098\n",
            " 395526/1000000: episode: 570, duration: 62.093s, episode steps: 1190, steps per second:  19, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.012317, mae: 0.846807, mean_q: 1.048311\n",
            " 396079/1000000: episode: 571, duration: 28.671s, episode steps: 553, steps per second:  19, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.013624, mae: 0.844349, mean_q: 1.042390\n",
            " 396581/1000000: episode: 572, duration: 26.173s, episode steps: 502, steps per second:  19, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.012155, mae: 0.848722, mean_q: 1.046141\n",
            " 397314/1000000: episode: 573, duration: 38.039s, episode steps: 733, steps per second:  19, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.012712, mae: 0.853563, mean_q: 1.052621\n",
            " 398192/1000000: episode: 574, duration: 45.729s, episode steps: 878, steps per second:  19, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.012217, mae: 0.861970, mean_q: 1.063483\n",
            " 398981/1000000: episode: 575, duration: 41.315s, episode steps: 789, steps per second:  19, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.012789, mae: 0.870958, mean_q: 1.072312\n",
            " 399755/1000000: episode: 576, duration: 40.359s, episode steps: 774, steps per second:  19, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.012717, mae: 0.847840, mean_q: 1.048487\n",
            " 400262/1000000: episode: 577, duration: 26.643s, episode steps: 507, steps per second:  19, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.012868, mae: 0.872987, mean_q: 1.080911\n",
            " 400895/1000000: episode: 578, duration: 33.330s, episode steps: 633, steps per second:  19, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.011664, mae: 0.893224, mean_q: 1.105857\n",
            " 401365/1000000: episode: 579, duration: 24.804s, episode steps: 470, steps per second:  19, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.015717, mae: 0.903121, mean_q: 1.115832\n",
            " 401989/1000000: episode: 580, duration: 33.011s, episode steps: 624, steps per second:  19, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.014311, mae: 0.905492, mean_q: 1.120687\n",
            " 402756/1000000: episode: 581, duration: 40.447s, episode steps: 767, steps per second:  19, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.013381, mae: 0.902415, mean_q: 1.117846\n",
            " 403531/1000000: episode: 582, duration: 40.634s, episode steps: 775, steps per second:  19, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.012819, mae: 0.904152, mean_q: 1.117873\n",
            " 404252/1000000: episode: 583, duration: 37.814s, episode steps: 721, steps per second:  19, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.015478, mae: 0.905711, mean_q: 1.119695\n",
            " 404816/1000000: episode: 584, duration: 29.664s, episode steps: 564, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.013379, mae: 0.891681, mean_q: 1.098986\n",
            " 405575/1000000: episode: 585, duration: 39.881s, episode steps: 759, steps per second:  19, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.013429, mae: 0.895808, mean_q: 1.104166\n",
            " 406074/1000000: episode: 586, duration: 26.419s, episode steps: 499, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.011759, mae: 0.905452, mean_q: 1.120466\n",
            " 406597/1000000: episode: 587, duration: 27.637s, episode steps: 523, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.013143, mae: 0.895537, mean_q: 1.106341\n",
            " 406985/1000000: episode: 588, duration: 20.315s, episode steps: 388, steps per second:  19, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.011956, mae: 0.889004, mean_q: 1.097657\n",
            " 407510/1000000: episode: 589, duration: 27.360s, episode steps: 525, steps per second:  19, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.012190, mae: 0.901302, mean_q: 1.114190\n",
            " 408040/1000000: episode: 590, duration: 27.848s, episode steps: 530, steps per second:  19, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.012046, mae: 0.888033, mean_q: 1.098044\n",
            " 408845/1000000: episode: 591, duration: 42.405s, episode steps: 805, steps per second:  19, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.012753, mae: 0.901808, mean_q: 1.114585\n",
            " 409495/1000000: episode: 592, duration: 33.816s, episode steps: 650, steps per second:  19, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.012280, mae: 0.869098, mean_q: 1.073540\n",
            " 410185/1000000: episode: 593, duration: 36.101s, episode steps: 690, steps per second:  19, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.012912, mae: 0.909469, mean_q: 1.120796\n",
            " 410827/1000000: episode: 594, duration: 33.458s, episode steps: 642, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.013287, mae: 0.940128, mean_q: 1.159546\n",
            " 411593/1000000: episode: 595, duration: 40.123s, episode steps: 766, steps per second:  19, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.012405, mae: 0.942898, mean_q: 1.167082\n",
            " 412251/1000000: episode: 596, duration: 34.551s, episode steps: 658, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.012678, mae: 0.942411, mean_q: 1.162187\n",
            " 412954/1000000: episode: 597, duration: 36.919s, episode steps: 703, steps per second:  19, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.014045, mae: 0.950883, mean_q: 1.177869\n",
            " 413840/1000000: episode: 598, duration: 46.542s, episode steps: 886, steps per second:  19, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.013707, mae: 0.942591, mean_q: 1.163776\n",
            " 415048/1000000: episode: 599, duration: 63.836s, episode steps: 1208, steps per second:  19, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.012843, mae: 0.949901, mean_q: 1.172293\n",
            " 415950/1000000: episode: 600, duration: 47.369s, episode steps: 902, steps per second:  19, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.013846, mae: 0.965727, mean_q: 1.190606\n",
            " 416514/1000000: episode: 601, duration: 29.376s, episode steps: 564, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.012799, mae: 0.949198, mean_q: 1.172037\n",
            " 416899/1000000: episode: 602, duration: 20.171s, episode steps: 385, steps per second:  19, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.011134, mae: 0.930681, mean_q: 1.150853\n",
            " 417442/1000000: episode: 603, duration: 28.376s, episode steps: 543, steps per second:  19, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.013355, mae: 0.948666, mean_q: 1.170829\n",
            " 418520/1000000: episode: 604, duration: 57.098s, episode steps: 1078, steps per second:  19, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.012471, mae: 0.942115, mean_q: 1.162358\n",
            " 419047/1000000: episode: 605, duration: 27.630s, episode steps: 527, steps per second:  19, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.012613, mae: 0.950470, mean_q: 1.172175\n",
            " 419664/1000000: episode: 606, duration: 32.697s, episode steps: 617, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.011796, mae: 0.929396, mean_q: 1.145219\n",
            " 420937/1000000: episode: 607, duration: 66.785s, episode steps: 1273, steps per second:  19, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.013192, mae: 1.001295, mean_q: 1.235737\n",
            " 421551/1000000: episode: 608, duration: 31.722s, episode steps: 614, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.013806, mae: 0.997576, mean_q: 1.230156\n",
            " 422840/1000000: episode: 609, duration: 67.225s, episode steps: 1289, steps per second:  19, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.014507, mae: 1.009687, mean_q: 1.243959\n",
            " 423541/1000000: episode: 610, duration: 36.745s, episode steps: 701, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.012773, mae: 1.018314, mean_q: 1.253651\n",
            " 424322/1000000: episode: 611, duration: 40.913s, episode steps: 781, steps per second:  19, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.013374, mae: 0.995074, mean_q: 1.226348\n",
            " 425017/1000000: episode: 612, duration: 36.334s, episode steps: 695, steps per second:  19, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.013080, mae: 1.010295, mean_q: 1.243882\n",
            " 425655/1000000: episode: 613, duration: 33.244s, episode steps: 638, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.014308, mae: 1.010572, mean_q: 1.245891\n",
            " 426297/1000000: episode: 614, duration: 33.781s, episode steps: 642, steps per second:  19, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.013715, mae: 1.014449, mean_q: 1.248608\n",
            " 426944/1000000: episode: 615, duration: 33.952s, episode steps: 647, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.012051, mae: 1.002240, mean_q: 1.233194\n",
            " 427699/1000000: episode: 616, duration: 39.249s, episode steps: 755, steps per second:  19, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.011782, mae: 1.006051, mean_q: 1.239167\n",
            " 428507/1000000: episode: 617, duration: 42.068s, episode steps: 808, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.013010, mae: 1.001095, mean_q: 1.232867\n",
            " 429081/1000000: episode: 618, duration: 30.008s, episode steps: 574, steps per second:  19, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.011982, mae: 1.008849, mean_q: 1.243168\n",
            " 429514/1000000: episode: 619, duration: 22.531s, episode steps: 433, steps per second:  19, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.014280, mae: 1.019902, mean_q: 1.254856\n",
            " 430019/1000000: episode: 620, duration: 26.346s, episode steps: 505, steps per second:  19, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.011791, mae: 1.005262, mean_q: 1.238233\n",
            " 430812/1000000: episode: 621, duration: 41.574s, episode steps: 793, steps per second:  19, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.012243, mae: 1.038703, mean_q: 1.281123\n",
            " 431395/1000000: episode: 622, duration: 30.424s, episode steps: 583, steps per second:  19, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.014924, mae: 1.040166, mean_q: 1.284848\n",
            " 432344/1000000: episode: 623, duration: 49.930s, episode steps: 949, steps per second:  19, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.013716, mae: 1.049836, mean_q: 1.292956\n",
            " 433041/1000000: episode: 624, duration: 36.604s, episode steps: 697, steps per second:  19, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.013068, mae: 1.031075, mean_q: 1.270300\n",
            " 433450/1000000: episode: 625, duration: 21.429s, episode steps: 409, steps per second:  19, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.012646, mae: 1.038837, mean_q: 1.282857\n",
            " 434176/1000000: episode: 626, duration: 38.333s, episode steps: 726, steps per second:  19, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.013390, mae: 1.039554, mean_q: 1.280281\n",
            " 434821/1000000: episode: 627, duration: 33.812s, episode steps: 645, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.014311, mae: 1.052133, mean_q: 1.296893\n",
            " 435493/1000000: episode: 628, duration: 35.204s, episode steps: 672, steps per second:  19, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.013070, mae: 1.040201, mean_q: 1.278647\n",
            " 436325/1000000: episode: 629, duration: 43.946s, episode steps: 832, steps per second:  19, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.012570, mae: 1.035014, mean_q: 1.275781\n",
            " 437182/1000000: episode: 630, duration: 44.996s, episode steps: 857, steps per second:  19, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.012300, mae: 1.038828, mean_q: 1.278963\n",
            " 437960/1000000: episode: 631, duration: 41.231s, episode steps: 778, steps per second:  19, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.014236, mae: 1.038316, mean_q: 1.278196\n",
            " 438883/1000000: episode: 632, duration: 48.478s, episode steps: 923, steps per second:  19, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.012710, mae: 1.034642, mean_q: 1.272678\n",
            " 439541/1000000: episode: 633, duration: 34.575s, episode steps: 658, steps per second:  19, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.013749, mae: 1.026017, mean_q: 1.261207\n",
            " 440386/1000000: episode: 634, duration: 44.168s, episode steps: 845, steps per second:  19, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.013058, mae: 1.048209, mean_q: 1.290016\n",
            " 441084/1000000: episode: 635, duration: 36.712s, episode steps: 698, steps per second:  19, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.012488, mae: 1.093398, mean_q: 1.345489\n",
            " 441530/1000000: episode: 636, duration: 23.434s, episode steps: 446, steps per second:  19, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.012896, mae: 1.087810, mean_q: 1.339938\n",
            " 442207/1000000: episode: 637, duration: 35.517s, episode steps: 677, steps per second:  19, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.011642, mae: 1.083643, mean_q: 1.333606\n",
            " 442938/1000000: episode: 638, duration: 38.392s, episode steps: 731, steps per second:  19, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.013133, mae: 1.088501, mean_q: 1.339269\n",
            " 443474/1000000: episode: 639, duration: 28.080s, episode steps: 536, steps per second:  19, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.013835, mae: 1.103476, mean_q: 1.357678\n",
            " 444398/1000000: episode: 640, duration: 48.430s, episode steps: 924, steps per second:  19, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.013088, mae: 1.089387, mean_q: 1.340237\n",
            " 445063/1000000: episode: 641, duration: 34.850s, episode steps: 665, steps per second:  19, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.014893, mae: 1.103683, mean_q: 1.355916\n",
            " 445691/1000000: episode: 642, duration: 32.964s, episode steps: 628, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.012710, mae: 1.071311, mean_q: 1.318825\n",
            " 446707/1000000: episode: 643, duration: 53.103s, episode steps: 1016, steps per second:  19, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.012898, mae: 1.087629, mean_q: 1.338893\n",
            " 447404/1000000: episode: 644, duration: 36.806s, episode steps: 697, steps per second:  19, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.012563, mae: 1.087998, mean_q: 1.340424\n",
            " 447966/1000000: episode: 645, duration: 29.703s, episode steps: 562, steps per second:  19, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.012546, mae: 1.089597, mean_q: 1.340227\n",
            " 448797/1000000: episode: 646, duration: 43.691s, episode steps: 831, steps per second:  19, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.012770, mae: 1.094530, mean_q: 1.346834\n",
            " 449598/1000000: episode: 647, duration: 41.957s, episode steps: 801, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.012692, mae: 1.084815, mean_q: 1.332431\n",
            " 450222/1000000: episode: 648, duration: 32.713s, episode steps: 624, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.011606, mae: 1.106520, mean_q: 1.364202\n",
            " 450583/1000000: episode: 649, duration: 18.843s, episode steps: 361, steps per second:  19, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.012049, mae: 1.123409, mean_q: 1.382088\n",
            " 450967/1000000: episode: 650, duration: 20.113s, episode steps: 384, steps per second:  19, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.014785, mae: 1.114963, mean_q: 1.371164\n",
            " 451363/1000000: episode: 651, duration: 20.784s, episode steps: 396, steps per second:  19, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.014284, mae: 1.129290, mean_q: 1.388765\n",
            " 452115/1000000: episode: 652, duration: 39.433s, episode steps: 752, steps per second:  19, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.012704, mae: 1.140352, mean_q: 1.401199\n",
            " 452622/1000000: episode: 653, duration: 26.753s, episode steps: 507, steps per second:  19, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.014625, mae: 1.149165, mean_q: 1.411020\n",
            " 453461/1000000: episode: 654, duration: 44.127s, episode steps: 839, steps per second:  19, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.013041, mae: 1.129144, mean_q: 1.387794\n",
            " 454264/1000000: episode: 655, duration: 42.485s, episode steps: 803, steps per second:  19, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.014036, mae: 1.150960, mean_q: 1.414973\n",
            " 454778/1000000: episode: 656, duration: 27.022s, episode steps: 514, steps per second:  19, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.015347, mae: 1.135994, mean_q: 1.397752\n",
            " 455184/1000000: episode: 657, duration: 21.420s, episode steps: 406, steps per second:  19, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.013689, mae: 1.128081, mean_q: 1.387539\n",
            " 456104/1000000: episode: 658, duration: 48.627s, episode steps: 920, steps per second:  19, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.014161, mae: 1.139572, mean_q: 1.400448\n",
            " 456741/1000000: episode: 659, duration: 33.620s, episode steps: 637, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.013485, mae: 1.136221, mean_q: 1.398499\n",
            " 457675/1000000: episode: 660, duration: 49.053s, episode steps: 934, steps per second:  19, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.014035, mae: 1.138078, mean_q: 1.400240\n",
            " 458360/1000000: episode: 661, duration: 36.258s, episode steps: 685, steps per second:  19, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.013161, mae: 1.117539, mean_q: 1.374296\n",
            " 458744/1000000: episode: 662, duration: 20.275s, episode steps: 384, steps per second:  19, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.014084, mae: 1.129961, mean_q: 1.391122\n",
            " 459561/1000000: episode: 663, duration: 43.164s, episode steps: 817, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.013635, mae: 1.131779, mean_q: 1.387281\n",
            " 460031/1000000: episode: 664, duration: 24.586s, episode steps: 470, steps per second:  19, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.013088, mae: 1.133724, mean_q: 1.390326\n",
            " 460710/1000000: episode: 665, duration: 35.649s, episode steps: 679, steps per second:  19, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.013834, mae: 1.187189, mean_q: 1.459795\n",
            " 461311/1000000: episode: 666, duration: 31.505s, episode steps: 601, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.013568, mae: 1.180374, mean_q: 1.450086\n",
            " 461713/1000000: episode: 667, duration: 21.199s, episode steps: 402, steps per second:  19, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.013373, mae: 1.180906, mean_q: 1.449912\n",
            " 462361/1000000: episode: 668, duration: 34.175s, episode steps: 648, steps per second:  19, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.013030, mae: 1.171939, mean_q: 1.436623\n",
            " 463549/1000000: episode: 669, duration: 62.416s, episode steps: 1188, steps per second:  19, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.013798, mae: 1.187980, mean_q: 1.456895\n",
            " 464224/1000000: episode: 670, duration: 35.628s, episode steps: 675, steps per second:  19, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.013850, mae: 1.181225, mean_q: 1.449191\n",
            " 464830/1000000: episode: 671, duration: 32.064s, episode steps: 606, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.013917, mae: 1.182418, mean_q: 1.449175\n",
            " 465410/1000000: episode: 672, duration: 30.832s, episode steps: 580, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.014089, mae: 1.181917, mean_q: 1.449617\n",
            " 466051/1000000: episode: 673, duration: 33.837s, episode steps: 641, steps per second:  19, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.013192, mae: 1.196325, mean_q: 1.465535\n",
            " 466979/1000000: episode: 674, duration: 49.136s, episode steps: 928, steps per second:  19, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.014353, mae: 1.171982, mean_q: 1.434214\n",
            " 467468/1000000: episode: 675, duration: 25.840s, episode steps: 489, steps per second:  19, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.011580, mae: 1.161142, mean_q: 1.420734\n",
            " 469069/1000000: episode: 676, duration: 84.271s, episode steps: 1601, steps per second:  19, episode reward: 20.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.013664, mae: 1.172981, mean_q: 1.435660\n",
            " 469705/1000000: episode: 677, duration: 33.697s, episode steps: 636, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.012149, mae: 1.160966, mean_q: 1.420901\n",
            " 470964/1000000: episode: 678, duration: 66.526s, episode steps: 1259, steps per second:  19, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.012736, mae: 1.212073, mean_q: 1.485573\n",
            " 471578/1000000: episode: 679, duration: 32.647s, episode steps: 614, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.013133, mae: 1.239093, mean_q: 1.519565\n",
            " 472157/1000000: episode: 680, duration: 30.530s, episode steps: 579, steps per second:  19, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.015486, mae: 1.220620, mean_q: 1.494426\n",
            " 472947/1000000: episode: 681, duration: 41.486s, episode steps: 790, steps per second:  19, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.015547, mae: 1.217993, mean_q: 1.492032\n",
            " 473633/1000000: episode: 682, duration: 36.184s, episode steps: 686, steps per second:  19, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.015855, mae: 1.234992, mean_q: 1.513696\n",
            " 474081/1000000: episode: 683, duration: 23.576s, episode steps: 448, steps per second:  19, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.013774, mae: 1.223690, mean_q: 1.498061\n",
            " 474704/1000000: episode: 684, duration: 32.967s, episode steps: 623, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.014625, mae: 1.210031, mean_q: 1.478977\n",
            " 475329/1000000: episode: 685, duration: 33.175s, episode steps: 625, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.014829, mae: 1.220522, mean_q: 1.494101\n",
            " 475939/1000000: episode: 686, duration: 32.213s, episode steps: 610, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.013604, mae: 1.215920, mean_q: 1.488884\n",
            " 476358/1000000: episode: 687, duration: 22.232s, episode steps: 419, steps per second:  19, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.013528, mae: 1.223624, mean_q: 1.498242\n",
            " 477175/1000000: episode: 688, duration: 43.537s, episode steps: 817, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.013275, mae: 1.213255, mean_q: 1.486369\n",
            " 477772/1000000: episode: 689, duration: 31.795s, episode steps: 597, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.013455, mae: 1.217409, mean_q: 1.488042\n",
            " 478506/1000000: episode: 690, duration: 38.920s, episode steps: 734, steps per second:  19, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.012982, mae: 1.209969, mean_q: 1.483377\n",
            " 479193/1000000: episode: 691, duration: 36.194s, episode steps: 687, steps per second:  19, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: 0.014405, mae: 1.209602, mean_q: 1.479805\n",
            " 479798/1000000: episode: 692, duration: 31.930s, episode steps: 605, steps per second:  19, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.013143, mae: 1.213183, mean_q: 1.484990\n",
            " 480689/1000000: episode: 693, duration: 47.093s, episode steps: 891, steps per second:  19, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.013738, mae: 1.246902, mean_q: 1.529226\n",
            " 481262/1000000: episode: 694, duration: 30.287s, episode steps: 573, steps per second:  19, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.014251, mae: 1.267937, mean_q: 1.552352\n",
            " 481779/1000000: episode: 695, duration: 27.355s, episode steps: 517, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.014884, mae: 1.253637, mean_q: 1.534160\n",
            " 482590/1000000: episode: 696, duration: 42.939s, episode steps: 811, steps per second:  19, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.014624, mae: 1.253554, mean_q: 1.533997\n",
            " 483499/1000000: episode: 697, duration: 48.228s, episode steps: 909, steps per second:  19, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.018065, mae: 1.243109, mean_q: 1.521946\n",
            " 484143/1000000: episode: 698, duration: 34.030s, episode steps: 644, steps per second:  19, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.013974, mae: 1.247541, mean_q: 1.525925\n",
            " 484803/1000000: episode: 699, duration: 34.837s, episode steps: 660, steps per second:  19, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.013637, mae: 1.261737, mean_q: 1.542257\n",
            " 485652/1000000: episode: 700, duration: 45.180s, episode steps: 849, steps per second:  19, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.012737, mae: 1.236971, mean_q: 1.513830\n",
            " 486154/1000000: episode: 701, duration: 26.686s, episode steps: 502, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.015008, mae: 1.230629, mean_q: 1.506328\n",
            " 486918/1000000: episode: 702, duration: 40.445s, episode steps: 764, steps per second:  19, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.014894, mae: 1.243947, mean_q: 1.522038\n",
            " 487770/1000000: episode: 703, duration: 44.982s, episode steps: 852, steps per second:  19, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.014441, mae: 1.256944, mean_q: 1.538409\n",
            " 488179/1000000: episode: 704, duration: 21.709s, episode steps: 409, steps per second:  19, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.014403, mae: 1.259396, mean_q: 1.543402\n",
            " 488630/1000000: episode: 705, duration: 23.918s, episode steps: 451, steps per second:  19, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.016230, mae: 1.266532, mean_q: 1.549699\n",
            " 489263/1000000: episode: 706, duration: 33.667s, episode steps: 633, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.013642, mae: 1.265032, mean_q: 1.547495\n",
            " 489744/1000000: episode: 707, duration: 25.641s, episode steps: 481, steps per second:  19, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.015501, mae: 1.257862, mean_q: 1.538539\n",
            " 490617/1000000: episode: 708, duration: 46.327s, episode steps: 873, steps per second:  19, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.014811, mae: 1.266897, mean_q: 1.549278\n",
            " 491366/1000000: episode: 709, duration: 39.522s, episode steps: 749, steps per second:  19, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.014837, mae: 1.275131, mean_q: 1.562289\n",
            " 491987/1000000: episode: 710, duration: 32.837s, episode steps: 621, steps per second:  19, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.015114, mae: 1.253246, mean_q: 1.533956\n",
            " 492960/1000000: episode: 711, duration: 51.679s, episode steps: 973, steps per second:  19, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.013505, mae: 1.252750, mean_q: 1.535852\n",
            " 494490/1000000: episode: 712, duration: 81.050s, episode steps: 1530, steps per second:  19, episode reward: 26.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.013236, mae: 1.261499, mean_q: 1.546078\n",
            " 495074/1000000: episode: 713, duration: 31.251s, episode steps: 584, steps per second:  19, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.015334, mae: 1.273820, mean_q: 1.558316\n",
            " 495587/1000000: episode: 714, duration: 27.242s, episode steps: 513, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.013980, mae: 1.267213, mean_q: 1.549757\n",
            " 496489/1000000: episode: 715, duration: 48.109s, episode steps: 902, steps per second:  19, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.014097, mae: 1.263497, mean_q: 1.547937\n",
            " 497134/1000000: episode: 716, duration: 34.225s, episode steps: 645, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.016079, mae: 1.280655, mean_q: 1.566008\n",
            " 497835/1000000: episode: 717, duration: 37.104s, episode steps: 701, steps per second:  19, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.015534, mae: 1.252207, mean_q: 1.533351\n",
            " 498639/1000000: episode: 718, duration: 42.758s, episode steps: 804, steps per second:  19, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.014178, mae: 1.247967, mean_q: 1.527224\n",
            " 499032/1000000: episode: 719, duration: 20.932s, episode steps: 393, steps per second:  19, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.015295, mae: 1.275904, mean_q: 1.561797\n",
            " 499526/1000000: episode: 720, duration: 26.488s, episode steps: 494, steps per second:  19, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.013955, mae: 1.243381, mean_q: 1.519850\n",
            " 500156/1000000: episode: 721, duration: 33.747s, episode steps: 630, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.014457, mae: 1.259123, mean_q: 1.542637\n",
            " 500751/1000000: episode: 722, duration: 31.989s, episode steps: 595, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.014473, mae: 1.311045, mean_q: 1.608728\n",
            " 501437/1000000: episode: 723, duration: 36.533s, episode steps: 686, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.013404, mae: 1.300079, mean_q: 1.592908\n",
            " 502076/1000000: episode: 724, duration: 34.145s, episode steps: 639, steps per second:  19, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.014695, mae: 1.309798, mean_q: 1.607226\n",
            " 502772/1000000: episode: 725, duration: 37.274s, episode steps: 696, steps per second:  19, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.015352, mae: 1.298297, mean_q: 1.587991\n",
            " 503714/1000000: episode: 726, duration: 50.190s, episode steps: 942, steps per second:  19, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.014369, mae: 1.303091, mean_q: 1.592991\n",
            " 504241/1000000: episode: 727, duration: 28.136s, episode steps: 527, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.014469, mae: 1.296660, mean_q: 1.585788\n",
            " 504849/1000000: episode: 728, duration: 32.290s, episode steps: 608, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.014342, mae: 1.297776, mean_q: 1.587161\n",
            " 505267/1000000: episode: 729, duration: 22.224s, episode steps: 418, steps per second:  19, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.013536, mae: 1.300102, mean_q: 1.591344\n",
            " 505890/1000000: episode: 730, duration: 33.424s, episode steps: 623, steps per second:  19, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.015406, mae: 1.312888, mean_q: 1.607999\n",
            " 506501/1000000: episode: 731, duration: 32.960s, episode steps: 611, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.014882, mae: 1.292414, mean_q: 1.581021\n",
            " 506914/1000000: episode: 732, duration: 22.149s, episode steps: 413, steps per second:  19, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.014730, mae: 1.304352, mean_q: 1.596376\n",
            " 507470/1000000: episode: 733, duration: 29.724s, episode steps: 556, steps per second:  19, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.015189, mae: 1.317673, mean_q: 1.610798\n",
            " 508007/1000000: episode: 734, duration: 28.748s, episode steps: 537, steps per second:  19, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.015665, mae: 1.304369, mean_q: 1.596186\n",
            " 508679/1000000: episode: 735, duration: 35.988s, episode steps: 672, steps per second:  19, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.013899, mae: 1.312742, mean_q: 1.606844\n",
            " 509291/1000000: episode: 736, duration: 32.768s, episode steps: 612, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.014053, mae: 1.305781, mean_q: 1.595710\n",
            " 510203/1000000: episode: 737, duration: 48.782s, episode steps: 912, steps per second:  19, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.013467, mae: 1.296023, mean_q: 1.585945\n",
            " 510624/1000000: episode: 738, duration: 22.755s, episode steps: 421, steps per second:  19, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.014496, mae: 1.342615, mean_q: 1.641420\n",
            " 511169/1000000: episode: 739, duration: 29.368s, episode steps: 545, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.013458, mae: 1.338982, mean_q: 1.641085\n",
            " 511796/1000000: episode: 740, duration: 33.433s, episode steps: 627, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.014558, mae: 1.335751, mean_q: 1.636007\n",
            " 512420/1000000: episode: 741, duration: 33.744s, episode steps: 624, steps per second:  18, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.014405, mae: 1.337186, mean_q: 1.635645\n",
            " 513223/1000000: episode: 742, duration: 43.153s, episode steps: 803, steps per second:  19, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.013315, mae: 1.324151, mean_q: 1.619450\n",
            " 513755/1000000: episode: 743, duration: 28.511s, episode steps: 532, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.014144, mae: 1.336323, mean_q: 1.632127\n",
            " 514294/1000000: episode: 744, duration: 28.955s, episode steps: 539, steps per second:  19, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.014900, mae: 1.331640, mean_q: 1.626570\n",
            " 514958/1000000: episode: 745, duration: 35.614s, episode steps: 664, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.013953, mae: 1.345004, mean_q: 1.643315\n",
            " 515400/1000000: episode: 746, duration: 23.724s, episode steps: 442, steps per second:  19, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.015237, mae: 1.325874, mean_q: 1.621829\n",
            " 515929/1000000: episode: 747, duration: 28.435s, episode steps: 529, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.014059, mae: 1.331213, mean_q: 1.625348\n",
            " 516438/1000000: episode: 748, duration: 27.148s, episode steps: 509, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.013659, mae: 1.311720, mean_q: 1.603595\n",
            " 517195/1000000: episode: 749, duration: 40.510s, episode steps: 757, steps per second:  19, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.012219, mae: 1.310632, mean_q: 1.600292\n",
            " 517831/1000000: episode: 750, duration: 34.034s, episode steps: 636, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.014268, mae: 1.316667, mean_q: 1.607046\n",
            " 518511/1000000: episode: 751, duration: 36.576s, episode steps: 680, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.013406, mae: 1.330632, mean_q: 1.624758\n",
            " 519153/1000000: episode: 752, duration: 34.464s, episode steps: 642, steps per second:  19, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.014134, mae: 1.335723, mean_q: 1.631544\n",
            " 520144/1000000: episode: 753, duration: 53.339s, episode steps: 991, steps per second:  19, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.014027, mae: 1.334386, mean_q: 1.630766\n",
            " 520997/1000000: episode: 754, duration: 46.080s, episode steps: 853, steps per second:  19, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.014532, mae: 1.338282, mean_q: 1.634032\n",
            " 521635/1000000: episode: 755, duration: 34.188s, episode steps: 638, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.016053, mae: 1.379809, mean_q: 1.684826\n",
            " 522002/1000000: episode: 756, duration: 19.715s, episode steps: 367, steps per second:  19, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.014823, mae: 1.353294, mean_q: 1.656642\n",
            " 522507/1000000: episode: 757, duration: 27.109s, episode steps: 505, steps per second:  19, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.014939, mae: 1.361350, mean_q: 1.665350\n",
            " 522897/1000000: episode: 758, duration: 21.122s, episode steps: 390, steps per second:  18, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.015990, mae: 1.360390, mean_q: 1.663083\n",
            " 523315/1000000: episode: 759, duration: 22.418s, episode steps: 418, steps per second:  19, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.014416, mae: 1.366811, mean_q: 1.669590\n",
            " 523703/1000000: episode: 760, duration: 20.982s, episode steps: 388, steps per second:  18, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.014495, mae: 1.346394, mean_q: 1.644857\n",
            " 524335/1000000: episode: 761, duration: 34.218s, episode steps: 632, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.014309, mae: 1.341913, mean_q: 1.641792\n",
            " 524949/1000000: episode: 762, duration: 33.180s, episode steps: 614, steps per second:  19, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.014766, mae: 1.348456, mean_q: 1.649388\n",
            " 525453/1000000: episode: 763, duration: 27.196s, episode steps: 504, steps per second:  19, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.014181, mae: 1.345343, mean_q: 1.644571\n",
            " 526179/1000000: episode: 764, duration: 38.893s, episode steps: 726, steps per second:  19, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.013356, mae: 1.357720, mean_q: 1.660778\n",
            " 527007/1000000: episode: 765, duration: 44.533s, episode steps: 828, steps per second:  19, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.014322, mae: 1.357061, mean_q: 1.660796\n",
            " 527975/1000000: episode: 766, duration: 52.178s, episode steps: 968, steps per second:  19, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.014858, mae: 1.346684, mean_q: 1.643453\n",
            " 528651/1000000: episode: 767, duration: 36.371s, episode steps: 676, steps per second:  19, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.015808, mae: 1.346911, mean_q: 1.641590\n",
            " 529150/1000000: episode: 768, duration: 26.994s, episode steps: 499, steps per second:  18, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.014144, mae: 1.366132, mean_q: 1.668652\n",
            " 529630/1000000: episode: 769, duration: 26.047s, episode steps: 480, steps per second:  18, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.014807, mae: 1.376241, mean_q: 1.677856\n",
            " 530453/1000000: episode: 770, duration: 44.354s, episode steps: 823, steps per second:  19, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.014708, mae: 1.368002, mean_q: 1.670184\n",
            " 530858/1000000: episode: 771, duration: 21.765s, episode steps: 405, steps per second:  19, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.013432, mae: 1.380268, mean_q: 1.684107\n",
            " 531909/1000000: episode: 772, duration: 56.623s, episode steps: 1051, steps per second:  19, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.014192, mae: 1.366578, mean_q: 1.667330\n",
            " 532702/1000000: episode: 773, duration: 42.604s, episode steps: 793, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.015408, mae: 1.382127, mean_q: 1.688412\n",
            " 533416/1000000: episode: 774, duration: 39.780s, episode steps: 714, steps per second:  18, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.014132, mae: 1.349629, mean_q: 1.648601\n",
            " 534065/1000000: episode: 775, duration: 35.372s, episode steps: 649, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.014414, mae: 1.379612, mean_q: 1.684492\n",
            " 534571/1000000: episode: 776, duration: 27.239s, episode steps: 506, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.015090, mae: 1.367297, mean_q: 1.668707\n",
            " 535510/1000000: episode: 777, duration: 50.710s, episode steps: 939, steps per second:  19, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.013294, mae: 1.376932, mean_q: 1.680564\n",
            " 535907/1000000: episode: 778, duration: 21.362s, episode steps: 397, steps per second:  19, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.012548, mae: 1.365706, mean_q: 1.667448\n",
            " 536550/1000000: episode: 779, duration: 34.737s, episode steps: 643, steps per second:  19, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.015496, mae: 1.371232, mean_q: 1.670952\n",
            " 537370/1000000: episode: 780, duration: 44.049s, episode steps: 820, steps per second:  19, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.014584, mae: 1.356815, mean_q: 1.657162\n",
            " 538111/1000000: episode: 781, duration: 40.014s, episode steps: 741, steps per second:  19, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.014488, mae: 1.367228, mean_q: 1.668426\n",
            " 538683/1000000: episode: 782, duration: 30.893s, episode steps: 572, steps per second:  19, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.015470, mae: 1.367944, mean_q: 1.670768\n",
            " 539654/1000000: episode: 783, duration: 52.557s, episode steps: 971, steps per second:  18, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.014683, mae: 1.388489, mean_q: 1.695902\n",
            " 540219/1000000: episode: 784, duration: 30.448s, episode steps: 565, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.012900, mae: 1.364677, mean_q: 1.665117\n",
            " 541093/1000000: episode: 785, duration: 47.853s, episode steps: 874, steps per second:  18, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.013047, mae: 1.391036, mean_q: 1.698855\n",
            " 541733/1000000: episode: 786, duration: 34.667s, episode steps: 640, steps per second:  18, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.012477, mae: 1.376711, mean_q: 1.683419\n",
            " 542264/1000000: episode: 787, duration: 28.870s, episode steps: 531, steps per second:  18, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.013761, mae: 1.376748, mean_q: 1.683167\n",
            " 542963/1000000: episode: 788, duration: 37.899s, episode steps: 699, steps per second:  18, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.015445, mae: 1.390464, mean_q: 1.696044\n",
            " 543759/1000000: episode: 789, duration: 43.122s, episode steps: 796, steps per second:  18, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.014276, mae: 1.378821, mean_q: 1.682370\n",
            " 544376/1000000: episode: 790, duration: 33.659s, episode steps: 617, steps per second:  18, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.014578, mae: 1.388504, mean_q: 1.694365\n",
            " 545227/1000000: episode: 791, duration: 46.192s, episode steps: 851, steps per second:  18, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.017520, mae: 1.391981, mean_q: 1.700559\n",
            " 545857/1000000: episode: 792, duration: 34.197s, episode steps: 630, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.024307, mae: 1.395772, mean_q: 1.702786\n",
            " 546509/1000000: episode: 793, duration: 35.396s, episode steps: 652, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.017081, mae: 1.395007, mean_q: 1.702700\n",
            " 547296/1000000: episode: 794, duration: 43.008s, episode steps: 787, steps per second:  18, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.015579, mae: 1.383875, mean_q: 1.690352\n",
            " 547991/1000000: episode: 795, duration: 37.849s, episode steps: 695, steps per second:  18, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.014658, mae: 1.370155, mean_q: 1.670626\n",
            " 548479/1000000: episode: 796, duration: 26.480s, episode steps: 488, steps per second:  18, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.012875, mae: 1.374330, mean_q: 1.677164\n",
            " 549336/1000000: episode: 797, duration: 46.495s, episode steps: 857, steps per second:  18, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.014724, mae: 1.394800, mean_q: 1.701445\n",
            " 549703/1000000: episode: 798, duration: 19.891s, episode steps: 367, steps per second:  18, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.015979, mae: 1.402725, mean_q: 1.711624\n",
            " 550198/1000000: episode: 799, duration: 27.002s, episode steps: 495, steps per second:  18, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.013744, mae: 1.410892, mean_q: 1.723549\n",
            " 550885/1000000: episode: 800, duration: 37.369s, episode steps: 687, steps per second:  18, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.013429, mae: 1.434023, mean_q: 1.749991\n",
            " 551439/1000000: episode: 801, duration: 29.938s, episode steps: 554, steps per second:  19, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.013990, mae: 1.433526, mean_q: 1.749250\n",
            " 552122/1000000: episode: 802, duration: 37.099s, episode steps: 683, steps per second:  18, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.014115, mae: 1.403971, mean_q: 1.715746\n",
            " 552799/1000000: episode: 803, duration: 36.984s, episode steps: 677, steps per second:  18, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.015034, mae: 1.419191, mean_q: 1.732979\n",
            " 553736/1000000: episode: 804, duration: 50.899s, episode steps: 937, steps per second:  18, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.013937, mae: 1.403821, mean_q: 1.713148\n",
            " 554382/1000000: episode: 805, duration: 34.997s, episode steps: 646, steps per second:  18, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.015196, mae: 1.422243, mean_q: 1.733274\n",
            " 555150/1000000: episode: 806, duration: 41.619s, episode steps: 768, steps per second:  18, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.015764, mae: 1.421540, mean_q: 1.734820\n",
            " 555804/1000000: episode: 807, duration: 35.657s, episode steps: 654, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.014692, mae: 1.430200, mean_q: 1.746730\n",
            " 556307/1000000: episode: 808, duration: 27.494s, episode steps: 503, steps per second:  18, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.016508, mae: 1.419200, mean_q: 1.731700\n",
            " 557046/1000000: episode: 809, duration: 40.445s, episode steps: 739, steps per second:  18, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.014798, mae: 1.417993, mean_q: 1.731027\n",
            " 557767/1000000: episode: 810, duration: 39.144s, episode steps: 721, steps per second:  18, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.015347, mae: 1.406309, mean_q: 1.718008\n",
            " 558407/1000000: episode: 811, duration: 35.157s, episode steps: 640, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.014565, mae: 1.425894, mean_q: 1.741254\n",
            " 558966/1000000: episode: 812, duration: 30.629s, episode steps: 559, steps per second:  18, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.019196, mae: 1.416002, mean_q: 1.727383\n",
            " 559618/1000000: episode: 813, duration: 35.670s, episode steps: 652, steps per second:  18, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.014349, mae: 1.415421, mean_q: 1.726932\n",
            " 560260/1000000: episode: 814, duration: 35.014s, episode steps: 642, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.012945, mae: 1.446827, mean_q: 1.765413\n",
            " 560953/1000000: episode: 815, duration: 37.801s, episode steps: 693, steps per second:  18, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.014361, mae: 1.443643, mean_q: 1.760302\n",
            " 561800/1000000: episode: 816, duration: 46.089s, episode steps: 847, steps per second:  18, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.013764, mae: 1.450883, mean_q: 1.769589\n",
            " 562222/1000000: episode: 817, duration: 23.173s, episode steps: 422, steps per second:  18, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.014028, mae: 1.475207, mean_q: 1.800657\n",
            " 562889/1000000: episode: 818, duration: 36.597s, episode steps: 667, steps per second:  18, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.014804, mae: 1.445761, mean_q: 1.765405\n",
            " 563264/1000000: episode: 819, duration: 20.569s, episode steps: 375, steps per second:  18, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.014803, mae: 1.436382, mean_q: 1.751747\n",
            " 563757/1000000: episode: 820, duration: 27.091s, episode steps: 493, steps per second:  18, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.013467, mae: 1.417647, mean_q: 1.729427\n",
            " 564410/1000000: episode: 821, duration: 35.600s, episode steps: 653, steps per second:  18, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.014108, mae: 1.454606, mean_q: 1.775147\n",
            " 565061/1000000: episode: 822, duration: 35.480s, episode steps: 651, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.014617, mae: 1.455718, mean_q: 1.774977\n",
            " 565487/1000000: episode: 823, duration: 23.160s, episode steps: 426, steps per second:  18, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.016889, mae: 1.452860, mean_q: 1.773293\n",
            " 566508/1000000: episode: 824, duration: 55.943s, episode steps: 1021, steps per second:  18, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.014719, mae: 1.447597, mean_q: 1.766262\n",
            " 567060/1000000: episode: 825, duration: 30.173s, episode steps: 552, steps per second:  18, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.016345, mae: 1.461036, mean_q: 1.781933\n",
            " 567742/1000000: episode: 826, duration: 37.200s, episode steps: 682, steps per second:  18, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.013175, mae: 1.444065, mean_q: 1.760754\n",
            " 568302/1000000: episode: 827, duration: 30.437s, episode steps: 560, steps per second:  18, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.014868, mae: 1.432846, mean_q: 1.747657\n",
            " 568985/1000000: episode: 828, duration: 37.286s, episode steps: 683, steps per second:  18, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.013546, mae: 1.441767, mean_q: 1.758099\n",
            " 569572/1000000: episode: 829, duration: 32.179s, episode steps: 587, steps per second:  18, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.014865, mae: 1.440946, mean_q: 1.755652\n",
            " 570288/1000000: episode: 830, duration: 39.580s, episode steps: 716, steps per second:  18, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.014708, mae: 1.459778, mean_q: 1.781034\n",
            " 570926/1000000: episode: 831, duration: 34.978s, episode steps: 638, steps per second:  18, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.012512, mae: 1.440578, mean_q: 1.759130\n",
            " 571590/1000000: episode: 832, duration: 36.707s, episode steps: 664, steps per second:  18, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.013747, mae: 1.444654, mean_q: 1.761575\n",
            " 572437/1000000: episode: 833, duration: 46.751s, episode steps: 847, steps per second:  18, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.014785, mae: 1.431645, mean_q: 1.746107\n",
            " 572855/1000000: episode: 834, duration: 22.971s, episode steps: 418, steps per second:  18, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.016391, mae: 1.420848, mean_q: 1.732453\n",
            " 573451/1000000: episode: 835, duration: 32.696s, episode steps: 596, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.013174, mae: 1.434677, mean_q: 1.750627\n",
            " 574085/1000000: episode: 836, duration: 35.012s, episode steps: 634, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.015798, mae: 1.424901, mean_q: 1.736020\n",
            " 574586/1000000: episode: 837, duration: 27.396s, episode steps: 501, steps per second:  18, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.016880, mae: 1.427329, mean_q: 1.740885\n",
            " 575223/1000000: episode: 838, duration: 34.733s, episode steps: 637, steps per second:  18, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.014016, mae: 1.442665, mean_q: 1.761782\n",
            " 576158/1000000: episode: 839, duration: 51.048s, episode steps: 935, steps per second:  18, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.029915, mae: 1.453684, mean_q: 1.773864\n",
            " 576696/1000000: episode: 840, duration: 29.578s, episode steps: 538, steps per second:  18, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.023897, mae: 1.457184, mean_q: 1.772367\n",
            " 577194/1000000: episode: 841, duration: 27.358s, episode steps: 498, steps per second:  18, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.016891, mae: 1.422272, mean_q: 1.730588\n",
            " 577955/1000000: episode: 842, duration: 41.506s, episode steps: 761, steps per second:  18, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.015278, mae: 1.444298, mean_q: 1.757729\n",
            " 578450/1000000: episode: 843, duration: 27.238s, episode steps: 495, steps per second:  18, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.015963, mae: 1.435383, mean_q: 1.747835\n",
            " 579265/1000000: episode: 844, duration: 44.707s, episode steps: 815, steps per second:  18, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.015805, mae: 1.436167, mean_q: 1.749000\n",
            " 579654/1000000: episode: 845, duration: 21.316s, episode steps: 389, steps per second:  18, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.015647, mae: 1.425168, mean_q: 1.737467\n",
            " 580279/1000000: episode: 846, duration: 34.259s, episode steps: 625, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.014632, mae: 1.436255, mean_q: 1.754324\n",
            " 580662/1000000: episode: 847, duration: 21.078s, episode steps: 383, steps per second:  18, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.016821, mae: 1.487914, mean_q: 1.817038\n",
            " 581828/1000000: episode: 848, duration: 64.121s, episode steps: 1166, steps per second:  18, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.015661, mae: 1.458958, mean_q: 1.781259\n",
            " 582458/1000000: episode: 849, duration: 34.775s, episode steps: 630, steps per second:  18, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.014293, mae: 1.461723, mean_q: 1.782784\n",
            " 583062/1000000: episode: 850, duration: 33.169s, episode steps: 604, steps per second:  18, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.014388, mae: 1.435100, mean_q: 1.751484\n",
            " 583778/1000000: episode: 851, duration: 39.338s, episode steps: 716, steps per second:  18, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.014361, mae: 1.444538, mean_q: 1.764116\n",
            " 584885/1000000: episode: 852, duration: 60.951s, episode steps: 1107, steps per second:  18, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.013999, mae: 1.460776, mean_q: 1.782921\n",
            " 585431/1000000: episode: 853, duration: 29.942s, episode steps: 546, steps per second:  18, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.013931, mae: 1.445462, mean_q: 1.761696\n",
            " 586566/1000000: episode: 854, duration: 62.640s, episode steps: 1135, steps per second:  18, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.013335, mae: 1.443996, mean_q: 1.760815\n",
            " 587799/1000000: episode: 855, duration: 67.706s, episode steps: 1233, steps per second:  18, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.014903, mae: 1.458314, mean_q: 1.777284\n",
            " 588306/1000000: episode: 856, duration: 27.919s, episode steps: 507, steps per second:  18, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.013704, mae: 1.446960, mean_q: 1.765833\n",
            " 588949/1000000: episode: 857, duration: 35.492s, episode steps: 643, steps per second:  18, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.013725, mae: 1.455302, mean_q: 1.775832\n",
            " 589638/1000000: episode: 858, duration: 38.024s, episode steps: 689, steps per second:  18, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.013221, mae: 1.456189, mean_q: 1.775724\n",
            " 590413/1000000: episode: 859, duration: 43.007s, episode steps: 775, steps per second:  18, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.014802, mae: 1.457948, mean_q: 1.777819\n",
            " 591242/1000000: episode: 860, duration: 45.725s, episode steps: 829, steps per second:  18, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.016185, mae: 1.487501, mean_q: 1.811530\n",
            " 591862/1000000: episode: 861, duration: 34.322s, episode steps: 620, steps per second:  18, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.014397, mae: 1.480450, mean_q: 1.802252\n",
            " 592357/1000000: episode: 862, duration: 27.686s, episode steps: 495, steps per second:  18, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.015480, mae: 1.467621, mean_q: 1.785428\n",
            " 592984/1000000: episode: 863, duration: 34.575s, episode steps: 627, steps per second:  18, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.014375, mae: 1.475004, mean_q: 1.796963\n",
            " 593496/1000000: episode: 864, duration: 28.510s, episode steps: 512, steps per second:  18, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.015806, mae: 1.476987, mean_q: 1.801066\n",
            " 594038/1000000: episode: 865, duration: 30.032s, episode steps: 542, steps per second:  18, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.016708, mae: 1.490253, mean_q: 1.812451\n",
            " 594436/1000000: episode: 866, duration: 22.074s, episode steps: 398, steps per second:  18, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.013314, mae: 1.471489, mean_q: 1.791236\n",
            " 594918/1000000: episode: 867, duration: 26.687s, episode steps: 482, steps per second:  18, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.013344, mae: 1.465626, mean_q: 1.787070\n",
            " 595557/1000000: episode: 868, duration: 35.350s, episode steps: 639, steps per second:  18, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.015146, mae: 1.461785, mean_q: 1.778878\n",
            " 596205/1000000: episode: 869, duration: 35.812s, episode steps: 648, steps per second:  18, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.016033, mae: 1.466908, mean_q: 1.786357\n",
            " 596689/1000000: episode: 870, duration: 26.761s, episode steps: 484, steps per second:  18, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.015070, mae: 1.471510, mean_q: 1.791443\n",
            " 597311/1000000: episode: 871, duration: 34.129s, episode steps: 622, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.018712, mae: 1.471317, mean_q: 1.795312\n",
            " 598198/1000000: episode: 872, duration: 49.485s, episode steps: 887, steps per second:  18, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.017403, mae: 1.471980, mean_q: 1.795691\n",
            " 598844/1000000: episode: 873, duration: 35.751s, episode steps: 646, steps per second:  18, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.014547, mae: 1.460656, mean_q: 1.779969\n",
            " 599503/1000000: episode: 874, duration: 36.621s, episode steps: 659, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.015144, mae: 1.466848, mean_q: 1.784559\n",
            " 599981/1000000: episode: 875, duration: 26.517s, episode steps: 478, steps per second:  18, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.014480, mae: 1.457922, mean_q: 1.775675\n",
            " 601184/1000000: episode: 876, duration: 66.951s, episode steps: 1203, steps per second:  18, episode reward: 21.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.013557, mae: 1.520022, mean_q: 1.852813\n",
            " 601797/1000000: episode: 877, duration: 34.122s, episode steps: 613, steps per second:  18, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.013428, mae: 1.512663, mean_q: 1.839516\n",
            " 602565/1000000: episode: 878, duration: 42.803s, episode steps: 768, steps per second:  18, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.014200, mae: 1.511425, mean_q: 1.838022\n",
            " 603169/1000000: episode: 879, duration: 33.639s, episode steps: 604, steps per second:  18, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.016700, mae: 1.518645, mean_q: 1.846379\n",
            " 603990/1000000: episode: 880, duration: 45.723s, episode steps: 821, steps per second:  18, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.015097, mae: 1.519715, mean_q: 1.848849\n",
            " 604948/1000000: episode: 881, duration: 53.459s, episode steps: 958, steps per second:  18, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.015473, mae: 1.514957, mean_q: 1.844243\n",
            " 605348/1000000: episode: 882, duration: 22.350s, episode steps: 400, steps per second:  18, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.017296, mae: 1.508737, mean_q: 1.836038\n",
            " 606017/1000000: episode: 883, duration: 37.387s, episode steps: 669, steps per second:  18, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.016379, mae: 1.514137, mean_q: 1.841961\n",
            " 606541/1000000: episode: 884, duration: 28.974s, episode steps: 524, steps per second:  18, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.015817, mae: 1.524090, mean_q: 1.854495\n",
            " 606951/1000000: episode: 885, duration: 22.669s, episode steps: 410, steps per second:  18, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.018929, mae: 1.493560, mean_q: 1.822409\n",
            " 607335/1000000: episode: 886, duration: 21.460s, episode steps: 384, steps per second:  18, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.015215, mae: 1.522670, mean_q: 1.854546\n",
            " 608663/1000000: episode: 887, duration: 73.834s, episode steps: 1328, steps per second:  18, episode reward: 15.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.014848, mae: 1.512197, mean_q: 1.839685\n",
            " 609528/1000000: episode: 888, duration: 48.516s, episode steps: 865, steps per second:  18, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.016191, mae: 1.520124, mean_q: 1.850124\n",
            " 610404/1000000: episode: 889, duration: 48.921s, episode steps: 876, steps per second:  18, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.013412, mae: 1.511559, mean_q: 1.839889\n",
            " 611295/1000000: episode: 890, duration: 49.383s, episode steps: 891, steps per second:  18, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.014055, mae: 1.532219, mean_q: 1.866566\n",
            " 612014/1000000: episode: 891, duration: 40.202s, episode steps: 719, steps per second:  18, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.015128, mae: 1.531998, mean_q: 1.866502\n",
            " 612652/1000000: episode: 892, duration: 35.587s, episode steps: 638, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.014308, mae: 1.529494, mean_q: 1.860843\n",
            " 613163/1000000: episode: 893, duration: 28.494s, episode steps: 511, steps per second:  18, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.016391, mae: 1.554345, mean_q: 1.891149\n",
            " 613714/1000000: episode: 894, duration: 30.745s, episode steps: 551, steps per second:  18, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.015182, mae: 1.528974, mean_q: 1.860543\n",
            " 614412/1000000: episode: 895, duration: 39.264s, episode steps: 698, steps per second:  18, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.015328, mae: 1.550656, mean_q: 1.887944\n",
            " 615195/1000000: episode: 896, duration: 43.951s, episode steps: 783, steps per second:  18, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.018988, mae: 1.546108, mean_q: 1.884177\n",
            " 615715/1000000: episode: 897, duration: 29.053s, episode steps: 520, steps per second:  18, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.015332, mae: 1.549878, mean_q: 1.888271\n",
            " 616626/1000000: episode: 898, duration: 51.143s, episode steps: 911, steps per second:  18, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.016405, mae: 1.531925, mean_q: 1.866751\n",
            " 618192/1000000: episode: 899, duration: 87.679s, episode steps: 1566, steps per second:  18, episode reward: 31.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.014458, mae: 1.530485, mean_q: 1.864567\n",
            " 618820/1000000: episode: 900, duration: 35.498s, episode steps: 628, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.014362, mae: 1.544222, mean_q: 1.879158\n",
            " 619385/1000000: episode: 901, duration: 31.868s, episode steps: 565, steps per second:  18, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.014571, mae: 1.538102, mean_q: 1.872141\n",
            " 620044/1000000: episode: 902, duration: 37.296s, episode steps: 659, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.014657, mae: 1.537446, mean_q: 1.869883\n",
            " 620742/1000000: episode: 903, duration: 39.275s, episode steps: 698, steps per second:  18, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.012667, mae: 1.571520, mean_q: 1.912438\n",
            " 621443/1000000: episode: 904, duration: 39.075s, episode steps: 701, steps per second:  18, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.015279, mae: 1.573969, mean_q: 1.914329\n",
            " 622198/1000000: episode: 905, duration: 42.384s, episode steps: 755, steps per second:  18, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.014451, mae: 1.571163, mean_q: 1.911789\n",
            " 622672/1000000: episode: 906, duration: 26.751s, episode steps: 474, steps per second:  18, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.018665, mae: 1.548385, mean_q: 1.882471\n",
            " 623052/1000000: episode: 907, duration: 21.554s, episode steps: 380, steps per second:  18, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.015374, mae: 1.569396, mean_q: 1.907048\n",
            " 623476/1000000: episode: 908, duration: 24.047s, episode steps: 424, steps per second:  18, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.016961, mae: 1.576694, mean_q: 1.916938\n",
            " 624208/1000000: episode: 909, duration: 41.269s, episode steps: 732, steps per second:  18, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.015879, mae: 1.566931, mean_q: 1.903879\n",
            " 624863/1000000: episode: 910, duration: 36.843s, episode steps: 655, steps per second:  18, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.017832, mae: 1.568174, mean_q: 1.909210\n",
            " 625547/1000000: episode: 911, duration: 38.655s, episode steps: 684, steps per second:  18, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.014601, mae: 1.555101, mean_q: 1.892674\n",
            " 625940/1000000: episode: 912, duration: 22.271s, episode steps: 393, steps per second:  18, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.014303, mae: 1.557059, mean_q: 1.892663\n",
            " 626494/1000000: episode: 913, duration: 31.172s, episode steps: 554, steps per second:  18, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.015877, mae: 1.573273, mean_q: 1.911033\n",
            " 627005/1000000: episode: 914, duration: 28.781s, episode steps: 511, steps per second:  18, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.014727, mae: 1.537146, mean_q: 1.867730\n",
            " 627791/1000000: episode: 915, duration: 43.916s, episode steps: 786, steps per second:  18, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.014179, mae: 1.552469, mean_q: 1.886966\n",
            " 628192/1000000: episode: 916, duration: 22.793s, episode steps: 401, steps per second:  18, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.016835, mae: 1.574338, mean_q: 1.915594\n",
            " 629414/1000000: episode: 917, duration: 68.689s, episode steps: 1222, steps per second:  18, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.016964, mae: 1.568834, mean_q: 1.906174\n",
            " 630138/1000000: episode: 918, duration: 40.632s, episode steps: 724, steps per second:  18, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.015229, mae: 1.537660, mean_q: 1.870673\n",
            " 630651/1000000: episode: 919, duration: 28.607s, episode steps: 513, steps per second:  18, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.015534, mae: 1.601081, mean_q: 1.943300\n",
            " 631076/1000000: episode: 920, duration: 24.165s, episode steps: 425, steps per second:  18, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.014016, mae: 1.576971, mean_q: 1.916166\n",
            " 631719/1000000: episode: 921, duration: 36.190s, episode steps: 643, steps per second:  18, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.013094, mae: 1.592978, mean_q: 1.937385\n",
            " 632357/1000000: episode: 922, duration: 35.949s, episode steps: 638, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.014324, mae: 1.595114, mean_q: 1.939409\n",
            " 633054/1000000: episode: 923, duration: 39.002s, episode steps: 697, steps per second:  18, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.014821, mae: 1.590705, mean_q: 1.934950\n",
            " 633716/1000000: episode: 924, duration: 37.483s, episode steps: 662, steps per second:  18, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.015158, mae: 1.590399, mean_q: 1.931405\n",
            " 634417/1000000: episode: 925, duration: 39.627s, episode steps: 701, steps per second:  18, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.013326, mae: 1.562600, mean_q: 1.897050\n",
            " 634812/1000000: episode: 926, duration: 22.184s, episode steps: 395, steps per second:  18, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.014757, mae: 1.597598, mean_q: 1.939798\n",
            " 635495/1000000: episode: 927, duration: 38.447s, episode steps: 683, steps per second:  18, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.012997, mae: 1.563417, mean_q: 1.897849\n",
            " 636172/1000000: episode: 928, duration: 38.387s, episode steps: 677, steps per second:  18, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.013708, mae: 1.581839, mean_q: 1.922106\n",
            " 636980/1000000: episode: 929, duration: 45.886s, episode steps: 808, steps per second:  18, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.014063, mae: 1.592867, mean_q: 1.932883\n",
            " 637571/1000000: episode: 930, duration: 33.241s, episode steps: 591, steps per second:  18, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.015670, mae: 1.565771, mean_q: 1.901170\n",
            " 638349/1000000: episode: 931, duration: 43.613s, episode steps: 778, steps per second:  18, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.014439, mae: 1.563578, mean_q: 1.895357\n",
            " 639352/1000000: episode: 932, duration: 56.309s, episode steps: 1003, steps per second:  18, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.015688, mae: 1.587967, mean_q: 1.927987\n",
            " 640011/1000000: episode: 933, duration: 37.273s, episode steps: 659, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.014294, mae: 1.579586, mean_q: 1.919270\n",
            " 640882/1000000: episode: 934, duration: 49.067s, episode steps: 871, steps per second:  18, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.015714, mae: 1.640100, mean_q: 1.993490\n",
            " 641712/1000000: episode: 935, duration: 47.034s, episode steps: 830, steps per second:  18, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.027418, mae: 1.620231, mean_q: 1.965829\n",
            " 642835/1000000: episode: 936, duration: 63.696s, episode steps: 1123, steps per second:  18, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.016499, mae: 1.627495, mean_q: 1.975841\n",
            " 643599/1000000: episode: 937, duration: 42.829s, episode steps: 764, steps per second:  18, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.016052, mae: 1.605828, mean_q: 1.952301\n",
            " 644354/1000000: episode: 938, duration: 42.503s, episode steps: 755, steps per second:  18, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.014953, mae: 1.615454, mean_q: 1.960823\n",
            " 645243/1000000: episode: 939, duration: 50.102s, episode steps: 889, steps per second:  18, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.015560, mae: 1.615982, mean_q: 1.961915\n",
            " 645916/1000000: episode: 940, duration: 38.249s, episode steps: 673, steps per second:  18, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.016102, mae: 1.622527, mean_q: 1.970765\n",
            " 646303/1000000: episode: 941, duration: 22.089s, episode steps: 387, steps per second:  18, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.018136, mae: 1.626641, mean_q: 1.972553\n",
            " 647056/1000000: episode: 942, duration: 42.945s, episode steps: 753, steps per second:  18, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.014330, mae: 1.618589, mean_q: 1.963680\n",
            " 647816/1000000: episode: 943, duration: 43.385s, episode steps: 760, steps per second:  18, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.015925, mae: 1.635177, mean_q: 1.984917\n",
            " 648917/1000000: episode: 944, duration: 62.776s, episode steps: 1101, steps per second:  18, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.014969, mae: 1.609496, mean_q: 1.952179\n",
            " 649540/1000000: episode: 945, duration: 35.114s, episode steps: 623, steps per second:  18, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.015792, mae: 1.610655, mean_q: 1.952884\n",
            " 650122/1000000: episode: 946, duration: 33.039s, episode steps: 582, steps per second:  18, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.014569, mae: 1.603026, mean_q: 1.947822\n",
            " 650613/1000000: episode: 947, duration: 27.835s, episode steps: 491, steps per second:  18, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.013798, mae: 1.599021, mean_q: 1.947461\n",
            " 651382/1000000: episode: 948, duration: 43.701s, episode steps: 769, steps per second:  18, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.015914, mae: 1.624753, mean_q: 1.973058\n",
            " 652006/1000000: episode: 949, duration: 35.323s, episode steps: 624, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.015613, mae: 1.616069, mean_q: 1.959438\n",
            " 652682/1000000: episode: 950, duration: 38.145s, episode steps: 676, steps per second:  18, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.017346, mae: 1.614307, mean_q: 1.959320\n",
            " 653781/1000000: episode: 951, duration: 62.256s, episode steps: 1099, steps per second:  18, episode reward:  8.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.016054, mae: 1.599873, mean_q: 1.943280\n",
            " 654380/1000000: episode: 952, duration: 33.911s, episode steps: 599, steps per second:  18, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.014631, mae: 1.610404, mean_q: 1.955083\n",
            " 655284/1000000: episode: 953, duration: 51.377s, episode steps: 904, steps per second:  18, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.017071, mae: 1.624730, mean_q: 1.978949\n",
            " 656210/1000000: episode: 954, duration: 52.447s, episode steps: 926, steps per second:  18, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.015541, mae: 1.594382, mean_q: 1.934135\n",
            " 657514/1000000: episode: 955, duration: 74.158s, episode steps: 1304, steps per second:  18, episode reward: 25.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.021468, mae: 1.611277, mean_q: 1.955917\n",
            " 658117/1000000: episode: 956, duration: 34.813s, episode steps: 603, steps per second:  17, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.013294, mae: 1.600501, mean_q: 1.943509\n",
            " 658735/1000000: episode: 957, duration: 35.745s, episode steps: 618, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.014232, mae: 1.607285, mean_q: 1.951565\n",
            " 659556/1000000: episode: 958, duration: 47.127s, episode steps: 821, steps per second:  17, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.014031, mae: 1.615574, mean_q: 1.962874\n",
            " 660191/1000000: episode: 959, duration: 36.184s, episode steps: 635, steps per second:  18, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.013741, mae: 1.624270, mean_q: 1.972355\n",
            " 660967/1000000: episode: 960, duration: 43.988s, episode steps: 776, steps per second:  18, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.014880, mae: 1.634156, mean_q: 1.982242\n",
            " 661507/1000000: episode: 961, duration: 30.587s, episode steps: 540, steps per second:  18, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.014209, mae: 1.628772, mean_q: 1.976920\n",
            " 662142/1000000: episode: 962, duration: 35.954s, episode steps: 635, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.014354, mae: 1.615378, mean_q: 1.959501\n",
            " 663132/1000000: episode: 963, duration: 56.034s, episode steps: 990, steps per second:  18, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.016830, mae: 1.622998, mean_q: 1.972020\n",
            " 663653/1000000: episode: 964, duration: 29.671s, episode steps: 521, steps per second:  18, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.015671, mae: 1.633258, mean_q: 1.984773\n",
            " 664190/1000000: episode: 965, duration: 30.587s, episode steps: 537, steps per second:  18, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.015286, mae: 1.634091, mean_q: 1.981357\n",
            " 664836/1000000: episode: 966, duration: 36.619s, episode steps: 646, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.015060, mae: 1.603384, mean_q: 1.945051\n",
            " 666088/1000000: episode: 967, duration: 71.002s, episode steps: 1252, steps per second:  18, episode reward: 18.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.015961, mae: 1.622230, mean_q: 1.965964\n",
            " 666716/1000000: episode: 968, duration: 35.847s, episode steps: 628, steps per second:  18, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.013770, mae: 1.605644, mean_q: 1.946353\n",
            " 667243/1000000: episode: 969, duration: 29.811s, episode steps: 527, steps per second:  18, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.014129, mae: 1.607769, mean_q: 1.951795\n",
            " 667647/1000000: episode: 970, duration: 22.895s, episode steps: 404, steps per second:  18, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.014709, mae: 1.615042, mean_q: 1.958355\n",
            " 668471/1000000: episode: 971, duration: 46.588s, episode steps: 824, steps per second:  18, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.017180, mae: 1.610849, mean_q: 1.956186\n",
            " 668989/1000000: episode: 972, duration: 29.401s, episode steps: 518, steps per second:  18, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.016357, mae: 1.618372, mean_q: 1.963998\n",
            " 669687/1000000: episode: 973, duration: 39.465s, episode steps: 698, steps per second:  18, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.017779, mae: 1.612362, mean_q: 1.954702\n",
            " 670483/1000000: episode: 974, duration: 45.075s, episode steps: 796, steps per second:  18, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.015075, mae: 1.616018, mean_q: 1.960119\n",
            " 670934/1000000: episode: 975, duration: 25.648s, episode steps: 451, steps per second:  18, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.012705, mae: 1.655501, mean_q: 2.007677\n",
            " 671519/1000000: episode: 976, duration: 33.031s, episode steps: 585, steps per second:  18, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.013991, mae: 1.647169, mean_q: 1.997586\n",
            " 671916/1000000: episode: 977, duration: 22.621s, episode steps: 397, steps per second:  18, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.014644, mae: 1.655401, mean_q: 2.008938\n",
            " 672490/1000000: episode: 978, duration: 32.721s, episode steps: 574, steps per second:  18, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.014646, mae: 1.633425, mean_q: 1.981404\n",
            " 673324/1000000: episode: 979, duration: 47.374s, episode steps: 834, steps per second:  18, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.015343, mae: 1.642755, mean_q: 1.992040\n",
            " 673966/1000000: episode: 980, duration: 36.493s, episode steps: 642, steps per second:  18, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.016571, mae: 1.634148, mean_q: 1.984089\n",
            " 674625/1000000: episode: 981, duration: 37.286s, episode steps: 659, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.016485, mae: 1.643882, mean_q: 1.994657\n",
            " 675304/1000000: episode: 982, duration: 38.750s, episode steps: 679, steps per second:  18, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.015882, mae: 1.619503, mean_q: 1.966065\n",
            " 675827/1000000: episode: 983, duration: 29.727s, episode steps: 523, steps per second:  18, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.017434, mae: 1.665406, mean_q: 2.017082\n",
            " 676309/1000000: episode: 984, duration: 27.549s, episode steps: 482, steps per second:  17, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.013310, mae: 1.633061, mean_q: 1.981206\n",
            " 676705/1000000: episode: 985, duration: 22.521s, episode steps: 396, steps per second:  18, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.015371, mae: 1.635366, mean_q: 1.981462\n",
            " 677405/1000000: episode: 986, duration: 40.045s, episode steps: 700, steps per second:  17, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.015541, mae: 1.640683, mean_q: 1.992303\n",
            " 678193/1000000: episode: 987, duration: 44.737s, episode steps: 788, steps per second:  18, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.015934, mae: 1.632570, mean_q: 1.979701\n",
            " 679216/1000000: episode: 988, duration: 58.773s, episode steps: 1023, steps per second:  17, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.015079, mae: 1.634061, mean_q: 1.981181\n",
            " 680002/1000000: episode: 989, duration: 44.761s, episode steps: 786, steps per second:  18, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.014761, mae: 1.626885, mean_q: 1.973377\n",
            " 680421/1000000: episode: 990, duration: 23.981s, episode steps: 419, steps per second:  17, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.015655, mae: 1.660619, mean_q: 2.018731\n",
            " 681112/1000000: episode: 991, duration: 39.155s, episode steps: 691, steps per second:  18, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.014784, mae: 1.642240, mean_q: 1.994093\n",
            " 681643/1000000: episode: 992, duration: 30.433s, episode steps: 531, steps per second:  17, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.016370, mae: 1.678250, mean_q: 2.037033\n",
            " 682065/1000000: episode: 993, duration: 24.126s, episode steps: 422, steps per second:  17, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.017275, mae: 1.667102, mean_q: 2.024668\n",
            " 682607/1000000: episode: 994, duration: 30.797s, episode steps: 542, steps per second:  18, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.014653, mae: 1.646728, mean_q: 2.001206\n",
            " 683355/1000000: episode: 995, duration: 42.807s, episode steps: 748, steps per second:  17, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.015639, mae: 1.665628, mean_q: 2.021809\n",
            " 684057/1000000: episode: 996, duration: 40.355s, episode steps: 702, steps per second:  17, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.015277, mae: 1.647922, mean_q: 2.002142\n",
            " 684591/1000000: episode: 997, duration: 30.571s, episode steps: 534, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.015575, mae: 1.652597, mean_q: 2.003301\n",
            " 685123/1000000: episode: 998, duration: 30.187s, episode steps: 532, steps per second:  18, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.014034, mae: 1.651649, mean_q: 2.003415\n",
            " 685757/1000000: episode: 999, duration: 36.440s, episode steps: 634, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.016371, mae: 1.671613, mean_q: 2.029871\n",
            " 686399/1000000: episode: 1000, duration: 36.501s, episode steps: 642, steps per second:  18, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.015582, mae: 1.655794, mean_q: 2.011818\n",
            " 686799/1000000: episode: 1001, duration: 22.710s, episode steps: 400, steps per second:  18, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.016565, mae: 1.650988, mean_q: 2.003115\n",
            " 687242/1000000: episode: 1002, duration: 25.272s, episode steps: 443, steps per second:  18, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.016918, mae: 1.672345, mean_q: 2.031135\n",
            " 688526/1000000: episode: 1003, duration: 73.165s, episode steps: 1284, steps per second:  18, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.016233, mae: 1.649808, mean_q: 2.003679\n",
            " 689155/1000000: episode: 1004, duration: 35.767s, episode steps: 629, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.015239, mae: 1.652082, mean_q: 2.005056\n",
            " 689773/1000000: episode: 1005, duration: 35.385s, episode steps: 618, steps per second:  17, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.015464, mae: 1.654086, mean_q: 2.008756\n",
            " 690299/1000000: episode: 1006, duration: 29.972s, episode steps: 526, steps per second:  18, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.016342, mae: 1.690767, mean_q: 2.052115\n",
            " 691116/1000000: episode: 1007, duration: 46.931s, episode steps: 817, steps per second:  17, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.012994, mae: 1.696095, mean_q: 2.060666\n",
            " 692211/1000000: episode: 1008, duration: 62.569s, episode steps: 1095, steps per second:  18, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.015078, mae: 1.710912, mean_q: 2.077537\n",
            " 692915/1000000: episode: 1009, duration: 40.082s, episode steps: 704, steps per second:  18, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.018140, mae: 1.692795, mean_q: 2.055211\n",
            " 693793/1000000: episode: 1010, duration: 50.101s, episode steps: 878, steps per second:  18, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.017338, mae: 1.718423, mean_q: 2.085022\n",
            " 694392/1000000: episode: 1011, duration: 34.186s, episode steps: 599, steps per second:  18, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.015778, mae: 1.694360, mean_q: 2.055689\n",
            " 694961/1000000: episode: 1012, duration: 32.683s, episode steps: 569, steps per second:  17, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.015746, mae: 1.709113, mean_q: 2.069991\n",
            " 695825/1000000: episode: 1013, duration: 49.417s, episode steps: 864, steps per second:  17, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.016108, mae: 1.694037, mean_q: 2.052859\n",
            " 696520/1000000: episode: 1014, duration: 39.906s, episode steps: 695, steps per second:  17, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.015388, mae: 1.715762, mean_q: 2.078360\n",
            " 697312/1000000: episode: 1015, duration: 45.483s, episode steps: 792, steps per second:  17, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.016699, mae: 1.698162, mean_q: 2.056952\n",
            " 697841/1000000: episode: 1016, duration: 30.308s, episode steps: 529, steps per second:  17, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.019040, mae: 1.700820, mean_q: 2.059887\n",
            " 698472/1000000: episode: 1017, duration: 36.069s, episode steps: 631, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.017004, mae: 1.693711, mean_q: 2.053489\n",
            " 699423/1000000: episode: 1018, duration: 54.581s, episode steps: 951, steps per second:  17, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.017452, mae: 1.710633, mean_q: 2.074786\n",
            " 700373/1000000: episode: 1019, duration: 54.569s, episode steps: 950, steps per second:  17, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.014041, mae: 1.720025, mean_q: 2.085513\n",
            " 700766/1000000: episode: 1020, duration: 22.408s, episode steps: 393, steps per second:  18, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.016522, mae: 1.724935, mean_q: 2.091377\n",
            " 701981/1000000: episode: 1021, duration: 70.122s, episode steps: 1215, steps per second:  17, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.015585, mae: 1.758771, mean_q: 2.133566\n",
            " 702606/1000000: episode: 1022, duration: 35.939s, episode steps: 625, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.015782, mae: 1.753865, mean_q: 2.126900\n",
            " 703214/1000000: episode: 1023, duration: 34.809s, episode steps: 608, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.019049, mae: 1.736114, mean_q: 2.105220\n",
            " 703818/1000000: episode: 1024, duration: 34.666s, episode steps: 604, steps per second:  17, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.019003, mae: 1.753149, mean_q: 2.123122\n",
            " 705065/1000000: episode: 1025, duration: 71.424s, episode steps: 1247, steps per second:  17, episode reward: 19.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.017117, mae: 1.745378, mean_q: 2.117774\n",
            " 705806/1000000: episode: 1026, duration: 42.364s, episode steps: 741, steps per second:  17, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.017239, mae: 1.738345, mean_q: 2.108011\n",
            " 706879/1000000: episode: 1027, duration: 61.465s, episode steps: 1073, steps per second:  17, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.015308, mae: 1.752691, mean_q: 2.124551\n",
            " 707675/1000000: episode: 1028, duration: 45.611s, episode steps: 796, steps per second:  17, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.017176, mae: 1.750098, mean_q: 2.120972\n",
            " 708281/1000000: episode: 1029, duration: 34.747s, episode steps: 606, steps per second:  17, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.015427, mae: 1.752017, mean_q: 2.122633\n",
            " 708916/1000000: episode: 1030, duration: 36.458s, episode steps: 635, steps per second:  17, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.017118, mae: 1.761498, mean_q: 2.134881\n",
            " 709335/1000000: episode: 1031, duration: 24.118s, episode steps: 419, steps per second:  17, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.015871, mae: 1.749428, mean_q: 2.120732\n",
            " 709981/1000000: episode: 1032, duration: 37.198s, episode steps: 646, steps per second:  17, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.018086, mae: 1.753636, mean_q: 2.121462\n",
            " 710495/1000000: episode: 1033, duration: 29.360s, episode steps: 514, steps per second:  18, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.014215, mae: 1.756127, mean_q: 2.128713\n",
            " 711681/1000000: episode: 1034, duration: 68.159s, episode steps: 1186, steps per second:  17, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.015868, mae: 1.760467, mean_q: 2.133576\n",
            " 712071/1000000: episode: 1035, duration: 22.409s, episode steps: 390, steps per second:  17, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.017616, mae: 1.774433, mean_q: 2.146493\n",
            " 712735/1000000: episode: 1036, duration: 37.994s, episode steps: 664, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.017011, mae: 1.764996, mean_q: 2.138337\n",
            " 713136/1000000: episode: 1037, duration: 23.559s, episode steps: 401, steps per second:  17, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.014342, mae: 1.782517, mean_q: 2.163200\n",
            " 713671/1000000: episode: 1038, duration: 30.875s, episode steps: 535, steps per second:  17, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.016071, mae: 1.748615, mean_q: 2.119805\n",
            " 714175/1000000: episode: 1039, duration: 29.377s, episode steps: 504, steps per second:  17, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.016684, mae: 1.752370, mean_q: 2.125525\n",
            " 715131/1000000: episode: 1040, duration: 56.039s, episode steps: 956, steps per second:  17, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.015723, mae: 1.756404, mean_q: 2.130126\n",
            " 715519/1000000: episode: 1041, duration: 22.457s, episode steps: 388, steps per second:  17, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.016614, mae: 1.749257, mean_q: 2.119140\n",
            " 716135/1000000: episode: 1042, duration: 35.556s, episode steps: 616, steps per second:  17, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.016078, mae: 1.763842, mean_q: 2.137553\n",
            " 716636/1000000: episode: 1043, duration: 29.216s, episode steps: 501, steps per second:  17, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.018291, mae: 1.768459, mean_q: 2.143212\n",
            " 717146/1000000: episode: 1044, duration: 29.514s, episode steps: 510, steps per second:  17, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.031803, mae: 1.761206, mean_q: 2.129155\n",
            " 717542/1000000: episode: 1045, duration: 22.786s, episode steps: 396, steps per second:  17, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.021512, mae: 1.757886, mean_q: 2.124451\n",
            " 718268/1000000: episode: 1046, duration: 42.040s, episode steps: 726, steps per second:  17, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.017015, mae: 1.746618, mean_q: 2.115714\n",
            " 719207/1000000: episode: 1047, duration: 54.011s, episode steps: 939, steps per second:  17, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.017118, mae: 1.753885, mean_q: 2.123693\n",
            " 719904/1000000: episode: 1048, duration: 40.218s, episode steps: 697, steps per second:  17, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.018432, mae: 1.748129, mean_q: 2.116449\n",
            " 720595/1000000: episode: 1049, duration: 39.782s, episode steps: 691, steps per second:  17, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.015326, mae: 1.791849, mean_q: 2.172089\n",
            " 721383/1000000: episode: 1050, duration: 45.250s, episode steps: 788, steps per second:  17, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.016844, mae: 1.782063, mean_q: 2.159890\n",
            " 722014/1000000: episode: 1051, duration: 36.234s, episode steps: 631, steps per second:  17, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.014634, mae: 1.795810, mean_q: 2.176604\n",
            " 722994/1000000: episode: 1052, duration: 56.471s, episode steps: 980, steps per second:  17, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.015995, mae: 1.758655, mean_q: 2.130163\n",
            " 724281/1000000: episode: 1053, duration: 75.486s, episode steps: 1287, steps per second:  17, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.014582, mae: 1.783121, mean_q: 2.160394\n",
            " 724772/1000000: episode: 1054, duration: 28.869s, episode steps: 491, steps per second:  17, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.015359, mae: 1.781555, mean_q: 2.159879\n",
            " 725637/1000000: episode: 1055, duration: 50.438s, episode steps: 865, steps per second:  17, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.016171, mae: 1.789354, mean_q: 2.169640\n",
            " 726243/1000000: episode: 1056, duration: 35.050s, episode steps: 606, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.016887, mae: 1.775154, mean_q: 2.150832\n",
            " 726767/1000000: episode: 1057, duration: 30.272s, episode steps: 524, steps per second:  17, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.016799, mae: 1.781117, mean_q: 2.161289\n",
            " 727305/1000000: episode: 1058, duration: 31.379s, episode steps: 538, steps per second:  17, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.014976, mae: 1.773770, mean_q: 2.148761\n",
            " 727940/1000000: episode: 1059, duration: 37.043s, episode steps: 635, steps per second:  17, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.016000, mae: 1.781046, mean_q: 2.158986\n",
            " 728600/1000000: episode: 1060, duration: 38.600s, episode steps: 660, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.015111, mae: 1.780640, mean_q: 2.157580\n",
            " 729458/1000000: episode: 1061, duration: 49.973s, episode steps: 858, steps per second:  17, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.017083, mae: 1.776705, mean_q: 2.154296\n",
            " 730141/1000000: episode: 1062, duration: 39.703s, episode steps: 683, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.015095, mae: 1.787618, mean_q: 2.167326\n",
            " 730699/1000000: episode: 1063, duration: 32.213s, episode steps: 558, steps per second:  17, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.014436, mae: 1.811144, mean_q: 2.196705\n",
            " 731312/1000000: episode: 1064, duration: 35.739s, episode steps: 613, steps per second:  17, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.017440, mae: 1.811724, mean_q: 2.193136\n",
            " 731952/1000000: episode: 1065, duration: 37.125s, episode steps: 640, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.015505, mae: 1.810556, mean_q: 2.192794\n",
            " 732695/1000000: episode: 1066, duration: 43.089s, episode steps: 743, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.016688, mae: 1.803577, mean_q: 2.184121\n",
            " 733426/1000000: episode: 1067, duration: 42.317s, episode steps: 731, steps per second:  17, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.016197, mae: 1.801085, mean_q: 2.179636\n",
            " 733856/1000000: episode: 1068, duration: 25.097s, episode steps: 430, steps per second:  17, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.015190, mae: 1.807295, mean_q: 2.190726\n",
            " 734383/1000000: episode: 1069, duration: 30.691s, episode steps: 527, steps per second:  17, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.020217, mae: 1.818370, mean_q: 2.202617\n",
            " 734819/1000000: episode: 1070, duration: 25.308s, episode steps: 436, steps per second:  17, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.017416, mae: 1.817478, mean_q: 2.201222\n",
            " 736068/1000000: episode: 1071, duration: 72.743s, episode steps: 1249, steps per second:  17, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.017483, mae: 1.820625, mean_q: 2.204221\n",
            " 736761/1000000: episode: 1072, duration: 40.641s, episode steps: 693, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.018175, mae: 1.790070, mean_q: 2.166419\n",
            " 737481/1000000: episode: 1073, duration: 41.781s, episode steps: 720, steps per second:  17, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.016375, mae: 1.807435, mean_q: 2.187899\n",
            " 738120/1000000: episode: 1074, duration: 37.169s, episode steps: 639, steps per second:  17, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.018581, mae: 1.815393, mean_q: 2.196768\n",
            " 738750/1000000: episode: 1075, duration: 36.566s, episode steps: 630, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.018616, mae: 1.801989, mean_q: 2.182355\n",
            " 739685/1000000: episode: 1076, duration: 54.458s, episode steps: 935, steps per second:  17, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.014537, mae: 1.804322, mean_q: 2.183801\n",
            " 740658/1000000: episode: 1077, duration: 56.530s, episode steps: 973, steps per second:  17, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.016173, mae: 1.821665, mean_q: 2.204567\n",
            " 741369/1000000: episode: 1078, duration: 41.219s, episode steps: 711, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.016415, mae: 1.839893, mean_q: 2.227068\n",
            " 742480/1000000: episode: 1079, duration: 64.475s, episode steps: 1111, steps per second:  17, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.016596, mae: 1.839532, mean_q: 2.226787\n",
            " 743352/1000000: episode: 1080, duration: 50.838s, episode steps: 872, steps per second:  17, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.016063, mae: 1.830916, mean_q: 2.220841\n",
            " 744365/1000000: episode: 1081, duration: 58.836s, episode steps: 1013, steps per second:  17, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.015558, mae: 1.810829, mean_q: 2.194611\n",
            " 745124/1000000: episode: 1082, duration: 44.336s, episode steps: 759, steps per second:  17, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.017370, mae: 1.819858, mean_q: 2.201637\n",
            " 745865/1000000: episode: 1083, duration: 43.289s, episode steps: 741, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.015199, mae: 1.830038, mean_q: 2.213407\n",
            " 746558/1000000: episode: 1084, duration: 40.253s, episode steps: 693, steps per second:  17, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.017104, mae: 1.829966, mean_q: 2.213262\n",
            " 747315/1000000: episode: 1085, duration: 43.772s, episode steps: 757, steps per second:  17, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.018209, mae: 1.821776, mean_q: 2.209428\n",
            " 748076/1000000: episode: 1086, duration: 44.367s, episode steps: 761, steps per second:  17, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.016240, mae: 1.859114, mean_q: 2.250058\n",
            " 748703/1000000: episode: 1087, duration: 36.586s, episode steps: 627, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.014762, mae: 1.816460, mean_q: 2.200156\n",
            " 749552/1000000: episode: 1088, duration: 49.344s, episode steps: 849, steps per second:  17, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.709 [0.000, 5.000],  loss: 0.022757, mae: 1.840541, mean_q: 2.227949\n",
            " 750228/1000000: episode: 1089, duration: 39.661s, episode steps: 676, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.016946, mae: 1.803212, mean_q: 2.185975\n",
            " 750890/1000000: episode: 1090, duration: 38.844s, episode steps: 662, steps per second:  17, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.014540, mae: 1.840369, mean_q: 2.230716\n",
            " 751405/1000000: episode: 1091, duration: 30.125s, episode steps: 515, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.015418, mae: 1.847225, mean_q: 2.238406\n",
            " 752049/1000000: episode: 1092, duration: 37.585s, episode steps: 644, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.015064, mae: 1.845950, mean_q: 2.234817\n",
            " 753018/1000000: episode: 1093, duration: 56.171s, episode steps: 969, steps per second:  17, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.014167, mae: 1.834382, mean_q: 2.220395\n",
            " 753665/1000000: episode: 1094, duration: 37.475s, episode steps: 647, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.019451, mae: 1.829957, mean_q: 2.215639\n",
            " 754282/1000000: episode: 1095, duration: 35.894s, episode steps: 617, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.016070, mae: 1.816970, mean_q: 2.198807\n",
            " 755004/1000000: episode: 1096, duration: 41.949s, episode steps: 722, steps per second:  17, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.016219, mae: 1.828040, mean_q: 2.213282\n",
            " 755522/1000000: episode: 1097, duration: 30.605s, episode steps: 518, steps per second:  17, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.018637, mae: 1.800168, mean_q: 2.177085\n",
            " 756377/1000000: episode: 1098, duration: 49.927s, episode steps: 855, steps per second:  17, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.014971, mae: 1.830818, mean_q: 2.218939\n",
            " 756785/1000000: episode: 1099, duration: 23.817s, episode steps: 408, steps per second:  17, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.015767, mae: 1.820883, mean_q: 2.206735\n",
            " 757728/1000000: episode: 1100, duration: 55.047s, episode steps: 943, steps per second:  17, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.015572, mae: 1.837231, mean_q: 2.224217\n",
            " 758526/1000000: episode: 1101, duration: 46.605s, episode steps: 798, steps per second:  17, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.017183, mae: 1.834569, mean_q: 2.221726\n",
            " 759069/1000000: episode: 1102, duration: 31.644s, episode steps: 543, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.014456, mae: 1.849328, mean_q: 2.239934\n",
            " 759621/1000000: episode: 1103, duration: 32.142s, episode steps: 552, steps per second:  17, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.015618, mae: 1.835091, mean_q: 2.219548\n",
            " 760317/1000000: episode: 1104, duration: 40.503s, episode steps: 696, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.015366, mae: 1.828856, mean_q: 2.215424\n",
            " 760848/1000000: episode: 1105, duration: 31.144s, episode steps: 531, steps per second:  17, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.014934, mae: 1.901808, mean_q: 2.303705\n",
            " 761800/1000000: episode: 1106, duration: 55.628s, episode steps: 952, steps per second:  17, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.014866, mae: 1.869017, mean_q: 2.264922\n",
            " 762584/1000000: episode: 1107, duration: 45.873s, episode steps: 784, steps per second:  17, episode reward:  4.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.016172, mae: 1.861981, mean_q: 2.259250\n",
            " 763246/1000000: episode: 1108, duration: 38.732s, episode steps: 662, steps per second:  17, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.017568, mae: 1.898149, mean_q: 2.301946\n",
            " 764011/1000000: episode: 1109, duration: 44.704s, episode steps: 765, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.015346, mae: 1.857884, mean_q: 2.251439\n",
            " 764941/1000000: episode: 1110, duration: 54.559s, episode steps: 930, steps per second:  17, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.016178, mae: 1.868042, mean_q: 2.264024\n",
            " 765904/1000000: episode: 1111, duration: 56.294s, episode steps: 963, steps per second:  17, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.016563, mae: 1.866465, mean_q: 2.260685\n",
            " 766729/1000000: episode: 1112, duration: 48.720s, episode steps: 825, steps per second:  17, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.015445, mae: 1.874663, mean_q: 2.271592\n",
            " 767240/1000000: episode: 1113, duration: 29.905s, episode steps: 511, steps per second:  17, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.015836, mae: 1.820692, mean_q: 2.204710\n",
            " 767767/1000000: episode: 1114, duration: 30.861s, episode steps: 527, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.016390, mae: 1.868363, mean_q: 2.261812\n",
            " 768435/1000000: episode: 1115, duration: 39.049s, episode steps: 668, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.014662, mae: 1.850562, mean_q: 2.240557\n",
            " 768831/1000000: episode: 1116, duration: 23.201s, episode steps: 396, steps per second:  17, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.014758, mae: 1.824987, mean_q: 2.207132\n",
            " 769619/1000000: episode: 1117, duration: 46.026s, episode steps: 788, steps per second:  17, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.015596, mae: 1.853259, mean_q: 2.243771\n",
            " 769979/1000000: episode: 1118, duration: 21.009s, episode steps: 360, steps per second:  17, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.015251, mae: 1.880889, mean_q: 2.278365\n",
            " 770764/1000000: episode: 1119, duration: 45.965s, episode steps: 785, steps per second:  17, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.014552, mae: 1.845048, mean_q: 2.235384\n",
            " 771362/1000000: episode: 1120, duration: 35.028s, episode steps: 598, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.015006, mae: 1.848604, mean_q: 2.234847\n",
            " 771921/1000000: episode: 1121, duration: 32.805s, episode steps: 559, steps per second:  17, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.017150, mae: 1.852409, mean_q: 2.241558\n",
            " 772330/1000000: episode: 1122, duration: 23.926s, episode steps: 409, steps per second:  17, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.016156, mae: 1.843107, mean_q: 2.230173\n",
            " 773610/1000000: episode: 1123, duration: 75.035s, episode steps: 1280, steps per second:  17, episode reward: 27.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.016512, mae: 1.872798, mean_q: 2.265818\n",
            " 774211/1000000: episode: 1124, duration: 35.068s, episode steps: 601, steps per second:  17, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.015836, mae: 1.870421, mean_q: 2.262868\n",
            " 775182/1000000: episode: 1125, duration: 56.999s, episode steps: 971, steps per second:  17, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.016785, mae: 1.862283, mean_q: 2.253856\n",
            " 775954/1000000: episode: 1126, duration: 45.232s, episode steps: 772, steps per second:  17, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.015944, mae: 1.840497, mean_q: 2.229141\n",
            " 776734/1000000: episode: 1127, duration: 45.660s, episode steps: 780, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.016861, mae: 1.841955, mean_q: 2.230329\n",
            " 777217/1000000: episode: 1128, duration: 28.446s, episode steps: 483, steps per second:  17, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.015822, mae: 1.861571, mean_q: 2.255126\n",
            " 777800/1000000: episode: 1129, duration: 34.194s, episode steps: 583, steps per second:  17, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.018464, mae: 1.860240, mean_q: 2.250496\n",
            " 778180/1000000: episode: 1130, duration: 22.394s, episode steps: 380, steps per second:  17, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.016342, mae: 1.860995, mean_q: 2.249976\n",
            " 778788/1000000: episode: 1131, duration: 35.843s, episode steps: 608, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.015970, mae: 1.870270, mean_q: 2.262904\n",
            " 779691/1000000: episode: 1132, duration: 53.270s, episode steps: 903, steps per second:  17, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.017329, mae: 1.870237, mean_q: 2.263187\n",
            " 780227/1000000: episode: 1133, duration: 31.240s, episode steps: 536, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.015431, mae: 1.871891, mean_q: 2.266075\n",
            " 781178/1000000: episode: 1134, duration: 55.206s, episode steps: 951, steps per second:  17, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.014984, mae: 1.874903, mean_q: 2.272515\n",
            " 781599/1000000: episode: 1135, duration: 24.550s, episode steps: 421, steps per second:  17, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.018261, mae: 1.882734, mean_q: 2.281627\n",
            " 782179/1000000: episode: 1136, duration: 34.363s, episode steps: 580, steps per second:  17, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.016915, mae: 1.884908, mean_q: 2.286433\n",
            " 782643/1000000: episode: 1137, duration: 27.531s, episode steps: 464, steps per second:  17, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.021899, mae: 1.871164, mean_q: 2.265899\n",
            " 783259/1000000: episode: 1138, duration: 36.506s, episode steps: 616, steps per second:  17, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.016738, mae: 1.893780, mean_q: 2.295890\n",
            " 783712/1000000: episode: 1139, duration: 26.718s, episode steps: 453, steps per second:  17, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.018455, mae: 1.901064, mean_q: 2.302863\n",
            " 784405/1000000: episode: 1140, duration: 41.028s, episode steps: 693, steps per second:  17, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.016875, mae: 1.873985, mean_q: 2.268797\n",
            " 785085/1000000: episode: 1141, duration: 39.907s, episode steps: 680, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.016137, mae: 1.877074, mean_q: 2.273906\n",
            " 785838/1000000: episode: 1142, duration: 44.023s, episode steps: 753, steps per second:  17, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.017756, mae: 1.874558, mean_q: 2.269719\n",
            " 786585/1000000: episode: 1143, duration: 43.861s, episode steps: 747, steps per second:  17, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.017389, mae: 1.885817, mean_q: 2.283155\n",
            " 787357/1000000: episode: 1144, duration: 45.321s, episode steps: 772, steps per second:  17, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.014947, mae: 1.864312, mean_q: 2.258980\n",
            " 788018/1000000: episode: 1145, duration: 39.026s, episode steps: 661, steps per second:  17, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.015093, mae: 1.835484, mean_q: 2.222439\n",
            " 788636/1000000: episode: 1146, duration: 36.412s, episode steps: 618, steps per second:  17, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.016850, mae: 1.856751, mean_q: 2.247539\n",
            " 789522/1000000: episode: 1147, duration: 52.233s, episode steps: 886, steps per second:  17, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.017833, mae: 1.868530, mean_q: 2.260916\n",
            " 790190/1000000: episode: 1148, duration: 39.303s, episode steps: 668, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.014071, mae: 1.865892, mean_q: 2.257780\n",
            " 790849/1000000: episode: 1149, duration: 38.810s, episode steps: 659, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.015150, mae: 1.877699, mean_q: 2.274984\n",
            " 791424/1000000: episode: 1150, duration: 34.064s, episode steps: 575, steps per second:  17, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.015861, mae: 1.888140, mean_q: 2.285337\n",
            " 791943/1000000: episode: 1151, duration: 30.581s, episode steps: 519, steps per second:  17, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.015185, mae: 1.875328, mean_q: 2.276672\n",
            " 792714/1000000: episode: 1152, duration: 45.729s, episode steps: 771, steps per second:  17, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.016746, mae: 1.873090, mean_q: 2.268598\n",
            " 793207/1000000: episode: 1153, duration: 29.015s, episode steps: 493, steps per second:  17, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.016837, mae: 1.897762, mean_q: 2.295775\n",
            " 794024/1000000: episode: 1154, duration: 47.986s, episode steps: 817, steps per second:  17, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.014541, mae: 1.879998, mean_q: 2.278092\n",
            " 794622/1000000: episode: 1155, duration: 35.281s, episode steps: 598, steps per second:  17, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.016947, mae: 1.866580, mean_q: 2.260438\n",
            " 795121/1000000: episode: 1156, duration: 29.379s, episode steps: 499, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.015871, mae: 1.893109, mean_q: 2.295888\n",
            " 795798/1000000: episode: 1157, duration: 39.592s, episode steps: 677, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.015258, mae: 1.880733, mean_q: 2.281405\n",
            " 796708/1000000: episode: 1158, duration: 53.823s, episode steps: 910, steps per second:  17, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.018001, mae: 1.878713, mean_q: 2.274470\n",
            " 797430/1000000: episode: 1159, duration: 42.651s, episode steps: 722, steps per second:  17, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.015848, mae: 1.884827, mean_q: 2.286718\n",
            " 798155/1000000: episode: 1160, duration: 43.067s, episode steps: 725, steps per second:  17, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.015478, mae: 1.870521, mean_q: 2.265689\n",
            " 798705/1000000: episode: 1161, duration: 32.752s, episode steps: 550, steps per second:  17, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.016473, mae: 1.892878, mean_q: 2.300150\n",
            " 799321/1000000: episode: 1162, duration: 36.604s, episode steps: 616, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.016147, mae: 1.868115, mean_q: 2.262854\n",
            " 799901/1000000: episode: 1163, duration: 34.255s, episode steps: 580, steps per second:  17, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.016165, mae: 1.874739, mean_q: 2.268356\n",
            " 800300/1000000: episode: 1164, duration: 23.553s, episode steps: 399, steps per second:  17, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.014856, mae: 1.917498, mean_q: 2.325664\n",
            " 800949/1000000: episode: 1165, duration: 38.416s, episode steps: 649, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.020240, mae: 1.919641, mean_q: 2.325211\n",
            " 801454/1000000: episode: 1166, duration: 29.736s, episode steps: 505, steps per second:  17, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.015627, mae: 1.893431, mean_q: 2.297209\n",
            " 802810/1000000: episode: 1167, duration: 80.026s, episode steps: 1356, steps per second:  17, episode reward: 25.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.015999, mae: 1.894922, mean_q: 2.295176\n",
            " 803189/1000000: episode: 1168, duration: 22.552s, episode steps: 379, steps per second:  17, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.015644, mae: 1.905484, mean_q: 2.308607\n",
            " 804157/1000000: episode: 1169, duration: 57.262s, episode steps: 968, steps per second:  17, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.018234, mae: 1.923300, mean_q: 2.330115\n",
            " 805126/1000000: episode: 1170, duration: 57.325s, episode steps: 969, steps per second:  17, episode reward: 25.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.016768, mae: 1.903288, mean_q: 2.306294\n",
            " 806274/1000000: episode: 1171, duration: 67.823s, episode steps: 1148, steps per second:  17, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.017511, mae: 1.924547, mean_q: 2.332048\n",
            " 807424/1000000: episode: 1172, duration: 68.097s, episode steps: 1150, steps per second:  17, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.017708, mae: 1.913768, mean_q: 2.316857\n",
            " 807934/1000000: episode: 1173, duration: 30.300s, episode steps: 510, steps per second:  17, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.018828, mae: 1.913866, mean_q: 2.316827\n",
            " 808309/1000000: episode: 1174, duration: 22.231s, episode steps: 375, steps per second:  17, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.018060, mae: 1.888751, mean_q: 2.290056\n",
            " 808843/1000000: episode: 1175, duration: 31.933s, episode steps: 534, steps per second:  17, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.017234, mae: 1.918675, mean_q: 2.323719\n",
            " 809799/1000000: episode: 1176, duration: 56.375s, episode steps: 956, steps per second:  17, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.016736, mae: 1.903850, mean_q: 2.305351\n",
            " 810365/1000000: episode: 1177, duration: 33.847s, episode steps: 566, steps per second:  17, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.015412, mae: 1.924399, mean_q: 2.331607\n",
            " 810920/1000000: episode: 1178, duration: 33.038s, episode steps: 555, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.016687, mae: 1.931427, mean_q: 2.339668\n",
            " 811555/1000000: episode: 1179, duration: 37.899s, episode steps: 635, steps per second:  17, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.014350, mae: 1.924165, mean_q: 2.334481\n",
            " 812037/1000000: episode: 1180, duration: 28.733s, episode steps: 482, steps per second:  17, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.014190, mae: 1.938311, mean_q: 2.351493\n",
            " 812830/1000000: episode: 1181, duration: 46.804s, episode steps: 793, steps per second:  17, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.015730, mae: 1.920115, mean_q: 2.326766\n",
            " 813351/1000000: episode: 1182, duration: 31.184s, episode steps: 521, steps per second:  17, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.016819, mae: 1.933060, mean_q: 2.343114\n",
            " 813965/1000000: episode: 1183, duration: 36.759s, episode steps: 614, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.020222, mae: 1.908610, mean_q: 2.312344\n",
            " 814630/1000000: episode: 1184, duration: 39.408s, episode steps: 665, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.017566, mae: 1.916597, mean_q: 2.323400\n",
            " 815288/1000000: episode: 1185, duration: 39.085s, episode steps: 658, steps per second:  17, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.016931, mae: 1.936111, mean_q: 2.350502\n",
            " 815896/1000000: episode: 1186, duration: 36.256s, episode steps: 608, steps per second:  17, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.014835, mae: 1.928255, mean_q: 2.337869\n",
            " 816475/1000000: episode: 1187, duration: 34.400s, episode steps: 579, steps per second:  17, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.017655, mae: 1.956972, mean_q: 2.371293\n",
            " 817234/1000000: episode: 1188, duration: 45.006s, episode steps: 759, steps per second:  17, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.019143, mae: 1.936199, mean_q: 2.347876\n",
            " 817973/1000000: episode: 1189, duration: 43.777s, episode steps: 739, steps per second:  17, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.018717, mae: 1.933163, mean_q: 2.342721\n",
            " 818848/1000000: episode: 1190, duration: 52.229s, episode steps: 875, steps per second:  17, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.020788, mae: 1.934148, mean_q: 2.342033\n",
            " 819552/1000000: episode: 1191, duration: 42.301s, episode steps: 704, steps per second:  17, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.015761, mae: 1.905752, mean_q: 2.308847\n",
            " 820315/1000000: episode: 1192, duration: 45.673s, episode steps: 763, steps per second:  17, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.015488, mae: 1.930925, mean_q: 2.343166\n",
            " 820857/1000000: episode: 1193, duration: 32.263s, episode steps: 542, steps per second:  17, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.016910, mae: 1.931866, mean_q: 2.344344\n",
            " 821424/1000000: episode: 1194, duration: 33.864s, episode steps: 567, steps per second:  17, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.015046, mae: 1.920007, mean_q: 2.328826\n",
            " 821946/1000000: episode: 1195, duration: 31.351s, episode steps: 522, steps per second:  17, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.015005, mae: 1.951580, mean_q: 2.362626\n",
            " 822378/1000000: episode: 1196, duration: 25.680s, episode steps: 432, steps per second:  17, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.016148, mae: 1.946731, mean_q: 2.356289\n",
            " 823077/1000000: episode: 1197, duration: 41.594s, episode steps: 699, steps per second:  17, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.015834, mae: 1.954535, mean_q: 2.366823\n",
            " 823720/1000000: episode: 1198, duration: 38.268s, episode steps: 643, steps per second:  17, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.016621, mae: 1.921883, mean_q: 2.328066\n",
            " 824830/1000000: episode: 1199, duration: 66.322s, episode steps: 1110, steps per second:  17, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.017457, mae: 1.960346, mean_q: 2.375088\n",
            " 825379/1000000: episode: 1200, duration: 32.742s, episode steps: 549, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.018089, mae: 1.948027, mean_q: 2.359073\n",
            " 826097/1000000: episode: 1201, duration: 42.594s, episode steps: 718, steps per second:  17, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.016096, mae: 1.959528, mean_q: 2.374191\n",
            " 826900/1000000: episode: 1202, duration: 47.635s, episode steps: 803, steps per second:  17, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.016087, mae: 1.947561, mean_q: 2.358078\n",
            " 827889/1000000: episode: 1203, duration: 58.925s, episode steps: 989, steps per second:  17, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.019416, mae: 1.941740, mean_q: 2.353136\n",
            " 828945/1000000: episode: 1204, duration: 62.904s, episode steps: 1056, steps per second:  17, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.016813, mae: 1.956155, mean_q: 2.368469\n",
            " 829486/1000000: episode: 1205, duration: 32.281s, episode steps: 541, steps per second:  17, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.015166, mae: 1.929307, mean_q: 2.336791\n",
            " 830121/1000000: episode: 1206, duration: 37.743s, episode steps: 635, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.017356, mae: 1.922963, mean_q: 2.328562\n",
            " 830623/1000000: episode: 1207, duration: 29.858s, episode steps: 502, steps per second:  17, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.014861, mae: 1.946904, mean_q: 2.355600\n",
            " 831028/1000000: episode: 1208, duration: 24.330s, episode steps: 405, steps per second:  17, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.015279, mae: 1.971669, mean_q: 2.388112\n",
            " 831900/1000000: episode: 1209, duration: 52.068s, episode steps: 872, steps per second:  17, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.015343, mae: 1.958194, mean_q: 2.371324\n",
            " 832718/1000000: episode: 1210, duration: 48.976s, episode steps: 818, steps per second:  17, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.016300, mae: 1.966514, mean_q: 2.384562\n",
            " 833202/1000000: episode: 1211, duration: 28.773s, episode steps: 484, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.015090, mae: 1.945932, mean_q: 2.355446\n",
            " 834610/1000000: episode: 1212, duration: 84.022s, episode steps: 1408, steps per second:  17, episode reward: 29.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.016745, mae: 1.948172, mean_q: 2.360237\n",
            " 835213/1000000: episode: 1213, duration: 35.911s, episode steps: 603, steps per second:  17, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.017769, mae: 1.965107, mean_q: 2.381797\n",
            " 835813/1000000: episode: 1214, duration: 35.966s, episode steps: 600, steps per second:  17, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.016138, mae: 1.938744, mean_q: 2.345798\n",
            " 836239/1000000: episode: 1215, duration: 25.428s, episode steps: 426, steps per second:  17, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.014186, mae: 1.941228, mean_q: 2.351206\n",
            " 837372/1000000: episode: 1216, duration: 67.706s, episode steps: 1133, steps per second:  17, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.016765, mae: 1.963271, mean_q: 2.376641\n",
            " 838295/1000000: episode: 1217, duration: 54.836s, episode steps: 923, steps per second:  17, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.017503, mae: 1.948713, mean_q: 2.360845\n",
            " 839097/1000000: episode: 1218, duration: 48.151s, episode steps: 802, steps per second:  17, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.016416, mae: 1.973950, mean_q: 2.390457\n",
            " 839608/1000000: episode: 1219, duration: 30.700s, episode steps: 511, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.017779, mae: 1.952094, mean_q: 2.364391\n",
            " 839990/1000000: episode: 1220, duration: 23.050s, episode steps: 382, steps per second:  17, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.018298, mae: 1.948674, mean_q: 2.362569\n",
            " 840529/1000000: episode: 1221, duration: 32.168s, episode steps: 539, steps per second:  17, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.014863, mae: 1.983881, mean_q: 2.404469\n",
            " 841036/1000000: episode: 1222, duration: 30.269s, episode steps: 507, steps per second:  17, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.021486, mae: 2.005558, mean_q: 2.433535\n",
            " 841714/1000000: episode: 1223, duration: 40.530s, episode steps: 678, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.017150, mae: 1.979998, mean_q: 2.400565\n",
            " 842473/1000000: episode: 1224, duration: 45.537s, episode steps: 759, steps per second:  17, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.018818, mae: 2.002827, mean_q: 2.427984\n",
            " 842960/1000000: episode: 1225, duration: 29.291s, episode steps: 487, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.018076, mae: 2.008808, mean_q: 2.431754\n",
            " 843743/1000000: episode: 1226, duration: 46.945s, episode steps: 783, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.017694, mae: 1.981433, mean_q: 2.400812\n",
            " 844434/1000000: episode: 1227, duration: 41.017s, episode steps: 691, steps per second:  17, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.016598, mae: 1.988661, mean_q: 2.412079\n",
            " 844958/1000000: episode: 1228, duration: 31.491s, episode steps: 524, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.016213, mae: 2.002345, mean_q: 2.422776\n",
            " 845463/1000000: episode: 1229, duration: 30.152s, episode steps: 505, steps per second:  17, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.017569, mae: 1.987204, mean_q: 2.405298\n",
            " 846638/1000000: episode: 1230, duration: 70.472s, episode steps: 1175, steps per second:  17, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.015812, mae: 1.991913, mean_q: 2.410417\n",
            " 847652/1000000: episode: 1231, duration: 60.776s, episode steps: 1014, steps per second:  17, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.017347, mae: 1.976183, mean_q: 2.392397\n",
            " 848046/1000000: episode: 1232, duration: 23.611s, episode steps: 394, steps per second:  17, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.015767, mae: 1.990346, mean_q: 2.409803\n",
            " 848404/1000000: episode: 1233, duration: 21.606s, episode steps: 358, steps per second:  17, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.015301, mae: 1.988326, mean_q: 2.409642\n",
            " 848798/1000000: episode: 1234, duration: 23.634s, episode steps: 394, steps per second:  17, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.015390, mae: 2.013689, mean_q: 2.434694\n",
            " 849504/1000000: episode: 1235, duration: 42.306s, episode steps: 706, steps per second:  17, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.017793, mae: 1.998747, mean_q: 2.420474\n",
            " 850016/1000000: episode: 1236, duration: 30.731s, episode steps: 512, steps per second:  17, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.017954, mae: 1.990847, mean_q: 2.409717\n",
            " 850501/1000000: episode: 1237, duration: 29.065s, episode steps: 485, steps per second:  17, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.018746, mae: 2.042894, mean_q: 2.472438\n",
            " 851054/1000000: episode: 1238, duration: 33.106s, episode steps: 553, steps per second:  17, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.017204, mae: 2.031682, mean_q: 2.460847\n",
            " 851762/1000000: episode: 1239, duration: 42.506s, episode steps: 708, steps per second:  17, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.017847, mae: 2.026052, mean_q: 2.452738\n",
            " 852637/1000000: episode: 1240, duration: 52.379s, episode steps: 875, steps per second:  17, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.017641, mae: 2.029128, mean_q: 2.455447\n",
            " 853660/1000000: episode: 1241, duration: 61.604s, episode steps: 1023, steps per second:  17, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.017205, mae: 2.041284, mean_q: 2.470029\n",
            " 854379/1000000: episode: 1242, duration: 43.157s, episode steps: 719, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.017977, mae: 2.007512, mean_q: 2.428220\n",
            " 855189/1000000: episode: 1243, duration: 48.803s, episode steps: 810, steps per second:  17, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.018153, mae: 2.019095, mean_q: 2.443168\n",
            " 855679/1000000: episode: 1244, duration: 29.430s, episode steps: 490, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.020250, mae: 2.031015, mean_q: 2.454762\n",
            " 856553/1000000: episode: 1245, duration: 52.402s, episode steps: 874, steps per second:  17, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.018018, mae: 2.031192, mean_q: 2.456902\n",
            " 857665/1000000: episode: 1246, duration: 66.729s, episode steps: 1112, steps per second:  17, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.016699, mae: 2.031673, mean_q: 2.460578\n",
            " 858144/1000000: episode: 1247, duration: 28.793s, episode steps: 479, steps per second:  17, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.017261, mae: 2.013548, mean_q: 2.436636\n",
            " 858966/1000000: episode: 1248, duration: 49.315s, episode steps: 822, steps per second:  17, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.018983, mae: 2.032401, mean_q: 2.458034\n",
            " 859806/1000000: episode: 1249, duration: 50.439s, episode steps: 840, steps per second:  17, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.019459, mae: 2.018732, mean_q: 2.441137\n",
            " 860447/1000000: episode: 1250, duration: 38.569s, episode steps: 641, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.018376, mae: 2.012994, mean_q: 2.436585\n",
            " 860944/1000000: episode: 1251, duration: 30.194s, episode steps: 497, steps per second:  16, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.017218, mae: 2.033154, mean_q: 2.463821\n",
            " 861712/1000000: episode: 1252, duration: 46.471s, episode steps: 768, steps per second:  17, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.017121, mae: 1.990150, mean_q: 2.407446\n",
            " 862209/1000000: episode: 1253, duration: 30.044s, episode steps: 497, steps per second:  17, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.017773, mae: 2.015172, mean_q: 2.439754\n",
            " 863075/1000000: episode: 1254, duration: 52.169s, episode steps: 866, steps per second:  17, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.016678, mae: 2.009538, mean_q: 2.432567\n",
            " 863598/1000000: episode: 1255, duration: 31.508s, episode steps: 523, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.017920, mae: 1.997355, mean_q: 2.421171\n",
            " 864118/1000000: episode: 1256, duration: 31.325s, episode steps: 520, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.019630, mae: 2.016216, mean_q: 2.440703\n",
            " 864765/1000000: episode: 1257, duration: 39.026s, episode steps: 647, steps per second:  17, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.019780, mae: 2.004667, mean_q: 2.429324\n",
            " 865320/1000000: episode: 1258, duration: 33.488s, episode steps: 555, steps per second:  17, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.018193, mae: 1.991485, mean_q: 2.412262\n",
            " 866128/1000000: episode: 1259, duration: 49.237s, episode steps: 808, steps per second:  16, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.015949, mae: 2.002962, mean_q: 2.429197\n",
            " 867178/1000000: episode: 1260, duration: 63.286s, episode steps: 1050, steps per second:  17, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.015847, mae: 2.009872, mean_q: 2.433706\n",
            " 867560/1000000: episode: 1261, duration: 23.121s, episode steps: 382, steps per second:  17, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.015730, mae: 1.999548, mean_q: 2.420737\n",
            " 868159/1000000: episode: 1262, duration: 36.409s, episode steps: 599, steps per second:  16, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.019384, mae: 2.028901, mean_q: 2.456452\n",
            " 868826/1000000: episode: 1263, duration: 40.363s, episode steps: 667, steps per second:  17, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.019007, mae: 2.014868, mean_q: 2.436953\n",
            " 869507/1000000: episode: 1264, duration: 41.007s, episode steps: 681, steps per second:  17, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.017966, mae: 2.016457, mean_q: 2.440472\n",
            " 870029/1000000: episode: 1265, duration: 31.705s, episode steps: 522, steps per second:  16, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.019083, mae: 2.004176, mean_q: 2.423696\n",
            " 870632/1000000: episode: 1266, duration: 36.582s, episode steps: 603, steps per second:  16, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.016694, mae: 1.995936, mean_q: 2.418053\n",
            " 871517/1000000: episode: 1267, duration: 53.890s, episode steps: 885, steps per second:  16, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.017351, mae: 1.988146, mean_q: 2.408269\n",
            " 872472/1000000: episode: 1268, duration: 57.397s, episode steps: 955, steps per second:  17, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.016384, mae: 1.982404, mean_q: 2.400835\n",
            " 873110/1000000: episode: 1269, duration: 38.585s, episode steps: 638, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.015176, mae: 1.999382, mean_q: 2.421209\n",
            " 874179/1000000: episode: 1270, duration: 64.751s, episode steps: 1069, steps per second:  17, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.016328, mae: 1.987770, mean_q: 2.405309\n",
            " 874582/1000000: episode: 1271, duration: 24.265s, episode steps: 403, steps per second:  17, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.015933, mae: 1.995853, mean_q: 2.414595\n",
            " 875684/1000000: episode: 1272, duration: 66.940s, episode steps: 1102, steps per second:  16, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.016513, mae: 1.982273, mean_q: 2.398777\n",
            " 876345/1000000: episode: 1273, duration: 40.217s, episode steps: 661, steps per second:  16, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.017480, mae: 1.999515, mean_q: 2.419059\n",
            " 876957/1000000: episode: 1274, duration: 36.938s, episode steps: 612, steps per second:  17, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.018055, mae: 1.983631, mean_q: 2.405020\n",
            " 877473/1000000: episode: 1275, duration: 31.177s, episode steps: 516, steps per second:  17, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.019486, mae: 2.003009, mean_q: 2.421786\n",
            " 877857/1000000: episode: 1276, duration: 23.301s, episode steps: 384, steps per second:  16, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.018061, mae: 1.988909, mean_q: 2.410702\n",
            " 878554/1000000: episode: 1277, duration: 42.161s, episode steps: 697, steps per second:  17, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.016277, mae: 1.981101, mean_q: 2.398433\n",
            " 879589/1000000: episode: 1278, duration: 62.723s, episode steps: 1035, steps per second:  17, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.016843, mae: 1.984157, mean_q: 2.404826\n",
            " 880303/1000000: episode: 1279, duration: 43.159s, episode steps: 714, steps per second:  17, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.016930, mae: 2.014884, mean_q: 2.440068\n",
            " 881069/1000000: episode: 1280, duration: 46.561s, episode steps: 766, steps per second:  16, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.015419, mae: 2.037276, mean_q: 2.466749\n",
            " 881591/1000000: episode: 1281, duration: 31.605s, episode steps: 522, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.019045, mae: 2.019277, mean_q: 2.442488\n",
            " 882190/1000000: episode: 1282, duration: 36.181s, episode steps: 599, steps per second:  17, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.016178, mae: 2.029906, mean_q: 2.454967\n",
            " 882580/1000000: episode: 1283, duration: 23.560s, episode steps: 390, steps per second:  17, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.019181, mae: 2.027765, mean_q: 2.453734\n",
            " 882990/1000000: episode: 1284, duration: 24.969s, episode steps: 410, steps per second:  16, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.018314, mae: 2.039443, mean_q: 2.468539\n",
            " 883633/1000000: episode: 1285, duration: 38.961s, episode steps: 643, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.017315, mae: 2.027928, mean_q: 2.452490\n",
            " 884283/1000000: episode: 1286, duration: 39.139s, episode steps: 650, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.017552, mae: 2.027119, mean_q: 2.452282\n",
            " 884685/1000000: episode: 1287, duration: 24.428s, episode steps: 402, steps per second:  16, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.022593, mae: 2.019149, mean_q: 2.442433\n",
            " 885444/1000000: episode: 1288, duration: 45.857s, episode steps: 759, steps per second:  17, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.018146, mae: 2.012904, mean_q: 2.432005\n",
            " 885830/1000000: episode: 1289, duration: 23.469s, episode steps: 386, steps per second:  16, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.016278, mae: 2.036086, mean_q: 2.464269\n",
            " 886617/1000000: episode: 1290, duration: 47.604s, episode steps: 787, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.019068, mae: 2.010839, mean_q: 2.433809\n",
            " 887199/1000000: episode: 1291, duration: 35.192s, episode steps: 582, steps per second:  17, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.015383, mae: 2.028121, mean_q: 2.455462\n",
            " 887728/1000000: episode: 1292, duration: 32.143s, episode steps: 529, steps per second:  16, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.016611, mae: 2.020262, mean_q: 2.444333\n",
            " 888283/1000000: episode: 1293, duration: 33.681s, episode steps: 555, steps per second:  16, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.015714, mae: 2.017831, mean_q: 2.441147\n",
            " 889035/1000000: episode: 1294, duration: 45.542s, episode steps: 752, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.017963, mae: 2.022369, mean_q: 2.448191\n",
            " 889565/1000000: episode: 1295, duration: 32.366s, episode steps: 530, steps per second:  16, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.016943, mae: 2.020618, mean_q: 2.446127\n",
            " 890666/1000000: episode: 1296, duration: 66.548s, episode steps: 1101, steps per second:  17, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.015336, mae: 2.019761, mean_q: 2.447183\n",
            " 891432/1000000: episode: 1297, duration: 46.847s, episode steps: 766, steps per second:  16, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.017796, mae: 2.032678, mean_q: 2.458176\n",
            " 891976/1000000: episode: 1298, duration: 33.286s, episode steps: 544, steps per second:  16, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.018352, mae: 2.044654, mean_q: 2.471708\n",
            " 892712/1000000: episode: 1299, duration: 44.850s, episode steps: 736, steps per second:  16, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.016690, mae: 2.038372, mean_q: 2.465376\n",
            " 893358/1000000: episode: 1300, duration: 39.089s, episode steps: 646, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.018319, mae: 2.022953, mean_q: 2.449127\n",
            " 894010/1000000: episode: 1301, duration: 39.709s, episode steps: 652, steps per second:  16, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.015293, mae: 2.038064, mean_q: 2.464233\n",
            " 894474/1000000: episode: 1302, duration: 28.256s, episode steps: 464, steps per second:  16, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.019206, mae: 2.045172, mean_q: 2.475178\n",
            " 895216/1000000: episode: 1303, duration: 45.042s, episode steps: 742, steps per second:  16, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.016641, mae: 2.031843, mean_q: 2.456372\n",
            " 895968/1000000: episode: 1304, duration: 46.109s, episode steps: 752, steps per second:  16, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.016893, mae: 2.021611, mean_q: 2.448584\n",
            " 896588/1000000: episode: 1305, duration: 38.170s, episode steps: 620, steps per second:  16, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.019215, mae: 2.037866, mean_q: 2.465465\n",
            " 897283/1000000: episode: 1306, duration: 42.322s, episode steps: 695, steps per second:  16, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.016772, mae: 2.038007, mean_q: 2.462980\n",
            " 897858/1000000: episode: 1307, duration: 35.097s, episode steps: 575, steps per second:  16, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.015482, mae: 2.044351, mean_q: 2.471435\n",
            " 898760/1000000: episode: 1308, duration: 54.872s, episode steps: 902, steps per second:  16, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.018220, mae: 2.049452, mean_q: 2.478710\n",
            " 899364/1000000: episode: 1309, duration: 37.188s, episode steps: 604, steps per second:  16, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.018343, mae: 2.047962, mean_q: 2.475238\n",
            " 899732/1000000: episode: 1310, duration: 22.743s, episode steps: 368, steps per second:  16, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.015456, mae: 1.983158, mean_q: 2.399218\n",
            " 900144/1000000: episode: 1311, duration: 25.245s, episode steps: 412, steps per second:  16, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.018489, mae: 2.041668, mean_q: 2.471291\n",
            " 900494/1000000: episode: 1312, duration: 21.497s, episode steps: 350, steps per second:  16, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.016819, mae: 2.021050, mean_q: 2.447050\n",
            " 901232/1000000: episode: 1313, duration: 45.180s, episode steps: 738, steps per second:  16, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.016928, mae: 2.050689, mean_q: 2.482415\n",
            " 902469/1000000: episode: 1314, duration: 75.750s, episode steps: 1237, steps per second:  16, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.019130, mae: 2.052788, mean_q: 2.482708\n",
            " 903634/1000000: episode: 1315, duration: 71.013s, episode steps: 1165, steps per second:  16, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.016590, mae: 2.053789, mean_q: 2.483745\n",
            " 904067/1000000: episode: 1316, duration: 26.256s, episode steps: 433, steps per second:  16, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.017595, mae: 2.035141, mean_q: 2.457531\n",
            " 904741/1000000: episode: 1317, duration: 40.861s, episode steps: 674, steps per second:  16, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.018922, mae: 2.035324, mean_q: 2.460341\n",
            " 905389/1000000: episode: 1318, duration: 39.571s, episode steps: 648, steps per second:  16, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.016589, mae: 2.035311, mean_q: 2.463584\n",
            " 906354/1000000: episode: 1319, duration: 59.152s, episode steps: 965, steps per second:  16, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.016981, mae: 2.039604, mean_q: 2.464154\n",
            " 906726/1000000: episode: 1320, duration: 22.986s, episode steps: 372, steps per second:  16, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.015658, mae: 2.053673, mean_q: 2.484630\n",
            " 907136/1000000: episode: 1321, duration: 25.285s, episode steps: 410, steps per second:  16, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.015942, mae: 2.045020, mean_q: 2.474183\n",
            " 907652/1000000: episode: 1322, duration: 32.097s, episode steps: 516, steps per second:  16, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.018919, mae: 2.050749, mean_q: 2.477893\n",
            " 908155/1000000: episode: 1323, duration: 30.866s, episode steps: 503, steps per second:  16, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.017855, mae: 2.026337, mean_q: 2.449123\n",
            " 908981/1000000: episode: 1324, duration: 50.886s, episode steps: 826, steps per second:  16, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.016062, mae: 2.046783, mean_q: 2.473752\n",
            " 909471/1000000: episode: 1325, duration: 29.959s, episode steps: 490, steps per second:  16, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.018983, mae: 2.023129, mean_q: 2.445519\n",
            " 909812/1000000: episode: 1326, duration: 21.225s, episode steps: 341, steps per second:  16, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.017409, mae: 2.026922, mean_q: 2.452273\n",
            " 910522/1000000: episode: 1327, duration: 43.857s, episode steps: 710, steps per second:  16, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.014973, mae: 2.089745, mean_q: 2.531082\n",
            " 910894/1000000: episode: 1328, duration: 23.014s, episode steps: 372, steps per second:  16, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.016175, mae: 2.097106, mean_q: 2.538598\n",
            " 912102/1000000: episode: 1329, duration: 75.194s, episode steps: 1208, steps per second:  16, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.018009, mae: 2.073112, mean_q: 2.507669\n",
            " 912691/1000000: episode: 1330, duration: 36.541s, episode steps: 589, steps per second:  16, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.018376, mae: 2.076079, mean_q: 2.511821\n",
            " 913390/1000000: episode: 1331, duration: 43.306s, episode steps: 699, steps per second:  16, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.018766, mae: 2.073772, mean_q: 2.510057\n",
            " 914031/1000000: episode: 1332, duration: 39.588s, episode steps: 641, steps per second:  16, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.016950, mae: 2.089145, mean_q: 2.530068\n",
            " 915333/1000000: episode: 1333, duration: 79.936s, episode steps: 1302, steps per second:  16, episode reward: 19.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.017077, mae: 2.067121, mean_q: 2.502679\n",
            " 915986/1000000: episode: 1334, duration: 40.167s, episode steps: 653, steps per second:  16, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.016426, mae: 2.097097, mean_q: 2.535117\n",
            " 916413/1000000: episode: 1335, duration: 26.420s, episode steps: 427, steps per second:  16, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.017116, mae: 2.054982, mean_q: 2.487224\n",
            " 916825/1000000: episode: 1336, duration: 25.545s, episode steps: 412, steps per second:  16, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.019154, mae: 2.114247, mean_q: 2.556128\n",
            " 917220/1000000: episode: 1337, duration: 24.474s, episode steps: 395, steps per second:  16, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.018588, mae: 2.062483, mean_q: 2.492913\n",
            " 918553/1000000: episode: 1338, duration: 82.146s, episode steps: 1333, steps per second:  16, episode reward: 21.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.017638, mae: 2.087128, mean_q: 2.525946\n",
            " 919272/1000000: episode: 1339, duration: 44.167s, episode steps: 719, steps per second:  16, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.019775, mae: 2.085212, mean_q: 2.523444\n",
            " 920291/1000000: episode: 1340, duration: 62.222s, episode steps: 1019, steps per second:  16, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.018393, mae: 2.101347, mean_q: 2.542501\n",
            " 921377/1000000: episode: 1341, duration: 66.762s, episode steps: 1086, steps per second:  16, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.015972, mae: 2.079250, mean_q: 2.515370\n",
            " 922135/1000000: episode: 1342, duration: 46.543s, episode steps: 758, steps per second:  16, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.016682, mae: 2.053524, mean_q: 2.479769\n",
            " 922911/1000000: episode: 1343, duration: 47.947s, episode steps: 776, steps per second:  16, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.019571, mae: 2.073821, mean_q: 2.507221\n",
            " 923572/1000000: episode: 1344, duration: 40.926s, episode steps: 661, steps per second:  16, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.017822, mae: 2.069324, mean_q: 2.503441\n",
            " 924918/1000000: episode: 1345, duration: 82.998s, episode steps: 1346, steps per second:  16, episode reward: 23.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.018074, mae: 2.081805, mean_q: 2.514141\n",
            " 925455/1000000: episode: 1346, duration: 32.989s, episode steps: 537, steps per second:  16, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.018001, mae: 2.091292, mean_q: 2.530287\n",
            " 926557/1000000: episode: 1347, duration: 67.784s, episode steps: 1102, steps per second:  16, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.017524, mae: 2.074013, mean_q: 2.507985\n",
            " 927155/1000000: episode: 1348, duration: 36.690s, episode steps: 598, steps per second:  16, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.018945, mae: 2.088217, mean_q: 2.528984\n",
            " 927784/1000000: episode: 1349, duration: 38.979s, episode steps: 629, steps per second:  16, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.018598, mae: 2.074164, mean_q: 2.508107\n",
            " 928240/1000000: episode: 1350, duration: 28.202s, episode steps: 456, steps per second:  16, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.019964, mae: 2.077208, mean_q: 2.509295\n",
            " 928866/1000000: episode: 1351, duration: 38.558s, episode steps: 626, steps per second:  16, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.015325, mae: 2.073455, mean_q: 2.506903\n",
            " 929424/1000000: episode: 1352, duration: 34.796s, episode steps: 558, steps per second:  16, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.018250, mae: 2.073829, mean_q: 2.507108\n",
            " 930089/1000000: episode: 1353, duration: 41.845s, episode steps: 665, steps per second:  16, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.018348, mae: 2.080930, mean_q: 2.515372\n",
            " 930785/1000000: episode: 1354, duration: 42.775s, episode steps: 696, steps per second:  16, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.016308, mae: 2.071450, mean_q: 2.505896\n",
            " 931734/1000000: episode: 1355, duration: 58.461s, episode steps: 949, steps per second:  16, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.015645, mae: 2.046067, mean_q: 2.474369\n",
            " 932272/1000000: episode: 1356, duration: 33.379s, episode steps: 538, steps per second:  16, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.016650, mae: 2.088825, mean_q: 2.527830\n",
            " 933100/1000000: episode: 1357, duration: 51.226s, episode steps: 828, steps per second:  16, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.017623, mae: 2.088646, mean_q: 2.526898\n",
            " 933710/1000000: episode: 1358, duration: 37.751s, episode steps: 610, steps per second:  16, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.018345, mae: 2.071972, mean_q: 2.505191\n",
            " 934165/1000000: episode: 1359, duration: 28.063s, episode steps: 455, steps per second:  16, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.015868, mae: 2.087139, mean_q: 2.524592\n",
            " 935025/1000000: episode: 1360, duration: 53.108s, episode steps: 860, steps per second:  16, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.016198, mae: 2.071834, mean_q: 2.502875\n",
            " 935721/1000000: episode: 1361, duration: 43.063s, episode steps: 696, steps per second:  16, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.018005, mae: 2.048115, mean_q: 2.474806\n",
            " 936500/1000000: episode: 1362, duration: 48.260s, episode steps: 779, steps per second:  16, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.016437, mae: 2.054070, mean_q: 2.483272\n",
            " 936940/1000000: episode: 1363, duration: 27.536s, episode steps: 440, steps per second:  16, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.018946, mae: 2.024136, mean_q: 2.445453\n",
            " 937433/1000000: episode: 1364, duration: 30.810s, episode steps: 493, steps per second:  16, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.022873, mae: 2.055819, mean_q: 2.486978\n",
            " 937972/1000000: episode: 1365, duration: 33.353s, episode steps: 539, steps per second:  16, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.018333, mae: 2.059040, mean_q: 2.487062\n",
            " 938839/1000000: episode: 1366, duration: 53.683s, episode steps: 867, steps per second:  16, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.018136, mae: 2.061671, mean_q: 2.491225\n",
            " 939475/1000000: episode: 1367, duration: 39.274s, episode steps: 636, steps per second:  16, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.019334, mae: 2.056947, mean_q: 2.486085\n",
            " 940080/1000000: episode: 1368, duration: 37.862s, episode steps: 605, steps per second:  16, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.015559, mae: 2.058566, mean_q: 2.487999\n",
            " 940535/1000000: episode: 1369, duration: 28.293s, episode steps: 455, steps per second:  16, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.017103, mae: 2.082907, mean_q: 2.521797\n",
            " 941179/1000000: episode: 1370, duration: 39.916s, episode steps: 644, steps per second:  16, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.016709, mae: 2.081532, mean_q: 2.516212\n",
            " 942078/1000000: episode: 1371, duration: 56.325s, episode steps: 899, steps per second:  16, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.017733, mae: 2.090731, mean_q: 2.529033\n",
            " 942684/1000000: episode: 1372, duration: 37.636s, episode steps: 606, steps per second:  16, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.018562, mae: 2.085266, mean_q: 2.520678\n",
            " 943372/1000000: episode: 1373, duration: 42.708s, episode steps: 688, steps per second:  16, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.016879, mae: 2.078530, mean_q: 2.518236\n",
            " 943846/1000000: episode: 1374, duration: 29.350s, episode steps: 474, steps per second:  16, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.016648, mae: 2.090570, mean_q: 2.527794\n",
            " 944471/1000000: episode: 1375, duration: 38.531s, episode steps: 625, steps per second:  16, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.016503, mae: 2.087158, mean_q: 2.526422\n",
            " 944964/1000000: episode: 1376, duration: 30.654s, episode steps: 493, steps per second:  16, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.017246, mae: 2.096754, mean_q: 2.534241\n",
            " 945991/1000000: episode: 1377, duration: 63.632s, episode steps: 1027, steps per second:  16, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.017612, mae: 2.081677, mean_q: 2.519369\n",
            " 947070/1000000: episode: 1378, duration: 67.302s, episode steps: 1079, steps per second:  16, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.018518, mae: 2.077987, mean_q: 2.511081\n",
            " 947525/1000000: episode: 1379, duration: 28.559s, episode steps: 455, steps per second:  16, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.016721, mae: 2.063888, mean_q: 2.496784\n",
            " 948109/1000000: episode: 1380, duration: 36.112s, episode steps: 584, steps per second:  16, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.016825, mae: 2.093319, mean_q: 2.533387\n",
            " 948659/1000000: episode: 1381, duration: 33.941s, episode steps: 550, steps per second:  16, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.016837, mae: 2.086670, mean_q: 2.526375\n",
            " 949248/1000000: episode: 1382, duration: 36.600s, episode steps: 589, steps per second:  16, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.019307, mae: 2.104739, mean_q: 2.548134\n",
            " 949803/1000000: episode: 1383, duration: 34.609s, episode steps: 555, steps per second:  16, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.018239, mae: 2.107342, mean_q: 2.548021\n",
            " 950643/1000000: episode: 1384, duration: 52.128s, episode steps: 840, steps per second:  16, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.019296, mae: 2.101794, mean_q: 2.543604\n",
            " 951598/1000000: episode: 1385, duration: 59.369s, episode steps: 955, steps per second:  16, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.018725, mae: 2.087970, mean_q: 2.525462\n",
            " 952216/1000000: episode: 1386, duration: 38.446s, episode steps: 618, steps per second:  16, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.020654, mae: 2.111301, mean_q: 2.551904\n",
            " 952923/1000000: episode: 1387, duration: 44.250s, episode steps: 707, steps per second:  16, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.016316, mae: 2.084579, mean_q: 2.521602\n",
            " 953572/1000000: episode: 1388, duration: 40.629s, episode steps: 649, steps per second:  16, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.016362, mae: 2.082852, mean_q: 2.523084\n",
            " 954480/1000000: episode: 1389, duration: 56.742s, episode steps: 908, steps per second:  16, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.018084, mae: 2.107442, mean_q: 2.546785\n",
            " 955231/1000000: episode: 1390, duration: 46.885s, episode steps: 751, steps per second:  16, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.018647, mae: 2.083462, mean_q: 2.519381\n",
            " 955945/1000000: episode: 1391, duration: 44.662s, episode steps: 714, steps per second:  16, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.019533, mae: 2.116624, mean_q: 2.557487\n",
            " 956699/1000000: episode: 1392, duration: 47.048s, episode steps: 754, steps per second:  16, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.017164, mae: 2.084067, mean_q: 2.517526\n",
            " 957226/1000000: episode: 1393, duration: 32.766s, episode steps: 527, steps per second:  16, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.018165, mae: 2.090865, mean_q: 2.530000\n",
            " 957780/1000000: episode: 1394, duration: 34.676s, episode steps: 554, steps per second:  16, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.017926, mae: 2.106123, mean_q: 2.546046\n",
            " 958311/1000000: episode: 1395, duration: 32.987s, episode steps: 531, steps per second:  16, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.020518, mae: 2.110438, mean_q: 2.550878\n",
            " 958923/1000000: episode: 1396, duration: 38.103s, episode steps: 612, steps per second:  16, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.017978, mae: 2.095581, mean_q: 2.533443\n",
            " 960334/1000000: episode: 1397, duration: 88.385s, episode steps: 1411, steps per second:  16, episode reward: 23.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.017886, mae: 2.108976, mean_q: 2.551101\n",
            " 961144/1000000: episode: 1398, duration: 50.960s, episode steps: 810, steps per second:  16, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.019125, mae: 2.132728, mean_q: 2.578269\n",
            " 961826/1000000: episode: 1399, duration: 43.026s, episode steps: 682, steps per second:  16, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.018245, mae: 2.128798, mean_q: 2.574420\n",
            " 962227/1000000: episode: 1400, duration: 25.032s, episode steps: 401, steps per second:  16, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.020654, mae: 2.149286, mean_q: 2.603395\n",
            " 963081/1000000: episode: 1401, duration: 53.410s, episode steps: 854, steps per second:  16, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.022186, mae: 2.118873, mean_q: 2.563038\n",
            " 963746/1000000: episode: 1402, duration: 41.429s, episode steps: 665, steps per second:  16, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.020004, mae: 2.133812, mean_q: 2.579389\n",
            " 964102/1000000: episode: 1403, duration: 22.202s, episode steps: 356, steps per second:  16, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.020333, mae: 2.133695, mean_q: 2.581596\n",
            " 964510/1000000: episode: 1404, duration: 25.524s, episode steps: 408, steps per second:  16, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.019011, mae: 2.102088, mean_q: 2.544025\n",
            " 965087/1000000: episode: 1405, duration: 36.187s, episode steps: 577, steps per second:  16, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.019670, mae: 2.125550, mean_q: 2.572022\n",
            " 966317/1000000: episode: 1406, duration: 77.097s, episode steps: 1230, steps per second:  16, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.018742, mae: 2.135074, mean_q: 2.583871\n",
            " 967257/1000000: episode: 1407, duration: 59.146s, episode steps: 940, steps per second:  16, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.018641, mae: 2.122956, mean_q: 2.568164\n",
            " 968245/1000000: episode: 1408, duration: 61.880s, episode steps: 988, steps per second:  16, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.020913, mae: 2.137449, mean_q: 2.582330\n",
            " 968903/1000000: episode: 1409, duration: 41.107s, episode steps: 658, steps per second:  16, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.017274, mae: 2.128703, mean_q: 2.573601\n",
            " 969429/1000000: episode: 1410, duration: 33.029s, episode steps: 526, steps per second:  16, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.018081, mae: 2.136047, mean_q: 2.585961\n",
            " 970091/1000000: episode: 1411, duration: 41.549s, episode steps: 662, steps per second:  16, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.019025, mae: 2.136816, mean_q: 2.586002\n",
            " 970827/1000000: episode: 1412, duration: 46.377s, episode steps: 736, steps per second:  16, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.019023, mae: 2.149389, mean_q: 2.603343\n",
            " 971500/1000000: episode: 1413, duration: 42.571s, episode steps: 673, steps per second:  16, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.019275, mae: 2.157838, mean_q: 2.609785\n",
            " 971997/1000000: episode: 1414, duration: 31.451s, episode steps: 497, steps per second:  16, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.019750, mae: 2.135574, mean_q: 2.578553\n",
            " 972525/1000000: episode: 1415, duration: 33.325s, episode steps: 528, steps per second:  16, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.020490, mae: 2.130460, mean_q: 2.573687\n",
            " 973272/1000000: episode: 1416, duration: 47.166s, episode steps: 747, steps per second:  16, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.019396, mae: 2.146088, mean_q: 2.591307\n",
            " 974449/1000000: episode: 1417, duration: 74.923s, episode steps: 1177, steps per second:  16, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.019402, mae: 2.155205, mean_q: 2.604359\n",
            " 975099/1000000: episode: 1418, duration: 41.035s, episode steps: 650, steps per second:  16, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.020632, mae: 2.167877, mean_q: 2.623948\n",
            " 976504/1000000: episode: 1419, duration: 88.961s, episode steps: 1405, steps per second:  16, episode reward: 32.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.018968, mae: 2.158282, mean_q: 2.610196\n",
            " 976902/1000000: episode: 1420, duration: 25.225s, episode steps: 398, steps per second:  16, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.019960, mae: 2.172017, mean_q: 2.625193\n",
            " 977714/1000000: episode: 1421, duration: 51.078s, episode steps: 812, steps per second:  16, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.020065, mae: 2.159353, mean_q: 2.610520\n",
            " 978399/1000000: episode: 1422, duration: 43.455s, episode steps: 685, steps per second:  16, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.018335, mae: 2.174656, mean_q: 2.628595\n",
            " 979317/1000000: episode: 1423, duration: 57.880s, episode steps: 918, steps per second:  16, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.019667, mae: 2.150730, mean_q: 2.598300\n",
            " 979729/1000000: episode: 1424, duration: 26.315s, episode steps: 412, steps per second:  16, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.018530, mae: 2.139675, mean_q: 2.585851\n",
            " 980443/1000000: episode: 1425, duration: 44.744s, episode steps: 714, steps per second:  16, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.019039, mae: 2.181525, mean_q: 2.638401\n",
            " 980845/1000000: episode: 1426, duration: 25.648s, episode steps: 402, steps per second:  16, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.019336, mae: 2.229536, mean_q: 2.695640\n",
            " 981459/1000000: episode: 1427, duration: 38.892s, episode steps: 614, steps per second:  16, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.019851, mae: 2.229312, mean_q: 2.693704\n",
            " 981836/1000000: episode: 1428, duration: 24.036s, episode steps: 377, steps per second:  16, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.015762, mae: 2.229894, mean_q: 2.694080\n",
            " 982993/1000000: episode: 1429, duration: 73.152s, episode steps: 1157, steps per second:  16, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.022179, mae: 2.225117, mean_q: 2.692745\n",
            " 983408/1000000: episode: 1430, duration: 26.183s, episode steps: 415, steps per second:  16, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.020385, mae: 2.212366, mean_q: 2.675472\n",
            " 984123/1000000: episode: 1431, duration: 45.175s, episode steps: 715, steps per second:  16, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.018322, mae: 2.230991, mean_q: 2.699721\n",
            " 984756/1000000: episode: 1432, duration: 40.008s, episode steps: 633, steps per second:  16, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.019485, mae: 2.231752, mean_q: 2.696792\n",
            " 985730/1000000: episode: 1433, duration: 61.677s, episode steps: 974, steps per second:  16, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.019931, mae: 2.229086, mean_q: 2.692145\n",
            " 986526/1000000: episode: 1434, duration: 50.485s, episode steps: 796, steps per second:  16, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.020624, mae: 2.244192, mean_q: 2.712316\n",
            " 987206/1000000: episode: 1435, duration: 42.937s, episode steps: 680, steps per second:  16, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.020681, mae: 2.251526, mean_q: 2.726265\n",
            " 988196/1000000: episode: 1436, duration: 62.862s, episode steps: 990, steps per second:  16, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.020559, mae: 2.228782, mean_q: 2.696775\n",
            " 989556/1000000: episode: 1437, duration: 86.288s, episode steps: 1360, steps per second:  16, episode reward: 21.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.023467, mae: 2.246195, mean_q: 2.715495\n",
            " 990231/1000000: episode: 1438, duration: 42.917s, episode steps: 675, steps per second:  16, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.018602, mae: 2.230005, mean_q: 2.696318\n",
            " 991222/1000000: episode: 1439, duration: 62.850s, episode steps: 991, steps per second:  16, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.022135, mae: 2.255462, mean_q: 2.726707\n",
            " 991853/1000000: episode: 1440, duration: 40.169s, episode steps: 631, steps per second:  16, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.021038, mae: 2.239218, mean_q: 2.708427\n",
            " 992598/1000000: episode: 1441, duration: 47.260s, episode steps: 745, steps per second:  16, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.019031, mae: 2.236629, mean_q: 2.707944\n",
            " 993490/1000000: episode: 1442, duration: 56.430s, episode steps: 892, steps per second:  16, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.020984, mae: 2.222296, mean_q: 2.688058\n",
            " 994149/1000000: episode: 1443, duration: 41.692s, episode steps: 659, steps per second:  16, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.023369, mae: 2.254067, mean_q: 2.728832\n",
            " 994830/1000000: episode: 1444, duration: 42.682s, episode steps: 681, steps per second:  16, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.022236, mae: 2.214666, mean_q: 2.679659\n",
            " 995651/1000000: episode: 1445, duration: 51.934s, episode steps: 821, steps per second:  16, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.020239, mae: 2.242504, mean_q: 2.713488\n",
            " 996560/1000000: episode: 1446, duration: 57.900s, episode steps: 909, steps per second:  16, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.024659, mae: 2.232629, mean_q: 2.699881\n",
            " 997055/1000000: episode: 1447, duration: 31.366s, episode steps: 495, steps per second:  16, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.022424, mae: 2.245478, mean_q: 2.718503\n",
            " 997522/1000000: episode: 1448, duration: 29.834s, episode steps: 467, steps per second:  16, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.021300, mae: 2.258952, mean_q: 2.732514\n",
            " 998302/1000000: episode: 1449, duration: 49.437s, episode steps: 780, steps per second:  16, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.020872, mae: 2.263455, mean_q: 2.738749\n",
            " 999066/1000000: episode: 1450, duration: 48.305s, episode steps: 764, steps per second:  16, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.021806, mae: 2.238407, mean_q: 2.708355\n",
            " 999783/1000000: episode: 1451, duration: 45.412s, episode steps: 717, steps per second:  16, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.021448, mae: 2.235915, mean_q: 2.703045\n",
            "done, took 51789.686 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 4.000, steps: 434\n",
            "Episode 2: reward: 3.000, steps: 352\n",
            "Episode 3: reward: 5.000, steps: 533\n",
            "Episode 4: reward: 7.000, steps: 495\n",
            "Episode 5: reward: 3.000, steps: 384\n",
            "Episode 6: reward: 14.000, steps: 652\n",
            "Episode 7: reward: 14.000, steps: 995\n",
            "Episode 8: reward: 24.000, steps: 1261\n",
            "Episode 9: reward: 27.000, steps: 1209\n",
            "Episode 10: reward: 7.000, steps: 519\n",
            "Episode 11: reward: 14.000, steps: 630\n",
            "Episode 12: reward: 16.000, steps: 957\n",
            "Episode 13: reward: 20.000, steps: 798\n",
            "Episode 14: reward: 6.000, steps: 466\n",
            "Episode 15: reward: 22.000, steps: 823\n",
            "Episode 16: reward: 20.000, steps: 788\n",
            "Episode 17: reward: 7.000, steps: 535\n",
            "Episode 18: reward: 20.000, steps: 957\n",
            "Episode 19: reward: 19.000, steps: 766\n",
            "Episode 20: reward: 12.000, steps: 786\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x79c5e7b6d9d0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# ==== Constantes ====\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "\n",
        "# ==== Procesador mejorado ====\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3  # (210, 160, 3)\n",
        "\n",
        "        # Recortar área útil: quitar HUD y bordes\n",
        "        cropped = observation[34:194, 8:152]  # Resulta en (160, 144, 3)\n",
        "\n",
        "        # Redimensionar y convertir a escala de grises\n",
        "        img = Image.fromarray(cropped)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')  # Escala de grises 84x84\n",
        "\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        # Promediar últimos 2 frames (mitiga flicker)\n",
        "        averaged = 0.5 * batch[:, -1] + 0.5 * batch[:, -2]\n",
        "        batch[:, -1] = averaged\n",
        "        return batch.astype('float32') / 255.\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "# ==== Preparar entorno ====\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "# ==== Modelo CNN tipo DeepMind ====\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 3, 1), input_shape=input_shape))  # (4, 84, 84) → (84, 84, 4)\n",
        "model.add(Conv2D(32, kernel_size=8, strides=4, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(nb_actions, activation='linear'))\n",
        "\n",
        "# ==== Memoria y política ====\n",
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "policy = BoltzmannQPolicy()\n",
        "\n",
        "# ==== Agente DQN ====\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               memory=memory,\n",
        "               processor=AtariProcessor(),\n",
        "               nb_steps_warmup=50000,\n",
        "               target_model_update=10000,\n",
        "               train_interval=4,\n",
        "               gamma=0.99,\n",
        "               policy=policy,\n",
        "               enable_double_dqn=True)\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.00025), metrics=['mae'])\n",
        "\n",
        "# ==== Callbacks ====\n",
        "checkpoint_weights_filename = 'dqn_{}_weights_{{step}}.h5f'.format(ENV_NAME)\n",
        "log_filename = 'dqn_{}_log.json'.format(ENV_NAME)\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000),\n",
        "    FileLogger(log_filename, interval=100)\n",
        "]\n",
        "\n",
        "# ==== Entrenamiento ====\n",
        "dqn.fit(env,\n",
        "        nb_steps=1000000,\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "# ==== Guardar pesos finales ====\n",
        "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
        "\n",
        "# ==== Evaluación ====\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "dDxWZqx-K6oj",
        "outputId": "b377ec78-dd23-4c29-8348-7d2998776ab9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Leer los logs guardados\n",
        "with open(log_filename) as f:\n",
        "    log_data = json.load(f)\n",
        "\n",
        "# Extraer rewards y episodios\n",
        "episode_rewards = log_data['episode_reward']\n",
        "episodes = list(range(1, len(episode_rewards) + 1))  # Episodios desde 1\n",
        "\n",
        "# (Opcional) Suavizar la curva con media móvil\n",
        "def moving_average(data, window_size=10):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "smoothed_rewards = moving_average(episode_rewards, window_size=10)\n",
        "\n",
        "# Graficar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(episodes, episode_rewards, alpha=0.3, label='Reward por episodio')\n",
        "plt.plot(episodes[:len(smoothed_rewards)], smoothed_rewards, color='red', label='Media móvil (10)')\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Reward')\n",
        "plt.title('Evolución del reward durante el entrenamiento')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zCenXgXqLzJS",
        "outputId": "38b94a61-a9b2-4ce3-bdfc-a62a353ba2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 4, 84, 84)]  0           []                               \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 84, 84, 4)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 20, 20, 32)   8224        ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 9, 9, 64)     32832       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 7, 7, 64)     36928       ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 3136)         0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          1606144     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          1606144     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 6)            3078        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            513         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 6)            0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 6)            0           ['dense_1[0][0]',                \n",
            "                                                                  'lambda[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,293,863\n",
            "Trainable params: 3,293,863\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Training for 1000000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    811/1000000: episode: 1, duration: 4.342s, episode steps: 811, steps per second: 187, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   1504/1000000: episode: 2, duration: 3.475s, episode steps: 693, steps per second: 199, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   2209/1000000: episode: 3, duration: 3.542s, episode steps: 705, steps per second: 199, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   2808/1000000: episode: 4, duration: 3.182s, episode steps: 599, steps per second: 188, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   3362/1000000: episode: 5, duration: 2.917s, episode steps: 554, steps per second: 190, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   4061/1000000: episode: 6, duration: 3.667s, episode steps: 699, steps per second: 191, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   4738/1000000: episode: 7, duration: 3.585s, episode steps: 677, steps per second: 189, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   5431/1000000: episode: 8, duration: 3.708s, episode steps: 693, steps per second: 187, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   6396/1000000: episode: 9, duration: 5.078s, episode steps: 965, steps per second: 190, episode reward:  9.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   7161/1000000: episode: 10, duration: 4.249s, episode steps: 765, steps per second: 180, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   8101/1000000: episode: 11, duration: 5.807s, episode steps: 940, steps per second: 162, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   8617/1000000: episode: 12, duration: 3.068s, episode steps: 516, steps per second: 168, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   9298/1000000: episode: 13, duration: 3.658s, episode steps: 681, steps per second: 186, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   9885/1000000: episode: 14, duration: 3.279s, episode steps: 587, steps per second: 179, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  10284/1000000: episode: 15, duration: 2.197s, episode steps: 399, steps per second: 182, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  10950/1000000: episode: 16, duration: 3.400s, episode steps: 666, steps per second: 196, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  11705/1000000: episode: 17, duration: 3.997s, episode steps: 755, steps per second: 189, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  12488/1000000: episode: 18, duration: 4.099s, episode steps: 783, steps per second: 191, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  13041/1000000: episode: 19, duration: 2.930s, episode steps: 553, steps per second: 189, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  13450/1000000: episode: 20, duration: 2.232s, episode steps: 409, steps per second: 183, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  13844/1000000: episode: 21, duration: 2.132s, episode steps: 394, steps per second: 185, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  14505/1000000: episode: 22, duration: 3.440s, episode steps: 661, steps per second: 192, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  15181/1000000: episode: 23, duration: 3.488s, episode steps: 676, steps per second: 194, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  15693/1000000: episode: 24, duration: 2.602s, episode steps: 512, steps per second: 197, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  16392/1000000: episode: 25, duration: 3.634s, episode steps: 699, steps per second: 192, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  17161/1000000: episode: 26, duration: 3.833s, episode steps: 769, steps per second: 201, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  17784/1000000: episode: 27, duration: 3.145s, episode steps: 623, steps per second: 198, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  18490/1000000: episode: 28, duration: 3.677s, episode steps: 706, steps per second: 192, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  18888/1000000: episode: 29, duration: 2.010s, episode steps: 398, steps per second: 198, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  20548/1000000: episode: 30, duration: 8.217s, episode steps: 1660, steps per second: 202, episode reward: 35.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  21445/1000000: episode: 31, duration: 4.619s, episode steps: 897, steps per second: 194, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  22264/1000000: episode: 32, duration: 4.069s, episode steps: 819, steps per second: 201, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  22803/1000000: episode: 33, duration: 2.726s, episode steps: 539, steps per second: 198, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  23289/1000000: episode: 34, duration: 2.585s, episode steps: 486, steps per second: 188, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  23935/1000000: episode: 35, duration: 3.276s, episode steps: 646, steps per second: 197, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  24621/1000000: episode: 36, duration: 3.487s, episode steps: 686, steps per second: 197, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  25248/1000000: episode: 37, duration: 3.163s, episode steps: 627, steps per second: 198, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  25794/1000000: episode: 38, duration: 2.888s, episode steps: 546, steps per second: 189, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  26554/1000000: episode: 39, duration: 3.902s, episode steps: 760, steps per second: 195, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  27466/1000000: episode: 40, duration: 4.720s, episode steps: 912, steps per second: 193, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  28040/1000000: episode: 41, duration: 3.080s, episode steps: 574, steps per second: 186, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  28641/1000000: episode: 42, duration: 2.997s, episode steps: 601, steps per second: 201, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  29129/1000000: episode: 43, duration: 2.517s, episode steps: 488, steps per second: 194, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  30022/1000000: episode: 44, duration: 4.875s, episode steps: 893, steps per second: 183, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  30759/1000000: episode: 45, duration: 4.052s, episode steps: 737, steps per second: 182, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  31175/1000000: episode: 46, duration: 2.298s, episode steps: 416, steps per second: 181, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  31785/1000000: episode: 47, duration: 3.207s, episode steps: 610, steps per second: 190, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  32291/1000000: episode: 48, duration: 2.694s, episode steps: 506, steps per second: 188, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  32996/1000000: episode: 49, duration: 3.716s, episode steps: 705, steps per second: 190, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  33548/1000000: episode: 50, duration: 3.091s, episode steps: 552, steps per second: 179, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  33997/1000000: episode: 51, duration: 2.490s, episode steps: 449, steps per second: 180, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  34818/1000000: episode: 52, duration: 4.669s, episode steps: 821, steps per second: 176, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  35173/1000000: episode: 53, duration: 2.030s, episode steps: 355, steps per second: 175, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  35691/1000000: episode: 54, duration: 2.885s, episode steps: 518, steps per second: 180, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  36208/1000000: episode: 55, duration: 2.810s, episode steps: 517, steps per second: 184, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  37090/1000000: episode: 56, duration: 5.001s, episode steps: 882, steps per second: 176, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  38065/1000000: episode: 57, duration: 5.224s, episode steps: 975, steps per second: 187, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  38444/1000000: episode: 58, duration: 2.012s, episode steps: 379, steps per second: 188, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  38805/1000000: episode: 59, duration: 1.946s, episode steps: 361, steps per second: 186, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  39378/1000000: episode: 60, duration: 3.279s, episode steps: 573, steps per second: 175, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  40083/1000000: episode: 61, duration: 3.879s, episode steps: 705, steps per second: 182, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  40896/1000000: episode: 62, duration: 4.570s, episode steps: 813, steps per second: 178, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  41383/1000000: episode: 63, duration: 2.778s, episode steps: 487, steps per second: 175, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  42189/1000000: episode: 64, duration: 4.436s, episode steps: 806, steps per second: 182, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  42867/1000000: episode: 65, duration: 3.645s, episode steps: 678, steps per second: 186, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  43626/1000000: episode: 66, duration: 4.253s, episode steps: 759, steps per second: 178, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  43994/1000000: episode: 67, duration: 2.150s, episode steps: 368, steps per second: 171, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  44610/1000000: episode: 68, duration: 3.458s, episode steps: 616, steps per second: 178, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  45256/1000000: episode: 69, duration: 3.474s, episode steps: 646, steps per second: 186, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  45625/1000000: episode: 70, duration: 2.049s, episode steps: 369, steps per second: 180, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  46021/1000000: episode: 71, duration: 2.122s, episode steps: 396, steps per second: 187, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  46387/1000000: episode: 72, duration: 1.967s, episode steps: 366, steps per second: 186, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  47423/1000000: episode: 73, duration: 5.394s, episode steps: 1036, steps per second: 192, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  48039/1000000: episode: 74, duration: 3.442s, episode steps: 616, steps per second: 179, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  48597/1000000: episode: 75, duration: 2.971s, episode steps: 558, steps per second: 188, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  49553/1000000: episode: 76, duration: 4.955s, episode steps: 956, steps per second: 193, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  50205/1000000: episode: 77, duration: 12.421s, episode steps: 652, steps per second:  52, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.004703, mae: 0.029020, mean_q: 0.035576\n",
            "  50707/1000000: episode: 78, duration: 22.891s, episode steps: 502, steps per second:  22, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.007499, mae: 0.031917, mean_q: 0.041329\n",
            "  51832/1000000: episode: 79, duration: 51.973s, episode steps: 1125, steps per second:  22, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.006788, mae: 0.029609, mean_q: 0.036791\n",
            "  52806/1000000: episode: 80, duration: 44.987s, episode steps: 974, steps per second:  22, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.008128, mae: 0.031272, mean_q: 0.039558\n",
            "  53678/1000000: episode: 81, duration: 40.525s, episode steps: 872, steps per second:  22, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006875, mae: 0.033979, mean_q: 0.043092\n",
            "  54201/1000000: episode: 82, duration: 24.389s, episode steps: 523, steps per second:  21, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.007962, mae: 0.028853, mean_q: 0.035583\n",
            "  55096/1000000: episode: 83, duration: 41.845s, episode steps: 895, steps per second:  21, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.007570, mae: 0.025612, mean_q: 0.031234\n",
            "  55768/1000000: episode: 84, duration: 31.059s, episode steps: 672, steps per second:  22, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.006036, mae: 0.026074, mean_q: 0.032149\n",
            "  56156/1000000: episode: 85, duration: 18.119s, episode steps: 388, steps per second:  21, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.007196, mae: 0.026010, mean_q: 0.031995\n",
            "  56784/1000000: episode: 86, duration: 28.967s, episode steps: 628, steps per second:  22, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.007375, mae: 0.034075, mean_q: 0.041912\n",
            "  57258/1000000: episode: 87, duration: 22.239s, episode steps: 474, steps per second:  21, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.007085, mae: 0.038549, mean_q: 0.045825\n",
            "  57788/1000000: episode: 88, duration: 24.748s, episode steps: 530, steps per second:  21, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.005354, mae: 0.027871, mean_q: 0.032306\n",
            "  58430/1000000: episode: 89, duration: 30.492s, episode steps: 642, steps per second:  21, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.007311, mae: 0.031239, mean_q: 0.038140\n",
            "  58985/1000000: episode: 90, duration: 26.253s, episode steps: 555, steps per second:  21, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.008197, mae: 0.031946, mean_q: 0.036850\n",
            "  59909/1000000: episode: 91, duration: 43.801s, episode steps: 924, steps per second:  21, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.007270, mae: 0.030874, mean_q: 0.036627\n",
            "  61003/1000000: episode: 92, duration: 51.540s, episode steps: 1094, steps per second:  21, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007111, mae: 0.049239, mean_q: 0.061194\n",
            "  61524/1000000: episode: 93, duration: 24.753s, episode steps: 521, steps per second:  21, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.007551, mae: 0.054127, mean_q: 0.066643\n",
            "  62031/1000000: episode: 94, duration: 24.030s, episode steps: 507, steps per second:  21, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.006683, mae: 0.050599, mean_q: 0.061219\n",
            "  62658/1000000: episode: 95, duration: 29.256s, episode steps: 627, steps per second:  21, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.006241, mae: 0.050558, mean_q: 0.062543\n",
            "  63427/1000000: episode: 96, duration: 36.336s, episode steps: 769, steps per second:  21, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.006350, mae: 0.048712, mean_q: 0.058924\n",
            "  64154/1000000: episode: 97, duration: 34.344s, episode steps: 727, steps per second:  21, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.007726, mae: 0.052415, mean_q: 0.063268\n",
            "  64953/1000000: episode: 98, duration: 37.681s, episode steps: 799, steps per second:  21, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.007449, mae: 0.052199, mean_q: 0.063202\n",
            "  65742/1000000: episode: 99, duration: 36.956s, episode steps: 789, steps per second:  21, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.006855, mae: 0.049991, mean_q: 0.061621\n",
            "  66673/1000000: episode: 100, duration: 44.100s, episode steps: 931, steps per second:  21, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.007497, mae: 0.054264, mean_q: 0.068424\n",
            "  67433/1000000: episode: 101, duration: 36.204s, episode steps: 760, steps per second:  21, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.006603, mae: 0.050018, mean_q: 0.062910\n",
            "  68176/1000000: episode: 102, duration: 35.530s, episode steps: 743, steps per second:  21, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.006716, mae: 0.052023, mean_q: 0.067775\n",
            "  68691/1000000: episode: 103, duration: 24.840s, episode steps: 515, steps per second:  21, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.008904, mae: 0.055882, mean_q: 0.068833\n",
            "  69191/1000000: episode: 104, duration: 23.882s, episode steps: 500, steps per second:  21, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.008654, mae: 0.055469, mean_q: 0.068989\n",
            "  69640/1000000: episode: 105, duration: 21.747s, episode steps: 449, steps per second:  21, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.006973, mae: 0.052861, mean_q: 0.065508\n",
            "  70134/1000000: episode: 106, duration: 24.050s, episode steps: 494, steps per second:  21, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.005358, mae: 0.051521, mean_q: 0.064741\n",
            "  70843/1000000: episode: 107, duration: 33.984s, episode steps: 709, steps per second:  21, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.007766, mae: 0.066322, mean_q: 0.080972\n",
            "  71914/1000000: episode: 108, duration: 51.652s, episode steps: 1071, steps per second:  21, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.006227, mae: 0.062866, mean_q: 0.079012\n",
            "  72754/1000000: episode: 109, duration: 40.619s, episode steps: 840, steps per second:  21, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.007518, mae: 0.066183, mean_q: 0.083454\n",
            "  73687/1000000: episode: 110, duration: 45.169s, episode steps: 933, steps per second:  21, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.008277, mae: 0.067518, mean_q: 0.084677\n",
            "  74061/1000000: episode: 111, duration: 17.994s, episode steps: 374, steps per second:  21, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.007870, mae: 0.062802, mean_q: 0.082827\n",
            "  74780/1000000: episode: 112, duration: 34.759s, episode steps: 719, steps per second:  21, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.006567, mae: 0.063349, mean_q: 0.082304\n",
            "  75276/1000000: episode: 113, duration: 23.975s, episode steps: 496, steps per second:  21, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007548, mae: 0.064008, mean_q: 0.078718\n",
            "  75908/1000000: episode: 114, duration: 31.068s, episode steps: 632, steps per second:  20, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.006637, mae: 0.061261, mean_q: 0.078279\n",
            "  76530/1000000: episode: 115, duration: 30.605s, episode steps: 622, steps per second:  20, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.005421, mae: 0.060247, mean_q: 0.076493\n",
            "  77276/1000000: episode: 116, duration: 36.428s, episode steps: 746, steps per second:  20, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.007161, mae: 0.063626, mean_q: 0.081076\n",
            "  77667/1000000: episode: 117, duration: 19.129s, episode steps: 391, steps per second:  20, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006793, mae: 0.062902, mean_q: 0.078515\n",
            "  78237/1000000: episode: 118, duration: 27.908s, episode steps: 570, steps per second:  20, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.006205, mae: 0.062626, mean_q: 0.078165\n",
            "  79405/1000000: episode: 119, duration: 56.837s, episode steps: 1168, steps per second:  21, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.006263, mae: 0.059992, mean_q: 0.076381\n",
            "  79980/1000000: episode: 120, duration: 27.755s, episode steps: 575, steps per second:  21, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.008763, mae: 0.067577, mean_q: 0.084223\n",
            "  80655/1000000: episode: 121, duration: 32.812s, episode steps: 675, steps per second:  21, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.007432, mae: 0.090911, mean_q: 0.116341\n",
            "  81052/1000000: episode: 122, duration: 19.585s, episode steps: 397, steps per second:  20, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.007685, mae: 0.091464, mean_q: 0.114695\n",
            "  81613/1000000: episode: 123, duration: 27.815s, episode steps: 561, steps per second:  20, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.007159, mae: 0.091488, mean_q: 0.113102\n",
            "  82463/1000000: episode: 124, duration: 41.824s, episode steps: 850, steps per second:  20, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.006523, mae: 0.086850, mean_q: 0.107998\n",
            "  83275/1000000: episode: 125, duration: 39.761s, episode steps: 812, steps per second:  20, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.006318, mae: 0.085555, mean_q: 0.107177\n",
            "  83811/1000000: episode: 126, duration: 26.220s, episode steps: 536, steps per second:  20, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.006760, mae: 0.088348, mean_q: 0.109194\n",
            "  84829/1000000: episode: 127, duration: 49.771s, episode steps: 1018, steps per second:  20, episode reward: 10.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006759, mae: 0.088561, mean_q: 0.111781\n",
            "  85665/1000000: episode: 128, duration: 41.070s, episode steps: 836, steps per second:  20, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.006469, mae: 0.086308, mean_q: 0.109130\n",
            "  86222/1000000: episode: 129, duration: 27.325s, episode steps: 557, steps per second:  20, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.006366, mae: 0.086569, mean_q: 0.106698\n",
            "  86615/1000000: episode: 130, duration: 19.259s, episode steps: 393, steps per second:  20, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.006376, mae: 0.087485, mean_q: 0.108043\n",
            "  87335/1000000: episode: 131, duration: 35.419s, episode steps: 720, steps per second:  20, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006598, mae: 0.087689, mean_q: 0.108795\n",
            "  88065/1000000: episode: 132, duration: 36.108s, episode steps: 730, steps per second:  20, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006598, mae: 0.086267, mean_q: 0.110164\n",
            "  88547/1000000: episode: 133, duration: 23.470s, episode steps: 482, steps per second:  21, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007039, mae: 0.088938, mean_q: 0.111828\n",
            "  89168/1000000: episode: 134, duration: 30.355s, episode steps: 621, steps per second:  20, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.006043, mae: 0.085834, mean_q: 0.110435\n",
            "  89727/1000000: episode: 135, duration: 27.585s, episode steps: 559, steps per second:  20, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.007249, mae: 0.086771, mean_q: 0.110985\n",
            "  90540/1000000: episode: 136, duration: 39.870s, episode steps: 813, steps per second:  20, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.005510, mae: 0.100137, mean_q: 0.128320\n",
            "  91246/1000000: episode: 137, duration: 34.607s, episode steps: 706, steps per second:  20, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.006962, mae: 0.109718, mean_q: 0.139173\n",
            "  91785/1000000: episode: 138, duration: 26.625s, episode steps: 539, steps per second:  20, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.006003, mae: 0.105935, mean_q: 0.135250\n",
            "  92408/1000000: episode: 139, duration: 30.694s, episode steps: 623, steps per second:  20, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.006659, mae: 0.106134, mean_q: 0.135116\n",
            "  93094/1000000: episode: 140, duration: 33.612s, episode steps: 686, steps per second:  20, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006867, mae: 0.110062, mean_q: 0.141768\n",
            "  93952/1000000: episode: 141, duration: 42.227s, episode steps: 858, steps per second:  20, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006268, mae: 0.106397, mean_q: 0.134848\n",
            "  94818/1000000: episode: 142, duration: 43.238s, episode steps: 866, steps per second:  20, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.007615, mae: 0.111024, mean_q: 0.139716\n",
            "  95518/1000000: episode: 143, duration: 35.119s, episode steps: 700, steps per second:  20, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.006485, mae: 0.105081, mean_q: 0.133623\n",
            "  96103/1000000: episode: 144, duration: 29.375s, episode steps: 585, steps per second:  20, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.006604, mae: 0.107282, mean_q: 0.135479\n",
            "  96881/1000000: episode: 145, duration: 38.930s, episode steps: 778, steps per second:  20, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.006828, mae: 0.108993, mean_q: 0.136368\n",
            "  97659/1000000: episode: 146, duration: 38.491s, episode steps: 778, steps per second:  20, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.006386, mae: 0.104684, mean_q: 0.133159\n",
            "  99125/1000000: episode: 147, duration: 73.163s, episode steps: 1466, steps per second:  20, episode reward: 15.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.006743, mae: 0.107978, mean_q: 0.137707\n",
            "  99852/1000000: episode: 148, duration: 36.210s, episode steps: 727, steps per second:  20, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.007051, mae: 0.108232, mean_q: 0.136578\n",
            " 100455/1000000: episode: 149, duration: 30.344s, episode steps: 603, steps per second:  20, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.006709, mae: 0.116899, mean_q: 0.147746\n",
            " 101104/1000000: episode: 150, duration: 32.699s, episode steps: 649, steps per second:  20, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.006736, mae: 0.122409, mean_q: 0.151811\n",
            " 101811/1000000: episode: 151, duration: 35.592s, episode steps: 707, steps per second:  20, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.006261, mae: 0.121076, mean_q: 0.151166\n",
            " 102375/1000000: episode: 152, duration: 28.466s, episode steps: 564, steps per second:  20, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006099, mae: 0.116463, mean_q: 0.147724\n",
            " 103093/1000000: episode: 153, duration: 36.291s, episode steps: 718, steps per second:  20, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.006884, mae: 0.118452, mean_q: 0.147560\n",
            " 104026/1000000: episode: 154, duration: 46.377s, episode steps: 933, steps per second:  20, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.007052, mae: 0.118847, mean_q: 0.150217\n",
            " 104580/1000000: episode: 155, duration: 27.505s, episode steps: 554, steps per second:  20, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.005076, mae: 0.111757, mean_q: 0.142867\n",
            " 105304/1000000: episode: 156, duration: 36.269s, episode steps: 724, steps per second:  20, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.006504, mae: 0.119779, mean_q: 0.152360\n",
            " 106017/1000000: episode: 157, duration: 36.003s, episode steps: 713, steps per second:  20, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.006745, mae: 0.117126, mean_q: 0.147442\n",
            " 106413/1000000: episode: 158, duration: 19.771s, episode steps: 396, steps per second:  20, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.004718, mae: 0.113694, mean_q: 0.144589\n",
            " 107238/1000000: episode: 159, duration: 41.395s, episode steps: 825, steps per second:  20, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.005810, mae: 0.116207, mean_q: 0.145679\n",
            " 108192/1000000: episode: 160, duration: 48.116s, episode steps: 954, steps per second:  20, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.006895, mae: 0.116207, mean_q: 0.145771\n",
            " 108661/1000000: episode: 161, duration: 23.708s, episode steps: 469, steps per second:  20, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.006308, mae: 0.117066, mean_q: 0.147872\n",
            " 109173/1000000: episode: 162, duration: 25.425s, episode steps: 512, steps per second:  20, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006741, mae: 0.115566, mean_q: 0.146225\n",
            " 109572/1000000: episode: 163, duration: 19.963s, episode steps: 399, steps per second:  20, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006642, mae: 0.119804, mean_q: 0.150465\n",
            " 110220/1000000: episode: 164, duration: 33.018s, episode steps: 648, steps per second:  20, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.007026, mae: 0.124541, mean_q: 0.158134\n",
            " 110688/1000000: episode: 165, duration: 23.975s, episode steps: 468, steps per second:  20, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.008443, mae: 0.143315, mean_q: 0.181430\n",
            " 111626/1000000: episode: 166, duration: 47.345s, episode steps: 938, steps per second:  20, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.006495, mae: 0.136692, mean_q: 0.174545\n",
            " 112309/1000000: episode: 167, duration: 34.725s, episode steps: 683, steps per second:  20, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.006671, mae: 0.136382, mean_q: 0.171982\n",
            " 113724/1000000: episode: 168, duration: 72.744s, episode steps: 1415, steps per second:  19, episode reward: 20.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.006676, mae: 0.137191, mean_q: 0.173161\n",
            " 114350/1000000: episode: 169, duration: 32.408s, episode steps: 626, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.007954, mae: 0.139239, mean_q: 0.176082\n",
            " 115152/1000000: episode: 170, duration: 41.531s, episode steps: 802, steps per second:  19, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.005664, mae: 0.130406, mean_q: 0.166223\n",
            " 115793/1000000: episode: 171, duration: 33.401s, episode steps: 641, steps per second:  19, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.007359, mae: 0.139353, mean_q: 0.176784\n",
            " 116290/1000000: episode: 172, duration: 25.507s, episode steps: 497, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.004845, mae: 0.128632, mean_q: 0.162292\n",
            " 116884/1000000: episode: 173, duration: 30.722s, episode steps: 594, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.007097, mae: 0.134259, mean_q: 0.167803\n",
            " 117501/1000000: episode: 174, duration: 32.196s, episode steps: 617, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.005828, mae: 0.133777, mean_q: 0.169148\n",
            " 118018/1000000: episode: 175, duration: 26.575s, episode steps: 517, steps per second:  19, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.007140, mae: 0.138365, mean_q: 0.174186\n",
            " 118597/1000000: episode: 176, duration: 30.491s, episode steps: 579, steps per second:  19, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.005953, mae: 0.135517, mean_q: 0.172496\n",
            " 119105/1000000: episode: 177, duration: 27.039s, episode steps: 508, steps per second:  19, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.007017, mae: 0.136890, mean_q: 0.173375\n",
            " 120072/1000000: episode: 178, duration: 50.308s, episode steps: 967, steps per second:  19, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.006353, mae: 0.130833, mean_q: 0.164993\n",
            " 120810/1000000: episode: 179, duration: 38.669s, episode steps: 738, steps per second:  19, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.006230, mae: 0.144037, mean_q: 0.179911\n",
            " 121939/1000000: episode: 180, duration: 58.286s, episode steps: 1129, steps per second:  19, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.006068, mae: 0.143512, mean_q: 0.179696\n",
            " 122901/1000000: episode: 181, duration: 49.649s, episode steps: 962, steps per second:  19, episode reward:  8.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.006978, mae: 0.148061, mean_q: 0.185503\n",
            " 124202/1000000: episode: 182, duration: 66.705s, episode steps: 1301, steps per second:  20, episode reward: 11.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006946, mae: 0.144778, mean_q: 0.182749\n",
            " 124789/1000000: episode: 183, duration: 30.146s, episode steps: 587, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006407, mae: 0.145012, mean_q: 0.180322\n",
            " 125529/1000000: episode: 184, duration: 37.765s, episode steps: 740, steps per second:  20, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.007116, mae: 0.143739, mean_q: 0.177307\n",
            " 126898/1000000: episode: 185, duration: 70.131s, episode steps: 1369, steps per second:  20, episode reward: 14.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.006449, mae: 0.144396, mean_q: 0.182215\n",
            " 128012/1000000: episode: 186, duration: 57.216s, episode steps: 1114, steps per second:  19, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.006121, mae: 0.145603, mean_q: 0.184817\n",
            " 128653/1000000: episode: 187, duration: 33.332s, episode steps: 641, steps per second:  19, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.007311, mae: 0.145887, mean_q: 0.184759\n",
            " 129531/1000000: episode: 188, duration: 45.114s, episode steps: 878, steps per second:  19, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.005526, mae: 0.143100, mean_q: 0.180212\n",
            " 130245/1000000: episode: 189, duration: 37.026s, episode steps: 714, steps per second:  19, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.006213, mae: 0.149269, mean_q: 0.186299\n",
            " 130654/1000000: episode: 190, duration: 21.346s, episode steps: 409, steps per second:  19, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.005733, mae: 0.159175, mean_q: 0.200071\n",
            " 131352/1000000: episode: 191, duration: 36.663s, episode steps: 698, steps per second:  19, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.005879, mae: 0.154957, mean_q: 0.195614\n",
            " 132169/1000000: episode: 192, duration: 42.569s, episode steps: 817, steps per second:  19, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.006153, mae: 0.156000, mean_q: 0.196405\n",
            " 132720/1000000: episode: 193, duration: 28.880s, episode steps: 551, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.007086, mae: 0.158561, mean_q: 0.197383\n",
            " 133355/1000000: episode: 194, duration: 33.080s, episode steps: 635, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.005458, mae: 0.153154, mean_q: 0.192231\n",
            " 133939/1000000: episode: 195, duration: 30.207s, episode steps: 584, steps per second:  19, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.007828, mae: 0.160145, mean_q: 0.199999\n",
            " 134443/1000000: episode: 196, duration: 26.226s, episode steps: 504, steps per second:  19, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.007242, mae: 0.155821, mean_q: 0.196629\n",
            " 135177/1000000: episode: 197, duration: 38.366s, episode steps: 734, steps per second:  19, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.005990, mae: 0.153798, mean_q: 0.194351\n",
            " 135890/1000000: episode: 198, duration: 37.204s, episode steps: 713, steps per second:  19, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007448, mae: 0.158087, mean_q: 0.197665\n",
            " 136409/1000000: episode: 199, duration: 27.410s, episode steps: 519, steps per second:  19, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.006352, mae: 0.153956, mean_q: 0.193881\n",
            " 137052/1000000: episode: 200, duration: 33.554s, episode steps: 643, steps per second:  19, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.006383, mae: 0.153077, mean_q: 0.193177\n",
            " 137625/1000000: episode: 201, duration: 30.561s, episode steps: 573, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.006391, mae: 0.154881, mean_q: 0.191675\n",
            " 138129/1000000: episode: 202, duration: 26.643s, episode steps: 504, steps per second:  19, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.006727, mae: 0.156633, mean_q: 0.195871\n",
            " 138675/1000000: episode: 203, duration: 28.774s, episode steps: 546, steps per second:  19, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007084, mae: 0.156779, mean_q: 0.196040\n",
            " 139360/1000000: episode: 204, duration: 36.692s, episode steps: 685, steps per second:  19, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.005945, mae: 0.152359, mean_q: 0.190423\n",
            " 139913/1000000: episode: 205, duration: 29.488s, episode steps: 553, steps per second:  19, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.288 [0.000, 5.000],  loss: 0.006242, mae: 0.154558, mean_q: 0.192751\n",
            " 140538/1000000: episode: 206, duration: 33.081s, episode steps: 625, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.007592, mae: 0.175250, mean_q: 0.217146\n",
            " 141064/1000000: episode: 207, duration: 27.957s, episode steps: 526, steps per second:  19, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.007503, mae: 0.181305, mean_q: 0.224844\n",
            " 142018/1000000: episode: 208, duration: 50.916s, episode steps: 954, steps per second:  19, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007163, mae: 0.181027, mean_q: 0.225975\n",
            " 142653/1000000: episode: 209, duration: 34.148s, episode steps: 635, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006394, mae: 0.176252, mean_q: 0.221076\n",
            " 143304/1000000: episode: 210, duration: 34.926s, episode steps: 651, steps per second:  19, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.005919, mae: 0.176124, mean_q: 0.219912\n",
            " 144023/1000000: episode: 211, duration: 38.294s, episode steps: 719, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.005083, mae: 0.175246, mean_q: 0.217438\n",
            " 144931/1000000: episode: 212, duration: 48.560s, episode steps: 908, steps per second:  19, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.007029, mae: 0.177338, mean_q: 0.219800\n",
            " 145530/1000000: episode: 213, duration: 32.205s, episode steps: 599, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.005969, mae: 0.174801, mean_q: 0.216105\n",
            " 146243/1000000: episode: 214, duration: 38.380s, episode steps: 713, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.006550, mae: 0.176986, mean_q: 0.220524\n",
            " 147572/1000000: episode: 215, duration: 71.850s, episode steps: 1329, steps per second:  18, episode reward: 23.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.006669, mae: 0.178438, mean_q: 0.222561\n",
            " 148186/1000000: episode: 216, duration: 33.111s, episode steps: 614, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.006904, mae: 0.177379, mean_q: 0.221912\n",
            " 148555/1000000: episode: 217, duration: 19.480s, episode steps: 369, steps per second:  19, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.705 [0.000, 5.000],  loss: 0.005192, mae: 0.169266, mean_q: 0.213321\n",
            " 149556/1000000: episode: 218, duration: 53.236s, episode steps: 1001, steps per second:  19, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.006458, mae: 0.176298, mean_q: 0.220189\n",
            " 149933/1000000: episode: 219, duration: 19.848s, episode steps: 377, steps per second:  19, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.005697, mae: 0.179169, mean_q: 0.223796\n",
            " 150551/1000000: episode: 220, duration: 32.579s, episode steps: 618, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006683, mae: 0.196756, mean_q: 0.245059\n",
            " 151262/1000000: episode: 221, duration: 37.648s, episode steps: 711, steps per second:  19, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.007506, mae: 0.202722, mean_q: 0.252114\n",
            " 151954/1000000: episode: 222, duration: 36.548s, episode steps: 692, steps per second:  19, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.007138, mae: 0.198824, mean_q: 0.247408\n",
            " 152498/1000000: episode: 223, duration: 28.926s, episode steps: 544, steps per second:  19, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.007748, mae: 0.205818, mean_q: 0.254228\n",
            " 153158/1000000: episode: 224, duration: 35.192s, episode steps: 660, steps per second:  19, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.007310, mae: 0.195360, mean_q: 0.243380\n",
            " 153942/1000000: episode: 225, duration: 41.755s, episode steps: 784, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.006963, mae: 0.197812, mean_q: 0.243916\n",
            " 154296/1000000: episode: 226, duration: 18.864s, episode steps: 354, steps per second:  19, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.008202, mae: 0.202875, mean_q: 0.250955\n",
            " 154916/1000000: episode: 227, duration: 32.617s, episode steps: 620, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.007661, mae: 0.200275, mean_q: 0.249001\n",
            " 155407/1000000: episode: 228, duration: 26.121s, episode steps: 491, steps per second:  19, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.005884, mae: 0.196955, mean_q: 0.246163\n",
            " 156037/1000000: episode: 229, duration: 33.387s, episode steps: 630, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.007409, mae: 0.197219, mean_q: 0.243907\n",
            " 156791/1000000: episode: 230, duration: 40.324s, episode steps: 754, steps per second:  19, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.005579, mae: 0.197708, mean_q: 0.245701\n",
            " 157735/1000000: episode: 231, duration: 50.177s, episode steps: 944, steps per second:  19, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.006758, mae: 0.194205, mean_q: 0.242297\n",
            " 158258/1000000: episode: 232, duration: 28.210s, episode steps: 523, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.006581, mae: 0.198166, mean_q: 0.248096\n",
            " 158848/1000000: episode: 233, duration: 31.533s, episode steps: 590, steps per second:  19, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.007984, mae: 0.199903, mean_q: 0.246743\n",
            " 159352/1000000: episode: 234, duration: 27.307s, episode steps: 504, steps per second:  18, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.007297, mae: 0.206234, mean_q: 0.255411\n",
            " 159903/1000000: episode: 235, duration: 29.731s, episode steps: 551, steps per second:  19, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.007636, mae: 0.192409, mean_q: 0.239876\n",
            " 160752/1000000: episode: 236, duration: 45.057s, episode steps: 849, steps per second:  19, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.006754, mae: 0.221970, mean_q: 0.276949\n",
            " 161977/1000000: episode: 237, duration: 65.229s, episode steps: 1225, steps per second:  19, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.007127, mae: 0.223878, mean_q: 0.277557\n",
            " 162582/1000000: episode: 238, duration: 32.140s, episode steps: 605, steps per second:  19, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.008545, mae: 0.229883, mean_q: 0.284923\n",
            " 163202/1000000: episode: 239, duration: 33.477s, episode steps: 620, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.006853, mae: 0.222425, mean_q: 0.275641\n",
            " 163813/1000000: episode: 240, duration: 32.524s, episode steps: 611, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.006848, mae: 0.224200, mean_q: 0.279442\n",
            " 164292/1000000: episode: 241, duration: 25.428s, episode steps: 479, steps per second:  19, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.006836, mae: 0.220710, mean_q: 0.276592\n",
            " 164808/1000000: episode: 242, duration: 27.567s, episode steps: 516, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.007004, mae: 0.223196, mean_q: 0.275288\n",
            " 165304/1000000: episode: 243, duration: 26.264s, episode steps: 496, steps per second:  19, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.006107, mae: 0.221291, mean_q: 0.273452\n",
            " 166320/1000000: episode: 244, duration: 53.985s, episode steps: 1016, steps per second:  19, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.007690, mae: 0.227703, mean_q: 0.281608\n",
            " 167043/1000000: episode: 245, duration: 38.258s, episode steps: 723, steps per second:  19, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007099, mae: 0.223902, mean_q: 0.277551\n",
            " 167442/1000000: episode: 246, duration: 21.254s, episode steps: 399, steps per second:  19, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.007442, mae: 0.231002, mean_q: 0.285506\n",
            " 168307/1000000: episode: 247, duration: 46.051s, episode steps: 865, steps per second:  19, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.007331, mae: 0.225117, mean_q: 0.278365\n",
            " 168939/1000000: episode: 248, duration: 34.090s, episode steps: 632, steps per second:  19, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.006775, mae: 0.221350, mean_q: 0.274397\n",
            " 169681/1000000: episode: 249, duration: 39.325s, episode steps: 742, steps per second:  19, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.008864, mae: 0.226400, mean_q: 0.282107\n",
            " 170372/1000000: episode: 250, duration: 36.459s, episode steps: 691, steps per second:  19, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.007517, mae: 0.230624, mean_q: 0.285886\n",
            " 170930/1000000: episode: 251, duration: 30.165s, episode steps: 558, steps per second:  18, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.007725, mae: 0.241017, mean_q: 0.298079\n",
            " 171438/1000000: episode: 252, duration: 27.558s, episode steps: 508, steps per second:  18, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006767, mae: 0.236867, mean_q: 0.293265\n",
            " 172044/1000000: episode: 253, duration: 33.404s, episode steps: 606, steps per second:  18, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007083, mae: 0.235456, mean_q: 0.290610\n",
            " 172416/1000000: episode: 254, duration: 20.417s, episode steps: 372, steps per second:  18, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.006995, mae: 0.246507, mean_q: 0.307289\n",
            " 173408/1000000: episode: 255, duration: 52.279s, episode steps: 992, steps per second:  19, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007415, mae: 0.237104, mean_q: 0.294856\n",
            " 174081/1000000: episode: 256, duration: 35.889s, episode steps: 673, steps per second:  19, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.008291, mae: 0.243847, mean_q: 0.300813\n",
            " 175388/1000000: episode: 257, duration: 69.679s, episode steps: 1307, steps per second:  19, episode reward: 14.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.007276, mae: 0.236129, mean_q: 0.293481\n",
            " 175899/1000000: episode: 258, duration: 27.462s, episode steps: 511, steps per second:  19, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006936, mae: 0.233937, mean_q: 0.291039\n",
            " 176712/1000000: episode: 259, duration: 43.697s, episode steps: 813, steps per second:  19, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.007135, mae: 0.234920, mean_q: 0.292528\n",
            " 177504/1000000: episode: 260, duration: 42.980s, episode steps: 792, steps per second:  18, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.006460, mae: 0.232624, mean_q: 0.289561\n",
            " 178043/1000000: episode: 261, duration: 29.165s, episode steps: 539, steps per second:  18, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.006873, mae: 0.234326, mean_q: 0.292396\n",
            " 178542/1000000: episode: 262, duration: 26.770s, episode steps: 499, steps per second:  19, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006781, mae: 0.236634, mean_q: 0.293949\n",
            " 179365/1000000: episode: 263, duration: 43.701s, episode steps: 823, steps per second:  19, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006795, mae: 0.232102, mean_q: 0.287641\n",
            " 179995/1000000: episode: 264, duration: 33.524s, episode steps: 630, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.007644, mae: 0.234826, mean_q: 0.291349\n",
            " 181098/1000000: episode: 265, duration: 58.947s, episode steps: 1103, steps per second:  19, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.007157, mae: 0.248619, mean_q: 0.308252\n",
            " 181590/1000000: episode: 266, duration: 26.024s, episode steps: 492, steps per second:  19, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.005770, mae: 0.234455, mean_q: 0.291382\n",
            " 182458/1000000: episode: 267, duration: 46.078s, episode steps: 868, steps per second:  19, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.007258, mae: 0.246293, mean_q: 0.306490\n",
            " 182964/1000000: episode: 268, duration: 26.990s, episode steps: 506, steps per second:  19, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.007380, mae: 0.252969, mean_q: 0.316594\n",
            " 183355/1000000: episode: 269, duration: 20.641s, episode steps: 391, steps per second:  19, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.008609, mae: 0.252227, mean_q: 0.314509\n",
            " 183819/1000000: episode: 270, duration: 24.636s, episode steps: 464, steps per second:  19, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.006933, mae: 0.243069, mean_q: 0.302674\n",
            " 185171/1000000: episode: 271, duration: 72.657s, episode steps: 1352, steps per second:  19, episode reward: 17.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.007300, mae: 0.245893, mean_q: 0.305134\n",
            " 185791/1000000: episode: 272, duration: 33.047s, episode steps: 620, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007590, mae: 0.247228, mean_q: 0.307571\n",
            " 186189/1000000: episode: 273, duration: 21.526s, episode steps: 398, steps per second:  18, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.764 [0.000, 5.000],  loss: 0.007029, mae: 0.241199, mean_q: 0.299367\n",
            " 186874/1000000: episode: 274, duration: 36.562s, episode steps: 685, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.007958, mae: 0.248812, mean_q: 0.310744\n",
            " 187497/1000000: episode: 275, duration: 33.436s, episode steps: 623, steps per second:  19, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.007214, mae: 0.243858, mean_q: 0.304763\n",
            " 188474/1000000: episode: 276, duration: 52.004s, episode steps: 977, steps per second:  19, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006822, mae: 0.246953, mean_q: 0.307845\n",
            " 189149/1000000: episode: 277, duration: 35.914s, episode steps: 675, steps per second:  19, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.006776, mae: 0.241257, mean_q: 0.301122\n",
            " 189863/1000000: episode: 278, duration: 37.879s, episode steps: 714, steps per second:  19, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.006217, mae: 0.242560, mean_q: 0.302986\n",
            " 190269/1000000: episode: 279, duration: 21.655s, episode steps: 406, steps per second:  19, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.007757, mae: 0.254991, mean_q: 0.316661\n",
            " 191064/1000000: episode: 280, duration: 42.360s, episode steps: 795, steps per second:  19, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.008025, mae: 0.270004, mean_q: 0.336289\n",
            " 191679/1000000: episode: 281, duration: 32.367s, episode steps: 615, steps per second:  19, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006511, mae: 0.263656, mean_q: 0.329868\n",
            " 192354/1000000: episode: 282, duration: 35.763s, episode steps: 675, steps per second:  19, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.007384, mae: 0.264723, mean_q: 0.329560\n",
            " 192787/1000000: episode: 283, duration: 22.939s, episode steps: 433, steps per second:  19, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.007147, mae: 0.262002, mean_q: 0.324291\n",
            " 193530/1000000: episode: 284, duration: 39.329s, episode steps: 743, steps per second:  19, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.007454, mae: 0.263136, mean_q: 0.327284\n",
            " 194336/1000000: episode: 285, duration: 42.325s, episode steps: 806, steps per second:  19, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.007836, mae: 0.266357, mean_q: 0.329275\n",
            " 194888/1000000: episode: 286, duration: 29.350s, episode steps: 552, steps per second:  19, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.007256, mae: 0.269232, mean_q: 0.333833\n",
            " 195378/1000000: episode: 287, duration: 25.750s, episode steps: 490, steps per second:  19, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007787, mae: 0.268217, mean_q: 0.330463\n",
            " 196343/1000000: episode: 288, duration: 51.153s, episode steps: 965, steps per second:  19, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007060, mae: 0.263977, mean_q: 0.325449\n",
            " 197142/1000000: episode: 289, duration: 41.841s, episode steps: 799, steps per second:  19, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007248, mae: 0.261003, mean_q: 0.322505\n",
            " 197718/1000000: episode: 290, duration: 30.154s, episode steps: 576, steps per second:  19, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.006534, mae: 0.260768, mean_q: 0.322951\n",
            " 198317/1000000: episode: 291, duration: 31.278s, episode steps: 599, steps per second:  19, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.007410, mae: 0.267272, mean_q: 0.331813\n",
            " 199417/1000000: episode: 292, duration: 58.088s, episode steps: 1100, steps per second:  19, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.007484, mae: 0.266587, mean_q: 0.329518\n",
            " 199826/1000000: episode: 293, duration: 21.552s, episode steps: 409, steps per second:  19, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: 0.007892, mae: 0.268996, mean_q: 0.332349\n",
            " 200408/1000000: episode: 294, duration: 30.769s, episode steps: 582, steps per second:  19, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.008087, mae: 0.291320, mean_q: 0.360713\n",
            " 201156/1000000: episode: 295, duration: 39.730s, episode steps: 748, steps per second:  19, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.008989, mae: 0.296618, mean_q: 0.367738\n",
            " 202559/1000000: episode: 296, duration: 73.679s, episode steps: 1403, steps per second:  19, episode reward: 14.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.009062, mae: 0.297723, mean_q: 0.367923\n",
            " 203262/1000000: episode: 297, duration: 36.478s, episode steps: 703, steps per second:  19, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.008254, mae: 0.297986, mean_q: 0.369838\n",
            " 203905/1000000: episode: 298, duration: 33.441s, episode steps: 643, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.008222, mae: 0.296197, mean_q: 0.364070\n",
            " 204410/1000000: episode: 299, duration: 26.694s, episode steps: 505, steps per second:  19, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.259 [0.000, 5.000],  loss: 0.009079, mae: 0.301277, mean_q: 0.371825\n",
            " 205755/1000000: episode: 300, duration: 69.918s, episode steps: 1345, steps per second:  19, episode reward: 25.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.008323, mae: 0.295179, mean_q: 0.364826\n",
            " 206288/1000000: episode: 301, duration: 27.962s, episode steps: 533, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007712, mae: 0.292287, mean_q: 0.361440\n",
            " 207110/1000000: episode: 302, duration: 43.073s, episode steps: 822, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.008311, mae: 0.294607, mean_q: 0.364965\n",
            " 207791/1000000: episode: 303, duration: 35.495s, episode steps: 681, steps per second:  19, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.007887, mae: 0.292957, mean_q: 0.363858\n",
            " 208471/1000000: episode: 304, duration: 35.398s, episode steps: 680, steps per second:  19, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.007705, mae: 0.291146, mean_q: 0.362036\n",
            " 209063/1000000: episode: 305, duration: 30.924s, episode steps: 592, steps per second:  19, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.007133, mae: 0.296691, mean_q: 0.367164\n",
            " 209770/1000000: episode: 306, duration: 36.689s, episode steps: 707, steps per second:  19, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.008121, mae: 0.293604, mean_q: 0.362587\n",
            " 210559/1000000: episode: 307, duration: 41.012s, episode steps: 789, steps per second:  19, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.009036, mae: 0.319006, mean_q: 0.392562\n",
            " 211292/1000000: episode: 308, duration: 38.254s, episode steps: 733, steps per second:  19, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.008520, mae: 0.321851, mean_q: 0.396151\n",
            " 211785/1000000: episode: 309, duration: 25.793s, episode steps: 493, steps per second:  19, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.009170, mae: 0.327557, mean_q: 0.402334\n",
            " 212697/1000000: episode: 310, duration: 47.798s, episode steps: 912, steps per second:  19, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.008834, mae: 0.320841, mean_q: 0.394431\n",
            " 213334/1000000: episode: 311, duration: 33.616s, episode steps: 637, steps per second:  19, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.007920, mae: 0.313218, mean_q: 0.385398\n",
            " 214337/1000000: episode: 312, duration: 52.872s, episode steps: 1003, steps per second:  19, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.008416, mae: 0.322639, mean_q: 0.398524\n",
            " 214963/1000000: episode: 313, duration: 32.899s, episode steps: 626, steps per second:  19, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.008256, mae: 0.319896, mean_q: 0.393193\n",
            " 215652/1000000: episode: 314, duration: 36.783s, episode steps: 689, steps per second:  19, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.008338, mae: 0.314625, mean_q: 0.385954\n",
            " 216383/1000000: episode: 315, duration: 39.475s, episode steps: 731, steps per second:  19, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.008474, mae: 0.315093, mean_q: 0.388531\n",
            " 217126/1000000: episode: 316, duration: 39.822s, episode steps: 743, steps per second:  19, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.009626, mae: 0.320758, mean_q: 0.396555\n",
            " 217529/1000000: episode: 317, duration: 21.656s, episode steps: 403, steps per second:  19, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.007806, mae: 0.308729, mean_q: 0.382418\n",
            " 218171/1000000: episode: 318, duration: 34.225s, episode steps: 642, steps per second:  19, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.007938, mae: 0.316826, mean_q: 0.392168\n",
            " 218853/1000000: episode: 319, duration: 36.391s, episode steps: 682, steps per second:  19, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.008173, mae: 0.315428, mean_q: 0.389889\n",
            " 219367/1000000: episode: 320, duration: 27.252s, episode steps: 514, steps per second:  19, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.008311, mae: 0.310158, mean_q: 0.382020\n",
            " 220176/1000000: episode: 321, duration: 43.204s, episode steps: 809, steps per second:  19, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.008716, mae: 0.327659, mean_q: 0.404482\n",
            " 220929/1000000: episode: 322, duration: 40.358s, episode steps: 753, steps per second:  19, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.008192, mae: 0.347496, mean_q: 0.428789\n",
            " 221875/1000000: episode: 323, duration: 50.248s, episode steps: 946, steps per second:  19, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.009490, mae: 0.351858, mean_q: 0.433302\n",
            " 222340/1000000: episode: 324, duration: 24.787s, episode steps: 465, steps per second:  19, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.008494, mae: 0.357100, mean_q: 0.440364\n",
            " 222887/1000000: episode: 325, duration: 29.436s, episode steps: 547, steps per second:  19, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.008247, mae: 0.354125, mean_q: 0.434542\n",
            " 223500/1000000: episode: 326, duration: 32.716s, episode steps: 613, steps per second:  19, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.009145, mae: 0.349726, mean_q: 0.429733\n",
            " 224077/1000000: episode: 327, duration: 31.117s, episode steps: 577, steps per second:  19, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.008340, mae: 0.340367, mean_q: 0.419607\n",
            " 224873/1000000: episode: 328, duration: 42.338s, episode steps: 796, steps per second:  19, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.009672, mae: 0.354816, mean_q: 0.435831\n",
            " 225703/1000000: episode: 329, duration: 44.094s, episode steps: 830, steps per second:  19, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.008709, mae: 0.345968, mean_q: 0.425572\n",
            " 226250/1000000: episode: 330, duration: 29.475s, episode steps: 547, steps per second:  19, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.008398, mae: 0.348709, mean_q: 0.429075\n",
            " 227014/1000000: episode: 331, duration: 41.027s, episode steps: 764, steps per second:  19, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007867, mae: 0.347294, mean_q: 0.429939\n",
            " 227411/1000000: episode: 332, duration: 21.070s, episode steps: 397, steps per second:  19, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: 0.007548, mae: 0.343825, mean_q: 0.425757\n",
            " 228373/1000000: episode: 333, duration: 51.372s, episode steps: 962, steps per second:  19, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.008643, mae: 0.346681, mean_q: 0.426821\n",
            " 229240/1000000: episode: 334, duration: 47.026s, episode steps: 867, steps per second:  18, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.007949, mae: 0.350247, mean_q: 0.432457\n",
            " 230097/1000000: episode: 335, duration: 46.474s, episode steps: 857, steps per second:  18, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.009336, mae: 0.353217, mean_q: 0.435126\n",
            " 231354/1000000: episode: 336, duration: 67.384s, episode steps: 1257, steps per second:  19, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.010396, mae: 0.374231, mean_q: 0.460624\n",
            " 232037/1000000: episode: 337, duration: 36.653s, episode steps: 683, steps per second:  19, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.010400, mae: 0.375871, mean_q: 0.459214\n",
            " 233020/1000000: episode: 338, duration: 52.914s, episode steps: 983, steps per second:  19, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.008726, mae: 0.372854, mean_q: 0.457315\n",
            " 233676/1000000: episode: 339, duration: 35.978s, episode steps: 656, steps per second:  18, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.008964, mae: 0.374650, mean_q: 0.458584\n",
            " 234619/1000000: episode: 340, duration: 51.318s, episode steps: 943, steps per second:  18, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.009139, mae: 0.372234, mean_q: 0.456073\n",
            " 235005/1000000: episode: 341, duration: 21.061s, episode steps: 386, steps per second:  18, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.010072, mae: 0.374711, mean_q: 0.460152\n",
            " 235624/1000000: episode: 342, duration: 34.166s, episode steps: 619, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.008908, mae: 0.372567, mean_q: 0.457575\n",
            " 236046/1000000: episode: 343, duration: 23.179s, episode steps: 422, steps per second:  18, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.009004, mae: 0.371801, mean_q: 0.454687\n",
            " 236866/1000000: episode: 344, duration: 44.042s, episode steps: 820, steps per second:  19, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.009710, mae: 0.369492, mean_q: 0.452977\n",
            " 237518/1000000: episode: 345, duration: 34.717s, episode steps: 652, steps per second:  19, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.010216, mae: 0.374980, mean_q: 0.460558\n",
            " 237964/1000000: episode: 346, duration: 24.398s, episode steps: 446, steps per second:  18, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.008930, mae: 0.372250, mean_q: 0.458623\n",
            " 238609/1000000: episode: 347, duration: 35.738s, episode steps: 645, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.010189, mae: 0.379219, mean_q: 0.465233\n",
            " 239330/1000000: episode: 348, duration: 39.459s, episode steps: 721, steps per second:  18, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.008555, mae: 0.365590, mean_q: 0.449139\n",
            " 240120/1000000: episode: 349, duration: 42.781s, episode steps: 790, steps per second:  18, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.008731, mae: 0.370645, mean_q: 0.456369\n",
            " 240765/1000000: episode: 350, duration: 35.008s, episode steps: 645, steps per second:  18, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.009300, mae: 0.397924, mean_q: 0.488861\n",
            " 241273/1000000: episode: 351, duration: 27.459s, episode steps: 508, steps per second:  19, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.008764, mae: 0.397849, mean_q: 0.488899\n",
            " 241671/1000000: episode: 352, duration: 21.445s, episode steps: 398, steps per second:  19, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.009057, mae: 0.397982, mean_q: 0.489464\n",
            " 242301/1000000: episode: 353, duration: 33.805s, episode steps: 630, steps per second:  19, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.010851, mae: 0.407834, mean_q: 0.499708\n",
            " 242986/1000000: episode: 354, duration: 36.984s, episode steps: 685, steps per second:  19, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.009829, mae: 0.397454, mean_q: 0.487331\n",
            " 243557/1000000: episode: 355, duration: 31.229s, episode steps: 571, steps per second:  18, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.009381, mae: 0.401686, mean_q: 0.493474\n",
            " 244416/1000000: episode: 356, duration: 46.814s, episode steps: 859, steps per second:  18, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.009020, mae: 0.396096, mean_q: 0.488319\n",
            " 245026/1000000: episode: 357, duration: 33.495s, episode steps: 610, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.009440, mae: 0.400501, mean_q: 0.492050\n",
            " 245641/1000000: episode: 358, duration: 33.635s, episode steps: 615, steps per second:  18, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.009500, mae: 0.395480, mean_q: 0.486963\n",
            " 246326/1000000: episode: 359, duration: 37.320s, episode steps: 685, steps per second:  18, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.009448, mae: 0.385913, mean_q: 0.472469\n",
            " 247067/1000000: episode: 360, duration: 40.232s, episode steps: 741, steps per second:  18, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.008786, mae: 0.397584, mean_q: 0.488362\n",
            " 248058/1000000: episode: 361, duration: 54.040s, episode steps: 991, steps per second:  18, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.008608, mae: 0.391402, mean_q: 0.480379\n",
            " 248588/1000000: episode: 362, duration: 28.815s, episode steps: 530, steps per second:  18, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.009938, mae: 0.403656, mean_q: 0.496582\n",
            " 249769/1000000: episode: 363, duration: 64.491s, episode steps: 1181, steps per second:  18, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.008118, mae: 0.393272, mean_q: 0.483787\n",
            " 250269/1000000: episode: 364, duration: 27.226s, episode steps: 500, steps per second:  18, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.008541, mae: 0.410936, mean_q: 0.506828\n",
            " 250809/1000000: episode: 365, duration: 29.271s, episode steps: 540, steps per second:  18, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.009255, mae: 0.432805, mean_q: 0.531393\n",
            " 251382/1000000: episode: 366, duration: 31.260s, episode steps: 573, steps per second:  18, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.010716, mae: 0.426155, mean_q: 0.523236\n",
            " 251977/1000000: episode: 367, duration: 32.587s, episode steps: 595, steps per second:  18, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.010434, mae: 0.427980, mean_q: 0.523818\n",
            " 252371/1000000: episode: 368, duration: 21.378s, episode steps: 394, steps per second:  18, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.009559, mae: 0.433649, mean_q: 0.534644\n",
            " 252903/1000000: episode: 369, duration: 29.433s, episode steps: 532, steps per second:  18, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.009051, mae: 0.420636, mean_q: 0.517441\n",
            " 253529/1000000: episode: 370, duration: 34.791s, episode steps: 626, steps per second:  18, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.010042, mae: 0.431923, mean_q: 0.529571\n",
            " 254039/1000000: episode: 371, duration: 27.718s, episode steps: 510, steps per second:  18, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.008766, mae: 0.422560, mean_q: 0.518884\n",
            " 254735/1000000: episode: 372, duration: 37.901s, episode steps: 696, steps per second:  18, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.009212, mae: 0.425491, mean_q: 0.524142\n",
            " 255367/1000000: episode: 373, duration: 34.428s, episode steps: 632, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.009075, mae: 0.423217, mean_q: 0.521363\n",
            " 256141/1000000: episode: 374, duration: 42.676s, episode steps: 774, steps per second:  18, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.010006, mae: 0.427755, mean_q: 0.524819\n",
            " 256587/1000000: episode: 375, duration: 24.728s, episode steps: 446, steps per second:  18, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.009788, mae: 0.425520, mean_q: 0.522584\n",
            " 257750/1000000: episode: 376, duration: 64.130s, episode steps: 1163, steps per second:  18, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.009475, mae: 0.429212, mean_q: 0.528869\n",
            " 258528/1000000: episode: 377, duration: 42.408s, episode steps: 778, steps per second:  18, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.009439, mae: 0.424008, mean_q: 0.520368\n",
            " 258961/1000000: episode: 378, duration: 23.545s, episode steps: 433, steps per second:  18, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.010744, mae: 0.426847, mean_q: 0.523980\n",
            " 259589/1000000: episode: 379, duration: 34.760s, episode steps: 628, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.009641, mae: 0.426897, mean_q: 0.524179\n",
            " 260262/1000000: episode: 380, duration: 37.924s, episode steps: 673, steps per second:  18, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.008869, mae: 0.437866, mean_q: 0.539169\n",
            " 261030/1000000: episode: 381, duration: 42.339s, episode steps: 768, steps per second:  18, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.009956, mae: 0.458306, mean_q: 0.565539\n",
            " 261712/1000000: episode: 382, duration: 37.788s, episode steps: 682, steps per second:  18, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.010242, mae: 0.447584, mean_q: 0.549843\n",
            " 262107/1000000: episode: 383, duration: 21.842s, episode steps: 395, steps per second:  18, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.010436, mae: 0.448501, mean_q: 0.550026\n",
            " 262847/1000000: episode: 384, duration: 40.754s, episode steps: 740, steps per second:  18, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.009588, mae: 0.450815, mean_q: 0.552974\n",
            " 263386/1000000: episode: 385, duration: 29.842s, episode steps: 539, steps per second:  18, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.009702, mae: 0.447683, mean_q: 0.548615\n",
            " 264162/1000000: episode: 386, duration: 43.272s, episode steps: 776, steps per second:  18, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.009974, mae: 0.454743, mean_q: 0.557840\n",
            " 264700/1000000: episode: 387, duration: 29.674s, episode steps: 538, steps per second:  18, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.010447, mae: 0.453634, mean_q: 0.556844\n",
            " 265675/1000000: episode: 388, duration: 53.622s, episode steps: 975, steps per second:  18, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.009935, mae: 0.445285, mean_q: 0.546349\n",
            " 266559/1000000: episode: 389, duration: 48.648s, episode steps: 884, steps per second:  18, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.010305, mae: 0.457462, mean_q: 0.562524\n",
            " 267189/1000000: episode: 390, duration: 34.205s, episode steps: 630, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.009940, mae: 0.449201, mean_q: 0.552817\n",
            " 267872/1000000: episode: 391, duration: 38.093s, episode steps: 683, steps per second:  18, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.009264, mae: 0.441896, mean_q: 0.542580\n",
            " 268669/1000000: episode: 392, duration: 44.384s, episode steps: 797, steps per second:  18, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.010238, mae: 0.449809, mean_q: 0.554152\n",
            " 269216/1000000: episode: 393, duration: 30.189s, episode steps: 547, steps per second:  18, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.009608, mae: 0.446716, mean_q: 0.549196\n",
            " 270083/1000000: episode: 394, duration: 48.276s, episode steps: 867, steps per second:  18, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.009600, mae: 0.453138, mean_q: 0.556431\n",
            " 271014/1000000: episode: 395, duration: 51.909s, episode steps: 931, steps per second:  18, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.009220, mae: 0.479928, mean_q: 0.589452\n",
            " 271797/1000000: episode: 396, duration: 43.881s, episode steps: 783, steps per second:  18, episode reward: 20.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.009791, mae: 0.478408, mean_q: 0.587022\n",
            " 272407/1000000: episode: 397, duration: 34.416s, episode steps: 610, steps per second:  18, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.010211, mae: 0.474272, mean_q: 0.580752\n",
            " 272906/1000000: episode: 398, duration: 27.854s, episode steps: 499, steps per second:  18, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.009850, mae: 0.475514, mean_q: 0.582837\n",
            " 273358/1000000: episode: 399, duration: 25.357s, episode steps: 452, steps per second:  18, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.009170, mae: 0.466895, mean_q: 0.572582\n",
            " 273756/1000000: episode: 400, duration: 22.078s, episode steps: 398, steps per second:  18, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.008818, mae: 0.467157, mean_q: 0.572067\n",
            " 274136/1000000: episode: 401, duration: 21.271s, episode steps: 380, steps per second:  18, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.674 [0.000, 5.000],  loss: 0.009671, mae: 0.470200, mean_q: 0.575902\n",
            " 274793/1000000: episode: 402, duration: 36.873s, episode steps: 657, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.010369, mae: 0.468093, mean_q: 0.573821\n",
            " 275150/1000000: episode: 403, duration: 20.156s, episode steps: 357, steps per second:  18, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.008474, mae: 0.461816, mean_q: 0.566474\n",
            " 275703/1000000: episode: 404, duration: 31.060s, episode steps: 553, steps per second:  18, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.010592, mae: 0.466242, mean_q: 0.572358\n",
            " 276329/1000000: episode: 405, duration: 35.732s, episode steps: 626, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.010450, mae: 0.475063, mean_q: 0.583643\n",
            " 277198/1000000: episode: 406, duration: 49.667s, episode steps: 869, steps per second:  17, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.010176, mae: 0.475962, mean_q: 0.583653\n",
            " 277869/1000000: episode: 407, duration: 38.316s, episode steps: 671, steps per second:  18, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.010431, mae: 0.469729, mean_q: 0.576505\n",
            " 278347/1000000: episode: 408, duration: 26.808s, episode steps: 478, steps per second:  18, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.009652, mae: 0.469932, mean_q: 0.578935\n",
            " 278745/1000000: episode: 409, duration: 22.407s, episode steps: 398, steps per second:  18, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.009018, mae: 0.471180, mean_q: 0.579594\n",
            " 279767/1000000: episode: 410, duration: 57.381s, episode steps: 1022, steps per second:  18, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.008935, mae: 0.469312, mean_q: 0.578112\n",
            " 280516/1000000: episode: 411, duration: 42.161s, episode steps: 749, steps per second:  18, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.008829, mae: 0.479362, mean_q: 0.589168\n",
            " 281320/1000000: episode: 412, duration: 45.501s, episode steps: 804, steps per second:  18, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.009442, mae: 0.484806, mean_q: 0.596840\n",
            " 281922/1000000: episode: 413, duration: 34.080s, episode steps: 602, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.010011, mae: 0.481789, mean_q: 0.593393\n",
            " 282315/1000000: episode: 414, duration: 22.300s, episode steps: 393, steps per second:  18, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.009800, mae: 0.486168, mean_q: 0.599778\n",
            " 283025/1000000: episode: 415, duration: 40.053s, episode steps: 710, steps per second:  18, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.009026, mae: 0.479959, mean_q: 0.591209\n",
            " 283832/1000000: episode: 416, duration: 45.588s, episode steps: 807, steps per second:  18, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.011318, mae: 0.483979, mean_q: 0.591691\n",
            " 284242/1000000: episode: 417, duration: 22.974s, episode steps: 410, steps per second:  18, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.010245, mae: 0.483356, mean_q: 0.592665\n",
            " 284875/1000000: episode: 418, duration: 35.298s, episode steps: 633, steps per second:  18, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.009333, mae: 0.481138, mean_q: 0.589644\n",
            " 285462/1000000: episode: 419, duration: 32.608s, episode steps: 587, steps per second:  18, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.009861, mae: 0.480701, mean_q: 0.589758\n",
            " 286138/1000000: episode: 420, duration: 37.940s, episode steps: 676, steps per second:  18, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.009933, mae: 0.483443, mean_q: 0.593727\n",
            " 287328/1000000: episode: 421, duration: 66.636s, episode steps: 1190, steps per second:  18, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.011573, mae: 0.482552, mean_q: 0.589790\n",
            " 287860/1000000: episode: 422, duration: 30.219s, episode steps: 532, steps per second:  18, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.009500, mae: 0.481111, mean_q: 0.591427\n",
            " 289014/1000000: episode: 423, duration: 65.333s, episode steps: 1154, steps per second:  18, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.009102, mae: 0.476756, mean_q: 0.584506\n",
            " 290384/1000000: episode: 424, duration: 77.176s, episode steps: 1370, steps per second:  18, episode reward: 14.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.010516, mae: 0.489440, mean_q: 0.602161\n",
            " 290792/1000000: episode: 425, duration: 23.136s, episode steps: 408, steps per second:  18, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.008049, mae: 0.496888, mean_q: 0.611108\n",
            " 291696/1000000: episode: 426, duration: 51.311s, episode steps: 904, steps per second:  18, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.009203, mae: 0.516603, mean_q: 0.634204\n",
            " 292054/1000000: episode: 427, duration: 20.240s, episode steps: 358, steps per second:  18, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.011024, mae: 0.509709, mean_q: 0.626367\n",
            " 292743/1000000: episode: 428, duration: 38.808s, episode steps: 689, steps per second:  18, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.009430, mae: 0.508721, mean_q: 0.625669\n",
            " 293352/1000000: episode: 429, duration: 34.339s, episode steps: 609, steps per second:  18, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.009707, mae: 0.496573, mean_q: 0.609698\n",
            " 293745/1000000: episode: 430, duration: 22.273s, episode steps: 393, steps per second:  18, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.009419, mae: 0.507145, mean_q: 0.624679\n",
            " 294491/1000000: episode: 431, duration: 41.804s, episode steps: 746, steps per second:  18, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.009891, mae: 0.499468, mean_q: 0.613103\n",
            " 295369/1000000: episode: 432, duration: 49.548s, episode steps: 878, steps per second:  18, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.009502, mae: 0.506902, mean_q: 0.621737\n",
            " 296289/1000000: episode: 433, duration: 52.479s, episode steps: 920, steps per second:  18, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.008326, mae: 0.495663, mean_q: 0.608534\n",
            " 297465/1000000: episode: 434, duration: 66.911s, episode steps: 1176, steps per second:  18, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.009571, mae: 0.504392, mean_q: 0.620593\n",
            " 297854/1000000: episode: 435, duration: 22.008s, episode steps: 389, steps per second:  18, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.009206, mae: 0.501967, mean_q: 0.619237\n",
            " 298330/1000000: episode: 436, duration: 26.959s, episode steps: 476, steps per second:  18, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.010382, mae: 0.500323, mean_q: 0.615532\n",
            " 299099/1000000: episode: 437, duration: 43.617s, episode steps: 769, steps per second:  18, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.010154, mae: 0.503418, mean_q: 0.618854\n",
            " 299637/1000000: episode: 438, duration: 30.735s, episode steps: 538, steps per second:  18, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.009120, mae: 0.505063, mean_q: 0.621466\n",
            " 300283/1000000: episode: 439, duration: 36.754s, episode steps: 646, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.009470, mae: 0.510665, mean_q: 0.628028\n",
            " 301322/1000000: episode: 440, duration: 58.889s, episode steps: 1039, steps per second:  18, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.010273, mae: 0.533578, mean_q: 0.654146\n",
            " 301844/1000000: episode: 441, duration: 29.696s, episode steps: 522, steps per second:  18, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.010286, mae: 0.532792, mean_q: 0.654756\n",
            " 302676/1000000: episode: 442, duration: 47.434s, episode steps: 832, steps per second:  18, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.009079, mae: 0.526173, mean_q: 0.646522\n",
            " 303504/1000000: episode: 443, duration: 47.528s, episode steps: 828, steps per second:  17, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.010048, mae: 0.524827, mean_q: 0.645056\n",
            " 304264/1000000: episode: 444, duration: 43.457s, episode steps: 760, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.010342, mae: 0.540396, mean_q: 0.664725\n",
            " 305454/1000000: episode: 445, duration: 68.255s, episode steps: 1190, steps per second:  17, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.009733, mae: 0.526054, mean_q: 0.645577\n",
            " 306279/1000000: episode: 446, duration: 46.746s, episode steps: 825, steps per second:  18, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.010350, mae: 0.528955, mean_q: 0.649576\n",
            " 306942/1000000: episode: 447, duration: 37.456s, episode steps: 663, steps per second:  18, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.010800, mae: 0.522052, mean_q: 0.641255\n",
            " 307683/1000000: episode: 448, duration: 42.033s, episode steps: 741, steps per second:  18, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.010139, mae: 0.530060, mean_q: 0.651146\n",
            " 308277/1000000: episode: 449, duration: 33.918s, episode steps: 594, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.010511, mae: 0.532753, mean_q: 0.654587\n",
            " 309321/1000000: episode: 450, duration: 59.137s, episode steps: 1044, steps per second:  18, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.009214, mae: 0.521941, mean_q: 0.641964\n",
            " 309929/1000000: episode: 451, duration: 34.540s, episode steps: 608, steps per second:  18, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.009897, mae: 0.531498, mean_q: 0.654386\n",
            " 310713/1000000: episode: 452, duration: 44.614s, episode steps: 784, steps per second:  18, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.010015, mae: 0.534475, mean_q: 0.656839\n",
            " 311421/1000000: episode: 453, duration: 40.740s, episode steps: 708, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.011227, mae: 0.531337, mean_q: 0.653106\n",
            " 312229/1000000: episode: 454, duration: 46.093s, episode steps: 808, steps per second:  18, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.011065, mae: 0.534442, mean_q: 0.656794\n",
            " 313081/1000000: episode: 455, duration: 49.188s, episode steps: 852, steps per second:  17, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.010253, mae: 0.533352, mean_q: 0.657067\n",
            " 313730/1000000: episode: 456, duration: 37.169s, episode steps: 649, steps per second:  17, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.011020, mae: 0.537163, mean_q: 0.660434\n",
            " 314238/1000000: episode: 457, duration: 28.968s, episode steps: 508, steps per second:  18, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.011996, mae: 0.538714, mean_q: 0.661396\n",
            " 315047/1000000: episode: 458, duration: 46.138s, episode steps: 809, steps per second:  18, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.011550, mae: 0.528428, mean_q: 0.648950\n",
            " 315754/1000000: episode: 459, duration: 40.745s, episode steps: 707, steps per second:  17, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.011209, mae: 0.548300, mean_q: 0.676192\n",
            " 316264/1000000: episode: 460, duration: 29.306s, episode steps: 510, steps per second:  17, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.010560, mae: 0.535074, mean_q: 0.659090\n",
            " 316893/1000000: episode: 461, duration: 36.136s, episode steps: 629, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.010154, mae: 0.529161, mean_q: 0.651421\n",
            " 317700/1000000: episode: 462, duration: 45.791s, episode steps: 807, steps per second:  18, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.010360, mae: 0.532985, mean_q: 0.657593\n",
            " 318437/1000000: episode: 463, duration: 42.216s, episode steps: 737, steps per second:  17, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.008992, mae: 0.537038, mean_q: 0.661487\n",
            " 319250/1000000: episode: 464, duration: 46.553s, episode steps: 813, steps per second:  17, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.009467, mae: 0.522282, mean_q: 0.642719\n",
            " 320164/1000000: episode: 465, duration: 52.141s, episode steps: 914, steps per second:  18, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.010373, mae: 0.539605, mean_q: 0.664369\n",
            " 320842/1000000: episode: 466, duration: 39.282s, episode steps: 678, steps per second:  17, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.011636, mae: 0.574633, mean_q: 0.706860\n",
            " 321884/1000000: episode: 467, duration: 59.844s, episode steps: 1042, steps per second:  17, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.009354, mae: 0.564696, mean_q: 0.695628\n",
            " 322826/1000000: episode: 468, duration: 53.920s, episode steps: 942, steps per second:  17, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.009809, mae: 0.562439, mean_q: 0.693449\n",
            " 323505/1000000: episode: 469, duration: 38.238s, episode steps: 679, steps per second:  18, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.010565, mae: 0.564664, mean_q: 0.696816\n",
            " 323914/1000000: episode: 470, duration: 23.472s, episode steps: 409, steps per second:  17, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.009506, mae: 0.560647, mean_q: 0.691276\n",
            " 324438/1000000: episode: 471, duration: 30.408s, episode steps: 524, steps per second:  17, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.011019, mae: 0.575350, mean_q: 0.708683\n",
            " 325133/1000000: episode: 472, duration: 40.114s, episode steps: 695, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.010742, mae: 0.570000, mean_q: 0.702685\n",
            " 325764/1000000: episode: 473, duration: 36.344s, episode steps: 631, steps per second:  17, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.009659, mae: 0.555867, mean_q: 0.683826\n",
            " 326344/1000000: episode: 474, duration: 33.353s, episode steps: 580, steps per second:  17, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.010996, mae: 0.570166, mean_q: 0.701364\n",
            " 327494/1000000: episode: 475, duration: 65.595s, episode steps: 1150, steps per second:  18, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.009539, mae: 0.555770, mean_q: 0.684803\n",
            " 328186/1000000: episode: 476, duration: 39.484s, episode steps: 692, steps per second:  18, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.011024, mae: 0.568246, mean_q: 0.700166\n",
            " 328554/1000000: episode: 477, duration: 21.121s, episode steps: 368, steps per second:  17, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.009815, mae: 0.569101, mean_q: 0.700842\n",
            " 329293/1000000: episode: 478, duration: 42.649s, episode steps: 739, steps per second:  17, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.011728, mae: 0.570949, mean_q: 0.705040\n",
            " 330051/1000000: episode: 479, duration: 43.437s, episode steps: 758, steps per second:  17, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.010699, mae: 0.565247, mean_q: 0.693785\n",
            " 330743/1000000: episode: 480, duration: 39.558s, episode steps: 692, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.008813, mae: 0.586938, mean_q: 0.722460\n",
            " 331774/1000000: episode: 481, duration: 58.927s, episode steps: 1031, steps per second:  17, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.009267, mae: 0.580427, mean_q: 0.714454\n",
            " 333173/1000000: episode: 482, duration: 79.552s, episode steps: 1399, steps per second:  18, episode reward: 13.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.010642, mae: 0.577638, mean_q: 0.708446\n",
            " 333559/1000000: episode: 483, duration: 21.865s, episode steps: 386, steps per second:  18, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.010595, mae: 0.569387, mean_q: 0.698500\n",
            " 334135/1000000: episode: 484, duration: 32.761s, episode steps: 576, steps per second:  18, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.011021, mae: 0.575237, mean_q: 0.705730\n",
            " 334755/1000000: episode: 485, duration: 35.356s, episode steps: 620, steps per second:  18, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.010295, mae: 0.581394, mean_q: 0.713693\n",
            " 335306/1000000: episode: 486, duration: 31.562s, episode steps: 551, steps per second:  17, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.010562, mae: 0.586047, mean_q: 0.719466\n",
            " 336051/1000000: episode: 487, duration: 42.192s, episode steps: 745, steps per second:  18, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.010466, mae: 0.586573, mean_q: 0.719931\n",
            " 336950/1000000: episode: 488, duration: 51.250s, episode steps: 899, steps per second:  18, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.010078, mae: 0.574935, mean_q: 0.707295\n",
            " 337920/1000000: episode: 489, duration: 54.908s, episode steps: 970, steps per second:  18, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.010155, mae: 0.579251, mean_q: 0.712798\n",
            " 338444/1000000: episode: 490, duration: 30.481s, episode steps: 524, steps per second:  17, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.010591, mae: 0.578898, mean_q: 0.708157\n",
            " 338852/1000000: episode: 491, duration: 23.658s, episode steps: 408, steps per second:  17, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.012442, mae: 0.592207, mean_q: 0.724619\n",
            " 339837/1000000: episode: 492, duration: 56.798s, episode steps: 985, steps per second:  17, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.009025, mae: 0.568912, mean_q: 0.697351\n",
            " 340502/1000000: episode: 493, duration: 37.913s, episode steps: 665, steps per second:  18, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.010441, mae: 0.602802, mean_q: 0.738005\n",
            " 340950/1000000: episode: 494, duration: 25.422s, episode steps: 448, steps per second:  18, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.010521, mae: 0.609625, mean_q: 0.748706\n",
            " 341449/1000000: episode: 495, duration: 28.190s, episode steps: 499, steps per second:  18, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.009837, mae: 0.609370, mean_q: 0.748676\n",
            " 342675/1000000: episode: 496, duration: 69.047s, episode steps: 1226, steps per second:  18, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.010895, mae: 0.606582, mean_q: 0.746410\n",
            " 343495/1000000: episode: 497, duration: 45.958s, episode steps: 820, steps per second:  18, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.009389, mae: 0.603629, mean_q: 0.741971\n",
            " 344174/1000000: episode: 498, duration: 38.308s, episode steps: 679, steps per second:  18, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.009741, mae: 0.602513, mean_q: 0.740551\n",
            " 344701/1000000: episode: 499, duration: 29.970s, episode steps: 527, steps per second:  18, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.009975, mae: 0.599835, mean_q: 0.737078\n",
            " 345678/1000000: episode: 500, duration: 55.356s, episode steps: 977, steps per second:  18, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.010213, mae: 0.611621, mean_q: 0.751372\n",
            " 346116/1000000: episode: 501, duration: 24.919s, episode steps: 438, steps per second:  18, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.010727, mae: 0.615571, mean_q: 0.755116\n",
            " 346796/1000000: episode: 502, duration: 38.688s, episode steps: 680, steps per second:  18, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.009336, mae: 0.603166, mean_q: 0.742072\n",
            " 348135/1000000: episode: 503, duration: 76.241s, episode steps: 1339, steps per second:  18, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.010406, mae: 0.603010, mean_q: 0.742087\n",
            " 348641/1000000: episode: 504, duration: 29.185s, episode steps: 506, steps per second:  17, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.009733, mae: 0.616264, mean_q: 0.758029\n",
            " 349352/1000000: episode: 505, duration: 40.700s, episode steps: 711, steps per second:  17, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.009115, mae: 0.596381, mean_q: 0.734127\n",
            " 350018/1000000: episode: 506, duration: 38.102s, episode steps: 666, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.009611, mae: 0.602504, mean_q: 0.741535\n",
            " 350699/1000000: episode: 507, duration: 38.949s, episode steps: 681, steps per second:  17, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.010514, mae: 0.643980, mean_q: 0.792836\n",
            " 351177/1000000: episode: 508, duration: 27.360s, episode steps: 478, steps per second:  17, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.011553, mae: 0.643682, mean_q: 0.790024\n",
            " 351791/1000000: episode: 509, duration: 35.002s, episode steps: 614, steps per second:  18, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.010411, mae: 0.630553, mean_q: 0.776235\n",
            " 352426/1000000: episode: 510, duration: 36.270s, episode steps: 635, steps per second:  18, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.010185, mae: 0.632650, mean_q: 0.777563\n",
            " 353013/1000000: episode: 511, duration: 33.381s, episode steps: 587, steps per second:  18, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.010903, mae: 0.631301, mean_q: 0.774018\n",
            " 353552/1000000: episode: 512, duration: 30.743s, episode steps: 539, steps per second:  18, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.008848, mae: 0.622652, mean_q: 0.765458\n",
            " 354136/1000000: episode: 513, duration: 33.441s, episode steps: 584, steps per second:  17, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.010631, mae: 0.634262, mean_q: 0.779256\n",
            " 354952/1000000: episode: 514, duration: 46.730s, episode steps: 816, steps per second:  17, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.011362, mae: 0.624058, mean_q: 0.767010\n",
            " 355780/1000000: episode: 515, duration: 47.293s, episode steps: 828, steps per second:  18, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.011751, mae: 0.633417, mean_q: 0.778462\n",
            " 356874/1000000: episode: 516, duration: 62.574s, episode steps: 1094, steps per second:  17, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.011120, mae: 0.633821, mean_q: 0.779071\n",
            " 357572/1000000: episode: 517, duration: 40.125s, episode steps: 698, steps per second:  17, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.009997, mae: 0.630566, mean_q: 0.774586\n",
            " 358017/1000000: episode: 518, duration: 25.602s, episode steps: 445, steps per second:  17, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.010340, mae: 0.628833, mean_q: 0.774706\n",
            " 358934/1000000: episode: 519, duration: 52.239s, episode steps: 917, steps per second:  18, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.009714, mae: 0.627786, mean_q: 0.771839\n",
            " 359436/1000000: episode: 520, duration: 28.557s, episode steps: 502, steps per second:  18, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.010018, mae: 0.617690, mean_q: 0.758651\n",
            " 359921/1000000: episode: 521, duration: 27.677s, episode steps: 485, steps per second:  18, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.010630, mae: 0.638070, mean_q: 0.783048\n",
            " 360549/1000000: episode: 522, duration: 35.745s, episode steps: 628, steps per second:  18, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.011402, mae: 0.645755, mean_q: 0.793644\n",
            " 361290/1000000: episode: 523, duration: 42.281s, episode steps: 741, steps per second:  18, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.010040, mae: 0.646059, mean_q: 0.794725\n",
            " 361925/1000000: episode: 524, duration: 36.364s, episode steps: 635, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.010250, mae: 0.647909, mean_q: 0.796512\n",
            " 362568/1000000: episode: 525, duration: 36.899s, episode steps: 643, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.011424, mae: 0.655139, mean_q: 0.803489\n",
            " 363054/1000000: episode: 526, duration: 27.848s, episode steps: 486, steps per second:  17, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.011843, mae: 0.656702, mean_q: 0.805581\n",
            " 363627/1000000: episode: 527, duration: 32.625s, episode steps: 573, steps per second:  18, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.011648, mae: 0.661501, mean_q: 0.814084\n",
            " 364395/1000000: episode: 528, duration: 43.889s, episode steps: 768, steps per second:  17, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.010859, mae: 0.637923, mean_q: 0.786010\n",
            " 365014/1000000: episode: 529, duration: 35.587s, episode steps: 619, steps per second:  17, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.010956, mae: 0.648017, mean_q: 0.797182\n",
            " 366074/1000000: episode: 530, duration: 60.713s, episode steps: 1060, steps per second:  17, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.010672, mae: 0.649209, mean_q: 0.800614\n",
            " 366880/1000000: episode: 531, duration: 46.320s, episode steps: 806, steps per second:  17, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.010665, mae: 0.648928, mean_q: 0.798855\n",
            " 367305/1000000: episode: 532, duration: 24.543s, episode steps: 425, steps per second:  17, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.010501, mae: 0.644265, mean_q: 0.794330\n",
            " 367688/1000000: episode: 533, duration: 22.063s, episode steps: 383, steps per second:  17, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.009310, mae: 0.637861, mean_q: 0.786819\n",
            " 368257/1000000: episode: 534, duration: 32.947s, episode steps: 569, steps per second:  17, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.010839, mae: 0.648908, mean_q: 0.801159\n",
            " 369281/1000000: episode: 535, duration: 58.761s, episode steps: 1024, steps per second:  17, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.010857, mae: 0.651144, mean_q: 0.800300\n",
            " 369989/1000000: episode: 536, duration: 40.764s, episode steps: 708, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.010090, mae: 0.647289, mean_q: 0.793625\n",
            " 370657/1000000: episode: 537, duration: 38.735s, episode steps: 668, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.010628, mae: 0.681323, mean_q: 0.836550\n",
            " 371046/1000000: episode: 538, duration: 22.538s, episode steps: 389, steps per second:  17, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.011805, mae: 0.680393, mean_q: 0.835097\n",
            " 371725/1000000: episode: 539, duration: 39.274s, episode steps: 679, steps per second:  17, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.010473, mae: 0.678457, mean_q: 0.831586\n",
            " 372409/1000000: episode: 540, duration: 39.563s, episode steps: 684, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.011638, mae: 0.684541, mean_q: 0.838137\n",
            " 373331/1000000: episode: 541, duration: 53.093s, episode steps: 922, steps per second:  17, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.012613, mae: 0.687190, mean_q: 0.843899\n",
            " 373957/1000000: episode: 542, duration: 35.900s, episode steps: 626, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.010884, mae: 0.678111, mean_q: 0.834966\n",
            " 374811/1000000: episode: 543, duration: 48.865s, episode steps: 854, steps per second:  17, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.011402, mae: 0.679421, mean_q: 0.835353\n",
            " 375677/1000000: episode: 544, duration: 49.674s, episode steps: 866, steps per second:  17, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.010072, mae: 0.671540, mean_q: 0.825991\n",
            " 376342/1000000: episode: 545, duration: 38.257s, episode steps: 665, steps per second:  17, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.010326, mae: 0.674910, mean_q: 0.830851\n",
            " 376931/1000000: episode: 546, duration: 33.686s, episode steps: 589, steps per second:  17, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.011085, mae: 0.672398, mean_q: 0.826520\n",
            " 377618/1000000: episode: 547, duration: 39.268s, episode steps: 687, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.011020, mae: 0.674788, mean_q: 0.829538\n",
            " 378249/1000000: episode: 548, duration: 36.428s, episode steps: 631, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.010433, mae: 0.671987, mean_q: 0.825796\n",
            " 378707/1000000: episode: 549, duration: 26.296s, episode steps: 458, steps per second:  17, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.009476, mae: 0.667935, mean_q: 0.821497\n",
            " 379114/1000000: episode: 550, duration: 23.319s, episode steps: 407, steps per second:  17, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.012308, mae: 0.687110, mean_q: 0.843434\n",
            " 380073/1000000: episode: 551, duration: 54.849s, episode steps: 959, steps per second:  17, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.010849, mae: 0.686209, mean_q: 0.843048\n",
            " 381030/1000000: episode: 552, duration: 54.650s, episode steps: 957, steps per second:  18, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.010581, mae: 0.712765, mean_q: 0.876797\n",
            " 381813/1000000: episode: 553, duration: 45.323s, episode steps: 783, steps per second:  17, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.012027, mae: 0.724201, mean_q: 0.888256\n",
            " 382677/1000000: episode: 554, duration: 49.234s, episode steps: 864, steps per second:  18, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.011660, mae: 0.716799, mean_q: 0.879513\n",
            " 383326/1000000: episode: 555, duration: 37.032s, episode steps: 649, steps per second:  18, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.010946, mae: 0.704108, mean_q: 0.862242\n",
            " 383767/1000000: episode: 556, duration: 25.270s, episode steps: 441, steps per second:  17, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.012053, mae: 0.705705, mean_q: 0.865256\n",
            " 384299/1000000: episode: 557, duration: 30.624s, episode steps: 532, steps per second:  17, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.011727, mae: 0.718081, mean_q: 0.880536\n",
            " 384978/1000000: episode: 558, duration: 39.000s, episode steps: 679, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.011461, mae: 0.703494, mean_q: 0.863872\n",
            " 385660/1000000: episode: 559, duration: 38.659s, episode steps: 682, steps per second:  18, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.009922, mae: 0.702891, mean_q: 0.862555\n",
            " 386224/1000000: episode: 560, duration: 32.557s, episode steps: 564, steps per second:  17, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.010389, mae: 0.700719, mean_q: 0.859783\n",
            " 387265/1000000: episode: 561, duration: 60.186s, episode steps: 1041, steps per second:  17, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.010415, mae: 0.701688, mean_q: 0.861951\n",
            " 387978/1000000: episode: 562, duration: 41.350s, episode steps: 713, steps per second:  17, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.011190, mae: 0.702529, mean_q: 0.862837\n",
            " 388423/1000000: episode: 563, duration: 25.533s, episode steps: 445, steps per second:  17, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.011165, mae: 0.695517, mean_q: 0.854764\n",
            " 389247/1000000: episode: 564, duration: 47.087s, episode steps: 824, steps per second:  17, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.011990, mae: 0.709557, mean_q: 0.872178\n",
            " 389726/1000000: episode: 565, duration: 27.706s, episode steps: 479, steps per second:  17, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.010050, mae: 0.710049, mean_q: 0.871892\n",
            " 390404/1000000: episode: 566, duration: 38.976s, episode steps: 678, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.009990, mae: 0.729893, mean_q: 0.898299\n",
            " 391139/1000000: episode: 567, duration: 41.906s, episode steps: 735, steps per second:  18, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.011193, mae: 0.744101, mean_q: 0.913981\n",
            " 391864/1000000: episode: 568, duration: 41.676s, episode steps: 725, steps per second:  17, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.011207, mae: 0.747730, mean_q: 0.919268\n",
            " 392406/1000000: episode: 569, duration: 31.099s, episode steps: 542, steps per second:  17, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.012124, mae: 0.740965, mean_q: 0.908994\n",
            " 393023/1000000: episode: 570, duration: 35.235s, episode steps: 617, steps per second:  18, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.011780, mae: 0.742676, mean_q: 0.910254\n",
            " 393816/1000000: episode: 571, duration: 45.488s, episode steps: 793, steps per second:  17, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.010484, mae: 0.744026, mean_q: 0.914110\n",
            " 394910/1000000: episode: 572, duration: 63.604s, episode steps: 1094, steps per second:  17, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.010651, mae: 0.748704, mean_q: 0.920039\n",
            " 395615/1000000: episode: 573, duration: 40.719s, episode steps: 705, steps per second:  17, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.011617, mae: 0.731574, mean_q: 0.897780\n",
            " 396543/1000000: episode: 574, duration: 53.196s, episode steps: 928, steps per second:  17, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.011007, mae: 0.738613, mean_q: 0.905159\n",
            " 397284/1000000: episode: 575, duration: 42.373s, episode steps: 741, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.010886, mae: 0.736759, mean_q: 0.902171\n",
            " 398003/1000000: episode: 576, duration: 41.793s, episode steps: 719, steps per second:  17, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.010074, mae: 0.729368, mean_q: 0.894195\n",
            " 398967/1000000: episode: 577, duration: 55.850s, episode steps: 964, steps per second:  17, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.010716, mae: 0.738085, mean_q: 0.904940\n",
            " 399730/1000000: episode: 578, duration: 44.170s, episode steps: 763, steps per second:  17, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.011378, mae: 0.744539, mean_q: 0.912095\n",
            " 400352/1000000: episode: 579, duration: 36.418s, episode steps: 622, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.011698, mae: 0.746012, mean_q: 0.914527\n",
            " 400826/1000000: episode: 580, duration: 27.534s, episode steps: 474, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.608 [0.000, 5.000],  loss: 0.011011, mae: 0.750184, mean_q: 0.920629\n",
            " 401406/1000000: episode: 581, duration: 33.197s, episode steps: 580, steps per second:  17, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.011424, mae: 0.752816, mean_q: 0.924320\n",
            " 402131/1000000: episode: 582, duration: 41.382s, episode steps: 725, steps per second:  18, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.010335, mae: 0.745778, mean_q: 0.915093\n",
            " 402735/1000000: episode: 583, duration: 34.304s, episode steps: 604, steps per second:  18, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.010467, mae: 0.749870, mean_q: 0.920854\n",
            " 403453/1000000: episode: 584, duration: 41.516s, episode steps: 718, steps per second:  17, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.011257, mae: 0.735852, mean_q: 0.902672\n",
            " 404181/1000000: episode: 585, duration: 41.863s, episode steps: 728, steps per second:  17, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.010439, mae: 0.743685, mean_q: 0.911384\n",
            " 405090/1000000: episode: 586, duration: 51.872s, episode steps: 909, steps per second:  18, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.012133, mae: 0.752966, mean_q: 0.922445\n",
            " 405988/1000000: episode: 587, duration: 51.235s, episode steps: 898, steps per second:  18, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.011085, mae: 0.749379, mean_q: 0.919233\n",
            " 406897/1000000: episode: 588, duration: 51.861s, episode steps: 909, steps per second:  18, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.011818, mae: 0.747510, mean_q: 0.916189\n",
            " 407941/1000000: episode: 589, duration: 59.918s, episode steps: 1044, steps per second:  17, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.011180, mae: 0.745726, mean_q: 0.915179\n",
            " 408893/1000000: episode: 590, duration: 54.422s, episode steps: 952, steps per second:  17, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.011678, mae: 0.756471, mean_q: 0.928658\n",
            " 409503/1000000: episode: 591, duration: 34.529s, episode steps: 610, steps per second:  18, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.011750, mae: 0.744554, mean_q: 0.913145\n",
            " 410368/1000000: episode: 592, duration: 49.468s, episode steps: 865, steps per second:  17, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.011204, mae: 0.755046, mean_q: 0.926569\n",
            " 410967/1000000: episode: 593, duration: 34.380s, episode steps: 599, steps per second:  17, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.011394, mae: 0.751364, mean_q: 0.923104\n",
            " 411620/1000000: episode: 594, duration: 37.440s, episode steps: 653, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.011205, mae: 0.755935, mean_q: 0.927502\n",
            " 412547/1000000: episode: 595, duration: 52.873s, episode steps: 927, steps per second:  18, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.011833, mae: 0.762893, mean_q: 0.937305\n",
            " 413526/1000000: episode: 596, duration: 55.912s, episode steps: 979, steps per second:  18, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.010637, mae: 0.750362, mean_q: 0.924143\n",
            " 413857/1000000: episode: 597, duration: 18.940s, episode steps: 331, steps per second:  17, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.010076, mae: 0.755688, mean_q: 0.929237\n",
            " 414630/1000000: episode: 598, duration: 44.115s, episode steps: 773, steps per second:  18, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.011543, mae: 0.764095, mean_q: 0.939664\n",
            " 415330/1000000: episode: 599, duration: 40.296s, episode steps: 700, steps per second:  17, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.009818, mae: 0.754370, mean_q: 0.927592\n",
            " 416559/1000000: episode: 600, duration: 71.982s, episode steps: 1229, steps per second:  17, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.011094, mae: 0.757369, mean_q: 0.928987\n",
            " 417459/1000000: episode: 601, duration: 51.989s, episode steps: 900, steps per second:  17, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.010331, mae: 0.761235, mean_q: 0.935108\n",
            " 417842/1000000: episode: 602, duration: 22.006s, episode steps: 383, steps per second:  17, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.011281, mae: 0.756374, mean_q: 0.928347\n",
            " 418345/1000000: episode: 603, duration: 28.780s, episode steps: 503, steps per second:  17, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.012185, mae: 0.761529, mean_q: 0.933200\n",
            " 419265/1000000: episode: 604, duration: 52.199s, episode steps: 920, steps per second:  18, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.011452, mae: 0.760913, mean_q: 0.934635\n",
            " 419872/1000000: episode: 605, duration: 34.124s, episode steps: 607, steps per second:  18, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.011190, mae: 0.754384, mean_q: 0.927573\n",
            " 420657/1000000: episode: 606, duration: 45.041s, episode steps: 785, steps per second:  17, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.010361, mae: 0.788424, mean_q: 0.969230\n",
            " 421458/1000000: episode: 607, duration: 45.831s, episode steps: 801, steps per second:  17, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.010456, mae: 0.793349, mean_q: 0.973883\n",
            " 421996/1000000: episode: 608, duration: 30.682s, episode steps: 538, steps per second:  18, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.011060, mae: 0.794659, mean_q: 0.978312\n",
            " 422818/1000000: episode: 609, duration: 47.104s, episode steps: 822, steps per second:  17, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.011331, mae: 0.799515, mean_q: 0.983192\n",
            " 423819/1000000: episode: 610, duration: 56.967s, episode steps: 1001, steps per second:  18, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.009923, mae: 0.793947, mean_q: 0.976075\n",
            " 424440/1000000: episode: 611, duration: 35.518s, episode steps: 621, steps per second:  17, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.011876, mae: 0.795507, mean_q: 0.975090\n",
            " 425101/1000000: episode: 612, duration: 38.062s, episode steps: 661, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.010679, mae: 0.796634, mean_q: 0.976877\n",
            " 425634/1000000: episode: 613, duration: 30.677s, episode steps: 533, steps per second:  17, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.011016, mae: 0.799427, mean_q: 0.981216\n",
            " 426344/1000000: episode: 614, duration: 40.811s, episode steps: 710, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.010918, mae: 0.801215, mean_q: 0.981148\n",
            " 427426/1000000: episode: 615, duration: 62.312s, episode steps: 1082, steps per second:  17, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.011086, mae: 0.798360, mean_q: 0.979829\n",
            " 428024/1000000: episode: 616, duration: 34.499s, episode steps: 598, steps per second:  17, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.011133, mae: 0.787487, mean_q: 0.966573\n",
            " 428543/1000000: episode: 617, duration: 30.142s, episode steps: 519, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.010896, mae: 0.789414, mean_q: 0.971357\n",
            " 429524/1000000: episode: 618, duration: 57.025s, episode steps: 981, steps per second:  17, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.010527, mae: 0.786925, mean_q: 0.967620\n",
            " 430290/1000000: episode: 619, duration: 44.575s, episode steps: 766, steps per second:  17, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.010517, mae: 0.798798, mean_q: 0.980178\n",
            " 430798/1000000: episode: 620, duration: 29.583s, episode steps: 508, steps per second:  17, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.010782, mae: 0.825942, mean_q: 1.016481\n",
            " 431599/1000000: episode: 621, duration: 46.837s, episode steps: 801, steps per second:  17, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.011208, mae: 0.809188, mean_q: 0.993548\n",
            " 432270/1000000: episode: 622, duration: 39.203s, episode steps: 671, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.011494, mae: 0.811683, mean_q: 0.995538\n",
            " 432766/1000000: episode: 623, duration: 29.375s, episode steps: 496, steps per second:  17, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.010898, mae: 0.809855, mean_q: 0.996243\n",
            " 433625/1000000: episode: 624, duration: 49.714s, episode steps: 859, steps per second:  17, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.010797, mae: 0.813206, mean_q: 0.998687\n",
            " 434335/1000000: episode: 625, duration: 40.961s, episode steps: 710, steps per second:  17, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.010777, mae: 0.805423, mean_q: 0.989453\n",
            " 435083/1000000: episode: 626, duration: 43.686s, episode steps: 748, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.010580, mae: 0.811192, mean_q: 0.994945\n",
            " 435638/1000000: episode: 627, duration: 32.590s, episode steps: 555, steps per second:  17, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.010975, mae: 0.811557, mean_q: 0.995617\n",
            " 436486/1000000: episode: 628, duration: 49.613s, episode steps: 848, steps per second:  17, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.010110, mae: 0.803563, mean_q: 0.987575\n",
            " 437348/1000000: episode: 629, duration: 50.704s, episode steps: 862, steps per second:  17, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.009618, mae: 0.808010, mean_q: 0.992441\n",
            " 438173/1000000: episode: 630, duration: 48.467s, episode steps: 825, steps per second:  17, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.011481, mae: 0.805586, mean_q: 0.989908\n",
            " 439097/1000000: episode: 631, duration: 53.902s, episode steps: 924, steps per second:  17, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.010989, mae: 0.809190, mean_q: 0.995249\n",
            " 440066/1000000: episode: 632, duration: 56.826s, episode steps: 969, steps per second:  17, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.011508, mae: 0.811409, mean_q: 0.999703\n",
            " 440702/1000000: episode: 633, duration: 37.234s, episode steps: 636, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.011360, mae: 0.849777, mean_q: 1.044882\n",
            " 441204/1000000: episode: 634, duration: 29.537s, episode steps: 502, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.010441, mae: 0.849702, mean_q: 1.043288\n",
            " 441875/1000000: episode: 635, duration: 39.360s, episode steps: 671, steps per second:  17, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.009640, mae: 0.840573, mean_q: 1.030394\n",
            " 442270/1000000: episode: 636, duration: 23.444s, episode steps: 395, steps per second:  17, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.011246, mae: 0.844271, mean_q: 1.033199\n",
            " 443142/1000000: episode: 637, duration: 51.645s, episode steps: 872, steps per second:  17, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.011105, mae: 0.845293, mean_q: 1.037507\n",
            " 443538/1000000: episode: 638, duration: 23.332s, episode steps: 396, steps per second:  17, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.009412, mae: 0.842548, mean_q: 1.034768\n",
            " 444030/1000000: episode: 639, duration: 28.945s, episode steps: 492, steps per second:  17, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.009881, mae: 0.839170, mean_q: 1.028089\n",
            " 444843/1000000: episode: 640, duration: 47.677s, episode steps: 813, steps per second:  17, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.010935, mae: 0.843842, mean_q: 1.034047\n",
            " 445801/1000000: episode: 641, duration: 56.498s, episode steps: 958, steps per second:  17, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.010781, mae: 0.848107, mean_q: 1.039310\n",
            " 446204/1000000: episode: 642, duration: 23.890s, episode steps: 403, steps per second:  17, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.012565, mae: 0.851703, mean_q: 1.043167\n",
            " 446862/1000000: episode: 643, duration: 38.652s, episode steps: 658, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.010451, mae: 0.843352, mean_q: 1.032906\n",
            " 447602/1000000: episode: 644, duration: 43.511s, episode steps: 740, steps per second:  17, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.010924, mae: 0.839223, mean_q: 1.028571\n",
            " 447948/1000000: episode: 645, duration: 20.588s, episode steps: 346, steps per second:  17, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.010193, mae: 0.847866, mean_q: 1.039774\n",
            " 448754/1000000: episode: 646, duration: 47.807s, episode steps: 806, steps per second:  17, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.009762, mae: 0.833331, mean_q: 1.022966\n",
            " 449416/1000000: episode: 647, duration: 39.560s, episode steps: 662, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.011192, mae: 0.837765, mean_q: 1.025547\n",
            " 450306/1000000: episode: 648, duration: 52.912s, episode steps: 890, steps per second:  17, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.010932, mae: 0.849003, mean_q: 1.041053\n",
            " 451168/1000000: episode: 649, duration: 51.141s, episode steps: 862, steps per second:  17, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.010279, mae: 0.876895, mean_q: 1.076556\n",
            " 451912/1000000: episode: 650, duration: 44.692s, episode steps: 744, steps per second:  17, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.010359, mae: 0.879440, mean_q: 1.078365\n",
            " 452555/1000000: episode: 651, duration: 38.502s, episode steps: 643, steps per second:  17, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.010341, mae: 0.877517, mean_q: 1.075959\n",
            " 453186/1000000: episode: 652, duration: 37.414s, episode steps: 631, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.011337, mae: 0.873075, mean_q: 1.070254\n",
            " 453523/1000000: episode: 653, duration: 20.153s, episode steps: 337, steps per second:  17, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.011409, mae: 0.884837, mean_q: 1.085484\n",
            " 454107/1000000: episode: 654, duration: 35.285s, episode steps: 584, steps per second:  17, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.009918, mae: 0.858816, mean_q: 1.053741\n",
            " 454760/1000000: episode: 655, duration: 40.244s, episode steps: 653, steps per second:  16, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.009893, mae: 0.866303, mean_q: 1.063377\n",
            " 455184/1000000: episode: 656, duration: 25.565s, episode steps: 424, steps per second:  17, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.009775, mae: 0.855434, mean_q: 1.050987\n",
            " 455555/1000000: episode: 657, duration: 21.975s, episode steps: 371, steps per second:  17, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.011654, mae: 0.877767, mean_q: 1.076865\n",
            " 455955/1000000: episode: 658, duration: 23.716s, episode steps: 400, steps per second:  17, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.010805, mae: 0.870011, mean_q: 1.070188\n",
            " 456401/1000000: episode: 659, duration: 26.502s, episode steps: 446, steps per second:  17, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.010942, mae: 0.862116, mean_q: 1.057309\n",
            " 457088/1000000: episode: 660, duration: 41.629s, episode steps: 687, steps per second:  17, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.010031, mae: 0.855840, mean_q: 1.049361\n",
            " 457623/1000000: episode: 661, duration: 32.389s, episode steps: 535, steps per second:  17, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.010995, mae: 0.869969, mean_q: 1.066000\n",
            " 458471/1000000: episode: 662, duration: 51.058s, episode steps: 848, steps per second:  17, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.011368, mae: 0.874925, mean_q: 1.072663\n",
            " 459096/1000000: episode: 663, duration: 37.542s, episode steps: 625, steps per second:  17, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.010745, mae: 0.865775, mean_q: 1.063571\n",
            " 459821/1000000: episode: 664, duration: 42.785s, episode steps: 725, steps per second:  17, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.011525, mae: 0.866864, mean_q: 1.062230\n",
            " 460484/1000000: episode: 665, duration: 38.998s, episode steps: 663, steps per second:  17, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.009896, mae: 0.878648, mean_q: 1.078506\n",
            " 461290/1000000: episode: 666, duration: 47.487s, episode steps: 806, steps per second:  17, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.010671, mae: 0.872857, mean_q: 1.067884\n",
            " 462064/1000000: episode: 667, duration: 45.520s, episode steps: 774, steps per second:  17, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.010550, mae: 0.878488, mean_q: 1.075199\n",
            " 462844/1000000: episode: 668, duration: 45.944s, episode steps: 780, steps per second:  17, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.009646, mae: 0.863665, mean_q: 1.059159\n",
            " 463376/1000000: episode: 669, duration: 31.513s, episode steps: 532, steps per second:  17, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.011256, mae: 0.877730, mean_q: 1.076226\n",
            " 464156/1000000: episode: 670, duration: 46.394s, episode steps: 780, steps per second:  17, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.010762, mae: 0.870905, mean_q: 1.066597\n",
            " 465040/1000000: episode: 671, duration: 52.907s, episode steps: 884, steps per second:  17, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.011201, mae: 0.872225, mean_q: 1.067565\n",
            " 465778/1000000: episode: 672, duration: 44.201s, episode steps: 738, steps per second:  17, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.011636, mae: 0.873189, mean_q: 1.069655\n",
            " 466419/1000000: episode: 673, duration: 38.549s, episode steps: 641, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.012027, mae: 0.895915, mean_q: 1.096133\n",
            " 467215/1000000: episode: 674, duration: 47.697s, episode steps: 796, steps per second:  17, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.010996, mae: 0.873958, mean_q: 1.070822\n",
            " 467698/1000000: episode: 675, duration: 28.673s, episode steps: 483, steps per second:  17, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.011619, mae: 0.871300, mean_q: 1.070099\n",
            " 468560/1000000: episode: 676, duration: 50.303s, episode steps: 862, steps per second:  17, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.011972, mae: 0.886314, mean_q: 1.086442\n",
            " 469411/1000000: episode: 677, duration: 50.199s, episode steps: 851, steps per second:  17, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.010520, mae: 0.868114, mean_q: 1.065034\n",
            " 470704/1000000: episode: 678, duration: 76.094s, episode steps: 1293, steps per second:  17, episode reward: 14.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.010342, mae: 0.882534, mean_q: 1.082582\n",
            " 471266/1000000: episode: 679, duration: 33.276s, episode steps: 562, steps per second:  17, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.010411, mae: 0.897857, mean_q: 1.103786\n",
            " 471886/1000000: episode: 680, duration: 36.855s, episode steps: 620, steps per second:  17, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.011824, mae: 0.898373, mean_q: 1.100453\n",
            " 472539/1000000: episode: 681, duration: 39.065s, episode steps: 653, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.011746, mae: 0.900856, mean_q: 1.104354\n",
            " 473530/1000000: episode: 682, duration: 59.383s, episode steps: 991, steps per second:  17, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.011699, mae: 0.898167, mean_q: 1.100063\n",
            " 474082/1000000: episode: 683, duration: 33.133s, episode steps: 552, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.012893, mae: 0.899990, mean_q: 1.101933\n",
            " 474984/1000000: episode: 684, duration: 54.736s, episode steps: 902, steps per second:  16, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.012082, mae: 0.902788, mean_q: 1.103267\n",
            " 475621/1000000: episode: 685, duration: 38.304s, episode steps: 637, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.011758, mae: 0.908959, mean_q: 1.112024\n",
            " 476060/1000000: episode: 686, duration: 26.369s, episode steps: 439, steps per second:  17, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.010894, mae: 0.888315, mean_q: 1.088864\n",
            " 476586/1000000: episode: 687, duration: 31.895s, episode steps: 526, steps per second:  16, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.012081, mae: 0.907428, mean_q: 1.110676\n",
            " 477515/1000000: episode: 688, duration: 55.500s, episode steps: 929, steps per second:  17, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.011227, mae: 0.896220, mean_q: 1.098928\n",
            " 478265/1000000: episode: 689, duration: 45.244s, episode steps: 750, steps per second:  17, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.012285, mae: 0.883042, mean_q: 1.081594\n",
            " 478661/1000000: episode: 690, duration: 23.644s, episode steps: 396, steps per second:  17, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.012310, mae: 0.895064, mean_q: 1.095075\n",
            " 479052/1000000: episode: 691, duration: 23.269s, episode steps: 391, steps per second:  17, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.013897, mae: 0.901663, mean_q: 1.103952\n",
            " 479766/1000000: episode: 692, duration: 42.685s, episode steps: 714, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.011109, mae: 0.902448, mean_q: 1.104997\n",
            " 480347/1000000: episode: 693, duration: 34.877s, episode steps: 581, steps per second:  17, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.011246, mae: 0.911874, mean_q: 1.118556\n",
            " 480983/1000000: episode: 694, duration: 38.170s, episode steps: 636, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.012681, mae: 0.929979, mean_q: 1.141765\n",
            " 481743/1000000: episode: 695, duration: 45.167s, episode steps: 760, steps per second:  17, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.012446, mae: 0.925325, mean_q: 1.134133\n",
            " 482533/1000000: episode: 696, duration: 47.351s, episode steps: 790, steps per second:  17, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.011085, mae: 0.917496, mean_q: 1.124501\n",
            " 482947/1000000: episode: 697, duration: 25.015s, episode steps: 414, steps per second:  17, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.010202, mae: 0.914384, mean_q: 1.120123\n",
            " 483482/1000000: episode: 698, duration: 32.376s, episode steps: 535, steps per second:  17, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.011360, mae: 0.914462, mean_q: 1.120225\n",
            " 484020/1000000: episode: 699, duration: 32.816s, episode steps: 538, steps per second:  16, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.011433, mae: 0.919956, mean_q: 1.128717\n",
            " 485187/1000000: episode: 700, duration: 71.152s, episode steps: 1167, steps per second:  16, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.011314, mae: 0.915862, mean_q: 1.120887\n",
            " 485701/1000000: episode: 701, duration: 31.421s, episode steps: 514, steps per second:  16, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.010794, mae: 0.927984, mean_q: 1.136790\n",
            " 486450/1000000: episode: 702, duration: 45.573s, episode steps: 749, steps per second:  16, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.011742, mae: 0.926574, mean_q: 1.135387\n",
            " 486992/1000000: episode: 703, duration: 32.992s, episode steps: 542, steps per second:  16, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.010576, mae: 0.922310, mean_q: 1.129256\n",
            " 487734/1000000: episode: 704, duration: 45.350s, episode steps: 742, steps per second:  16, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.010428, mae: 0.914964, mean_q: 1.120228\n",
            " 488394/1000000: episode: 705, duration: 40.300s, episode steps: 660, steps per second:  16, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.010017, mae: 0.921310, mean_q: 1.129265\n",
            " 489013/1000000: episode: 706, duration: 37.867s, episode steps: 619, steps per second:  16, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.011484, mae: 0.938311, mean_q: 1.148047\n",
            " 489545/1000000: episode: 707, duration: 32.485s, episode steps: 532, steps per second:  16, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.011729, mae: 0.918683, mean_q: 1.122852\n",
            " 490223/1000000: episode: 708, duration: 41.607s, episode steps: 678, steps per second:  16, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.010864, mae: 0.930996, mean_q: 1.137638\n",
            " 490905/1000000: episode: 709, duration: 41.661s, episode steps: 682, steps per second:  16, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.010951, mae: 0.943635, mean_q: 1.153755\n",
            " 491453/1000000: episode: 710, duration: 33.487s, episode steps: 548, steps per second:  16, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.011048, mae: 0.945832, mean_q: 1.156084\n",
            " 492238/1000000: episode: 711, duration: 47.763s, episode steps: 785, steps per second:  16, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.011486, mae: 0.945611, mean_q: 1.157454\n",
            " 492900/1000000: episode: 712, duration: 40.071s, episode steps: 662, steps per second:  17, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.012135, mae: 0.965382, mean_q: 1.180292\n",
            " 493524/1000000: episode: 713, duration: 38.248s, episode steps: 624, steps per second:  16, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.010913, mae: 0.937365, mean_q: 1.147221\n",
            " 493913/1000000: episode: 714, duration: 23.782s, episode steps: 389, steps per second:  16, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.010787, mae: 0.954526, mean_q: 1.169547\n",
            " 494374/1000000: episode: 715, duration: 28.122s, episode steps: 461, steps per second:  16, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.011826, mae: 0.930639, mean_q: 1.140366\n",
            " 494917/1000000: episode: 716, duration: 33.458s, episode steps: 543, steps per second:  16, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.011073, mae: 0.935707, mean_q: 1.146043\n",
            " 495919/1000000: episode: 717, duration: 61.517s, episode steps: 1002, steps per second:  16, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.011969, mae: 0.945448, mean_q: 1.157455\n",
            " 496627/1000000: episode: 718, duration: 43.282s, episode steps: 708, steps per second:  16, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.012052, mae: 0.947100, mean_q: 1.159324\n",
            " 497343/1000000: episode: 719, duration: 43.363s, episode steps: 716, steps per second:  17, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.011451, mae: 0.945886, mean_q: 1.159812\n",
            " 497758/1000000: episode: 720, duration: 25.173s, episode steps: 415, steps per second:  16, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.011463, mae: 0.965175, mean_q: 1.181903\n",
            " 498178/1000000: episode: 721, duration: 25.478s, episode steps: 420, steps per second:  16, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.009704, mae: 0.928081, mean_q: 1.137050\n",
            " 498809/1000000: episode: 722, duration: 38.888s, episode steps: 631, steps per second:  16, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.011423, mae: 0.956617, mean_q: 1.171656\n",
            " 499615/1000000: episode: 723, duration: 49.425s, episode steps: 806, steps per second:  16, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.010366, mae: 0.926379, mean_q: 1.135820\n",
            " 500398/1000000: episode: 724, duration: 48.285s, episode steps: 783, steps per second:  16, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.009353, mae: 0.948890, mean_q: 1.162147\n",
            " 501181/1000000: episode: 725, duration: 48.398s, episode steps: 783, steps per second:  16, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.010982, mae: 0.986914, mean_q: 1.206446\n",
            " 501813/1000000: episode: 726, duration: 38.709s, episode steps: 632, steps per second:  16, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.009934, mae: 0.963975, mean_q: 1.178703\n",
            " 502354/1000000: episode: 727, duration: 32.912s, episode steps: 541, steps per second:  16, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.012690, mae: 0.991025, mean_q: 1.210275\n",
            " 503104/1000000: episode: 728, duration: 45.674s, episode steps: 750, steps per second:  16, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.010709, mae: 0.977562, mean_q: 1.192067\n",
            " 503923/1000000: episode: 729, duration: 50.393s, episode steps: 819, steps per second:  16, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.010362, mae: 0.971094, mean_q: 1.183651\n",
            " 504424/1000000: episode: 730, duration: 30.935s, episode steps: 501, steps per second:  16, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.011580, mae: 0.973438, mean_q: 1.187238\n",
            " 504813/1000000: episode: 731, duration: 24.011s, episode steps: 389, steps per second:  16, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.011344, mae: 0.988844, mean_q: 1.206709\n",
            " 505458/1000000: episode: 732, duration: 39.258s, episode steps: 645, steps per second:  16, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.011066, mae: 0.964779, mean_q: 1.177377\n",
            " 506042/1000000: episode: 733, duration: 35.762s, episode steps: 584, steps per second:  16, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.011387, mae: 0.971812, mean_q: 1.188362\n",
            " 507231/1000000: episode: 734, duration: 72.795s, episode steps: 1189, steps per second:  16, episode reward:  8.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.011588, mae: 0.977135, mean_q: 1.195440\n",
            " 507612/1000000: episode: 735, duration: 23.517s, episode steps: 381, steps per second:  16, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.011975, mae: 0.972433, mean_q: 1.187222\n",
            " 508208/1000000: episode: 736, duration: 36.835s, episode steps: 596, steps per second:  16, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.011398, mae: 0.972870, mean_q: 1.188553\n",
            " 509108/1000000: episode: 737, duration: 55.487s, episode steps: 900, steps per second:  16, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.011669, mae: 0.978458, mean_q: 1.195349\n",
            " 509721/1000000: episode: 738, duration: 37.617s, episode steps: 613, steps per second:  16, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.012800, mae: 0.983830, mean_q: 1.201983\n",
            " 510317/1000000: episode: 739, duration: 36.502s, episode steps: 596, steps per second:  16, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.010318, mae: 0.989349, mean_q: 1.211693\n",
            " 510823/1000000: episode: 740, duration: 31.078s, episode steps: 506, steps per second:  16, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.011443, mae: 1.020086, mean_q: 1.246457\n",
            " 511472/1000000: episode: 741, duration: 39.880s, episode steps: 649, steps per second:  16, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.010541, mae: 0.997632, mean_q: 1.217937\n",
            " 512287/1000000: episode: 742, duration: 49.905s, episode steps: 815, steps per second:  16, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.011172, mae: 1.009579, mean_q: 1.235604\n",
            " 513021/1000000: episode: 743, duration: 45.007s, episode steps: 734, steps per second:  16, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.011192, mae: 0.983507, mean_q: 1.202702\n",
            " 513588/1000000: episode: 744, duration: 34.813s, episode steps: 567, steps per second:  16, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.011588, mae: 0.993669, mean_q: 1.214765\n",
            " 514328/1000000: episode: 745, duration: 45.207s, episode steps: 740, steps per second:  16, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.010677, mae: 0.991411, mean_q: 1.211519\n",
            " 515013/1000000: episode: 746, duration: 41.982s, episode steps: 685, steps per second:  16, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.011769, mae: 0.981475, mean_q: 1.199486\n",
            " 516062/1000000: episode: 747, duration: 64.054s, episode steps: 1049, steps per second:  16, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.012007, mae: 0.994921, mean_q: 1.212201\n",
            " 516591/1000000: episode: 748, duration: 32.391s, episode steps: 529, steps per second:  16, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.013127, mae: 1.006961, mean_q: 1.229920\n",
            " 517011/1000000: episode: 749, duration: 25.727s, episode steps: 420, steps per second:  16, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.010439, mae: 1.005797, mean_q: 1.232075\n",
            " 517566/1000000: episode: 750, duration: 33.891s, episode steps: 555, steps per second:  16, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.011396, mae: 0.994050, mean_q: 1.215425\n",
            " 518511/1000000: episode: 751, duration: 56.952s, episode steps: 945, steps per second:  17, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.011227, mae: 0.985607, mean_q: 1.203299\n",
            " 519050/1000000: episode: 752, duration: 32.902s, episode steps: 539, steps per second:  16, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.012206, mae: 0.993641, mean_q: 1.214592\n",
            " 519448/1000000: episode: 753, duration: 24.373s, episode steps: 398, steps per second:  16, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.012138, mae: 0.999904, mean_q: 1.221377\n",
            " 520231/1000000: episode: 754, duration: 47.553s, episode steps: 783, steps per second:  16, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.010594, mae: 1.001695, mean_q: 1.222145\n",
            " 521487/1000000: episode: 755, duration: 76.372s, episode steps: 1256, steps per second:  16, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.011871, mae: 1.024015, mean_q: 1.250241\n",
            " 522411/1000000: episode: 756, duration: 56.190s, episode steps: 924, steps per second:  16, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.011153, mae: 1.016496, mean_q: 1.241259\n",
            " 523067/1000000: episode: 757, duration: 39.989s, episode steps: 656, steps per second:  16, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.011600, mae: 1.014556, mean_q: 1.238665\n",
            " 524054/1000000: episode: 758, duration: 59.609s, episode steps: 987, steps per second:  17, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.011086, mae: 1.015022, mean_q: 1.239663\n",
            " 524687/1000000: episode: 759, duration: 38.136s, episode steps: 633, steps per second:  17, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.011353, mae: 1.021922, mean_q: 1.252883\n",
            " 525395/1000000: episode: 760, duration: 42.906s, episode steps: 708, steps per second:  17, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.011965, mae: 1.013774, mean_q: 1.236293\n",
            " 526069/1000000: episode: 761, duration: 41.241s, episode steps: 674, steps per second:  16, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.011485, mae: 1.012929, mean_q: 1.235107\n",
            " 526532/1000000: episode: 762, duration: 28.015s, episode steps: 463, steps per second:  17, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.011182, mae: 1.014743, mean_q: 1.237514\n",
            " 526927/1000000: episode: 763, duration: 23.554s, episode steps: 395, steps per second:  17, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.012211, mae: 1.009248, mean_q: 1.231657\n",
            " 527505/1000000: episode: 764, duration: 34.717s, episode steps: 578, steps per second:  17, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.010949, mae: 1.006822, mean_q: 1.228579\n",
            " 528130/1000000: episode: 765, duration: 37.647s, episode steps: 625, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.011025, mae: 1.026710, mean_q: 1.255085\n",
            " 528626/1000000: episode: 766, duration: 29.713s, episode steps: 496, steps per second:  17, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.010536, mae: 1.018949, mean_q: 1.245031\n",
            " 529167/1000000: episode: 767, duration: 32.380s, episode steps: 541, steps per second:  17, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.010145, mae: 0.993863, mean_q: 1.213192\n",
            " 529617/1000000: episode: 768, duration: 27.258s, episode steps: 450, steps per second:  17, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.010043, mae: 1.017979, mean_q: 1.243869\n",
            " 530473/1000000: episode: 769, duration: 51.754s, episode steps: 856, steps per second:  17, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.011185, mae: 1.022377, mean_q: 1.246701\n",
            " 531109/1000000: episode: 770, duration: 38.620s, episode steps: 636, steps per second:  16, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.011400, mae: 1.043422, mean_q: 1.273332\n",
            " 531781/1000000: episode: 771, duration: 40.193s, episode steps: 672, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.010927, mae: 1.039631, mean_q: 1.269628\n",
            " 532744/1000000: episode: 772, duration: 58.117s, episode steps: 963, steps per second:  17, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.012223, mae: 1.031885, mean_q: 1.260396\n",
            " 533614/1000000: episode: 773, duration: 52.296s, episode steps: 870, steps per second:  17, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.011503, mae: 1.046031, mean_q: 1.276835\n",
            " 534110/1000000: episode: 774, duration: 29.507s, episode steps: 496, steps per second:  17, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.013307, mae: 1.040601, mean_q: 1.270228\n",
            " 534968/1000000: episode: 775, duration: 51.132s, episode steps: 858, steps per second:  17, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.011671, mae: 1.026114, mean_q: 1.251406\n",
            " 535671/1000000: episode: 776, duration: 42.157s, episode steps: 703, steps per second:  17, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.011464, mae: 1.029189, mean_q: 1.255980\n",
            " 536062/1000000: episode: 777, duration: 23.421s, episode steps: 391, steps per second:  17, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.012342, mae: 1.046413, mean_q: 1.277167\n",
            " 536635/1000000: episode: 778, duration: 34.042s, episode steps: 573, steps per second:  17, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.011942, mae: 1.034576, mean_q: 1.262966\n",
            " 537294/1000000: episode: 779, duration: 39.236s, episode steps: 659, steps per second:  17, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.011696, mae: 1.048847, mean_q: 1.280015\n",
            " 537797/1000000: episode: 780, duration: 30.153s, episode steps: 503, steps per second:  17, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.010515, mae: 1.039228, mean_q: 1.268634\n",
            " 538188/1000000: episode: 781, duration: 23.472s, episode steps: 391, steps per second:  17, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.010972, mae: 1.019608, mean_q: 1.244993\n",
            " 539021/1000000: episode: 782, duration: 50.033s, episode steps: 833, steps per second:  17, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.011808, mae: 1.038517, mean_q: 1.267291\n",
            " 539627/1000000: episode: 783, duration: 35.972s, episode steps: 606, steps per second:  17, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.011010, mae: 1.043866, mean_q: 1.273981\n",
            " 540531/1000000: episode: 784, duration: 52.806s, episode steps: 904, steps per second:  17, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.011411, mae: 1.046712, mean_q: 1.278101\n",
            " 541341/1000000: episode: 785, duration: 47.124s, episode steps: 810, steps per second:  17, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.011166, mae: 1.045023, mean_q: 1.276272\n",
            " 542259/1000000: episode: 786, duration: 52.816s, episode steps: 918, steps per second:  17, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.013321, mae: 1.054509, mean_q: 1.287106\n",
            " 542947/1000000: episode: 787, duration: 39.872s, episode steps: 688, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.013646, mae: 1.063033, mean_q: 1.297363\n",
            " 543810/1000000: episode: 788, duration: 49.892s, episode steps: 863, steps per second:  17, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.011873, mae: 1.060957, mean_q: 1.294956\n",
            " 544488/1000000: episode: 789, duration: 39.622s, episode steps: 678, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.012158, mae: 1.056882, mean_q: 1.289975\n",
            " 544893/1000000: episode: 790, duration: 23.797s, episode steps: 405, steps per second:  17, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.011665, mae: 1.041949, mean_q: 1.270966\n",
            " 545629/1000000: episode: 791, duration: 42.436s, episode steps: 736, steps per second:  17, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.013235, mae: 1.049473, mean_q: 1.281373\n",
            " 546498/1000000: episode: 792, duration: 49.484s, episode steps: 869, steps per second:  18, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.011376, mae: 1.039459, mean_q: 1.269654\n",
            " 547129/1000000: episode: 793, duration: 36.073s, episode steps: 631, steps per second:  17, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.012840, mae: 1.043163, mean_q: 1.271729\n",
            " 547534/1000000: episode: 794, duration: 23.209s, episode steps: 405, steps per second:  17, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.012306, mae: 1.064133, mean_q: 1.299751\n",
            " 548204/1000000: episode: 795, duration: 39.424s, episode steps: 670, steps per second:  17, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.011792, mae: 1.038893, mean_q: 1.270177\n",
            " 548802/1000000: episode: 796, duration: 35.434s, episode steps: 598, steps per second:  17, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.013708, mae: 1.068680, mean_q: 1.306480\n",
            " 549838/1000000: episode: 797, duration: 61.444s, episode steps: 1036, steps per second:  17, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.013707, mae: 1.058745, mean_q: 1.294379\n",
            " 550758/1000000: episode: 798, duration: 54.581s, episode steps: 920, steps per second:  17, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.012294, mae: 1.090598, mean_q: 1.330174\n",
            " 551450/1000000: episode: 799, duration: 41.171s, episode steps: 692, steps per second:  17, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.012233, mae: 1.083593, mean_q: 1.323780\n",
            " 551896/1000000: episode: 800, duration: 26.787s, episode steps: 446, steps per second:  17, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.011422, mae: 1.093532, mean_q: 1.335124\n",
            " 552817/1000000: episode: 801, duration: 54.902s, episode steps: 921, steps per second:  17, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.013129, mae: 1.096426, mean_q: 1.341439\n",
            " 553529/1000000: episode: 802, duration: 42.510s, episode steps: 712, steps per second:  17, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.013262, mae: 1.091623, mean_q: 1.334572\n",
            " 554161/1000000: episode: 803, duration: 37.619s, episode steps: 632, steps per second:  17, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.011744, mae: 1.083979, mean_q: 1.323002\n",
            " 554917/1000000: episode: 804, duration: 44.985s, episode steps: 756, steps per second:  17, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.012101, mae: 1.085125, mean_q: 1.325498\n",
            " 555627/1000000: episode: 805, duration: 41.923s, episode steps: 710, steps per second:  17, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.011329, mae: 1.082575, mean_q: 1.322680\n",
            " 556024/1000000: episode: 806, duration: 23.790s, episode steps: 397, steps per second:  17, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.013478, mae: 1.105497, mean_q: 1.349512\n",
            " 556690/1000000: episode: 807, duration: 39.472s, episode steps: 666, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.013164, mae: 1.081830, mean_q: 1.320193\n",
            " 557551/1000000: episode: 808, duration: 51.032s, episode steps: 861, steps per second:  17, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.013145, mae: 1.083328, mean_q: 1.322431\n",
            " 558379/1000000: episode: 809, duration: 49.456s, episode steps: 828, steps per second:  17, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.012837, mae: 1.084690, mean_q: 1.325001\n",
            " 558995/1000000: episode: 810, duration: 36.907s, episode steps: 616, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.011969, mae: 1.085625, mean_q: 1.326870\n",
            " 560038/1000000: episode: 811, duration: 62.136s, episode steps: 1043, steps per second:  17, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.011981, mae: 1.092887, mean_q: 1.334903\n",
            " 560430/1000000: episode: 812, duration: 23.211s, episode steps: 392, steps per second:  17, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.013271, mae: 1.139012, mean_q: 1.390425\n",
            " 560923/1000000: episode: 813, duration: 29.309s, episode steps: 493, steps per second:  17, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.014584, mae: 1.149109, mean_q: 1.401296\n",
            " 561569/1000000: episode: 814, duration: 38.787s, episode steps: 646, steps per second:  17, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.012214, mae: 1.109621, mean_q: 1.352668\n",
            " 562238/1000000: episode: 815, duration: 39.948s, episode steps: 669, steps per second:  17, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.012548, mae: 1.137255, mean_q: 1.385681\n",
            " 563325/1000000: episode: 816, duration: 64.929s, episode steps: 1087, steps per second:  17, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.012201, mae: 1.128667, mean_q: 1.374685\n",
            " 563987/1000000: episode: 817, duration: 39.375s, episode steps: 662, steps per second:  17, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.012684, mae: 1.123971, mean_q: 1.368826\n",
            " 564539/1000000: episode: 818, duration: 32.861s, episode steps: 552, steps per second:  17, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.012082, mae: 1.125137, mean_q: 1.371438\n",
            " 565194/1000000: episode: 819, duration: 39.278s, episode steps: 655, steps per second:  17, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.012963, mae: 1.117535, mean_q: 1.363508\n",
            " 565997/1000000: episode: 820, duration: 48.152s, episode steps: 803, steps per second:  17, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.013362, mae: 1.129489, mean_q: 1.377579\n",
            " 566339/1000000: episode: 821, duration: 20.298s, episode steps: 342, steps per second:  17, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.013087, mae: 1.104860, mean_q: 1.346911\n",
            " 566940/1000000: episode: 822, duration: 36.102s, episode steps: 601, steps per second:  17, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.013251, mae: 1.127836, mean_q: 1.373187\n",
            " 567655/1000000: episode: 823, duration: 42.924s, episode steps: 715, steps per second:  17, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.013218, mae: 1.119042, mean_q: 1.365509\n",
            " 568322/1000000: episode: 824, duration: 40.019s, episode steps: 667, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.013342, mae: 1.123046, mean_q: 1.371402\n",
            " 568689/1000000: episode: 825, duration: 21.881s, episode steps: 367, steps per second:  17, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.011974, mae: 1.115970, mean_q: 1.360856\n",
            " 569740/1000000: episode: 826, duration: 62.757s, episode steps: 1051, steps per second:  17, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.011691, mae: 1.118692, mean_q: 1.364843\n",
            " 570449/1000000: episode: 827, duration: 42.368s, episode steps: 709, steps per second:  17, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.013640, mae: 1.141677, mean_q: 1.393869\n",
            " 570971/1000000: episode: 828, duration: 31.214s, episode steps: 522, steps per second:  17, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.012410, mae: 1.160627, mean_q: 1.415662\n",
            " 571915/1000000: episode: 829, duration: 57.765s, episode steps: 944, steps per second:  16, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.013879, mae: 1.171836, mean_q: 1.428467\n",
            " 572587/1000000: episode: 830, duration: 40.715s, episode steps: 672, steps per second:  17, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.013935, mae: 1.175109, mean_q: 1.433520\n",
            " 573293/1000000: episode: 831, duration: 43.412s, episode steps: 706, steps per second:  16, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.013312, mae: 1.145361, mean_q: 1.396574\n",
            " 573698/1000000: episode: 832, duration: 24.823s, episode steps: 405, steps per second:  16, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.012633, mae: 1.162340, mean_q: 1.419483\n",
            " 574076/1000000: episode: 833, duration: 23.302s, episode steps: 378, steps per second:  16, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.013583, mae: 1.148215, mean_q: 1.400912\n",
            " 574795/1000000: episode: 834, duration: 43.587s, episode steps: 719, steps per second:  16, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.013610, mae: 1.162047, mean_q: 1.418902\n",
            " 575496/1000000: episode: 835, duration: 42.653s, episode steps: 701, steps per second:  16, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.013517, mae: 1.160656, mean_q: 1.416924\n",
            " 575986/1000000: episode: 836, duration: 30.495s, episode steps: 490, steps per second:  16, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.012562, mae: 1.155107, mean_q: 1.408148\n",
            " 576634/1000000: episode: 837, duration: 39.803s, episode steps: 648, steps per second:  16, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.016150, mae: 1.166908, mean_q: 1.420071\n",
            " 577519/1000000: episode: 838, duration: 53.963s, episode steps: 885, steps per second:  16, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.014059, mae: 1.160534, mean_q: 1.415767\n",
            " 577916/1000000: episode: 839, duration: 24.331s, episode steps: 397, steps per second:  16, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.013101, mae: 1.152383, mean_q: 1.406537\n",
            " 578604/1000000: episode: 840, duration: 41.689s, episode steps: 688, steps per second:  17, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.012951, mae: 1.168510, mean_q: 1.423573\n",
            " 579096/1000000: episode: 841, duration: 29.735s, episode steps: 492, steps per second:  17, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.014223, mae: 1.164797, mean_q: 1.418488\n",
            " 579635/1000000: episode: 842, duration: 32.380s, episode steps: 539, steps per second:  17, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.013022, mae: 1.156078, mean_q: 1.408913\n",
            " 580001/1000000: episode: 843, duration: 22.131s, episode steps: 366, steps per second:  17, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.013707, mae: 1.180731, mean_q: 1.439407\n",
            " 580631/1000000: episode: 844, duration: 37.925s, episode steps: 630, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.012467, mae: 1.171590, mean_q: 1.429881\n",
            " 581378/1000000: episode: 845, duration: 44.604s, episode steps: 747, steps per second:  17, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.012693, mae: 1.173047, mean_q: 1.432125\n",
            " 581890/1000000: episode: 846, duration: 30.715s, episode steps: 512, steps per second:  17, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.011437, mae: 1.182833, mean_q: 1.443728\n",
            " 582433/1000000: episode: 847, duration: 32.961s, episode steps: 543, steps per second:  16, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.709 [0.000, 5.000],  loss: 0.012886, mae: 1.195055, mean_q: 1.457326\n",
            " 582935/1000000: episode: 848, duration: 30.408s, episode steps: 502, steps per second:  17, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.012590, mae: 1.192989, mean_q: 1.454000\n",
            " 583720/1000000: episode: 849, duration: 47.344s, episode steps: 785, steps per second:  17, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.013140, mae: 1.192689, mean_q: 1.453692\n",
            " 584319/1000000: episode: 850, duration: 36.343s, episode steps: 599, steps per second:  16, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.012853, mae: 1.175101, mean_q: 1.430278\n",
            " 585056/1000000: episode: 851, duration: 44.504s, episode steps: 737, steps per second:  17, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.012690, mae: 1.177206, mean_q: 1.436232\n",
            " 585693/1000000: episode: 852, duration: 38.713s, episode steps: 637, steps per second:  16, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.013755, mae: 1.178342, mean_q: 1.439064\n",
            " 586242/1000000: episode: 853, duration: 32.570s, episode steps: 549, steps per second:  17, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.013117, mae: 1.189675, mean_q: 1.451014\n",
            " 586851/1000000: episode: 854, duration: 35.741s, episode steps: 609, steps per second:  17, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.014166, mae: 1.186440, mean_q: 1.448188\n",
            " 588243/1000000: episode: 855, duration: 83.178s, episode steps: 1392, steps per second:  17, episode reward: 23.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.013225, mae: 1.171548, mean_q: 1.428421\n",
            " 588665/1000000: episode: 856, duration: 24.802s, episode steps: 422, steps per second:  17, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.013291, mae: 1.167180, mean_q: 1.424459\n",
            " 589175/1000000: episode: 857, duration: 30.004s, episode steps: 510, steps per second:  17, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.013136, mae: 1.175398, mean_q: 1.432737\n",
            " 589683/1000000: episode: 858, duration: 29.920s, episode steps: 508, steps per second:  17, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.011809, mae: 1.159405, mean_q: 1.411095\n",
            " 590519/1000000: episode: 859, duration: 50.051s, episode steps: 836, steps per second:  17, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.012794, mae: 1.195843, mean_q: 1.457391\n",
            " 591068/1000000: episode: 860, duration: 33.169s, episode steps: 549, steps per second:  17, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.012269, mae: 1.180197, mean_q: 1.436982\n",
            " 591706/1000000: episode: 861, duration: 38.385s, episode steps: 638, steps per second:  17, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.013405, mae: 1.187795, mean_q: 1.445080\n",
            " 592359/1000000: episode: 862, duration: 38.953s, episode steps: 653, steps per second:  17, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.013043, mae: 1.188639, mean_q: 1.447274\n",
            " 592762/1000000: episode: 863, duration: 24.605s, episode steps: 403, steps per second:  16, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.013468, mae: 1.201452, mean_q: 1.463691\n",
            " 593738/1000000: episode: 864, duration: 59.027s, episode steps: 976, steps per second:  17, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.013563, mae: 1.196326, mean_q: 1.458714\n",
            " 594693/1000000: episode: 865, duration: 57.462s, episode steps: 955, steps per second:  17, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.013216, mae: 1.195340, mean_q: 1.456741\n",
            " 595849/1000000: episode: 866, duration: 69.465s, episode steps: 1156, steps per second:  17, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.012992, mae: 1.178094, mean_q: 1.433908\n",
            " 596361/1000000: episode: 867, duration: 30.903s, episode steps: 512, steps per second:  17, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.013157, mae: 1.188692, mean_q: 1.445804\n",
            " 597068/1000000: episode: 868, duration: 42.807s, episode steps: 707, steps per second:  17, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.012390, mae: 1.183592, mean_q: 1.441274\n",
            "done, took 30911.684 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 16.000, steps: 929\n",
            "Episode 2: reward: 17.000, steps: 791\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3416113635.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# ==== Evaluación ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rl/core.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Select an action.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_recent_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompute_q_values\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_batch_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompute_batch_q_values\u001b[0;34m(self, state_batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_batch_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_state_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4606\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4608\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4609\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4610\u001b[0m         output_structure = tf.nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1482\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                                                run_metadata_ptr)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Permute, Lambda\n",
        "from tensorflow.keras.layers import Add, Subtract\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# ==== Constantes ====\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "\n",
        "# ==== Procesador ====\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3  # (210, 160, 3)\n",
        "        cropped = observation[34:194, 8:152]\n",
        "        img = Image.fromarray(cropped).resize(INPUT_SHAPE).convert('L')\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        averaged = 0.5 * batch[:, -1] + 0.5 * batch[:, -2]\n",
        "        batch[:, -1] = averaged\n",
        "        return batch.astype('float32') / 255.\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "# ==== Entorno ====\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "# ==== Modelo DUELING DQN ====\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "input_layer = Input(shape=input_shape)\n",
        "x = Permute((2, 3, 1))(input_layer)\n",
        "x = Conv2D(32, 8, strides=4, activation='relu')(x)\n",
        "x = Conv2D(64, 4, strides=2, activation='relu')(x)\n",
        "x = Conv2D(64, 3, strides=1, activation='relu')(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Stream for state value V(s)\n",
        "v = Dense(512, activation='relu')(x)\n",
        "v = Dense(1)(v)\n",
        "\n",
        "# Stream for advantage A(s,a)\n",
        "a = Dense(512, activation='relu')(x)\n",
        "a = Dense(nb_actions)(a)\n",
        "\n",
        "# Combine streams into Q-values: Q(s,a) = V(s) + (A(s,a) - mean(A))\n",
        "q_values = Add()([v, Lambda(lambda a: a - K.mean(a, axis=1, keepdims=True))(a)])\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=q_values)\n",
        "print(model.summary())\n",
        "\n",
        "# ==== Memoria y política ====\n",
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "policy = BoltzmannQPolicy()\n",
        "\n",
        "# ==== Agente ====\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               memory=memory,\n",
        "               processor=AtariProcessor(),\n",
        "               nb_steps_warmup=50000,\n",
        "               target_model_update=10000,\n",
        "               train_interval=4,\n",
        "               gamma=0.99,\n",
        "               policy=policy,\n",
        "               enable_double_dqn=True)\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.00025), metrics=['mae'])\n",
        "\n",
        "# ==== Callbacks ====\n",
        "checkpoint_weights_filename = 'dqn_{}_dueling_weights_{{step}}.h5f'.format(ENV_NAME)\n",
        "log_filename = 'dqn_{}_dueling_log.json'.format(ENV_NAME)\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000),\n",
        "    FileLogger(log_filename, interval=100)\n",
        "]\n",
        "\n",
        "# ==== Entrenamiento ====\n",
        "dqn.fit(env,\n",
        "        nb_steps=1000000,\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "# ==== Guardar pesos ====\n",
        "dqn.save_weights('dqn_{}_dueling_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
        "\n",
        "# ==== Evaluación ====\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "-rrzT_0yNXTo",
        "outputId": "f9f59be0-eb66-44f0-b092-82e0f959db23"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Leer los logs guardados\n",
        "with open(log_filename) as f:\n",
        "    log_data = json.load(f)\n",
        "\n",
        "# Extraer rewards y episodios\n",
        "episode_rewards = log_data['episode_reward']\n",
        "episodes = list(range(1, len(episode_rewards) + 1))  # Episodios desde 1\n",
        "\n",
        "# (Opcional) Suavizar la curva con media móvil\n",
        "def moving_average(data, window_size=10):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "smoothed_rewards = moving_average(episode_rewards, window_size=10)\n",
        "\n",
        "# Graficar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(episodes, episode_rewards, alpha=0.3, label='Reward por episodio')\n",
        "plt.plot(episodes[:len(smoothed_rewards)], smoothed_rewards, color='red', label='Media móvil (10)')\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Reward')\n",
        "plt.title('Evolución del reward durante el entrenamiento- Dueling')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sebAqjJQD0-n",
        "outputId": "6e897c02-1dbd-4554-d7d6-59d8c452645c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 250000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    420/250000: episode: 1, duration: 1.972s, episode steps: 420, steps per second: 213, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "    980/250000: episode: 2, duration: 2.419s, episode steps: 560, steps per second: 231, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1378/250000: episode: 3, duration: 1.835s, episode steps: 398, steps per second: 217, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2082/250000: episode: 4, duration: 2.991s, episode steps: 704, steps per second: 235, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2919/250000: episode: 5, duration: 3.472s, episode steps: 837, steps per second: 241, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3438/250000: episode: 6, duration: 2.200s, episode steps: 519, steps per second: 236, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4320/250000: episode: 7, duration: 3.760s, episode steps: 882, steps per second: 235, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5239/250000: episode: 8, duration: 4.175s, episode steps: 919, steps per second: 220, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5792/250000: episode: 9, duration: 2.293s, episode steps: 553, steps per second: 241, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6576/250000: episode: 10, duration: 3.267s, episode steps: 784, steps per second: 240, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7652/250000: episode: 11, duration: 4.645s, episode steps: 1076, steps per second: 232, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8311/250000: episode: 12, duration: 2.750s, episode steps: 659, steps per second: 240, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9242/250000: episode: 13, duration: 3.984s, episode steps: 931, steps per second: 234, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9756/250000: episode: 14, duration: 2.141s, episode steps: 514, steps per second: 240, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  10669/250000: episode: 15, duration: 23.581s, episode steps: 913, steps per second:  39, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.006554, mae: 0.026671, mean_q: 0.040424, mean_eps: 0.962790\n",
            "  11515/250000: episode: 16, duration: 27.458s, episode steps: 846, steps per second:  31, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.006752, mae: 0.029585, mean_q: 0.042583, mean_eps: 0.960069\n",
            "  12393/250000: episode: 17, duration: 28.883s, episode steps: 878, steps per second:  30, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.007417, mae: 0.032610, mean_q: 0.047642, mean_eps: 0.956966\n",
            "  13345/250000: episode: 18, duration: 30.809s, episode steps: 952, steps per second:  31, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.006727, mae: 0.032587, mean_q: 0.045900, mean_eps: 0.953668\n",
            "  14042/250000: episode: 19, duration: 22.636s, episode steps: 697, steps per second:  31, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.008615, mae: 0.036034, mean_q: 0.050514, mean_eps: 0.950702\n",
            "  14441/250000: episode: 20, duration: 13.109s, episode steps: 399, steps per second:  30, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.006199, mae: 0.026410, mean_q: 0.041829, mean_eps: 0.948729\n",
            "  14839/250000: episode: 21, duration: 13.070s, episode steps: 398, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.005584, mae: 0.031025, mean_q: 0.044741, mean_eps: 0.947296\n",
            "  15444/250000: episode: 22, duration: 20.124s, episode steps: 605, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.007008, mae: 0.027408, mean_q: 0.041185, mean_eps: 0.945496\n",
            "  16736/250000: episode: 23, duration: 42.505s, episode steps: 1292, steps per second:  30, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007409, mae: 0.031191, mean_q: 0.045247, mean_eps: 0.942083\n",
            "  18027/250000: episode: 24, duration: 42.471s, episode steps: 1291, steps per second:  30, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006396, mae: 0.031600, mean_q: 0.045719, mean_eps: 0.937432\n",
            "  18672/250000: episode: 25, duration: 21.652s, episode steps: 645, steps per second:  30, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.007376, mae: 0.033842, mean_q: 0.050343, mean_eps: 0.933947\n",
            "  19348/250000: episode: 26, duration: 22.654s, episode steps: 676, steps per second:  30, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.008004, mae: 0.033854, mean_q: 0.053201, mean_eps: 0.931571\n",
            "  19946/250000: episode: 27, duration: 19.729s, episode steps: 598, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.006615, mae: 0.032690, mean_q: 0.051676, mean_eps: 0.929274\n",
            "  20556/250000: episode: 28, duration: 20.194s, episode steps: 610, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.007587, mae: 0.059645, mean_q: 0.084335, mean_eps: 0.927100\n",
            "  21768/250000: episode: 29, duration: 40.247s, episode steps: 1212, steps per second:  30, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.006231, mae: 0.055098, mean_q: 0.079092, mean_eps: 0.923824\n",
            "  22173/250000: episode: 30, duration: 13.451s, episode steps: 405, steps per second:  30, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.008072, mae: 0.055795, mean_q: 0.079918, mean_eps: 0.920908\n",
            "  22852/250000: episode: 31, duration: 22.562s, episode steps: 679, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.006606, mae: 0.054971, mean_q: 0.076258, mean_eps: 0.918957\n",
            "  23562/250000: episode: 32, duration: 23.709s, episode steps: 710, steps per second:  30, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.007300, mae: 0.058840, mean_q: 0.084679, mean_eps: 0.916458\n",
            "  24220/250000: episode: 33, duration: 21.830s, episode steps: 658, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.007158, mae: 0.055964, mean_q: 0.079787, mean_eps: 0.913996\n",
            "  24978/250000: episode: 34, duration: 25.141s, episode steps: 758, steps per second:  30, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.005713, mae: 0.055870, mean_q: 0.081410, mean_eps: 0.911447\n",
            "  25867/250000: episode: 35, duration: 29.279s, episode steps: 889, steps per second:  30, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006893, mae: 0.055600, mean_q: 0.080371, mean_eps: 0.908481\n",
            "  26721/250000: episode: 36, duration: 28.780s, episode steps: 854, steps per second:  30, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.007055, mae: 0.054088, mean_q: 0.081715, mean_eps: 0.905342\n",
            "  27234/250000: episode: 37, duration: 16.823s, episode steps: 513, steps per second:  30, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.007220, mae: 0.058987, mean_q: 0.087909, mean_eps: 0.902879\n",
            "  27909/250000: episode: 38, duration: 22.279s, episode steps: 675, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.007042, mae: 0.056430, mean_q: 0.079736, mean_eps: 0.900741\n",
            "  28663/250000: episode: 39, duration: 24.582s, episode steps: 754, steps per second:  31, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.005720, mae: 0.051266, mean_q: 0.075231, mean_eps: 0.898170\n",
            "  29262/250000: episode: 40, duration: 19.533s, episode steps: 599, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.006465, mae: 0.059524, mean_q: 0.091715, mean_eps: 0.895737\n",
            "  30029/250000: episode: 41, duration: 24.999s, episode steps: 767, steps per second:  31, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.006123, mae: 0.055823, mean_q: 0.081723, mean_eps: 0.893274\n",
            "  30665/250000: episode: 42, duration: 20.513s, episode steps: 636, steps per second:  31, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.008395, mae: 0.090229, mean_q: 0.126909, mean_eps: 0.890747\n",
            "  31346/250000: episode: 43, duration: 22.299s, episode steps: 681, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007193, mae: 0.083164, mean_q: 0.118789, mean_eps: 0.888378\n",
            "  32026/250000: episode: 44, duration: 22.233s, episode steps: 680, steps per second:  31, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: 0.005964, mae: 0.076178, mean_q: 0.109947, mean_eps: 0.885930\n",
            "  33709/250000: episode: 45, duration: 54.774s, episode steps: 1683, steps per second:  31, episode reward: 23.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.006169, mae: 0.079202, mean_q: 0.109528, mean_eps: 0.881675\n",
            "  34545/250000: episode: 46, duration: 27.655s, episode steps: 836, steps per second:  30, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.006042, mae: 0.079579, mean_q: 0.112422, mean_eps: 0.877139\n",
            "  35034/250000: episode: 47, duration: 16.032s, episode steps: 489, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: 0.005250, mae: 0.076370, mean_q: 0.109727, mean_eps: 0.874756\n",
            "  35807/250000: episode: 48, duration: 25.448s, episode steps: 773, steps per second:  30, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.006460, mae: 0.078809, mean_q: 0.109903, mean_eps: 0.872488\n",
            "  36451/250000: episode: 49, duration: 21.052s, episode steps: 644, steps per second:  31, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.006976, mae: 0.078843, mean_q: 0.107584, mean_eps: 0.869939\n",
            "  37163/250000: episode: 50, duration: 23.572s, episode steps: 712, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.006605, mae: 0.079574, mean_q: 0.111930, mean_eps: 0.867498\n",
            "  37587/250000: episode: 51, duration: 13.784s, episode steps: 424, steps per second:  31, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.008269, mae: 0.079929, mean_q: 0.117211, mean_eps: 0.865454\n",
            "  38146/250000: episode: 52, duration: 18.451s, episode steps: 559, steps per second:  30, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.005812, mae: 0.072957, mean_q: 0.102600, mean_eps: 0.863682\n",
            "  38821/250000: episode: 53, duration: 22.470s, episode steps: 675, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.006295, mae: 0.077115, mean_q: 0.106914, mean_eps: 0.861458\n",
            "  39471/250000: episode: 54, duration: 21.541s, episode steps: 650, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.005545, mae: 0.075042, mean_q: 0.105154, mean_eps: 0.859074\n",
            "  40309/250000: episode: 55, duration: 27.749s, episode steps: 838, steps per second:  30, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006766, mae: 0.086269, mean_q: 0.120366, mean_eps: 0.856396\n",
            "  41444/250000: episode: 56, duration: 37.048s, episode steps: 1135, steps per second:  31, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.007837, mae: 0.106676, mean_q: 0.145799, mean_eps: 0.852846\n",
            "  42352/250000: episode: 57, duration: 30.122s, episode steps: 908, steps per second:  30, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.006664, mae: 0.100309, mean_q: 0.133319, mean_eps: 0.849174\n",
            "  43281/250000: episode: 58, duration: 30.704s, episode steps: 929, steps per second:  30, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.005977, mae: 0.096896, mean_q: 0.128381, mean_eps: 0.845862\n",
            "  44036/250000: episode: 59, duration: 24.949s, episode steps: 755, steps per second:  30, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.006137, mae: 0.099201, mean_q: 0.131593, mean_eps: 0.842831\n",
            "  44520/250000: episode: 60, duration: 16.255s, episode steps: 484, steps per second:  30, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.005364, mae: 0.100095, mean_q: 0.134434, mean_eps: 0.840606\n",
            "  45517/250000: episode: 61, duration: 32.814s, episode steps: 997, steps per second:  30, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.007054, mae: 0.103292, mean_q: 0.135934, mean_eps: 0.837935\n",
            "  46154/250000: episode: 62, duration: 21.019s, episode steps: 637, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.005910, mae: 0.099819, mean_q: 0.133883, mean_eps: 0.834990\n",
            "  46858/250000: episode: 63, duration: 23.223s, episode steps: 704, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.005994, mae: 0.099443, mean_q: 0.132569, mean_eps: 0.832578\n",
            "  47998/250000: episode: 64, duration: 37.287s, episode steps: 1140, steps per second:  31, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.006601, mae: 0.100809, mean_q: 0.135106, mean_eps: 0.829259\n",
            "  48743/250000: episode: 65, duration: 24.769s, episode steps: 745, steps per second:  30, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.006995, mae: 0.101448, mean_q: 0.138106, mean_eps: 0.825868\n",
            "  49457/250000: episode: 66, duration: 23.892s, episode steps: 714, steps per second:  30, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.006388, mae: 0.101502, mean_q: 0.134665, mean_eps: 0.823240\n",
            "  50158/250000: episode: 67, duration: 23.338s, episode steps: 701, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.005850, mae: 0.103872, mean_q: 0.137399, mean_eps: 0.820691\n",
            "  50964/250000: episode: 68, duration: 26.813s, episode steps: 806, steps per second:  30, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.008789, mae: 0.130701, mean_q: 0.174112, mean_eps: 0.817984\n",
            "  51635/250000: episode: 69, duration: 22.321s, episode steps: 671, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.007076, mae: 0.125427, mean_q: 0.166093, mean_eps: 0.815327\n",
            "  52015/250000: episode: 70, duration: 12.628s, episode steps: 380, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.184 [0.000, 5.000],  loss: 0.005694, mae: 0.122241, mean_q: 0.162979, mean_eps: 0.813434\n",
            "  52407/250000: episode: 71, duration: 13.002s, episode steps: 392, steps per second:  30, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.006038, mae: 0.121557, mean_q: 0.160843, mean_eps: 0.812044\n",
            "  53056/250000: episode: 72, duration: 22.023s, episode steps: 649, steps per second:  29, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.005967, mae: 0.122195, mean_q: 0.161500, mean_eps: 0.810172\n",
            "  53439/250000: episode: 73, duration: 12.792s, episode steps: 383, steps per second:  30, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.007084, mae: 0.127617, mean_q: 0.168424, mean_eps: 0.808314\n",
            "  54705/250000: episode: 74, duration: 41.896s, episode steps: 1266, steps per second:  30, episode reward: 24.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006635, mae: 0.125321, mean_q: 0.166568, mean_eps: 0.805341\n",
            "  55795/250000: episode: 75, duration: 36.703s, episode steps: 1090, steps per second:  30, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.007318, mae: 0.125600, mean_q: 0.168371, mean_eps: 0.801100\n",
            "  56984/250000: episode: 76, duration: 39.571s, episode steps: 1189, steps per second:  30, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006581, mae: 0.122558, mean_q: 0.162038, mean_eps: 0.797003\n",
            "  58031/250000: episode: 77, duration: 34.644s, episode steps: 1047, steps per second:  30, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: 0.006531, mae: 0.124576, mean_q: 0.165138, mean_eps: 0.792978\n",
            "  58632/250000: episode: 78, duration: 20.178s, episode steps: 601, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.006483, mae: 0.121154, mean_q: 0.163260, mean_eps: 0.790012\n",
            "  59278/250000: episode: 79, duration: 21.323s, episode steps: 646, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.006009, mae: 0.124135, mean_q: 0.167565, mean_eps: 0.787766\n",
            "  59781/250000: episode: 80, duration: 16.765s, episode steps: 503, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: 0.006497, mae: 0.126324, mean_q: 0.168535, mean_eps: 0.785692\n",
            "  60415/250000: episode: 81, duration: 20.926s, episode steps: 634, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.007966, mae: 0.143424, mean_q: 0.188381, mean_eps: 0.783647\n",
            "  61113/250000: episode: 82, duration: 22.584s, episode steps: 698, steps per second:  31, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.007730, mae: 0.152757, mean_q: 0.201321, mean_eps: 0.781250\n",
            "  61658/250000: episode: 83, duration: 17.445s, episode steps: 545, steps per second:  31, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006938, mae: 0.150637, mean_q: 0.194733, mean_eps: 0.779010\n",
            "  62518/250000: episode: 84, duration: 27.567s, episode steps: 860, steps per second:  31, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.007456, mae: 0.148863, mean_q: 0.195526, mean_eps: 0.776483\n",
            "  63008/250000: episode: 85, duration: 16.190s, episode steps: 490, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.829 [0.000, 5.000],  loss: 0.007445, mae: 0.148462, mean_q: 0.198327, mean_eps: 0.774057\n",
            "  63683/250000: episode: 86, duration: 21.949s, episode steps: 675, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.008686, mae: 0.155440, mean_q: 0.204624, mean_eps: 0.771962\n",
            "  64119/250000: episode: 87, duration: 14.658s, episode steps: 436, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.005709, mae: 0.145138, mean_q: 0.189914, mean_eps: 0.769960\n",
            "  64750/250000: episode: 88, duration: 20.554s, episode steps: 631, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.007300, mae: 0.146028, mean_q: 0.189485, mean_eps: 0.768038\n",
            "  65399/250000: episode: 89, duration: 21.380s, episode steps: 649, steps per second:  30, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.006406, mae: 0.143216, mean_q: 0.187657, mean_eps: 0.765734\n",
            "  66239/250000: episode: 90, duration: 27.385s, episode steps: 840, steps per second:  31, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.006341, mae: 0.150406, mean_q: 0.196789, mean_eps: 0.763055\n",
            "  66826/250000: episode: 91, duration: 19.218s, episode steps: 587, steps per second:  31, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.008102, mae: 0.153681, mean_q: 0.201739, mean_eps: 0.760485\n",
            "  67702/250000: episode: 92, duration: 28.680s, episode steps: 876, steps per second:  31, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.006406, mae: 0.148817, mean_q: 0.192303, mean_eps: 0.757850\n",
            "  68288/250000: episode: 93, duration: 19.162s, episode steps: 586, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.007517, mae: 0.153215, mean_q: 0.199501, mean_eps: 0.755222\n",
            "  68799/250000: episode: 94, duration: 16.807s, episode steps: 511, steps per second:  30, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.006865, mae: 0.147473, mean_q: 0.194349, mean_eps: 0.753249\n",
            "  69692/250000: episode: 95, duration: 28.994s, episode steps: 893, steps per second:  31, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.006505, mae: 0.143873, mean_q: 0.187806, mean_eps: 0.750722\n",
            "  70802/250000: episode: 96, duration: 35.794s, episode steps: 1110, steps per second:  31, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.006378, mae: 0.161853, mean_q: 0.209187, mean_eps: 0.747114\n",
            "  71926/250000: episode: 97, duration: 36.717s, episode steps: 1124, steps per second:  31, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.007369, mae: 0.168042, mean_q: 0.218709, mean_eps: 0.743090\n",
            "  73063/250000: episode: 98, duration: 37.288s, episode steps: 1137, steps per second:  30, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007087, mae: 0.169911, mean_q: 0.218825, mean_eps: 0.739022\n",
            "  73471/250000: episode: 99, duration: 13.310s, episode steps: 408, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.007320, mae: 0.168366, mean_q: 0.216779, mean_eps: 0.736242\n",
            "  74153/250000: episode: 100, duration: 22.225s, episode steps: 682, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.006814, mae: 0.167439, mean_q: 0.218651, mean_eps: 0.734277\n",
            "  74763/250000: episode: 101, duration: 20.367s, episode steps: 610, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.005584, mae: 0.162925, mean_q: 0.212476, mean_eps: 0.731951\n",
            "  75748/250000: episode: 102, duration: 32.370s, episode steps: 985, steps per second:  30, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.006858, mae: 0.169104, mean_q: 0.220013, mean_eps: 0.729086\n",
            "  76449/250000: episode: 103, duration: 23.408s, episode steps: 701, steps per second:  30, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.006930, mae: 0.166373, mean_q: 0.217407, mean_eps: 0.726047\n",
            "  77226/250000: episode: 104, duration: 25.178s, episode steps: 777, steps per second:  31, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.007905, mae: 0.169999, mean_q: 0.221105, mean_eps: 0.723383\n",
            "  77600/250000: episode: 105, duration: 12.422s, episode steps: 374, steps per second:  30, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.006823, mae: 0.164063, mean_q: 0.218012, mean_eps: 0.721317\n",
            "  78181/250000: episode: 106, duration: 19.048s, episode steps: 581, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.006942, mae: 0.161159, mean_q: 0.211143, mean_eps: 0.719596\n",
            "  79431/250000: episode: 107, duration: 41.154s, episode steps: 1250, steps per second:  30, episode reward: 13.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.007068, mae: 0.166902, mean_q: 0.216736, mean_eps: 0.716298\n",
            "  80197/250000: episode: 108, duration: 25.180s, episode steps: 766, steps per second:  30, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.007075, mae: 0.176729, mean_q: 0.228410, mean_eps: 0.712670\n",
            "  80700/250000: episode: 109, duration: 16.481s, episode steps: 503, steps per second:  31, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.007078, mae: 0.193984, mean_q: 0.247070, mean_eps: 0.710387\n",
            "  81748/250000: episode: 110, duration: 34.656s, episode steps: 1048, steps per second:  30, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.007514, mae: 0.195790, mean_q: 0.251150, mean_eps: 0.707601\n",
            "  82224/250000: episode: 111, duration: 15.707s, episode steps: 476, steps per second:  30, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.007403, mae: 0.194527, mean_q: 0.251233, mean_eps: 0.704858\n",
            "  82743/250000: episode: 112, duration: 17.312s, episode steps: 519, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.007112, mae: 0.192347, mean_q: 0.247919, mean_eps: 0.703065\n",
            "  83408/250000: episode: 113, duration: 21.806s, episode steps: 665, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.007291, mae: 0.192885, mean_q: 0.247686, mean_eps: 0.700934\n",
            "  83946/250000: episode: 114, duration: 18.129s, episode steps: 538, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.008405, mae: 0.188964, mean_q: 0.241563, mean_eps: 0.698766\n",
            "  84446/250000: episode: 115, duration: 16.230s, episode steps: 500, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007083, mae: 0.186142, mean_q: 0.239123, mean_eps: 0.696894\n",
            "  85172/250000: episode: 116, duration: 23.952s, episode steps: 726, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.005771, mae: 0.185689, mean_q: 0.239130, mean_eps: 0.694691\n",
            "  85670/250000: episode: 117, duration: 16.389s, episode steps: 498, steps per second:  30, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.008046, mae: 0.196050, mean_q: 0.250236, mean_eps: 0.692488\n",
            "  86117/250000: episode: 118, duration: 14.844s, episode steps: 447, steps per second:  30, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.006504, mae: 0.182929, mean_q: 0.234267, mean_eps: 0.690782\n",
            "  86875/250000: episode: 119, duration: 24.825s, episode steps: 758, steps per second:  31, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.007065, mae: 0.195290, mean_q: 0.250100, mean_eps: 0.688614\n",
            "  87582/250000: episode: 120, duration: 23.019s, episode steps: 707, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.007030, mae: 0.192310, mean_q: 0.245322, mean_eps: 0.685979\n",
            "  88166/250000: episode: 121, duration: 19.051s, episode steps: 584, steps per second:  31, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.286 [0.000, 5.000],  loss: 0.006857, mae: 0.191992, mean_q: 0.247039, mean_eps: 0.683654\n",
            "  88800/250000: episode: 122, duration: 20.864s, episode steps: 634, steps per second:  30, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.005673, mae: 0.188513, mean_q: 0.241979, mean_eps: 0.681465\n",
            "  89201/250000: episode: 123, duration: 13.487s, episode steps: 401, steps per second:  30, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.006561, mae: 0.189517, mean_q: 0.242298, mean_eps: 0.679600\n",
            "  89731/250000: episode: 124, duration: 17.404s, episode steps: 530, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.006598, mae: 0.189750, mean_q: 0.241838, mean_eps: 0.677922\n",
            "  90512/250000: episode: 125, duration: 26.062s, episode steps: 781, steps per second:  30, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.006873, mae: 0.202112, mean_q: 0.259353, mean_eps: 0.675568\n",
            "  90990/250000: episode: 126, duration: 15.983s, episode steps: 478, steps per second:  30, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.007335, mae: 0.212932, mean_q: 0.269789, mean_eps: 0.673300\n",
            "  91963/250000: episode: 127, duration: 32.202s, episode steps: 973, steps per second:  30, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.008146, mae: 0.211358, mean_q: 0.269996, mean_eps: 0.670686\n",
            "  92577/250000: episode: 128, duration: 20.394s, episode steps: 614, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.007881, mae: 0.211381, mean_q: 0.271130, mean_eps: 0.667828\n",
            "  93073/250000: episode: 129, duration: 16.300s, episode steps: 496, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.007660, mae: 0.214820, mean_q: 0.273457, mean_eps: 0.665826\n",
            "  93579/250000: episode: 130, duration: 16.814s, episode steps: 506, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.006952, mae: 0.208956, mean_q: 0.265687, mean_eps: 0.664026\n",
            "  94258/250000: episode: 131, duration: 22.675s, episode steps: 679, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.007348, mae: 0.213080, mean_q: 0.271943, mean_eps: 0.661895\n",
            "  94968/250000: episode: 132, duration: 23.784s, episode steps: 710, steps per second:  30, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.006892, mae: 0.203105, mean_q: 0.258997, mean_eps: 0.659397\n",
            "  95568/250000: episode: 133, duration: 19.785s, episode steps: 600, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.865 [0.000, 5.000],  loss: 0.007098, mae: 0.202620, mean_q: 0.259165, mean_eps: 0.657042\n",
            "  95935/250000: episode: 134, duration: 12.282s, episode steps: 367, steps per second:  30, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.006796, mae: 0.210319, mean_q: 0.267628, mean_eps: 0.655300\n",
            "  96578/250000: episode: 135, duration: 21.242s, episode steps: 643, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.006691, mae: 0.206208, mean_q: 0.262177, mean_eps: 0.653478\n",
            "  97228/250000: episode: 136, duration: 21.339s, episode steps: 650, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.006672, mae: 0.208666, mean_q: 0.265227, mean_eps: 0.651153\n",
            "  97671/250000: episode: 137, duration: 14.473s, episode steps: 443, steps per second:  31, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.008936, mae: 0.215493, mean_q: 0.275504, mean_eps: 0.649187\n",
            "  98403/250000: episode: 138, duration: 24.387s, episode steps: 732, steps per second:  30, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.801 [0.000, 5.000],  loss: 0.007139, mae: 0.202086, mean_q: 0.259149, mean_eps: 0.647070\n",
            "  99126/250000: episode: 139, duration: 24.019s, episode steps: 723, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.008368, mae: 0.211971, mean_q: 0.272045, mean_eps: 0.644450\n",
            "  99867/250000: episode: 140, duration: 24.508s, episode steps: 741, steps per second:  30, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.006453, mae: 0.205586, mean_q: 0.264522, mean_eps: 0.641814\n",
            " 100487/250000: episode: 141, duration: 20.293s, episode steps: 620, steps per second:  31, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.913 [0.000, 5.000],  loss: 0.007718, mae: 0.243343, mean_q: 0.309089, mean_eps: 0.639366\n",
            " 101155/250000: episode: 142, duration: 21.775s, episode steps: 668, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007776, mae: 0.249460, mean_q: 0.312244, mean_eps: 0.637048\n",
            " 101828/250000: episode: 143, duration: 22.282s, episode steps: 673, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.006716, mae: 0.244558, mean_q: 0.309527, mean_eps: 0.634636\n",
            " 102483/250000: episode: 144, duration: 21.629s, episode steps: 655, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.008094, mae: 0.246785, mean_q: 0.311924, mean_eps: 0.632246\n",
            " 102997/250000: episode: 145, duration: 17.200s, episode steps: 514, steps per second:  30, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.008083, mae: 0.251153, mean_q: 0.317541, mean_eps: 0.630136\n",
            " 104024/250000: episode: 146, duration: 34.345s, episode steps: 1027, steps per second:  30, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.007980, mae: 0.251090, mean_q: 0.320389, mean_eps: 0.627364\n",
            " 104358/250000: episode: 147, duration: 10.979s, episode steps: 334, steps per second:  30, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.835 [0.000, 5.000],  loss: 0.008103, mae: 0.251586, mean_q: 0.317850, mean_eps: 0.624916\n",
            " 105182/250000: episode: 148, duration: 27.123s, episode steps: 824, steps per second:  30, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.008908, mae: 0.251643, mean_q: 0.317043, mean_eps: 0.622828\n",
            " 105627/250000: episode: 149, duration: 14.754s, episode steps: 445, steps per second:  30, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.008150, mae: 0.246101, mean_q: 0.308565, mean_eps: 0.620546\n",
            " 106097/250000: episode: 150, duration: 15.603s, episode steps: 470, steps per second:  30, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.066 [0.000, 5.000],  loss: 0.009266, mae: 0.249360, mean_q: 0.315136, mean_eps: 0.618897\n",
            " 106740/250000: episode: 151, duration: 21.489s, episode steps: 643, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.008598, mae: 0.257629, mean_q: 0.326148, mean_eps: 0.616895\n",
            " 107866/250000: episode: 152, duration: 37.728s, episode steps: 1126, steps per second:  30, episode reward: 25.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.008521, mae: 0.250617, mean_q: 0.317516, mean_eps: 0.613713\n",
            " 108474/250000: episode: 153, duration: 19.953s, episode steps: 608, steps per second:  30, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.009051, mae: 0.251022, mean_q: 0.316288, mean_eps: 0.610588\n",
            " 109156/250000: episode: 154, duration: 22.488s, episode steps: 682, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.773 [0.000, 5.000],  loss: 0.007678, mae: 0.248818, mean_q: 0.314053, mean_eps: 0.608270\n",
            " 109499/250000: episode: 155, duration: 11.432s, episode steps: 343, steps per second:  30, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.007200, mae: 0.249616, mean_q: 0.316245, mean_eps: 0.606426\n",
            " 109945/250000: episode: 156, duration: 14.752s, episode steps: 446, steps per second:  30, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.006713, mae: 0.248252, mean_q: 0.312634, mean_eps: 0.605001\n",
            " 111044/250000: episode: 157, duration: 36.421s, episode steps: 1099, steps per second:  30, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.007598, mae: 0.267183, mean_q: 0.335074, mean_eps: 0.602222\n",
            " 111569/250000: episode: 158, duration: 17.438s, episode steps: 525, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.299 [0.000, 5.000],  loss: 0.008000, mae: 0.266978, mean_q: 0.333683, mean_eps: 0.599298\n",
            " 112327/250000: episode: 159, duration: 25.198s, episode steps: 758, steps per second:  30, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.008194, mae: 0.276997, mean_q: 0.346296, mean_eps: 0.596987\n",
            " 112690/250000: episode: 160, duration: 11.984s, episode steps: 363, steps per second:  30, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.008643, mae: 0.278735, mean_q: 0.349237, mean_eps: 0.594971\n",
            " 113251/250000: episode: 161, duration: 18.408s, episode steps: 561, steps per second:  30, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.006993, mae: 0.273158, mean_q: 0.343114, mean_eps: 0.593308\n",
            " 114151/250000: episode: 162, duration: 29.813s, episode steps: 900, steps per second:  30, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: 0.008378, mae: 0.267283, mean_q: 0.332459, mean_eps: 0.590680\n",
            " 115086/250000: episode: 163, duration: 30.908s, episode steps: 935, steps per second:  30, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.009085, mae: 0.277628, mean_q: 0.345950, mean_eps: 0.587375\n",
            " 116028/250000: episode: 164, duration: 31.033s, episode steps: 942, steps per second:  30, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.050 [0.000, 5.000],  loss: 0.009383, mae: 0.277226, mean_q: 0.347728, mean_eps: 0.583998\n",
            " 116429/250000: episode: 165, duration: 13.415s, episode steps: 401, steps per second:  30, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.778 [0.000, 5.000],  loss: 0.008654, mae: 0.279667, mean_q: 0.351514, mean_eps: 0.581579\n",
            " 117089/250000: episode: 166, duration: 21.746s, episode steps: 660, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.008562, mae: 0.277415, mean_q: 0.347890, mean_eps: 0.579664\n",
            " 118022/250000: episode: 167, duration: 30.717s, episode steps: 933, steps per second:  30, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.007391, mae: 0.272437, mean_q: 0.342438, mean_eps: 0.576798\n",
            " 118696/250000: episode: 168, duration: 22.512s, episode steps: 674, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.008557, mae: 0.273499, mean_q: 0.343033, mean_eps: 0.573911\n",
            " 119219/250000: episode: 169, duration: 17.287s, episode steps: 523, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.007475, mae: 0.271320, mean_q: 0.339671, mean_eps: 0.571758\n",
            " 119794/250000: episode: 170, duration: 19.117s, episode steps: 575, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.009017, mae: 0.277568, mean_q: 0.347257, mean_eps: 0.569778\n",
            " 120260/250000: episode: 171, duration: 15.399s, episode steps: 466, steps per second:  30, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.010159, mae: 0.292799, mean_q: 0.368343, mean_eps: 0.567906\n",
            " 120670/250000: episode: 172, duration: 13.687s, episode steps: 410, steps per second:  30, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.009875, mae: 0.298061, mean_q: 0.378607, mean_eps: 0.566330\n",
            " 121196/250000: episode: 173, duration: 17.493s, episode steps: 526, steps per second:  30, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.008871, mae: 0.297547, mean_q: 0.373764, mean_eps: 0.564645\n",
            " 121751/250000: episode: 174, duration: 18.430s, episode steps: 555, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.009795, mae: 0.297999, mean_q: 0.372783, mean_eps: 0.562701\n",
            " 122124/250000: episode: 175, duration: 12.369s, episode steps: 373, steps per second:  30, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.131 [0.000, 5.000],  loss: 0.009321, mae: 0.296095, mean_q: 0.370709, mean_eps: 0.561030\n",
            " 122763/250000: episode: 176, duration: 21.023s, episode steps: 639, steps per second:  30, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.008738, mae: 0.304302, mean_q: 0.381616, mean_eps: 0.559209\n",
            " 123827/250000: episode: 177, duration: 34.944s, episode steps: 1064, steps per second:  30, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.008936, mae: 0.299315, mean_q: 0.375888, mean_eps: 0.556142\n",
            " 124681/250000: episode: 178, duration: 28.273s, episode steps: 854, steps per second:  30, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.008934, mae: 0.301389, mean_q: 0.376610, mean_eps: 0.552686\n",
            " 125309/250000: episode: 179, duration: 20.989s, episode steps: 628, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.009055, mae: 0.291235, mean_q: 0.364060, mean_eps: 0.550014\n",
            " 125643/250000: episode: 180, duration: 11.064s, episode steps: 334, steps per second:  30, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.007723, mae: 0.298650, mean_q: 0.374237, mean_eps: 0.548286\n",
            " 126031/250000: episode: 181, duration: 12.826s, episode steps: 388, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.009793, mae: 0.305584, mean_q: 0.383294, mean_eps: 0.546990\n",
            " 126427/250000: episode: 182, duration: 13.036s, episode steps: 396, steps per second:  30, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.010099, mae: 0.312323, mean_q: 0.391971, mean_eps: 0.545579\n",
            " 126958/250000: episode: 183, duration: 17.470s, episode steps: 531, steps per second:  30, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.009421, mae: 0.297023, mean_q: 0.371133, mean_eps: 0.543909\n",
            " 128174/250000: episode: 184, duration: 40.319s, episode steps: 1216, steps per second:  30, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.008644, mae: 0.292888, mean_q: 0.367896, mean_eps: 0.540762\n",
            " 128559/250000: episode: 185, duration: 12.858s, episode steps: 385, steps per second:  30, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.008471, mae: 0.302634, mean_q: 0.379637, mean_eps: 0.537882\n",
            " 129088/250000: episode: 186, duration: 17.419s, episode steps: 529, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.008344, mae: 0.293603, mean_q: 0.367303, mean_eps: 0.536241\n",
            " 129539/250000: episode: 187, duration: 14.666s, episode steps: 451, steps per second:  31, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.044 [0.000, 5.000],  loss: 0.008380, mae: 0.296782, mean_q: 0.372807, mean_eps: 0.534477\n",
            " 130180/250000: episode: 188, duration: 21.136s, episode steps: 641, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.007780, mae: 0.305180, mean_q: 0.385202, mean_eps: 0.532511\n",
            " 131051/250000: episode: 189, duration: 28.641s, episode steps: 871, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.242 [0.000, 5.000],  loss: 0.009452, mae: 0.338058, mean_q: 0.423682, mean_eps: 0.529790\n",
            " 131530/250000: episode: 190, duration: 15.882s, episode steps: 479, steps per second:  30, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.012181, mae: 0.342787, mean_q: 0.427757, mean_eps: 0.527356\n",
            " 131892/250000: episode: 191, duration: 11.987s, episode steps: 362, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.008409, mae: 0.342442, mean_q: 0.428850, mean_eps: 0.525844\n",
            " 132514/250000: episode: 192, duration: 20.563s, episode steps: 622, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.009275, mae: 0.323206, mean_q: 0.403225, mean_eps: 0.524073\n",
            " 133011/250000: episode: 193, duration: 16.484s, episode steps: 497, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.011498, mae: 0.334598, mean_q: 0.418627, mean_eps: 0.522057\n",
            " 133486/250000: episode: 194, duration: 15.790s, episode steps: 475, steps per second:  30, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.009380, mae: 0.330251, mean_q: 0.412658, mean_eps: 0.520307\n",
            " 134366/250000: episode: 195, duration: 28.821s, episode steps: 880, steps per second:  31, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.009140, mae: 0.332522, mean_q: 0.416870, mean_eps: 0.517866\n",
            " 135239/250000: episode: 196, duration: 29.115s, episode steps: 873, steps per second:  30, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.009414, mae: 0.334137, mean_q: 0.417980, mean_eps: 0.514713\n",
            " 135772/250000: episode: 197, duration: 17.670s, episode steps: 533, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.186 [0.000, 5.000],  loss: 0.008759, mae: 0.325757, mean_q: 0.407802, mean_eps: 0.512186\n",
            " 136154/250000: episode: 198, duration: 12.797s, episode steps: 382, steps per second:  30, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.683 [0.000, 5.000],  loss: 0.008788, mae: 0.329250, mean_q: 0.412834, mean_eps: 0.510537\n",
            " 136512/250000: episode: 199, duration: 11.933s, episode steps: 358, steps per second:  30, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.008418, mae: 0.338127, mean_q: 0.426759, mean_eps: 0.509205\n",
            " 137661/250000: episode: 200, duration: 38.023s, episode steps: 1149, steps per second:  30, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.184 [0.000, 5.000],  loss: 0.009862, mae: 0.329922, mean_q: 0.414320, mean_eps: 0.506490\n",
            " 138103/250000: episode: 201, duration: 14.688s, episode steps: 442, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.009881, mae: 0.329995, mean_q: 0.411544, mean_eps: 0.503625\n",
            " 138493/250000: episode: 202, duration: 13.003s, episode steps: 390, steps per second:  30, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.008794, mae: 0.327533, mean_q: 0.410083, mean_eps: 0.502127\n",
            " 139121/250000: episode: 203, duration: 20.766s, episode steps: 628, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.009538, mae: 0.330725, mean_q: 0.413593, mean_eps: 0.500291\n",
            " 139612/250000: episode: 204, duration: 16.356s, episode steps: 491, steps per second:  30, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.008028, mae: 0.335525, mean_q: 0.420027, mean_eps: 0.498282\n",
            " 140434/250000: episode: 205, duration: 27.252s, episode steps: 822, steps per second:  30, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.009553, mae: 0.364384, mean_q: 0.457744, mean_eps: 0.495921\n",
            " 141209/250000: episode: 206, duration: 25.690s, episode steps: 775, steps per second:  30, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.010629, mae: 0.371064, mean_q: 0.463231, mean_eps: 0.493041\n",
            " 141721/250000: episode: 207, duration: 16.919s, episode steps: 512, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.080 [0.000, 5.000],  loss: 0.010311, mae: 0.376592, mean_q: 0.470664, mean_eps: 0.490722\n",
            " 142538/250000: episode: 208, duration: 27.356s, episode steps: 817, steps per second:  30, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.286 [0.000, 5.000],  loss: 0.009647, mae: 0.375589, mean_q: 0.469429, mean_eps: 0.488332\n",
            " 142931/250000: episode: 209, duration: 13.118s, episode steps: 393, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.009006, mae: 0.367871, mean_q: 0.459647, mean_eps: 0.486158\n",
            " 143454/250000: episode: 210, duration: 17.410s, episode steps: 523, steps per second:  30, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.009162, mae: 0.361925, mean_q: 0.454123, mean_eps: 0.484509\n",
            " 144168/250000: episode: 211, duration: 23.899s, episode steps: 714, steps per second:  30, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.929 [0.000, 5.000],  loss: 0.012284, mae: 0.375818, mean_q: 0.467785, mean_eps: 0.482284\n",
            " 144678/250000: episode: 212, duration: 17.404s, episode steps: 510, steps per second:  29, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.011454, mae: 0.377886, mean_q: 0.472085, mean_eps: 0.480081\n",
            " 145686/250000: episode: 213, duration: 34.037s, episode steps: 1008, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.129 [0.000, 5.000],  loss: 0.008883, mae: 0.368074, mean_q: 0.458919, mean_eps: 0.477345\n",
            " 146359/250000: episode: 214, duration: 22.604s, episode steps: 673, steps per second:  30, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.010603, mae: 0.387159, mean_q: 0.481644, mean_eps: 0.474321\n",
            " 146878/250000: episode: 215, duration: 17.479s, episode steps: 519, steps per second:  30, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.009215, mae: 0.377153, mean_q: 0.469666, mean_eps: 0.472175\n",
            " 147558/250000: episode: 216, duration: 22.711s, episode steps: 680, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.010136, mae: 0.385822, mean_q: 0.481459, mean_eps: 0.470015\n",
            " 148193/250000: episode: 217, duration: 20.960s, episode steps: 635, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.010178, mae: 0.379547, mean_q: 0.472430, mean_eps: 0.467646\n",
            " 148991/250000: episode: 218, duration: 26.185s, episode steps: 798, steps per second:  30, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.010720, mae: 0.369087, mean_q: 0.459242, mean_eps: 0.465069\n",
            " 150026/250000: episode: 219, duration: 34.671s, episode steps: 1035, steps per second:  30, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.011067, mae: 0.377488, mean_q: 0.469755, mean_eps: 0.461771\n",
            " 150391/250000: episode: 220, duration: 12.138s, episode steps: 365, steps per second:  30, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.967 [0.000, 5.000],  loss: 0.009367, mae: 0.420840, mean_q: 0.523859, mean_eps: 0.459251\n",
            " 150974/250000: episode: 221, duration: 19.403s, episode steps: 583, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.009088, mae: 0.419203, mean_q: 0.522982, mean_eps: 0.457545\n",
            " 152166/250000: episode: 222, duration: 38.955s, episode steps: 1192, steps per second:  31, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.008911, mae: 0.413228, mean_q: 0.515164, mean_eps: 0.454348\n",
            " 153393/250000: episode: 223, duration: 40.856s, episode steps: 1227, steps per second:  30, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.009644, mae: 0.409909, mean_q: 0.509343, mean_eps: 0.449992\n",
            " 154239/250000: episode: 224, duration: 28.475s, episode steps: 846, steps per second:  30, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.010405, mae: 0.409973, mean_q: 0.509950, mean_eps: 0.446262\n",
            " 155237/250000: episode: 225, duration: 33.524s, episode steps: 998, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.010705, mae: 0.415086, mean_q: 0.517134, mean_eps: 0.442943\n",
            " 156209/250000: episode: 226, duration: 32.560s, episode steps: 972, steps per second:  30, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.010223, mae: 0.412086, mean_q: 0.513478, mean_eps: 0.439394\n",
            " 156718/250000: episode: 227, duration: 16.794s, episode steps: 509, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.234 [0.000, 5.000],  loss: 0.010809, mae: 0.405217, mean_q: 0.505339, mean_eps: 0.436730\n",
            " 157578/250000: episode: 228, duration: 28.365s, episode steps: 860, steps per second:  30, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.121 [0.000, 5.000],  loss: 0.010356, mae: 0.411708, mean_q: 0.512446, mean_eps: 0.434267\n",
            " 158261/250000: episode: 229, duration: 22.825s, episode steps: 683, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.167 [0.000, 5.000],  loss: 0.010287, mae: 0.421708, mean_q: 0.525652, mean_eps: 0.431488\n",
            " 158651/250000: episode: 230, duration: 12.826s, episode steps: 390, steps per second:  30, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.010026, mae: 0.412554, mean_q: 0.513725, mean_eps: 0.429558\n",
            " 159076/250000: episode: 231, duration: 14.471s, episode steps: 425, steps per second:  29, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.009720, mae: 0.405564, mean_q: 0.503822, mean_eps: 0.428097\n",
            " 159881/250000: episode: 232, duration: 26.841s, episode steps: 805, steps per second:  30, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.010405, mae: 0.413574, mean_q: 0.514143, mean_eps: 0.425879\n",
            " 160372/250000: episode: 233, duration: 16.269s, episode steps: 491, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.009139, mae: 0.432199, mean_q: 0.538050, mean_eps: 0.423546\n",
            " 160985/250000: episode: 234, duration: 20.366s, episode steps: 613, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.008969, mae: 0.435464, mean_q: 0.541546, mean_eps: 0.421559\n",
            " 161473/250000: episode: 235, duration: 16.124s, episode steps: 488, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.009489, mae: 0.438127, mean_q: 0.542118, mean_eps: 0.419572\n",
            " 162416/250000: episode: 236, duration: 31.509s, episode steps: 943, steps per second:  30, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.010836, mae: 0.445769, mean_q: 0.554449, mean_eps: 0.417002\n",
            " 162791/250000: episode: 237, duration: 12.546s, episode steps: 375, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.012541, mae: 0.450654, mean_q: 0.560704, mean_eps: 0.414633\n",
            " 163556/250000: episode: 238, duration: 26.049s, episode steps: 765, steps per second:  29, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: 0.011606, mae: 0.453195, mean_q: 0.562817, mean_eps: 0.412581\n",
            " 164066/250000: episode: 239, duration: 17.482s, episode steps: 510, steps per second:  29, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.009735, mae: 0.440360, mean_q: 0.548626, mean_eps: 0.410284\n",
            " 164473/250000: episode: 240, duration: 13.688s, episode steps: 407, steps per second:  30, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.009258, mae: 0.427963, mean_q: 0.532845, mean_eps: 0.408628\n",
            " 164941/250000: episode: 241, duration: 15.447s, episode steps: 468, steps per second:  30, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.010794, mae: 0.438405, mean_q: 0.545558, mean_eps: 0.407051\n",
            " 165774/250000: episode: 242, duration: 27.592s, episode steps: 833, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.009824, mae: 0.432443, mean_q: 0.538330, mean_eps: 0.404711\n",
            " 166304/250000: episode: 243, duration: 17.828s, episode steps: 530, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.011341, mae: 0.441533, mean_q: 0.548066, mean_eps: 0.402263\n",
            " 167165/250000: episode: 244, duration: 28.720s, episode steps: 861, steps per second:  30, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.848 [0.000, 5.000],  loss: 0.010674, mae: 0.439039, mean_q: 0.545874, mean_eps: 0.399758\n",
            " 167778/250000: episode: 245, duration: 20.629s, episode steps: 613, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.010797, mae: 0.442270, mean_q: 0.549932, mean_eps: 0.397101\n",
            " 168847/250000: episode: 246, duration: 36.186s, episode steps: 1069, steps per second:  30, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.842 [0.000, 5.000],  loss: 0.009577, mae: 0.434285, mean_q: 0.541408, mean_eps: 0.394077\n",
            " 169349/250000: episode: 247, duration: 16.826s, episode steps: 502, steps per second:  30, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.010927, mae: 0.439762, mean_q: 0.546739, mean_eps: 0.391247\n",
            " 170004/250000: episode: 248, duration: 22.030s, episode steps: 655, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.010570, mae: 0.439430, mean_q: 0.546016, mean_eps: 0.389166\n",
            " 170469/250000: episode: 249, duration: 15.709s, episode steps: 465, steps per second:  30, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.114 [0.000, 5.000],  loss: 0.013169, mae: 0.471950, mean_q: 0.586674, mean_eps: 0.387150\n",
            " 171087/250000: episode: 250, duration: 20.545s, episode steps: 618, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.010693, mae: 0.458143, mean_q: 0.569851, mean_eps: 0.385199\n",
            " 171916/250000: episode: 251, duration: 28.167s, episode steps: 829, steps per second:  29, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.013700, mae: 0.481333, mean_q: 0.598038, mean_eps: 0.382600\n",
            " 172830/250000: episode: 252, duration: 30.778s, episode steps: 914, steps per second:  30, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.011385, mae: 0.472377, mean_q: 0.586617, mean_eps: 0.379461\n",
            " 173191/250000: episode: 253, duration: 12.090s, episode steps: 361, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.010995, mae: 0.481094, mean_q: 0.596302, mean_eps: 0.377164\n",
            " 173706/250000: episode: 254, duration: 17.184s, episode steps: 515, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.010231, mae: 0.453902, mean_q: 0.563299, mean_eps: 0.375587\n",
            " 174412/250000: episode: 255, duration: 24.443s, episode steps: 706, steps per second:  29, episode reward: 19.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.958 [0.000, 5.000],  loss: 0.011601, mae: 0.472597, mean_q: 0.586647, mean_eps: 0.373391\n",
            " 175127/250000: episode: 256, duration: 24.706s, episode steps: 715, steps per second:  29, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.010737, mae: 0.473757, mean_q: 0.587987, mean_eps: 0.370835\n",
            " 175907/250000: episode: 257, duration: 26.655s, episode steps: 780, steps per second:  29, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.011907, mae: 0.476858, mean_q: 0.592420, mean_eps: 0.368142\n",
            " 176506/250000: episode: 258, duration: 20.101s, episode steps: 599, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.012057, mae: 0.472102, mean_q: 0.586605, mean_eps: 0.365658\n",
            " 176903/250000: episode: 259, duration: 13.487s, episode steps: 397, steps per second:  29, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.010526, mae: 0.460758, mean_q: 0.573977, mean_eps: 0.363866\n",
            " 177415/250000: episode: 260, duration: 17.460s, episode steps: 512, steps per second:  29, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.756 [0.000, 5.000],  loss: 0.010983, mae: 0.470025, mean_q: 0.583460, mean_eps: 0.362231\n",
            " 178327/250000: episode: 261, duration: 31.188s, episode steps: 912, steps per second:  29, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.011076, mae: 0.466542, mean_q: 0.580245, mean_eps: 0.359668\n",
            " 178970/250000: episode: 262, duration: 21.960s, episode steps: 643, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.010579, mae: 0.459162, mean_q: 0.573468, mean_eps: 0.356867\n",
            " 179497/250000: episode: 263, duration: 17.968s, episode steps: 527, steps per second:  29, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.010386, mae: 0.454159, mean_q: 0.566165, mean_eps: 0.354758\n",
            " 180048/250000: episode: 264, duration: 19.153s, episode steps: 551, steps per second:  29, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.009892, mae: 0.475180, mean_q: 0.593818, mean_eps: 0.352821\n",
            " 180708/250000: episode: 265, duration: 22.522s, episode steps: 660, steps per second:  29, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.010648, mae: 0.468282, mean_q: 0.582727, mean_eps: 0.350646\n",
            " 181797/250000: episode: 266, duration: 37.643s, episode steps: 1089, steps per second:  29, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.011213, mae: 0.476026, mean_q: 0.591682, mean_eps: 0.347493\n",
            " 182290/250000: episode: 267, duration: 16.813s, episode steps: 493, steps per second:  29, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.011695, mae: 0.465185, mean_q: 0.578965, mean_eps: 0.344642\n",
            " 183352/250000: episode: 268, duration: 36.501s, episode steps: 1062, steps per second:  29, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.011469, mae: 0.464251, mean_q: 0.576936, mean_eps: 0.341848\n",
            " 184279/250000: episode: 269, duration: 31.426s, episode steps: 927, steps per second:  29, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.235 [0.000, 5.000],  loss: 0.011798, mae: 0.475265, mean_q: 0.591241, mean_eps: 0.338270\n",
            " 185111/250000: episode: 270, duration: 27.876s, episode steps: 832, steps per second:  30, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.010312, mae: 0.469024, mean_q: 0.584281, mean_eps: 0.335102\n",
            " 185779/250000: episode: 271, duration: 22.559s, episode steps: 668, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.012498, mae: 0.481336, mean_q: 0.597394, mean_eps: 0.332402\n",
            " 186695/250000: episode: 272, duration: 30.867s, episode steps: 916, steps per second:  30, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.010717, mae: 0.465433, mean_q: 0.579591, mean_eps: 0.329550\n",
            " 187323/250000: episode: 273, duration: 21.321s, episode steps: 628, steps per second:  29, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.010359, mae: 0.466362, mean_q: 0.580344, mean_eps: 0.326771\n",
            " 187814/250000: episode: 274, duration: 16.612s, episode steps: 491, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.813 [0.000, 5.000],  loss: 0.010526, mae: 0.474618, mean_q: 0.588230, mean_eps: 0.324755\n",
            " 188418/250000: episode: 275, duration: 20.203s, episode steps: 604, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.011146, mae: 0.482984, mean_q: 0.599618, mean_eps: 0.322782\n",
            " 189008/250000: episode: 276, duration: 19.723s, episode steps: 590, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.012551, mae: 0.473969, mean_q: 0.586735, mean_eps: 0.320637\n",
            " 189697/250000: episode: 277, duration: 22.954s, episode steps: 689, steps per second:  30, episode reward: 19.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.878 [0.000, 5.000],  loss: 0.011949, mae: 0.470373, mean_q: 0.581384, mean_eps: 0.318333\n",
            " 190090/250000: episode: 278, duration: 13.215s, episode steps: 393, steps per second:  30, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.010523, mae: 0.475485, mean_q: 0.589348, mean_eps: 0.316382\n",
            " 190610/250000: episode: 279, duration: 17.360s, episode steps: 520, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.767 [0.000, 5.000],  loss: 0.010177, mae: 0.502860, mean_q: 0.623158, mean_eps: 0.314740\n",
            " 191442/250000: episode: 280, duration: 28.318s, episode steps: 832, steps per second:  29, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.011865, mae: 0.512724, mean_q: 0.634175, mean_eps: 0.312306\n",
            " 192130/250000: episode: 281, duration: 23.186s, episode steps: 688, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.766 [0.000, 5.000],  loss: 0.011894, mae: 0.505999, mean_q: 0.626843, mean_eps: 0.309570\n",
            " 192945/250000: episode: 282, duration: 27.393s, episode steps: 815, steps per second:  30, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.012064, mae: 0.510497, mean_q: 0.633709, mean_eps: 0.306863\n",
            " 193630/250000: episode: 283, duration: 22.880s, episode steps: 685, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.012539, mae: 0.504146, mean_q: 0.623501, mean_eps: 0.304163\n",
            " 194120/250000: episode: 284, duration: 16.643s, episode steps: 490, steps per second:  29, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.011758, mae: 0.512609, mean_q: 0.637452, mean_eps: 0.302054\n",
            " 194577/250000: episode: 285, duration: 15.499s, episode steps: 457, steps per second:  29, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.009910, mae: 0.503149, mean_q: 0.627160, mean_eps: 0.300347\n",
            " 194977/250000: episode: 286, duration: 13.411s, episode steps: 400, steps per second:  30, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.011025, mae: 0.506572, mean_q: 0.629452, mean_eps: 0.298799\n",
            " 195301/250000: episode: 287, duration: 10.858s, episode steps: 324, steps per second:  30, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.011967, mae: 0.490888, mean_q: 0.610067, mean_eps: 0.297496\n",
            " 195671/250000: episode: 288, duration: 12.639s, episode steps: 370, steps per second:  29, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: 0.016402, mae: 0.508452, mean_q: 0.630247, mean_eps: 0.296250\n",
            " 196064/250000: episode: 289, duration: 13.467s, episode steps: 393, steps per second:  29, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.967 [0.000, 5.000],  loss: 0.014237, mae: 0.496089, mean_q: 0.612606, mean_eps: 0.294882\n",
            " 197301/250000: episode: 290, duration: 41.593s, episode steps: 1237, steps per second:  30, episode reward: 29.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.002 [0.000, 5.000],  loss: 0.010480, mae: 0.496928, mean_q: 0.617281, mean_eps: 0.291945\n",
            " 197955/250000: episode: 291, duration: 22.112s, episode steps: 654, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.028 [0.000, 5.000],  loss: 0.010147, mae: 0.505585, mean_q: 0.626641, mean_eps: 0.288539\n",
            " 198450/250000: episode: 292, duration: 16.876s, episode steps: 495, steps per second:  29, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.135 [0.000, 5.000],  loss: 0.010928, mae: 0.506209, mean_q: 0.628208, mean_eps: 0.286473\n",
            " 199644/250000: episode: 293, duration: 40.087s, episode steps: 1194, steps per second:  30, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.011018, mae: 0.497271, mean_q: 0.615827, mean_eps: 0.283434\n",
            " 200222/250000: episode: 294, duration: 19.291s, episode steps: 578, steps per second:  30, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.761 [0.000, 5.000],  loss: 0.011645, mae: 0.524841, mean_q: 0.651582, mean_eps: 0.280245\n",
            " 200860/250000: episode: 295, duration: 21.379s, episode steps: 638, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.011164, mae: 0.546005, mean_q: 0.678986, mean_eps: 0.278056\n",
            " 201413/250000: episode: 296, duration: 18.823s, episode steps: 553, steps per second:  29, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.989 [0.000, 5.000],  loss: 0.010300, mae: 0.531117, mean_q: 0.659069, mean_eps: 0.275910\n",
            " 201819/250000: episode: 297, duration: 13.550s, episode steps: 406, steps per second:  30, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.008766, mae: 0.544135, mean_q: 0.676694, mean_eps: 0.274182\n",
            " 202477/250000: episode: 298, duration: 22.064s, episode steps: 658, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.255 [0.000, 5.000],  loss: 0.009543, mae: 0.534137, mean_q: 0.662756, mean_eps: 0.272267\n",
            " 203016/250000: episode: 299, duration: 17.865s, episode steps: 539, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.012823, mae: 0.536251, mean_q: 0.662578, mean_eps: 0.270114\n",
            " 203783/250000: episode: 300, duration: 25.978s, episode steps: 767, steps per second:  30, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.030 [0.000, 5.000],  loss: 0.011701, mae: 0.538417, mean_q: 0.666156, mean_eps: 0.267767\n",
            " 204753/250000: episode: 301, duration: 32.999s, episode steps: 970, steps per second:  29, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.010782, mae: 0.535293, mean_q: 0.664147, mean_eps: 0.264635\n",
            " 205527/250000: episode: 302, duration: 26.490s, episode steps: 774, steps per second:  29, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: 0.010395, mae: 0.534532, mean_q: 0.663424, mean_eps: 0.261496\n",
            " 206016/250000: episode: 303, duration: 16.836s, episode steps: 489, steps per second:  29, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.755 [0.000, 5.000],  loss: 0.011318, mae: 0.534203, mean_q: 0.662623, mean_eps: 0.259228\n",
            " 206912/250000: episode: 304, duration: 30.332s, episode steps: 896, steps per second:  30, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.839 [0.000, 5.000],  loss: 0.012939, mae: 0.544655, mean_q: 0.676118, mean_eps: 0.256737\n",
            " 207397/250000: episode: 305, duration: 16.434s, episode steps: 485, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.012581, mae: 0.537298, mean_q: 0.667405, mean_eps: 0.254246\n",
            " 208175/250000: episode: 306, duration: 26.133s, episode steps: 778, steps per second:  30, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.009599, mae: 0.535733, mean_q: 0.665273, mean_eps: 0.251970\n",
            " 208664/250000: episode: 307, duration: 16.462s, episode steps: 489, steps per second:  30, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.012524, mae: 0.541175, mean_q: 0.671077, mean_eps: 0.249695\n",
            " 209399/250000: episode: 308, duration: 24.800s, episode steps: 735, steps per second:  30, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.976 [0.000, 5.000],  loss: 0.011312, mae: 0.534697, mean_q: 0.661313, mean_eps: 0.247492\n",
            " 210066/250000: episode: 309, duration: 22.621s, episode steps: 667, steps per second:  29, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.202 [0.000, 5.000],  loss: 0.009879, mae: 0.540361, mean_q: 0.669010, mean_eps: 0.244965\n",
            " 210404/250000: episode: 310, duration: 11.516s, episode steps: 338, steps per second:  29, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.007336, mae: 0.554684, mean_q: 0.687213, mean_eps: 0.243158\n",
            " 210960/250000: episode: 311, duration: 18.809s, episode steps: 556, steps per second:  30, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.010478, mae: 0.560468, mean_q: 0.690432, mean_eps: 0.241552\n",
            " 211530/250000: episode: 312, duration: 19.230s, episode steps: 570, steps per second:  30, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 1.921 [0.000, 5.000],  loss: 0.010417, mae: 0.562199, mean_q: 0.695223, mean_eps: 0.239522\n",
            " 212663/250000: episode: 313, duration: 38.257s, episode steps: 1133, steps per second:  30, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.767 [0.000, 5.000],  loss: 0.011051, mae: 0.562882, mean_q: 0.695189, mean_eps: 0.236454\n",
            " 213588/250000: episode: 314, duration: 31.401s, episode steps: 925, steps per second:  29, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.011576, mae: 0.559633, mean_q: 0.691656, mean_eps: 0.232754\n",
            " 214517/250000: episode: 315, duration: 32.098s, episode steps: 929, steps per second:  29, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.010957, mae: 0.563257, mean_q: 0.697665, mean_eps: 0.229413\n",
            " 215116/250000: episode: 316, duration: 20.379s, episode steps: 599, steps per second:  29, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.745 [0.000, 5.000],  loss: 0.010625, mae: 0.558093, mean_q: 0.692256, mean_eps: 0.226662\n",
            " 216155/250000: episode: 317, duration: 35.441s, episode steps: 1039, steps per second:  29, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.010988, mae: 0.562939, mean_q: 0.696777, mean_eps: 0.223718\n",
            " 216758/250000: episode: 318, duration: 20.337s, episode steps: 603, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.012005, mae: 0.561597, mean_q: 0.693931, mean_eps: 0.220758\n",
            " 217691/250000: episode: 319, duration: 31.974s, episode steps: 933, steps per second:  29, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.011410, mae: 0.561457, mean_q: 0.694477, mean_eps: 0.217994\n",
            " 218225/250000: episode: 320, duration: 18.693s, episode steps: 534, steps per second:  29, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.010082, mae: 0.551523, mean_q: 0.682682, mean_eps: 0.215351\n",
            " 219042/250000: episode: 321, duration: 27.857s, episode steps: 817, steps per second:  29, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.011218, mae: 0.564306, mean_q: 0.698820, mean_eps: 0.212918\n",
            " 220144/250000: episode: 322, duration: 37.586s, episode steps: 1102, steps per second:  29, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.011291, mae: 0.566547, mean_q: 0.704015, mean_eps: 0.209469\n",
            " 220513/250000: episode: 323, duration: 12.596s, episode steps: 369, steps per second:  29, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.190 [0.000, 5.000],  loss: 0.011679, mae: 0.615317, mean_q: 0.764036, mean_eps: 0.206819\n",
            " 221261/250000: episode: 324, duration: 25.571s, episode steps: 748, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.008915, mae: 0.595467, mean_q: 0.736569, mean_eps: 0.204803\n",
            " 222069/250000: episode: 325, duration: 27.492s, episode steps: 808, steps per second:  29, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.013512, mae: 0.597729, mean_q: 0.739070, mean_eps: 0.202002\n",
            " 223000/250000: episode: 326, duration: 31.754s, episode steps: 931, steps per second:  29, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.011414, mae: 0.591814, mean_q: 0.731169, mean_eps: 0.198878\n",
            " 223960/250000: episode: 327, duration: 32.948s, episode steps: 960, steps per second:  29, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.901 [0.000, 5.000],  loss: 0.015062, mae: 0.583902, mean_q: 0.720555, mean_eps: 0.195479\n",
            " 224906/250000: episode: 328, duration: 32.370s, episode steps: 946, steps per second:  29, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.127 [0.000, 5.000],  loss: 0.012263, mae: 0.594037, mean_q: 0.732478, mean_eps: 0.192045\n",
            " 225659/250000: episode: 329, duration: 26.054s, episode steps: 753, steps per second:  29, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.011549, mae: 0.594297, mean_q: 0.732538, mean_eps: 0.188985\n",
            " 226489/250000: episode: 330, duration: 28.363s, episode steps: 830, steps per second:  29, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.012910, mae: 0.592403, mean_q: 0.729600, mean_eps: 0.186134\n",
            " 227171/250000: episode: 331, duration: 23.149s, episode steps: 682, steps per second:  29, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.821 [0.000, 5.000],  loss: 0.013265, mae: 0.596467, mean_q: 0.733996, mean_eps: 0.183412\n",
            " 228098/250000: episode: 332, duration: 31.533s, episode steps: 927, steps per second:  29, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.771 [0.000, 5.000],  loss: 0.010242, mae: 0.587447, mean_q: 0.723946, mean_eps: 0.180518\n",
            " 228495/250000: episode: 333, duration: 13.474s, episode steps: 397, steps per second:  29, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.012235, mae: 0.583088, mean_q: 0.718692, mean_eps: 0.178134\n",
            " 229206/250000: episode: 334, duration: 24.525s, episode steps: 711, steps per second:  29, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.014832, mae: 0.603157, mean_q: 0.744071, mean_eps: 0.176140\n",
            " 229597/250000: episode: 335, duration: 13.656s, episode steps: 391, steps per second:  29, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.010836, mae: 0.596155, mean_q: 0.735388, mean_eps: 0.174153\n",
            " 230608/250000: episode: 336, duration: 34.592s, episode steps: 1011, steps per second:  29, episode reward: 27.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.013044, mae: 0.628103, mean_q: 0.778687, mean_eps: 0.171633\n",
            " 231318/250000: episode: 337, duration: 24.396s, episode steps: 710, steps per second:  29, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.114 [0.000, 5.000],  loss: 0.011636, mae: 0.648566, mean_q: 0.802120, mean_eps: 0.168537\n",
            " 232129/250000: episode: 338, duration: 27.818s, episode steps: 811, steps per second:  29, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.011881, mae: 0.636692, mean_q: 0.785609, mean_eps: 0.165794\n",
            " 232479/250000: episode: 339, duration: 11.933s, episode steps: 350, steps per second:  29, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.013222, mae: 0.626687, mean_q: 0.772629, mean_eps: 0.163706\n",
            " 233427/250000: episode: 340, duration: 32.740s, episode steps: 948, steps per second:  29, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.012 [0.000, 5.000],  loss: 0.012677, mae: 0.631045, mean_q: 0.778548, mean_eps: 0.161373\n",
            " 234435/250000: episode: 341, duration: 35.461s, episode steps: 1008, steps per second:  28, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.014793, mae: 0.651424, mean_q: 0.803011, mean_eps: 0.157852\n",
            " 235368/250000: episode: 342, duration: 33.345s, episode steps: 933, steps per second:  28, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.012315, mae: 0.637326, mean_q: 0.785553, mean_eps: 0.154360\n",
            " 236020/250000: episode: 343, duration: 23.239s, episode steps: 652, steps per second:  28, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.012829, mae: 0.644680, mean_q: 0.796022, mean_eps: 0.151509\n",
            " 237024/250000: episode: 344, duration: 35.327s, episode steps: 1004, steps per second:  28, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.019873, mae: 0.651142, mean_q: 0.799123, mean_eps: 0.148528\n",
            " 237494/250000: episode: 345, duration: 16.514s, episode steps: 470, steps per second:  28, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.100 [0.000, 5.000],  loss: 0.014375, mae: 0.653495, mean_q: 0.803287, mean_eps: 0.145871\n",
            " 238221/250000: episode: 346, duration: 25.586s, episode steps: 727, steps per second:  28, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.001 [0.000, 5.000],  loss: 0.013020, mae: 0.649785, mean_q: 0.799832, mean_eps: 0.143711\n",
            " 238671/250000: episode: 347, duration: 15.660s, episode steps: 450, steps per second:  29, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.189 [0.000, 5.000],  loss: 0.013089, mae: 0.643108, mean_q: 0.790378, mean_eps: 0.141594\n",
            " 239576/250000: episode: 348, duration: 31.459s, episode steps: 905, steps per second:  29, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.001 [0.000, 5.000],  loss: 0.011864, mae: 0.640871, mean_q: 0.788442, mean_eps: 0.139161\n",
            " 240224/250000: episode: 349, duration: 22.824s, episode steps: 648, steps per second:  28, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.010466, mae: 0.645830, mean_q: 0.795470, mean_eps: 0.136367\n",
            " 240879/250000: episode: 350, duration: 22.917s, episode steps: 655, steps per second:  29, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.960 [0.000, 5.000],  loss: 0.011785, mae: 0.670002, mean_q: 0.825531, mean_eps: 0.134020\n",
            " 241711/250000: episode: 351, duration: 28.878s, episode steps: 832, steps per second:  29, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.037 [0.000, 5.000],  loss: 0.012208, mae: 0.671426, mean_q: 0.824982, mean_eps: 0.131342\n",
            " 242985/250000: episode: 352, duration: 44.660s, episode steps: 1274, steps per second:  29, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.919 [0.000, 5.000],  loss: 0.013969, mae: 0.674485, mean_q: 0.831016, mean_eps: 0.127547\n",
            " 243344/250000: episode: 353, duration: 12.629s, episode steps: 359, steps per second:  28, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.012382, mae: 0.678699, mean_q: 0.837421, mean_eps: 0.124610\n",
            " 244015/250000: episode: 354, duration: 23.531s, episode steps: 671, steps per second:  29, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.823 [0.000, 5.000],  loss: 0.013865, mae: 0.675260, mean_q: 0.830676, mean_eps: 0.122759\n",
            " 244718/250000: episode: 355, duration: 24.687s, episode steps: 703, steps per second:  28, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.013322, mae: 0.686448, mean_q: 0.844730, mean_eps: 0.120282\n",
            " 245577/250000: episode: 356, duration: 29.861s, episode steps: 859, steps per second:  29, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.789 [0.000, 5.000],  loss: 0.011982, mae: 0.679313, mean_q: 0.838797, mean_eps: 0.117467\n",
            " 246580/250000: episode: 357, duration: 35.028s, episode steps: 1003, steps per second:  29, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.730 [0.000, 5.000],  loss: 0.012880, mae: 0.685839, mean_q: 0.844117, mean_eps: 0.114119\n",
            " 247236/250000: episode: 358, duration: 22.886s, episode steps: 656, steps per second:  29, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.849 [0.000, 5.000],  loss: 0.017406, mae: 0.686741, mean_q: 0.844371, mean_eps: 0.111138\n",
            " 247609/250000: episode: 359, duration: 13.080s, episode steps: 373, steps per second:  29, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.017544, mae: 0.677818, mean_q: 0.831908, mean_eps: 0.109281\n",
            " 248433/250000: episode: 360, duration: 28.451s, episode steps: 824, steps per second:  29, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.013273, mae: 0.682841, mean_q: 0.840459, mean_eps: 0.107121\n",
            " 249455/250000: episode: 361, duration: 35.388s, episode steps: 1022, steps per second:  29, episode reward: 28.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.015676, mae: 0.683792, mean_q: 0.840985, mean_eps: 0.103802\n",
            "done, took 8072.487 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 16.000, steps: 829\n",
            "Episode 2: reward: 12.000, steps: 671\n",
            "Episode 3: reward: 20.000, steps: 1077\n",
            "Episode 4: reward: 9.000, steps: 547\n",
            "Episode 5: reward: 7.000, steps: 387\n",
            "Episode 6: reward: 9.000, steps: 694\n",
            "Episode 7: reward: 19.000, steps: 954\n",
            "Episode 8: reward: 30.000, steps: 1337\n",
            "Episode 9: reward: 12.000, steps: 525\n",
            "Episode 10: reward: 22.000, steps: 960\n",
            "Episode 11: reward: 15.000, steps: 822\n",
            "Episode 12: reward: 12.000, steps: 680\n",
            "Episode 13: reward: 12.000, steps: 704\n",
            "Episode 14: reward: 20.000, steps: 973\n",
            "Episode 15: reward: 17.000, steps: 935\n",
            "Episode 16: reward: 12.000, steps: 634\n",
            "Episode 17: reward: 15.000, steps: 756\n",
            "Episode 18: reward: 9.000, steps: 526\n",
            "Episode 19: reward: 8.000, steps: 388\n",
            "Episode 20: reward: 10.000, steps: 557\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'History' object is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-1045547301.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# ==== Cálculo de promedio ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode_reward'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0mmean_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🎯 Recompensa promedio sobre 20 episodios: {mean_reward:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'History' object is not iterable"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Lambda, Add, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "\n",
        "# ==== Constantes ====\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "\n",
        "# ==== Procesador ====\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        img = Image.fromarray(observation).resize(INPUT_SHAPE).convert('L')\n",
        "        return np.array(img).astype('uint8')\n",
        "    def process_state_batch(self, batch):\n",
        "        return batch.astype('float32') / 255.\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "# ==== Dueling CNN tipo DeepMind ====\n",
        "def build_dueling_model(nb_actions, input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Permute((2, 3, 1))(inputs)\n",
        "    x = Conv2D(32, 8, strides=4, activation='relu')(x)\n",
        "    x = Conv2D(64, 4, strides=2, activation='relu')(x)\n",
        "    x = Conv2D(64, 3, strides=1, activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Dueling streams\n",
        "    value = Dense(512, activation='relu')(x)\n",
        "    value = Dense(1)(value)\n",
        "\n",
        "    advantage = Dense(512, activation='relu')(x)\n",
        "    advantage = Dense(nb_actions)(advantage)\n",
        "\n",
        "    # Combine streams\n",
        "    advantage_mean = Lambda(lambda a: a - K.mean(a, axis=1, keepdims=True))(advantage)\n",
        "    q_values = Add()([value, advantage_mean])\n",
        "\n",
        "    return Model(inputs=inputs, outputs=q_values)\n",
        "\n",
        "# ==== Preparar entorno ====\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "\n",
        "# ==== Modelo y agente ====\n",
        "model = build_dueling_model(nb_actions, input_shape)\n",
        "\n",
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=1.0, value_min=0.1, value_test=0.05,\n",
        "                              nb_steps=250000)\n",
        "\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               memory=memory,\n",
        "               processor=AtariProcessor(),\n",
        "               nb_steps_warmup=10000,\n",
        "               enable_double_dqn=True,\n",
        "               target_model_update=10000,\n",
        "               policy=policy,\n",
        "               train_interval=4,\n",
        "               gamma=0.99)\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.00025), metrics=['mae'])\n",
        "\n",
        "# ==== Entrenamiento rápido ====\n",
        "dqn.fit(env,\n",
        "        nb_steps=250000,\n",
        "        visualize=False,\n",
        "        verbose=2)\n",
        "\n",
        "# ==== Guardar modelo ====\n",
        "dqn.save_weights(f'dqn_{ENV_NAME}_dueling_double.h5f', overwrite=True)\n",
        "\n",
        "# ==== Evaluación ====\n",
        "history = dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "# ==== Cálculo de promedio ====\n",
        "rewards = [ep.history['episode_reward'][0] for ep in history]\n",
        "mean_reward = np.mean(rewards)\n",
        "print(f\"\\n🎯 Recompensa promedio sobre 20 episodios: {mean_reward:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mK_7sjPv3ueF",
        "outputId": "1fc65718-90ad-4976-8260-a95a7ccdedfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 250000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    420/250000: episode: 1, duration: 1.746s, episode steps: 420, steps per second: 241, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "    980/250000: episode: 2, duration: 2.239s, episode steps: 560, steps per second: 250, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1378/250000: episode: 3, duration: 1.620s, episode steps: 398, steps per second: 246, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2082/250000: episode: 4, duration: 2.803s, episode steps: 704, steps per second: 251, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2997/250000: episode: 5, duration: 3.605s, episode steps: 915, steps per second: 254, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3958/250000: episode: 6, duration: 3.853s, episode steps: 961, steps per second: 249, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4693/250000: episode: 7, duration: 3.007s, episode steps: 735, steps per second: 244, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5382/250000: episode: 8, duration: 2.757s, episode steps: 689, steps per second: 250, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6668/250000: episode: 9, duration: 4.974s, episode steps: 1286, steps per second: 259, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7086/250000: episode: 10, duration: 1.671s, episode steps: 418, steps per second: 250, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7680/250000: episode: 11, duration: 2.311s, episode steps: 594, steps per second: 257, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8516/250000: episode: 12, duration: 3.209s, episode steps: 836, steps per second: 261, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9002/250000: episode: 13, duration: 1.891s, episode steps: 486, steps per second: 257, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9372/250000: episode: 14, duration: 1.432s, episode steps: 370, steps per second: 258, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9719/250000: episode: 15, duration: 1.383s, episode steps: 347, steps per second: 251, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10434/250000: episode: 16, duration: 2.895s, episode steps: 715, steps per second: 247, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11452/250000: episode: 17, duration: 3.989s, episode steps: 1018, steps per second: 255, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12080/250000: episode: 18, duration: 2.487s, episode steps: 628, steps per second: 253, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12837/250000: episode: 19, duration: 2.968s, episode steps: 757, steps per second: 255, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13263/250000: episode: 20, duration: 1.721s, episode steps: 426, steps per second: 248, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13958/250000: episode: 21, duration: 2.768s, episode steps: 695, steps per second: 251, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14336/250000: episode: 22, duration: 1.499s, episode steps: 378, steps per second: 252, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15054/250000: episode: 23, duration: 2.830s, episode steps: 718, steps per second: 254, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15654/250000: episode: 24, duration: 2.340s, episode steps: 600, steps per second: 256, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16316/250000: episode: 25, duration: 2.691s, episode steps: 662, steps per second: 246, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16840/250000: episode: 26, duration: 2.103s, episode steps: 524, steps per second: 249, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17486/250000: episode: 27, duration: 2.555s, episode steps: 646, steps per second: 253, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17848/250000: episode: 28, duration: 1.423s, episode steps: 362, steps per second: 254, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18600/250000: episode: 29, duration: 2.936s, episode steps: 752, steps per second: 256, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19107/250000: episode: 30, duration: 1.988s, episode steps: 507, steps per second: 255, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19826/250000: episode: 31, duration: 2.874s, episode steps: 719, steps per second: 250, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20766/250000: episode: 32, duration: 3.644s, episode steps: 940, steps per second: 258, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21389/250000: episode: 33, duration: 2.430s, episode steps: 623, steps per second: 256, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22009/250000: episode: 34, duration: 2.425s, episode steps: 620, steps per second: 256, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22857/250000: episode: 35, duration: 3.396s, episode steps: 848, steps per second: 250, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23498/250000: episode: 36, duration: 2.568s, episode steps: 641, steps per second: 250, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24056/250000: episode: 37, duration: 2.181s, episode steps: 558, steps per second: 256, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24680/250000: episode: 38, duration: 2.482s, episode steps: 624, steps per second: 251, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25518/250000: episode: 39, duration: 3.330s, episode steps: 838, steps per second: 252, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26402/250000: episode: 40, duration: 3.507s, episode steps: 884, steps per second: 252, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27363/250000: episode: 41, duration: 3.770s, episode steps: 961, steps per second: 255, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27744/250000: episode: 42, duration: 1.476s, episode steps: 381, steps per second: 258, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28546/250000: episode: 43, duration: 3.100s, episode steps: 802, steps per second: 259, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28923/250000: episode: 44, duration: 1.511s, episode steps: 377, steps per second: 249, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30157/250000: episode: 45, duration: 4.792s, episode steps: 1234, steps per second: 258, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30925/250000: episode: 46, duration: 3.000s, episode steps: 768, steps per second: 256, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31947/250000: episode: 47, duration: 4.064s, episode steps: 1022, steps per second: 251, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32981/250000: episode: 48, duration: 4.061s, episode steps: 1034, steps per second: 255, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33942/250000: episode: 49, duration: 3.757s, episode steps: 961, steps per second: 256, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34600/250000: episode: 50, duration: 2.589s, episode steps: 658, steps per second: 254, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35495/250000: episode: 51, duration: 3.605s, episode steps: 895, steps per second: 248, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36073/250000: episode: 52, duration: 2.240s, episode steps: 578, steps per second: 258, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37004/250000: episode: 53, duration: 3.634s, episode steps: 931, steps per second: 256, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37550/250000: episode: 54, duration: 2.179s, episode steps: 546, steps per second: 251, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38139/250000: episode: 55, duration: 2.401s, episode steps: 589, steps per second: 245, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39291/250000: episode: 56, duration: 4.510s, episode steps: 1152, steps per second: 255, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40691/250000: episode: 57, duration: 5.456s, episode steps: 1400, steps per second: 257, episode reward: 12.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41100/250000: episode: 58, duration: 1.785s, episode steps: 409, steps per second: 229, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42120/250000: episode: 59, duration: 4.047s, episode steps: 1020, steps per second: 252, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42512/250000: episode: 60, duration: 1.573s, episode steps: 392, steps per second: 249, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42903/250000: episode: 61, duration: 1.539s, episode steps: 391, steps per second: 254, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.675 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43512/250000: episode: 62, duration: 2.375s, episode steps: 609, steps per second: 256, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44043/250000: episode: 63, duration: 2.089s, episode steps: 531, steps per second: 254, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44433/250000: episode: 64, duration: 1.608s, episode steps: 390, steps per second: 243, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44905/250000: episode: 65, duration: 1.855s, episode steps: 472, steps per second: 254, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45613/250000: episode: 66, duration: 2.790s, episode steps: 708, steps per second: 254, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46571/250000: episode: 67, duration: 3.724s, episode steps: 958, steps per second: 257, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47356/250000: episode: 68, duration: 3.122s, episode steps: 785, steps per second: 251, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47727/250000: episode: 69, duration: 1.491s, episode steps: 371, steps per second: 249, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49213/250000: episode: 70, duration: 5.684s, episode steps: 1486, steps per second: 261, episode reward: 14.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49713/250000: episode: 71, duration: 1.951s, episode steps: 500, steps per second: 256, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  51187/250000: episode: 72, duration: 39.572s, episode steps: 1474, steps per second:  37, episode reward: 18.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.006931, mae: 0.027104, mean_q: -0.007060, mean_eps: 0.807743\n",
            "  52408/250000: episode: 73, duration: 39.177s, episode steps: 1221, steps per second:  31, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.007140, mae: 0.029669, mean_q: -0.014024, mean_eps: 0.803175\n",
            "  52750/250000: episode: 74, duration: 10.971s, episode steps: 342, steps per second:  31, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.005961, mae: 0.024196, mean_q: -0.012315, mean_eps: 0.800204\n",
            "  53974/250000: episode: 75, duration: 39.550s, episode steps: 1224, steps per second:  31, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.005618, mae: 0.028509, mean_q: -0.017955, mean_eps: 0.797224\n",
            "  54472/250000: episode: 76, duration: 16.033s, episode steps: 498, steps per second:  31, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.705 [0.000, 5.000],  loss: 0.007490, mae: 0.026283, mean_q: -0.011578, mean_eps: 0.793956\n",
            "  54814/250000: episode: 77, duration: 11.026s, episode steps: 342, steps per second:  31, episode reward:  6.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.004222, mae: 0.032694, mean_q: -0.025694, mean_eps: 0.792360\n",
            "  55324/250000: episode: 78, duration: 16.444s, episode steps: 510, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.005744, mae: 0.029321, mean_q: -0.022419, mean_eps: 0.790742\n",
            "  55992/250000: episode: 79, duration: 22.231s, episode steps: 668, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.006939, mae: 0.025963, mean_q: -0.013604, mean_eps: 0.788507\n",
            "  57532/250000: episode: 80, duration: 49.761s, episode steps: 1540, steps per second:  31, episode reward: 16.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.005916, mae: 0.027531, mean_q: -0.015142, mean_eps: 0.784312\n",
            "  57921/250000: episode: 81, duration: 12.757s, episode steps: 389, steps per second:  30, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.006045, mae: 0.026541, mean_q: -0.017542, mean_eps: 0.780641\n",
            "  58422/250000: episode: 82, duration: 16.201s, episode steps: 501, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006078, mae: 0.025470, mean_q: -0.009258, mean_eps: 0.778946\n",
            "  58842/250000: episode: 83, duration: 13.433s, episode steps: 420, steps per second:  31, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.006225, mae: 0.027915, mean_q: -0.015711, mean_eps: 0.777198\n",
            "  59370/250000: episode: 84, duration: 16.855s, episode steps: 528, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006020, mae: 0.029541, mean_q: -0.019726, mean_eps: 0.775397\n",
            "  59901/250000: episode: 85, duration: 17.121s, episode steps: 531, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.006377, mae: 0.030724, mean_q: -0.018314, mean_eps: 0.773383\n",
            "  60649/250000: episode: 86, duration: 23.943s, episode steps: 748, steps per second:  31, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.006443, mae: 0.026468, mean_q: 0.005800, mean_eps: 0.770951\n",
            "  61306/250000: episode: 87, duration: 20.880s, episode steps: 657, steps per second:  31, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.005454, mae: 0.025843, mean_q: 0.002632, mean_eps: 0.768284\n",
            "  61894/250000: episode: 88, duration: 18.888s, episode steps: 588, steps per second:  31, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.005392, mae: 0.025058, mean_q: -0.000342, mean_eps: 0.765920\n",
            "  62554/250000: episode: 89, duration: 21.225s, episode steps: 660, steps per second:  31, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.005804, mae: 0.024751, mean_q: 0.001252, mean_eps: 0.763549\n",
            "  63100/250000: episode: 90, duration: 17.466s, episode steps: 546, steps per second:  31, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.006262, mae: 0.024561, mean_q: 0.001374, mean_eps: 0.761261\n",
            "  63573/250000: episode: 91, duration: 15.239s, episode steps: 473, steps per second:  31, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.005946, mae: 0.025389, mean_q: 0.005567, mean_eps: 0.759323\n",
            "  64216/250000: episode: 92, duration: 20.642s, episode steps: 643, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.006899, mae: 0.026264, mean_q: 0.006471, mean_eps: 0.757203\n",
            "  65325/250000: episode: 93, duration: 35.540s, episode steps: 1109, steps per second:  31, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.005949, mae: 0.028119, mean_q: 0.002758, mean_eps: 0.753874\n",
            "  65845/250000: episode: 94, duration: 16.662s, episode steps: 520, steps per second:  31, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.004774, mae: 0.023955, mean_q: 0.000308, mean_eps: 0.750773\n",
            "  66354/250000: episode: 95, duration: 16.404s, episode steps: 509, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006149, mae: 0.027420, mean_q: 0.001339, mean_eps: 0.748820\n",
            "  66982/250000: episode: 96, duration: 20.072s, episode steps: 628, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.006624, mae: 0.027915, mean_q: 0.003307, mean_eps: 0.746662\n",
            "  67686/250000: episode: 97, duration: 22.664s, episode steps: 704, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.006837, mae: 0.028528, mean_q: 0.005809, mean_eps: 0.744131\n",
            "  68777/250000: episode: 98, duration: 35.088s, episode steps: 1091, steps per second:  31, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.005683, mae: 0.027982, mean_q: 0.002805, mean_eps: 0.740718\n",
            "  70055/250000: episode: 99, duration: 40.949s, episode steps: 1278, steps per second:  31, episode reward: 29.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.006591, mae: 0.026663, mean_q: 0.003768, mean_eps: 0.736219\n",
            "  70852/250000: episode: 100, duration: 25.636s, episode steps: 797, steps per second:  31, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.006115, mae: 0.027321, mean_q: 0.004312, mean_eps: 0.732282\n",
            "  71621/250000: episode: 101, duration: 24.744s, episode steps: 769, steps per second:  31, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.007004, mae: 0.028673, mean_q: 0.008649, mean_eps: 0.729303\n",
            "  72035/250000: episode: 102, duration: 13.413s, episode steps: 414, steps per second:  31, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.775 [0.000, 5.000],  loss: 0.006088, mae: 0.026938, mean_q: 0.004833, mean_eps: 0.727054\n",
            "  72996/250000: episode: 103, duration: 30.953s, episode steps: 961, steps per second:  31, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.007033, mae: 0.027974, mean_q: 0.006869, mean_eps: 0.724447\n",
            "  73546/250000: episode: 104, duration: 17.822s, episode steps: 550, steps per second:  31, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.004438, mae: 0.025539, mean_q: 0.001674, mean_eps: 0.721574\n",
            "  74564/250000: episode: 105, duration: 32.609s, episode steps: 1018, steps per second:  31, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.735 [0.000, 5.000],  loss: 0.007225, mae: 0.027664, mean_q: 0.006725, mean_eps: 0.718595\n",
            "  75392/250000: episode: 106, duration: 26.745s, episode steps: 828, steps per second:  31, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.008046, mae: 0.030175, mean_q: 0.009759, mean_eps: 0.715091\n",
            "  75762/250000: episode: 107, duration: 11.956s, episode steps: 370, steps per second:  31, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.114 [0.000, 5.000],  loss: 0.007482, mae: 0.030269, mean_q: 0.010444, mean_eps: 0.712811\n",
            "  76443/250000: episode: 108, duration: 22.234s, episode steps: 681, steps per second:  31, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.006459, mae: 0.029977, mean_q: 0.009069, mean_eps: 0.710812\n",
            "  76955/250000: episode: 109, duration: 16.666s, episode steps: 512, steps per second:  31, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.005984, mae: 0.028780, mean_q: 0.005567, mean_eps: 0.708548\n",
            "  77931/250000: episode: 110, duration: 31.350s, episode steps: 976, steps per second:  31, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.007286, mae: 0.031534, mean_q: 0.010541, mean_eps: 0.705720\n",
            "  78687/250000: episode: 111, duration: 24.644s, episode steps: 756, steps per second:  31, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.286 [0.000, 5.000],  loss: 0.007353, mae: 0.029360, mean_q: 0.008798, mean_eps: 0.702430\n",
            "  79119/250000: episode: 112, duration: 13.899s, episode steps: 432, steps per second:  31, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.005030, mae: 0.028540, mean_q: 0.006538, mean_eps: 0.700172\n",
            "  79810/250000: episode: 113, duration: 22.446s, episode steps: 691, steps per second:  31, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.006746, mae: 0.030392, mean_q: 0.007924, mean_eps: 0.698037\n",
            "  80672/250000: episode: 114, duration: 27.636s, episode steps: 862, steps per second:  31, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.006192, mae: 0.028379, mean_q: 0.008601, mean_eps: 0.695088\n",
            "  81383/250000: episode: 115, duration: 23.076s, episode steps: 711, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.006759, mae: 0.028455, mean_q: 0.006057, mean_eps: 0.692101\n",
            "  81912/250000: episode: 116, duration: 17.182s, episode steps: 529, steps per second:  31, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.007019, mae: 0.031169, mean_q: 0.008868, mean_eps: 0.689745\n",
            "  83447/250000: episode: 117, duration: 49.519s, episode steps: 1535, steps per second:  31, episode reward: 23.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.005950, mae: 0.029453, mean_q: 0.008737, mean_eps: 0.685824\n",
            "  83955/250000: episode: 118, duration: 16.427s, episode steps: 508, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.768 [0.000, 5.000],  loss: 0.005472, mae: 0.026015, mean_q: 0.003775, mean_eps: 0.681940\n",
            "  84307/250000: episode: 119, duration: 11.659s, episode steps: 352, steps per second:  30, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.007582, mae: 0.029481, mean_q: 0.008920, mean_eps: 0.680306\n",
            "  84941/250000: episode: 120, duration: 20.613s, episode steps: 634, steps per second:  31, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.006021, mae: 0.029830, mean_q: 0.010248, mean_eps: 0.678429\n",
            "  85294/250000: episode: 121, duration: 11.611s, episode steps: 353, steps per second:  30, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.007044, mae: 0.029528, mean_q: 0.009019, mean_eps: 0.676552\n",
            "  86431/250000: episode: 122, duration: 36.616s, episode steps: 1137, steps per second:  31, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.006960, mae: 0.029912, mean_q: 0.009240, mean_eps: 0.673724\n",
            "  86861/250000: episode: 123, duration: 13.893s, episode steps: 430, steps per second:  31, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.007392, mae: 0.029785, mean_q: 0.010983, mean_eps: 0.670745\n",
            "  88058/250000: episode: 124, duration: 38.528s, episode steps: 1197, steps per second:  31, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.006134, mae: 0.029137, mean_q: 0.008697, mean_eps: 0.667652\n",
            "  88678/250000: episode: 125, duration: 20.017s, episode steps: 620, steps per second:  31, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.008070, mae: 0.031885, mean_q: 0.013983, mean_eps: 0.664202\n",
            "  89567/250000: episode: 126, duration: 28.480s, episode steps: 889, steps per second:  31, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.006663, mae: 0.030485, mean_q: 0.010897, mean_eps: 0.661336\n",
            "  90116/250000: episode: 127, duration: 17.861s, episode steps: 549, steps per second:  31, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.823 [0.000, 5.000],  loss: 0.007484, mae: 0.031232, mean_q: 0.018728, mean_eps: 0.658608\n",
            "  90506/250000: episode: 128, duration: 13.216s, episode steps: 390, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.754 [0.000, 5.000],  loss: 0.006885, mae: 0.044062, mean_q: 0.053470, mean_eps: 0.656822\n",
            "  91161/250000: episode: 129, duration: 21.918s, episode steps: 655, steps per second:  30, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.007952, mae: 0.046936, mean_q: 0.054227, mean_eps: 0.654831\n",
            "  91763/250000: episode: 130, duration: 19.964s, episode steps: 602, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.875 [0.000, 5.000],  loss: 0.006967, mae: 0.044558, mean_q: 0.049079, mean_eps: 0.652444\n",
            "  92279/250000: episode: 131, duration: 17.203s, episode steps: 516, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.777 [0.000, 5.000],  loss: 0.006881, mae: 0.044021, mean_q: 0.046411, mean_eps: 0.650324\n",
            "  92966/250000: episode: 132, duration: 22.797s, episode steps: 687, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.006408, mae: 0.041871, mean_q: 0.043262, mean_eps: 0.648036\n",
            "  93368/250000: episode: 133, duration: 13.366s, episode steps: 402, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.006757, mae: 0.043756, mean_q: 0.047447, mean_eps: 0.645969\n",
            "  93710/250000: episode: 134, duration: 11.384s, episode steps: 342, steps per second:  30, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006310, mae: 0.042258, mean_q: 0.044534, mean_eps: 0.644556\n",
            "  94901/250000: episode: 135, duration: 39.249s, episode steps: 1191, steps per second:  30, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.006529, mae: 0.043720, mean_q: 0.044039, mean_eps: 0.641637\n",
            "  95672/250000: episode: 136, duration: 25.291s, episode steps: 771, steps per second:  30, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.006853, mae: 0.042158, mean_q: 0.043038, mean_eps: 0.637913\n",
            "  96534/250000: episode: 137, duration: 28.643s, episode steps: 862, steps per second:  30, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.005966, mae: 0.039089, mean_q: 0.038933, mean_eps: 0.634812\n",
            "  97411/250000: episode: 138, duration: 28.858s, episode steps: 877, steps per second:  30, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.006947, mae: 0.043683, mean_q: 0.044816, mean_eps: 0.631506\n",
            "  98079/250000: episode: 139, duration: 22.102s, episode steps: 668, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.005508, mae: 0.041211, mean_q: 0.043385, mean_eps: 0.628573\n",
            "  98470/250000: episode: 140, duration: 12.962s, episode steps: 391, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.007169, mae: 0.046036, mean_q: 0.046529, mean_eps: 0.626559\n",
            "  99142/250000: episode: 141, duration: 22.191s, episode steps: 672, steps per second:  30, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006459, mae: 0.042421, mean_q: 0.043415, mean_eps: 0.624537\n",
            "  99754/250000: episode: 142, duration: 20.242s, episode steps: 612, steps per second:  30, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.742 [0.000, 5.000],  loss: 0.006618, mae: 0.043387, mean_q: 0.043762, mean_eps: 0.622098\n",
            " 100441/250000: episode: 143, duration: 22.870s, episode steps: 687, steps per second:  30, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.006602, mae: 0.043033, mean_q: 0.045060, mean_eps: 0.619628\n",
            " 101529/250000: episode: 144, duration: 35.710s, episode steps: 1088, steps per second:  30, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.950 [0.000, 5.000],  loss: 0.005533, mae: 0.040637, mean_q: 0.040555, mean_eps: 0.616253\n",
            " 102056/250000: episode: 145, duration: 17.678s, episode steps: 527, steps per second:  30, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.005669, mae: 0.041447, mean_q: 0.038920, mean_eps: 0.613190\n",
            " 103265/250000: episode: 146, duration: 40.056s, episode steps: 1209, steps per second:  30, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.006052, mae: 0.041650, mean_q: 0.042881, mean_eps: 0.609892\n",
            " 103882/250000: episode: 147, duration: 20.348s, episode steps: 617, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.006087, mae: 0.040504, mean_q: 0.043073, mean_eps: 0.606419\n",
            " 104440/250000: episode: 148, duration: 18.573s, episode steps: 558, steps per second:  30, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.008160, mae: 0.044750, mean_q: 0.047381, mean_eps: 0.604192\n",
            " 105109/250000: episode: 149, duration: 22.254s, episode steps: 669, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.111 [0.000, 5.000],  loss: 0.007271, mae: 0.045037, mean_q: 0.045129, mean_eps: 0.601859\n",
            " 105904/250000: episode: 150, duration: 26.460s, episode steps: 795, steps per second:  30, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.007421, mae: 0.043856, mean_q: 0.046543, mean_eps: 0.599077\n",
            " 106652/250000: episode: 151, duration: 25.109s, episode steps: 748, steps per second:  30, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.006733, mae: 0.042883, mean_q: 0.044291, mean_eps: 0.596151\n",
            " 107302/250000: episode: 152, duration: 21.667s, episode steps: 650, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.007134, mae: 0.045375, mean_q: 0.048426, mean_eps: 0.593491\n",
            " 108022/250000: episode: 153, duration: 23.930s, episode steps: 720, steps per second:  30, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006838, mae: 0.042759, mean_q: 0.044557, mean_eps: 0.590884\n",
            " 109044/250000: episode: 154, duration: 34.447s, episode steps: 1022, steps per second:  30, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.186 [0.000, 5.000],  loss: 0.006371, mae: 0.042045, mean_q: 0.045431, mean_eps: 0.587578\n",
            " 110166/250000: episode: 155, duration: 37.583s, episode steps: 1122, steps per second:  30, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.006246, mae: 0.040860, mean_q: 0.041299, mean_eps: 0.583505\n",
            " 110796/250000: episode: 156, duration: 21.177s, episode steps: 630, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.005225, mae: 0.038371, mean_q: 0.039879, mean_eps: 0.580176\n",
            " 111164/250000: episode: 157, duration: 12.495s, episode steps: 368, steps per second:  29, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.007099, mae: 0.042787, mean_q: 0.042199, mean_eps: 0.578284\n",
            " 111844/250000: episode: 158, duration: 22.732s, episode steps: 680, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.005727, mae: 0.039072, mean_q: 0.038593, mean_eps: 0.576292\n",
            " 112716/250000: episode: 159, duration: 29.410s, episode steps: 872, steps per second:  30, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.006717, mae: 0.045106, mean_q: 0.046283, mean_eps: 0.573344\n",
            " 113174/250000: episode: 160, duration: 15.426s, episode steps: 458, steps per second:  30, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.005238, mae: 0.040236, mean_q: 0.041820, mean_eps: 0.570813\n",
            " 113696/250000: episode: 161, duration: 17.456s, episode steps: 522, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.234 [0.000, 5.000],  loss: 0.006309, mae: 0.042825, mean_q: 0.043448, mean_eps: 0.568951\n",
            " 114655/250000: episode: 162, duration: 31.816s, episode steps: 959, steps per second:  30, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.006177, mae: 0.042771, mean_q: 0.044600, mean_eps: 0.566139\n",
            " 115467/250000: episode: 163, duration: 26.675s, episode steps: 812, steps per second:  30, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.006537, mae: 0.042380, mean_q: 0.043866, mean_eps: 0.562772\n",
            " 116494/250000: episode: 164, duration: 34.165s, episode steps: 1027, steps per second:  30, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.006400, mae: 0.042325, mean_q: 0.043085, mean_eps: 0.559276\n",
            " 117145/250000: episode: 165, duration: 21.635s, episode steps: 651, steps per second:  30, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.007028, mae: 0.044292, mean_q: 0.046099, mean_eps: 0.556084\n",
            " 117625/250000: episode: 166, duration: 15.977s, episode steps: 480, steps per second:  30, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.006572, mae: 0.044549, mean_q: 0.047693, mean_eps: 0.553933\n",
            " 118754/250000: episode: 167, duration: 37.599s, episode steps: 1129, steps per second:  30, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.005739, mae: 0.043064, mean_q: 0.045918, mean_eps: 0.550878\n",
            " 119424/250000: episode: 168, duration: 22.495s, episode steps: 670, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.007288, mae: 0.045840, mean_q: 0.048694, mean_eps: 0.547466\n",
            " 119933/250000: episode: 169, duration: 16.917s, episode steps: 509, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.006784, mae: 0.044855, mean_q: 0.049342, mean_eps: 0.545224\n",
            " 121062/250000: episode: 170, duration: 37.388s, episode steps: 1129, steps per second:  30, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.005902, mae: 0.050868, mean_q: 0.059489, mean_eps: 0.542108\n",
            " 122120/250000: episode: 171, duration: 34.817s, episode steps: 1058, steps per second:  30, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.006844, mae: 0.053027, mean_q: 0.061496, mean_eps: 0.537958\n",
            " 122629/250000: episode: 172, duration: 17.051s, episode steps: 509, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.804 [0.000, 5.000],  loss: 0.006217, mae: 0.054280, mean_q: 0.064291, mean_eps: 0.534979\n",
            " 123206/250000: episode: 173, duration: 19.029s, episode steps: 577, steps per second:  30, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.005437, mae: 0.051141, mean_q: 0.059955, mean_eps: 0.532912\n",
            " 124098/250000: episode: 174, duration: 29.546s, episode steps: 892, steps per second:  30, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.005448, mae: 0.050820, mean_q: 0.057039, mean_eps: 0.530122\n",
            " 124605/250000: episode: 175, duration: 16.955s, episode steps: 507, steps per second:  30, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.059 [0.000, 5.000],  loss: 0.007147, mae: 0.054972, mean_q: 0.064979, mean_eps: 0.527462\n",
            " 125709/250000: episode: 176, duration: 37.198s, episode steps: 1104, steps per second:  30, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.006082, mae: 0.052545, mean_q: 0.059130, mean_eps: 0.524400\n",
            " 126233/250000: episode: 177, duration: 17.764s, episode steps: 524, steps per second:  29, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.006909, mae: 0.054557, mean_q: 0.061156, mean_eps: 0.521306\n",
            " 126901/250000: episode: 178, duration: 22.347s, episode steps: 668, steps per second:  30, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.099 [0.000, 5.000],  loss: 0.005751, mae: 0.051285, mean_q: 0.060261, mean_eps: 0.519042\n",
            " 127983/250000: episode: 179, duration: 36.361s, episode steps: 1082, steps per second:  30, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.007310, mae: 0.056261, mean_q: 0.065170, mean_eps: 0.515720\n",
            " 129028/250000: episode: 180, duration: 35.285s, episode steps: 1045, steps per second:  30, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.005266, mae: 0.050905, mean_q: 0.058558, mean_eps: 0.511685\n",
            " 129673/250000: episode: 181, duration: 21.704s, episode steps: 645, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: 0.006970, mae: 0.053785, mean_q: 0.061026, mean_eps: 0.508470\n",
            " 130314/250000: episode: 182, duration: 21.326s, episode steps: 641, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.778 [0.000, 5.000],  loss: 0.006405, mae: 0.050771, mean_q: 0.058236, mean_eps: 0.506023\n",
            " 131011/250000: episode: 183, duration: 23.055s, episode steps: 697, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.796 [0.000, 5.000],  loss: 0.006252, mae: 0.050472, mean_q: 0.056380, mean_eps: 0.503484\n",
            " 132565/250000: episode: 184, duration: 51.179s, episode steps: 1554, steps per second:  30, episode reward: 26.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.006840, mae: 0.053120, mean_q: 0.060319, mean_eps: 0.499206\n",
            " 133245/250000: episode: 185, duration: 22.482s, episode steps: 680, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.894 [0.000, 5.000],  loss: 0.006158, mae: 0.052855, mean_q: 0.057305, mean_eps: 0.494957\n",
            " 133980/250000: episode: 186, duration: 24.274s, episode steps: 735, steps per second:  30, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.005441, mae: 0.050242, mean_q: 0.055789, mean_eps: 0.492274\n",
            " 135046/250000: episode: 187, duration: 35.326s, episode steps: 1066, steps per second:  30, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.005575, mae: 0.050933, mean_q: 0.058727, mean_eps: 0.488854\n",
            " 135563/250000: episode: 188, duration: 17.073s, episode steps: 517, steps per second:  30, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.006228, mae: 0.053582, mean_q: 0.060894, mean_eps: 0.485845\n",
            " 136194/250000: episode: 189, duration: 20.909s, episode steps: 631, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.006123, mae: 0.052793, mean_q: 0.060878, mean_eps: 0.483664\n",
            " 136809/250000: episode: 190, duration: 20.356s, episode steps: 615, steps per second:  30, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.007467, mae: 0.054367, mean_q: 0.063328, mean_eps: 0.481292\n",
            " 137436/250000: episode: 191, duration: 20.828s, episode steps: 627, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.004767, mae: 0.049329, mean_q: 0.055075, mean_eps: 0.478936\n",
            " 138074/250000: episode: 192, duration: 21.237s, episode steps: 638, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.006109, mae: 0.052561, mean_q: 0.057845, mean_eps: 0.476535\n",
            " 138764/250000: episode: 193, duration: 23.035s, episode steps: 690, steps per second:  30, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.841 [0.000, 5.000],  loss: 0.005713, mae: 0.051448, mean_q: 0.057799, mean_eps: 0.474012\n",
            " 139573/250000: episode: 194, duration: 27.183s, episode steps: 809, steps per second:  30, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.006187, mae: 0.051029, mean_q: 0.058951, mean_eps: 0.471162\n",
            " 140379/250000: episode: 195, duration: 26.624s, episode steps: 806, steps per second:  30, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.006720, mae: 0.052537, mean_q: 0.059931, mean_eps: 0.468091\n",
            " 141154/250000: episode: 196, duration: 26.012s, episode steps: 775, steps per second:  30, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.006126, mae: 0.052339, mean_q: 0.059859, mean_eps: 0.465089\n",
            " 141862/250000: episode: 197, duration: 23.547s, episode steps: 708, steps per second:  30, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.798 [0.000, 5.000],  loss: 0.006187, mae: 0.051854, mean_q: 0.058569, mean_eps: 0.462270\n",
            " 142660/250000: episode: 198, duration: 26.554s, episode steps: 798, steps per second:  30, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.006346, mae: 0.053350, mean_q: 0.059303, mean_eps: 0.459412\n",
            " 143299/250000: episode: 199, duration: 21.427s, episode steps: 639, steps per second:  30, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.005171, mae: 0.050157, mean_q: 0.055497, mean_eps: 0.456684\n",
            " 144019/250000: episode: 200, duration: 23.985s, episode steps: 720, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.154 [0.000, 5.000],  loss: 0.005402, mae: 0.049607, mean_q: 0.055712, mean_eps: 0.454100\n",
            " 144838/250000: episode: 201, duration: 27.422s, episode steps: 819, steps per second:  30, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.006678, mae: 0.052885, mean_q: 0.060235, mean_eps: 0.451174\n",
            " 145481/250000: episode: 202, duration: 21.405s, episode steps: 643, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.006295, mae: 0.054017, mean_q: 0.062274, mean_eps: 0.448392\n",
            " 145864/250000: episode: 203, duration: 12.680s, episode steps: 383, steps per second:  30, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.005180, mae: 0.047569, mean_q: 0.054724, mean_eps: 0.446446\n",
            " 146432/250000: episode: 204, duration: 19.064s, episode steps: 568, steps per second:  30, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.174 [0.000, 5.000],  loss: 0.006060, mae: 0.052804, mean_q: 0.058545, mean_eps: 0.444645\n",
            " 147527/250000: episode: 205, duration: 36.516s, episode steps: 1095, steps per second:  30, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.005958, mae: 0.052066, mean_q: 0.058564, mean_eps: 0.441484\n",
            " 148022/250000: episode: 206, duration: 16.435s, episode steps: 495, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.004584, mae: 0.048017, mean_q: 0.052646, mean_eps: 0.438459\n",
            " 148653/250000: episode: 207, duration: 21.187s, episode steps: 631, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.007088, mae: 0.053607, mean_q: 0.060595, mean_eps: 0.436316\n",
            " 149283/250000: episode: 208, duration: 20.980s, episode steps: 630, steps per second:  30, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.819 [0.000, 5.000],  loss: 0.005471, mae: 0.050413, mean_q: 0.057440, mean_eps: 0.433922\n",
            " 150037/250000: episode: 209, duration: 25.321s, episode steps: 754, steps per second:  30, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.005080, mae: 0.049743, mean_q: 0.054175, mean_eps: 0.431292\n",
            " 150860/250000: episode: 210, duration: 27.328s, episode steps: 823, steps per second:  30, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.006178, mae: 0.067887, mean_q: 0.083266, mean_eps: 0.428298\n",
            " 151516/250000: episode: 211, duration: 21.902s, episode steps: 656, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.799 [0.000, 5.000],  loss: 0.007560, mae: 0.069082, mean_q: 0.082847, mean_eps: 0.425493\n",
            " 151864/250000: episode: 212, duration: 11.677s, episode steps: 348, steps per second:  30, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.007059, mae: 0.069671, mean_q: 0.081675, mean_eps: 0.423586\n",
            " 152854/250000: episode: 213, duration: 32.937s, episode steps: 990, steps per second:  30, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.006013, mae: 0.067190, mean_q: 0.080427, mean_eps: 0.421040\n",
            " 153842/250000: episode: 214, duration: 32.929s, episode steps: 988, steps per second:  30, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.006712, mae: 0.070177, mean_q: 0.083362, mean_eps: 0.417278\n",
            " 154245/250000: episode: 215, duration: 13.382s, episode steps: 403, steps per second:  30, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007371, mae: 0.069479, mean_q: 0.082037, mean_eps: 0.414633\n",
            " 154822/250000: episode: 216, duration: 19.201s, episode steps: 577, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.006567, mae: 0.067334, mean_q: 0.082119, mean_eps: 0.412771\n",
            " 155164/250000: episode: 217, duration: 11.535s, episode steps: 342, steps per second:  30, episode reward:  6.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.005476, mae: 0.064254, mean_q: 0.077567, mean_eps: 0.411030\n",
            " 155864/250000: episode: 218, duration: 23.285s, episode steps: 700, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.005162, mae: 0.064046, mean_q: 0.076529, mean_eps: 0.409054\n",
            " 156644/250000: episode: 219, duration: 26.246s, episode steps: 780, steps per second:  30, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.006328, mae: 0.067216, mean_q: 0.079715, mean_eps: 0.406242\n",
            " 157452/250000: episode: 220, duration: 27.095s, episode steps: 808, steps per second:  30, episode reward:  6.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.006254, mae: 0.065291, mean_q: 0.077197, mean_eps: 0.403225\n",
            " 157916/250000: episode: 221, duration: 15.703s, episode steps: 464, steps per second:  30, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.006341, mae: 0.065129, mean_q: 0.077318, mean_eps: 0.400808\n",
            " 158601/250000: episode: 222, duration: 23.034s, episode steps: 685, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.752 [0.000, 5.000],  loss: 0.007051, mae: 0.067692, mean_q: 0.080823, mean_eps: 0.398620\n",
            " 159159/250000: episode: 223, duration: 18.473s, episode steps: 558, steps per second:  30, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.006563, mae: 0.068064, mean_q: 0.082266, mean_eps: 0.396256\n",
            " 159967/250000: episode: 224, duration: 26.958s, episode steps: 808, steps per second:  30, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.006111, mae: 0.068465, mean_q: 0.081837, mean_eps: 0.393664\n",
            " 160726/250000: episode: 225, duration: 25.445s, episode steps: 759, steps per second:  30, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.005910, mae: 0.065802, mean_q: 0.080602, mean_eps: 0.390685\n",
            " 161398/250000: episode: 226, duration: 22.512s, episode steps: 672, steps per second:  30, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.006043, mae: 0.066226, mean_q: 0.078573, mean_eps: 0.387964\n",
            " 162182/250000: episode: 227, duration: 26.098s, episode steps: 784, steps per second:  30, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.006504, mae: 0.067155, mean_q: 0.079729, mean_eps: 0.385198\n",
            " 162669/250000: episode: 228, duration: 16.307s, episode steps: 487, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: 0.005890, mae: 0.067106, mean_q: 0.079243, mean_eps: 0.382781\n",
            " 163327/250000: episode: 229, duration: 21.876s, episode steps: 658, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.006612, mae: 0.069506, mean_q: 0.082938, mean_eps: 0.380608\n",
            " 164297/250000: episode: 230, duration: 32.276s, episode steps: 970, steps per second:  30, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.007689, mae: 0.072748, mean_q: 0.085509, mean_eps: 0.377514\n",
            " 165135/250000: episode: 231, duration: 27.914s, episode steps: 838, steps per second:  30, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.005181, mae: 0.065775, mean_q: 0.077127, mean_eps: 0.374079\n",
            " 165682/250000: episode: 232, duration: 18.103s, episode steps: 547, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.005973, mae: 0.065787, mean_q: 0.076344, mean_eps: 0.371450\n",
            " 166783/250000: episode: 233, duration: 36.708s, episode steps: 1101, steps per second:  30, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.735 [0.000, 5.000],  loss: 0.006562, mae: 0.067753, mean_q: 0.079582, mean_eps: 0.368318\n",
            " 167426/250000: episode: 234, duration: 21.641s, episode steps: 643, steps per second:  30, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.944 [0.000, 5.000],  loss: 0.006070, mae: 0.066614, mean_q: 0.078439, mean_eps: 0.365005\n",
            " 168215/250000: episode: 235, duration: 26.442s, episode steps: 789, steps per second:  30, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.005509, mae: 0.065687, mean_q: 0.077993, mean_eps: 0.362284\n",
            " 168793/250000: episode: 236, duration: 19.659s, episode steps: 578, steps per second:  29, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.005798, mae: 0.066996, mean_q: 0.079036, mean_eps: 0.359685\n",
            " 169281/250000: episode: 237, duration: 16.336s, episode steps: 488, steps per second:  30, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.006005, mae: 0.066376, mean_q: 0.079984, mean_eps: 0.357656\n",
            " 169838/250000: episode: 238, duration: 18.746s, episode steps: 557, steps per second:  30, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.006295, mae: 0.067490, mean_q: 0.079886, mean_eps: 0.355672\n",
            " 170614/250000: episode: 239, duration: 25.976s, episode steps: 776, steps per second:  30, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.006410, mae: 0.067776, mean_q: 0.081512, mean_eps: 0.353141\n",
            " 171610/250000: episode: 240, duration: 33.566s, episode steps: 996, steps per second:  30, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.006807, mae: 0.069045, mean_q: 0.081777, mean_eps: 0.349774\n",
            " 172145/250000: episode: 241, duration: 17.984s, episode steps: 535, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.037 [0.000, 5.000],  loss: 0.005894, mae: 0.068112, mean_q: 0.081000, mean_eps: 0.346864\n",
            " 172554/250000: episode: 242, duration: 13.754s, episode steps: 409, steps per second:  30, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.006167, mae: 0.067793, mean_q: 0.081908, mean_eps: 0.345070\n",
            " 173011/250000: episode: 243, duration: 15.296s, episode steps: 457, steps per second:  30, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.005847, mae: 0.066132, mean_q: 0.079779, mean_eps: 0.343428\n",
            " 173656/250000: episode: 244, duration: 21.719s, episode steps: 645, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.007027, mae: 0.070997, mean_q: 0.083988, mean_eps: 0.341338\n",
            " 174427/250000: episode: 245, duration: 25.736s, episode steps: 771, steps per second:  30, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.007293, mae: 0.068165, mean_q: 0.081992, mean_eps: 0.338648\n",
            " 174926/250000: episode: 246, duration: 16.871s, episode steps: 499, steps per second:  30, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.014 [0.000, 5.000],  loss: 0.006062, mae: 0.067061, mean_q: 0.080869, mean_eps: 0.336231\n",
            " 175286/250000: episode: 247, duration: 11.951s, episode steps: 360, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.005819, mae: 0.065931, mean_q: 0.077372, mean_eps: 0.334597\n",
            " 176261/250000: episode: 248, duration: 32.691s, episode steps: 975, steps per second:  30, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.005863, mae: 0.066655, mean_q: 0.079803, mean_eps: 0.332059\n",
            " 176814/250000: episode: 249, duration: 18.761s, episode steps: 553, steps per second:  29, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: 0.005701, mae: 0.063538, mean_q: 0.075508, mean_eps: 0.329156\n",
            " 177278/250000: episode: 250, duration: 15.507s, episode steps: 464, steps per second:  30, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007078, mae: 0.071311, mean_q: 0.082542, mean_eps: 0.327225\n",
            " 177648/250000: episode: 251, duration: 12.424s, episode steps: 370, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.004168, mae: 0.062122, mean_q: 0.073588, mean_eps: 0.325644\n",
            " 178029/250000: episode: 252, duration: 12.781s, episode steps: 381, steps per second:  30, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.367 [0.000, 5.000],  loss: 0.004889, mae: 0.062764, mean_q: 0.073298, mean_eps: 0.324216\n",
            " 178558/250000: episode: 253, duration: 17.689s, episode steps: 529, steps per second:  30, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.790 [0.000, 5.000],  loss: 0.006355, mae: 0.064543, mean_q: 0.075262, mean_eps: 0.322483\n",
            " 179248/250000: episode: 254, duration: 23.190s, episode steps: 690, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006447, mae: 0.066288, mean_q: 0.077575, mean_eps: 0.320172\n",
            " 179612/250000: episode: 255, duration: 12.388s, episode steps: 364, steps per second:  29, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.909 [0.000, 5.000],  loss: 0.006421, mae: 0.065085, mean_q: 0.076694, mean_eps: 0.318174\n",
            " 180120/250000: episode: 256, duration: 17.005s, episode steps: 508, steps per second:  30, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.006071, mae: 0.071572, mean_q: 0.088393, mean_eps: 0.316517\n",
            " 180667/250000: episode: 257, duration: 18.372s, episode steps: 547, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: 0.006979, mae: 0.088036, mean_q: 0.112984, mean_eps: 0.314510\n",
            " 181180/250000: episode: 258, duration: 17.139s, episode steps: 513, steps per second:  30, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 3.051 [0.000, 5.000],  loss: 0.006831, mae: 0.089070, mean_q: 0.112503, mean_eps: 0.312496\n",
            " 181561/250000: episode: 259, duration: 12.826s, episode steps: 381, steps per second:  30, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.005614, mae: 0.085664, mean_q: 0.106602, mean_eps: 0.310794\n",
            " 182218/250000: episode: 260, duration: 21.969s, episode steps: 657, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.947 [0.000, 5.000],  loss: 0.006758, mae: 0.086825, mean_q: 0.107515, mean_eps: 0.308818\n",
            " 182718/250000: episode: 261, duration: 16.592s, episode steps: 500, steps per second:  30, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.860 [0.000, 5.000],  loss: 0.007025, mae: 0.090776, mean_q: 0.113328, mean_eps: 0.306622\n",
            " 183340/250000: episode: 262, duration: 20.904s, episode steps: 622, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.926 [0.000, 5.000],  loss: 0.006314, mae: 0.089722, mean_q: 0.112521, mean_eps: 0.304494\n",
            " 184142/250000: episode: 263, duration: 26.950s, episode steps: 802, steps per second:  30, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.681 [0.000, 5.000],  loss: 0.006858, mae: 0.087240, mean_q: 0.108386, mean_eps: 0.301788\n",
            " 185161/250000: episode: 264, duration: 34.507s, episode steps: 1019, steps per second:  30, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.006238, mae: 0.087734, mean_q: 0.110504, mean_eps: 0.298322\n",
            " 185568/250000: episode: 265, duration: 13.909s, episode steps: 407, steps per second:  29, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.005627, mae: 0.086973, mean_q: 0.107926, mean_eps: 0.295617\n",
            " 186543/250000: episode: 266, duration: 33.057s, episode steps: 975, steps per second:  29, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.006232, mae: 0.087221, mean_q: 0.108772, mean_eps: 0.292995\n",
            " 187516/250000: episode: 267, duration: 32.878s, episode steps: 973, steps per second:  30, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.005977, mae: 0.085008, mean_q: 0.105312, mean_eps: 0.289294\n",
            " 188510/250000: episode: 268, duration: 33.687s, episode steps: 994, steps per second:  30, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.006260, mae: 0.088090, mean_q: 0.108680, mean_eps: 0.285554\n",
            " 189447/250000: episode: 269, duration: 31.794s, episode steps: 937, steps per second:  29, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.006867, mae: 0.089738, mean_q: 0.112147, mean_eps: 0.281884\n",
            " 189790/250000: episode: 270, duration: 11.677s, episode steps: 343, steps per second:  29, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.005996, mae: 0.085041, mean_q: 0.106209, mean_eps: 0.279452\n",
            " 190417/250000: episode: 271, duration: 21.254s, episode steps: 627, steps per second:  30, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: 0.005677, mae: 0.085125, mean_q: 0.105873, mean_eps: 0.277605\n",
            " 190984/250000: episode: 272, duration: 19.241s, episode steps: 567, steps per second:  29, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.215 [0.000, 5.000],  loss: 0.005913, mae: 0.087339, mean_q: 0.107890, mean_eps: 0.275340\n",
            " 191695/250000: episode: 273, duration: 24.263s, episode steps: 711, steps per second:  29, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.007030, mae: 0.087418, mean_q: 0.110045, mean_eps: 0.272916\n",
            " 192039/250000: episode: 274, duration: 11.593s, episode steps: 344, steps per second:  30, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.006195, mae: 0.083872, mean_q: 0.104198, mean_eps: 0.270909\n",
            " 192562/250000: episode: 275, duration: 18.001s, episode steps: 523, steps per second:  29, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006683, mae: 0.089568, mean_q: 0.111880, mean_eps: 0.269260\n",
            " 192903/250000: episode: 276, duration: 11.598s, episode steps: 341, steps per second:  29, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.005949, mae: 0.086101, mean_q: 0.106130, mean_eps: 0.267618\n",
            " 194198/250000: episode: 277, duration: 43.757s, episode steps: 1295, steps per second:  30, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.885 [0.000, 5.000],  loss: 0.005707, mae: 0.084806, mean_q: 0.106468, mean_eps: 0.264510\n",
            " 195187/250000: episode: 278, duration: 33.627s, episode steps: 989, steps per second:  29, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.006734, mae: 0.087501, mean_q: 0.108986, mean_eps: 0.260170\n",
            " 195671/250000: episode: 279, duration: 16.394s, episode steps: 484, steps per second:  30, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.180 [0.000, 5.000],  loss: 0.006427, mae: 0.089243, mean_q: 0.110566, mean_eps: 0.257374\n",
            " 196187/250000: episode: 280, duration: 17.730s, episode steps: 516, steps per second:  29, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.973 [0.000, 5.000],  loss: 0.006299, mae: 0.089409, mean_q: 0.110145, mean_eps: 0.255474\n",
            " 196705/250000: episode: 281, duration: 17.729s, episode steps: 518, steps per second:  29, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.994 [0.000, 5.000],  loss: 0.007632, mae: 0.084838, mean_q: 0.104178, mean_eps: 0.253505\n",
            " 197108/250000: episode: 282, duration: 13.728s, episode steps: 403, steps per second:  29, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.005701, mae: 0.087920, mean_q: 0.109598, mean_eps: 0.251757\n",
            " 197922/250000: episode: 283, duration: 27.632s, episode steps: 814, steps per second:  29, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.006233, mae: 0.086975, mean_q: 0.107580, mean_eps: 0.249447\n",
            " 198563/250000: episode: 284, duration: 21.979s, episode steps: 641, steps per second:  29, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.005786, mae: 0.082875, mean_q: 0.101314, mean_eps: 0.246680\n",
            " 199334/250000: episode: 285, duration: 25.458s, episode steps: 771, steps per second:  30, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.005958, mae: 0.085040, mean_q: 0.104631, mean_eps: 0.243998\n",
            " 200456/250000: episode: 286, duration: 37.158s, episode steps: 1122, steps per second:  30, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.172 [0.000, 5.000],  loss: 0.006522, mae: 0.087183, mean_q: 0.109720, mean_eps: 0.240403\n",
            " 201256/250000: episode: 287, duration: 26.515s, episode steps: 800, steps per second:  30, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.151 [0.000, 5.000],  loss: 0.006362, mae: 0.087948, mean_q: 0.111624, mean_eps: 0.236755\n",
            " 201747/250000: episode: 288, duration: 16.206s, episode steps: 491, steps per second:  30, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.189 [0.000, 5.000],  loss: 0.006928, mae: 0.090474, mean_q: 0.113467, mean_eps: 0.234300\n",
            " 202284/250000: episode: 289, duration: 17.753s, episode steps: 537, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.196 [0.000, 5.000],  loss: 0.007008, mae: 0.089829, mean_q: 0.113869, mean_eps: 0.232347\n",
            " 202989/250000: episode: 290, duration: 23.341s, episode steps: 705, steps per second:  30, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.006187, mae: 0.086146, mean_q: 0.109893, mean_eps: 0.229983\n",
            " 203915/250000: episode: 291, duration: 30.871s, episode steps: 926, steps per second:  30, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.874 [0.000, 5.000],  loss: 0.006738, mae: 0.087337, mean_q: 0.110919, mean_eps: 0.226882\n",
            " 204564/250000: episode: 292, duration: 21.766s, episode steps: 649, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.162 [0.000, 5.000],  loss: 0.006276, mae: 0.088312, mean_q: 0.113363, mean_eps: 0.223896\n",
            " 205264/250000: episode: 293, duration: 23.268s, episode steps: 700, steps per second:  30, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.837 [0.000, 5.000],  loss: 0.006611, mae: 0.086428, mean_q: 0.108619, mean_eps: 0.221334\n",
            " 205678/250000: episode: 294, duration: 13.860s, episode steps: 414, steps per second:  30, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.004652, mae: 0.081230, mean_q: 0.102141, mean_eps: 0.219214\n",
            " 206256/250000: episode: 295, duration: 19.167s, episode steps: 578, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.029 [0.000, 5.000],  loss: 0.005742, mae: 0.087871, mean_q: 0.110547, mean_eps: 0.217329\n",
            " 206618/250000: episode: 296, duration: 12.040s, episode steps: 362, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.006636, mae: 0.087980, mean_q: 0.108751, mean_eps: 0.215543\n",
            " 207215/250000: episode: 297, duration: 19.803s, episode steps: 597, steps per second:  30, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.006072, mae: 0.086401, mean_q: 0.107332, mean_eps: 0.213719\n",
            " 207714/250000: episode: 298, duration: 16.473s, episode steps: 499, steps per second:  30, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.990 [0.000, 5.000],  loss: 0.005421, mae: 0.084205, mean_q: 0.105455, mean_eps: 0.211637\n",
            " 208357/250000: episode: 299, duration: 21.530s, episode steps: 643, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.121 [0.000, 5.000],  loss: 0.006026, mae: 0.081706, mean_q: 0.100453, mean_eps: 0.209463\n",
            " 208935/250000: episode: 300, duration: 18.992s, episode steps: 578, steps per second:  30, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.007799, mae: 0.090900, mean_q: 0.112276, mean_eps: 0.207145\n",
            " 209507/250000: episode: 301, duration: 18.893s, episode steps: 572, steps per second:  30, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.006537, mae: 0.087422, mean_q: 0.108038, mean_eps: 0.204964\n",
            " 209893/250000: episode: 302, duration: 12.755s, episode steps: 386, steps per second:  30, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.764 [0.000, 5.000],  loss: 0.006130, mae: 0.087999, mean_q: 0.107905, mean_eps: 0.203140\n",
            " 210661/250000: episode: 303, duration: 25.477s, episode steps: 768, steps per second:  30, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.007125, mae: 0.105386, mean_q: 0.138319, mean_eps: 0.200944\n",
            " 212162/250000: episode: 304, duration: 49.637s, episode steps: 1501, steps per second:  30, episode reward: 29.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.101 [0.000, 5.000],  loss: 0.006963, mae: 0.110727, mean_q: 0.143917, mean_eps: 0.196634\n",
            " 213363/250000: episode: 305, duration: 40.091s, episode steps: 1201, steps per second:  30, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.006679, mae: 0.111099, mean_q: 0.144269, mean_eps: 0.191504\n",
            " 214315/250000: episode: 306, duration: 31.355s, episode steps: 952, steps per second:  30, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.099 [0.000, 5.000],  loss: 0.006557, mae: 0.111052, mean_q: 0.141703, mean_eps: 0.187416\n",
            " 214939/250000: episode: 307, duration: 20.802s, episode steps: 624, steps per second:  30, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.143 [0.000, 5.000],  loss: 0.005318, mae: 0.109657, mean_q: 0.139784, mean_eps: 0.184421\n",
            " 215609/250000: episode: 308, duration: 22.343s, episode steps: 670, steps per second:  30, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.006743, mae: 0.109724, mean_q: 0.139495, mean_eps: 0.181959\n",
            " 216225/250000: episode: 309, duration: 20.500s, episode steps: 616, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 3.144 [0.000, 5.000],  loss: 0.007005, mae: 0.114370, mean_q: 0.147417, mean_eps: 0.179512\n",
            " 217327/250000: episode: 310, duration: 36.487s, episode steps: 1102, steps per second:  30, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.006837, mae: 0.109848, mean_q: 0.141458, mean_eps: 0.176251\n",
            " 218048/250000: episode: 311, duration: 24.085s, episode steps: 721, steps per second:  30, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: 0.006043, mae: 0.109890, mean_q: 0.141338, mean_eps: 0.172793\n",
            " 218882/250000: episode: 312, duration: 27.977s, episode steps: 834, steps per second:  30, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.933 [0.000, 5.000],  loss: 0.007743, mae: 0.111488, mean_q: 0.143486, mean_eps: 0.169837\n",
            " 219510/250000: episode: 313, duration: 20.894s, episode steps: 628, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.898 [0.000, 5.000],  loss: 0.006470, mae: 0.108467, mean_q: 0.140799, mean_eps: 0.167055\n",
            " 220152/250000: episode: 314, duration: 21.596s, episode steps: 642, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.061 [0.000, 5.000],  loss: 0.006011, mae: 0.105774, mean_q: 0.136508, mean_eps: 0.164646\n",
            " 220484/250000: episode: 315, duration: 11.410s, episode steps: 332, steps per second:  29, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.919 [0.000, 5.000],  loss: 0.007317, mae: 0.112465, mean_q: 0.145007, mean_eps: 0.162799\n",
            " 221692/250000: episode: 316, duration: 40.326s, episode steps: 1208, steps per second:  30, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.006410, mae: 0.106651, mean_q: 0.136778, mean_eps: 0.159873\n",
            " 222875/250000: episode: 317, duration: 39.662s, episode steps: 1183, steps per second:  30, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.993 [0.000, 5.000],  loss: 0.006638, mae: 0.110970, mean_q: 0.141999, mean_eps: 0.155328\n",
            " 223522/250000: episode: 318, duration: 21.352s, episode steps: 647, steps per second:  30, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.108 [0.000, 5.000],  loss: 0.005942, mae: 0.106646, mean_q: 0.136722, mean_eps: 0.151848\n",
            " 224310/250000: episode: 319, duration: 26.323s, episode steps: 788, steps per second:  30, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.386 [0.000, 5.000],  loss: 0.006171, mae: 0.107687, mean_q: 0.138097, mean_eps: 0.149119\n",
            " 224954/250000: episode: 320, duration: 21.554s, episode steps: 644, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.171 [0.000, 5.000],  loss: 0.007296, mae: 0.111366, mean_q: 0.143247, mean_eps: 0.146398\n",
            " 225327/250000: episode: 321, duration: 12.452s, episode steps: 373, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.006917, mae: 0.115926, mean_q: 0.150188, mean_eps: 0.144468\n",
            " 225880/250000: episode: 322, duration: 18.647s, episode steps: 553, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.036 [0.000, 5.000],  loss: 0.006260, mae: 0.109688, mean_q: 0.140988, mean_eps: 0.142712\n",
            " 227003/250000: episode: 323, duration: 37.753s, episode steps: 1123, steps per second:  30, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.005366, mae: 0.105975, mean_q: 0.135881, mean_eps: 0.139528\n",
            " 228288/250000: episode: 324, duration: 42.994s, episode steps: 1285, steps per second:  30, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.005965, mae: 0.109125, mean_q: 0.140745, mean_eps: 0.134953\n",
            " 228843/250000: episode: 325, duration: 18.837s, episode steps: 555, steps per second:  29, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.966 [0.000, 5.000],  loss: 0.006770, mae: 0.112276, mean_q: 0.143642, mean_eps: 0.131457\n",
            " 229419/250000: episode: 326, duration: 19.256s, episode steps: 576, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: 0.005820, mae: 0.102802, mean_q: 0.131002, mean_eps: 0.129306\n",
            " 230690/250000: episode: 327, duration: 42.601s, episode steps: 1271, steps per second:  30, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.006583, mae: 0.109132, mean_q: 0.139162, mean_eps: 0.125795\n",
            " 231437/250000: episode: 328, duration: 25.125s, episode steps: 747, steps per second:  30, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.006984, mae: 0.109814, mean_q: 0.140921, mean_eps: 0.121957\n",
            " 232097/250000: episode: 329, duration: 22.267s, episode steps: 660, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.006635, mae: 0.108700, mean_q: 0.139084, mean_eps: 0.119282\n",
            " 232560/250000: episode: 330, duration: 15.768s, episode steps: 463, steps per second:  29, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.060 [0.000, 5.000],  loss: 0.006242, mae: 0.105129, mean_q: 0.133476, mean_eps: 0.117154\n",
            " 233193/250000: episode: 331, duration: 21.275s, episode steps: 633, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.007103, mae: 0.110095, mean_q: 0.141014, mean_eps: 0.115071\n",
            " 233932/250000: episode: 332, duration: 24.761s, episode steps: 739, steps per second:  30, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.005632, mae: 0.106102, mean_q: 0.135301, mean_eps: 0.112464\n",
            " 234601/250000: episode: 333, duration: 22.517s, episode steps: 669, steps per second:  30, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.006539, mae: 0.108282, mean_q: 0.138865, mean_eps: 0.109789\n",
            " 235230/250000: episode: 334, duration: 21.084s, episode steps: 629, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.839 [0.000, 5.000],  loss: 0.005438, mae: 0.104594, mean_q: 0.133511, mean_eps: 0.107319\n",
            " 235831/250000: episode: 335, duration: 20.061s, episode steps: 601, steps per second:  30, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.917 [0.000, 5.000],  loss: 0.006530, mae: 0.105893, mean_q: 0.136067, mean_eps: 0.104986\n",
            " 236231/250000: episode: 336, duration: 13.415s, episode steps: 400, steps per second:  30, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.008990, mae: 0.110772, mean_q: 0.141932, mean_eps: 0.103086\n",
            " 236649/250000: episode: 337, duration: 14.381s, episode steps: 418, steps per second:  29, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.921 [0.000, 5.000],  loss: 0.005706, mae: 0.105344, mean_q: 0.135186, mean_eps: 0.101528\n",
            " 237749/250000: episode: 338, duration: 37.084s, episode steps: 1100, steps per second:  30, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.006506, mae: 0.107081, mean_q: 0.136996, mean_eps: 0.098640\n",
            " 238358/250000: episode: 339, duration: 20.299s, episode steps: 609, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.005107, mae: 0.103671, mean_q: 0.134036, mean_eps: 0.095395\n",
            " 238833/250000: episode: 340, duration: 16.105s, episode steps: 475, steps per second:  29, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.088 [0.000, 5.000],  loss: 0.006560, mae: 0.110067, mean_q: 0.140991, mean_eps: 0.093335\n",
            " 239340/250000: episode: 341, duration: 16.882s, episode steps: 507, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.005647, mae: 0.105614, mean_q: 0.136425, mean_eps: 0.091473\n",
            " 240043/250000: episode: 342, duration: 23.772s, episode steps: 703, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.708 [0.000, 5.000],  loss: 0.006454, mae: 0.109970, mean_q: 0.141341, mean_eps: 0.089178\n",
            " 240516/250000: episode: 343, duration: 15.978s, episode steps: 473, steps per second:  30, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.007226, mae: 0.139283, mean_q: 0.182113, mean_eps: 0.086944\n",
            " 241573/250000: episode: 344, duration: 35.925s, episode steps: 1057, steps per second:  29, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.007316, mae: 0.135901, mean_q: 0.175891, mean_eps: 0.084033\n",
            " 242297/250000: episode: 345, duration: 25.097s, episode steps: 724, steps per second:  29, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.052 [0.000, 5.000],  loss: 0.006319, mae: 0.134115, mean_q: 0.173748, mean_eps: 0.080643\n",
            " 242788/250000: episode: 346, duration: 17.084s, episode steps: 491, steps per second:  29, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 3.051 [0.000, 5.000],  loss: 0.006302, mae: 0.131413, mean_q: 0.169573, mean_eps: 0.078340\n",
            " 243686/250000: episode: 347, duration: 31.159s, episode steps: 898, steps per second:  29, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.006694, mae: 0.129591, mean_q: 0.167701, mean_eps: 0.075703\n",
            " 244210/250000: episode: 348, duration: 18.307s, episode steps: 524, steps per second:  29, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.006945, mae: 0.135709, mean_q: 0.175700, mean_eps: 0.072998\n",
            " 245407/250000: episode: 349, duration: 41.704s, episode steps: 1197, steps per second:  29, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.975 [0.000, 5.000],  loss: 0.006907, mae: 0.132324, mean_q: 0.172098, mean_eps: 0.069730\n",
            " 246242/250000: episode: 350, duration: 29.033s, episode steps: 835, steps per second:  29, episode reward:  6.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.940 [0.000, 5.000],  loss: 0.006407, mae: 0.132312, mean_q: 0.171640, mean_eps: 0.065869\n",
            " 246838/250000: episode: 351, duration: 20.681s, episode steps: 596, steps per second:  29, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.006890, mae: 0.131799, mean_q: 0.170038, mean_eps: 0.063148\n",
            " 247390/250000: episode: 352, duration: 19.050s, episode steps: 552, steps per second:  29, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.259 [0.000, 5.000],  loss: 0.005510, mae: 0.126773, mean_q: 0.164223, mean_eps: 0.060967\n",
            " 247944/250000: episode: 353, duration: 19.231s, episode steps: 554, steps per second:  29, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.067 [0.000, 5.000],  loss: 0.006111, mae: 0.131864, mean_q: 0.170654, mean_eps: 0.058869\n",
            " 248329/250000: episode: 354, duration: 13.529s, episode steps: 385, steps per second:  28, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.925 [0.000, 5.000],  loss: 0.007653, mae: 0.135792, mean_q: 0.174088, mean_eps: 0.057083\n",
            " 249114/250000: episode: 355, duration: 27.459s, episode steps: 785, steps per second:  29, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.682 [0.000, 5.000],  loss: 0.006166, mae: 0.129894, mean_q: 0.165798, mean_eps: 0.054856\n",
            " 249618/250000: episode: 356, duration: 17.474s, episode steps: 504, steps per second:  29, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.006041, mae: 0.128537, mean_q: 0.164866, mean_eps: 0.052409\n",
            "done, took 6848.438 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 9.000, steps: 873\n",
            "Episode 2: reward: 8.000, steps: 641\n",
            "Episode 3: reward: 14.000, steps: 929\n",
            "Episode 4: reward: 26.000, steps: 1233\n",
            "Episode 5: reward: 5.000, steps: 609\n",
            "Episode 6: reward: 23.000, steps: 1383\n",
            "Episode 7: reward: 23.000, steps: 1362\n",
            "Episode 8: reward: 7.000, steps: 643\n",
            "Episode 9: reward: 10.000, steps: 835\n",
            "Episode 10: reward: 9.000, steps: 687\n",
            "Episode 11: reward: 6.000, steps: 671\n",
            "Episode 12: reward: 15.000, steps: 1456\n",
            "Episode 13: reward: 12.000, steps: 834\n",
            "Episode 14: reward: 12.000, steps: 835\n",
            "Episode 15: reward: 7.000, steps: 745\n",
            "Episode 16: reward: 14.000, steps: 1142\n",
            "Episode 17: reward: 8.000, steps: 645\n",
            "Episode 18: reward: 16.000, steps: 986\n",
            "Episode 19: reward: 21.000, steps: 1265\n",
            "Episode 20: reward: 15.000, steps: 1161\n",
            "\n",
            "🎯 Recompensa promedio tras refinamiento: 13.00\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAIjCAYAAADWYVDIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnXe8FNX5/z+z5TZuofcOgoCIioqoFBsolmA36lcgaqLRFI0mURPFEgl2Y4ya/GxRiT2WxEZUUFQQKTYUpEtHLvdebt0y5/fH7MyemTkzO7s7uzuz93m/XnB3Z6c8c/pznuc8R2KMMRAEQRAEQRAEQRAAgEChBSAIgiAIgiAIgvASpCQRBEEQBEEQBEFwkJJEEARBEARBEATBQUoSQRAEQRAEQRAEBylJBEEQBEEQBEEQHKQkEQRBEARBEARBcJCSRBAEQRAEQRAEwUFKEkEQBEEQBEEQBAcpSQRBuMZjjz2GRx55pNBiEARBEARBZAUpSQRRJEiShNmzZ+fs/pMnT8bkyZMtf3/hhRfwq1/9CocddljOZOB54oknIEkSNm7cmPa1s2fPhiRJ7gvlA2bOnImBAwdmfP3AgQMxc+ZM1+QpZnJdJwmFBQsWQJIkLFiwoNCiFIzvvvsOU6ZMQU1NDSRJwiuvvJJVG5ktlCdEMUBKEkG4iNopWf1bvHhxoUXMCd999x0uu+wyPP/88zjkkEMKLQ5BYNWqVZg9e3ZBBoiF5uOPP8bs2bNRV1dXaFGKittvvx2vvPJKocUQMmPGDHz55Zf405/+hKeeegqHHnpooUUiCN8TKrQABFGM3HLLLRg0aJDp+NChQwsgjTu88847lr99/vnnePzxx3HSSSflUSKCsGbVqlW4+eabMXny5KwsZ37k448/xs0334yZM2eiY8eOhRYn50ycOBEtLS0oKSnJ6XNuv/12nHXWWZg+fXpOn5MuLS0t+OSTT3DDDTfgyiuv1I7/3//9H8477zyUlpYWUDqC8C+kJBFEDjjppJOKbibPbgBy1lln5VGSwtLc3IyKiopCi2FJa2srSkpKEAh431GAMYbW1laUl5cXWpR2iyzLiEQiKCsrK7QoGRMIBHwtv5FYLAZZlh0rfbt37wYAk0IcDAYRDAbdFo8g2g3e70UJosiIRqPo3LkzZs2aZfqtoaEBZWVluOaaa7Rju3btwsUXX4wePXqgrKwMY8aMwZNPPpnyOVZrT6zW4zz99NM4/PDDUVFRgU6dOmHixIk665FoTZIT2TZu3AhJknDXXXfh73//O4YMGYLS0lIcdthhWLp0acr3AICvv/4axx57LMrLy9G3b1/cdtttkGVZeO6bb76JCRMmoEOHDqiqqsLJJ5+Mr7/+2tFzjEyePBkHHHAAli1bhokTJ6KiogLXX389AKCtrQ033XQThg4ditLSUvTr1w+//e1v0dbWpl1/xhlnmNwPTz31VEiShNdee007tmTJEkiShDfffBMAUFtbi2uuuQajR49GZWUlqqurcdJJJ+Hzzz/X3Uv1+3/22Wfxhz/8AX369EFFRQUaGhoAAK+88goOOOAAlJWV4YADDsC///1vx+/OGMNtt92Gvn37oqKiAsccc4wwHa3Kk2g9xMCBA3HKKafg7bffxqGHHory8nIt0Mfjjz+OY489Ft27d0dpaSlGjhyJhx56yHRf9R6LFi3C4YcfjrKyMgwePBj//Oc/dc8+++yzAQDHHHOM5u7Kr4/IppzU1dXh17/+Nfr164fS0lIMHToUc+fOtSyTqXBSlgBljdOVV16p5WtpaSlGjRqFt956Sztn9uzZuPbaawEAgwYN0t5dzQf1Hs888wxGjRqF0tJS7fqtW7fiJz/5CXr06KHd+7HHHtPJoJa5559/Hn/605/Qt29flJWV4bjjjsPatWt153744Yc4++yz0b9/f+29rrrqKrS0tOjOmzlzJiorK7F582accsopqKysRJ8+ffDggw8CAL788ksce+yx6NChAwYMGIB58+YJZTKuf1myZAlOPPFE1NTUoKKiApMmTcJHH32kO0ctv2vXrtUsbzU1NZg1axaam5t1ad/U1IQnn3xSS1N+bd6KFStw0kknobq6GpWVlTjuuOMcuVfz7eN9992ntY+rVq0CAHz77bc466yz0LlzZ5SVleHQQw/VtR2zZ8/GgAEDAADXXnstJEnS2n27OmhXfwDnbRAAbNmyBdOnT0eHDh3QvXt3XHXVVaayq/LCCy9g7NixKC8vR9euXXHhhRdi69atKdOJIAoBWZIIIgfU19fjhx9+0B2TJAldunRBOBzG6aefjpdffhmPPPKIbrbwlVdeQVtbG8477zwAihvF5MmTsXbtWlx55ZUYNGgQXnjhBcycORN1dXX41a9+5Yq8N998M2bPno0jjzwSt9xyC0pKSrBkyRK89957mDJlivCadGWbN28e9u3bh5/97GeQJAl33HEHzjjjDKxfvx7hcNhSth07duCYY45BLBbD73//e3To0AF///vfhdaHp556CjNmzMDUqVMxd+5cNDc346GHHsLRRx+NFStWZOR2tWfPHpx00kk477zzcOGFF6JHjx6QZRmnnXYaFi1ahJ/+9KcYMWIEvvzyS9x7771Ys2aNtm5hwoQJePXVV9HQ0IDq6mowxvDRRx8hEAjgww8/xGmnnQZAGUwGAgEcddRRAID169fjlVdewdlnn41BgwZh586deOSRRzBp0iSsWrUKvXv31sl46623oqSkBNdccw3a2tpQUlKCd955B2eeeSZGjhyJOXPmYM+ePZg1axb69u3r6L1vvPFG3HbbbZg2bRqmTZuG5cuXY8qUKYhEImmnIc/q1avx4x//GD/72c9w6aWXYvjw4QCAhx56CKNGjcJpp52GUCiE119/HT//+c8hyzKuuOIK3T3Wrl2Ls846CxdffDFmzJiBxx57DDNnzsTYsWMxatQoTJw4Eb/85S/xl7/8Bddffz1GjBgBANrfbMpJc3MzJk2ahK1bt+JnP/sZ+vfvj48//hjXXXcdtm/fjvvuuy+t9HBallQWLVqEl19+GT//+c9RVVWFv/zlLzjzzDOxefNmdOnSBWeccQbWrFmDf/3rX7j33nvRtWtXAEC3bt20e7z33nt4/vnnceWVV6Jr164YOHAgdu7ciSOOOEJTorp164Y333wTF198MRoaGvDrX/9aJ8ef//xnBAIBXHPNNaivr8cdd9yBCy64AEuWLNHOeeGFF9Dc3IzLL78cXbp0waeffooHHngAW7ZswQsvvKC7Xzwex0knnYSJEyfijjvuwDPPPIMrr7wSHTp0wA033IALLrgAZ5xxBh5++GFcdNFFGD9+vNClmX/Hk046CWPHjsVNN92EQCCgKeIffvghDj/8cN3555xzDgYNGoQ5c+Zg+fLl+H//7/+he/fumDt3LgClzFxyySU4/PDD8dOf/hQAMGTIEADKJM6ECRNQXV2N3/72twiHw3jkkUcwefJkLFy4EOPGjUtZDh5//HG0trbipz/9KUpLS9G5c2d8/fXXOOqoo9CnTx+t7Xv++ecxffp0vPTSSzj99NNxxhlnoGPHjrjqqqvw4x//GNOmTUNlZaXts1LVH8B5G9TS0oLjjjsOmzdvxi9/+Uv07t0bTz31FN577z3Tc5944gnMmjULhx12GObMmYOdO3fi/vvvx0cffYQVK1a0C9dQwmcwgiBc4/HHH2cAhP9KS0u1895++20GgL3++uu666dNm8YGDx6sfb/vvvsYAPb0009rxyKRCBs/fjyrrKxkDQ0N2nEA7KabbtK+z5gxgw0YMMAk40033cT4qv/dd9+xQCDATj/9dBaPx3XnyrKsfZ40aRKbNGlS2rJt2LCBAWBdunRhtbW12rmvvvqqMA2M/PrXv2YA2JIlS7Rju3btYjU1NQwA27BhA2OMsX379rGOHTuySy+9VHf9jh07WE1Nje64MQ2smDRpEgPAHn74Yd3xp556igUCAfbhhx/qjj/88MMMAPvoo48YY4wtXbqUAWBvvPEGY4yxL774ggFgZ599Nhs3bpx23WmnncYOPvhg7Xtra6spLzZs2MBKS0vZLbfcoh17//33GQA2ePBg1tzcrDv/oIMOYr169WJ1dXXasXfeeYcBEJYLnl27drGSkhJ28skn68rA9ddfzwCwGTNmaMes0lKtC2r+MMbYgAEDGAD21ltvmc43ys8YY1OnTtXVB/4eH3zwgU7e0tJS9pvf/EY79sILLzAA7P3339ddn045EXHrrbeyDh06sDVr1uiO//73v2fBYJBt3rxZO2askyKcliX1fiUlJWzt2rXasc8//5wBYA888IB27M477zSlPX+PQCDAvv76a93xiy++mPXq1Yv98MMPuuPnnXceq6mp0fJHLXMjRoxgbW1t2nn3338/A8C+/PJL7ZgoT+fMmcMkSWKbNm3Sjs2YMYMBYLfffrt2bO/evay8vJxJksSeffZZ7fi3335rSldVJjWvZVlm++23H5s6daqu/DY3N7NBgwaxE044QTumlt+f/OQnOjlPP/101qVLF92xDh066Mq+yvTp01lJSQlbt26ddmzbtm2sqqqKTZw40XQ+j9o+VldXs127dul+O+6449jo0aNZa2urdkyWZXbkkUey/fbbz3SPO++8U3e9XR1MVX+ctkFqP/D8889rx5qamtjQoUN1eRKJRFj37t3ZAQccwFpaWrRz//Of/zAA7MYbb7RNJ4IoBORuRxA54MEHH8T8+fN1/1RXKgA49thj0bVrVzz33HPasb1792L+/Pk499xztWNvvPEGevbsiR//+MfasXA4jF/+8pdobGzEwoULs5b1lVdegSzLuPHGG03rWOzCZKcr27nnnotOnTpp3ydMmABAmbG044033sARRxyhm/nt1q0bLrjgAt158+fPR11dHX784x/jhx9+0P4Fg0GMGzcO77//vu1zrCgtLTW5Rr7wwgsYMWIE9t9/f92zjj32WADQnnXwwQejsrISH3zwAQDFYtS3b19cdNFFWL58OZqbm8EYw6JFi7T0UJ+p5kU8HseePXtQWVmJ4cOHY/ny5SYZZ8yYobOsbd++HStXrsSMGTNQU1OjHT/hhBMwcuTIlO/8v//9D5FIBL/4xS90ZcBoTciEQYMGYerUqabjvPyqJXbSpElYv3496uvrdeeOHDlSl17dunXD8OHDU5YlIPty8sILL2DChAno1KmT7vrjjz8e8Xhcy2unOC1LKscff7xmwQCAAw88ENXV1Y7eXWXSpEm6csAYw0svvYRTTz0VjDGdHFOnTkV9fb2p3M2aNUtnBRfVZz5Pm5qa8MMPP+DII48EYwwrVqwwyXXJJZdonzt27Ijhw4ejQ4cOOOecc7Tjw4cPR8eOHW3fd+XKlfjuu+9w/vnnY8+ePdq7NDU14bjjjsMHH3xgco287LLLdN8nTJiAPXv2aK6rVsTjcbzzzjuYPn06Bg8erB3v1asXzj//fCxatCjlPQDgzDPP1Fn7amtr8d577+Gcc87Bvn37tHfYs2cPpk6diu+++y5jNzUn9cdpG/TGG2+gV69eunWpFRUVmrVN5bPPPsOuXbvw85//XLd+7OSTT8b++++P//73vxm9C0HkEnK3I4gccPjhh9sGbgiFQjjzzDMxb948tLW1obS0FC+//DKi0ahOSdq0aRP2228/k/Kiug1t2rQpa1nXrVuHQCDgaPDMk65s/fv3131XFaa9e/emfI7IXUV101L57rvvAEAbXBqprq62fY4Vffr0MS2g/u677/DNN9/oBjU8u3btAqAsnB4/fjw+/PBDAIqSNGHCBBx99NGIx+NYvHgxevTogdraWt2gRZZl3H///fjb3/6GDRs2IB6Pa7916dLF9Dyj25Ga9vvtt5/pXCtFy8n13bp10ym6mWDlIvXRRx/hpptuwieffKJbCwIoShOv7BnLEqCUp1RlCci+nHz33Xf44osvUua9U5yWJZVs3l3FmAe7d+9GXV0d/v73v+Pvf/97RnKI6vPmzZtx44034rXXXjPJZ1R8y8rKTGlQU1ODvn37miZrampqbN9XzeMZM2ZYnlNfX68ry3bvY1cmdu/ejebmZlN7BChtoSzL+P777zU3NiuMebJ27VowxvDHP/4Rf/zjH4XX7Nq1C3369LG9rwgnZchpG7Rp0yYMHTrUlEfG9FDbFFE67b///li0aFHa70EQuYaUJIIoEOeddx4eeeQRvPnmm5g+fTqef/557L///hgzZowr97eyAvGdXT6xirLEGHPl/urM8FNPPYWePXuafg+FMmvuRGufZFnG6NGjcc899wiv6devn/b56KOPxp/+9Ce0trbiww8/xA033ICOHTvigAMOwIcffogePXoAgE5Juv322/HHP/4RP/nJT3Drrbeic+fOCAQC+PWvfy0MDlDI6HDpljORrOvWrcNxxx2H/fffH/fccw/69euHkpISvPHGG7j33ntN75xNWcq2nMiyjBNOOAG//e1vhb8PGzYspQzG+zktS4A79ciYB2qaXHjhhZaKxYEHHpiWHPF4HCeccAJqa2vxu9/9Dvvvvz86dOiArVu3YubMmY7zNJP3Ve9955134qCDDhKeY1y3k+v2KRVWeXLNNdcILa9A5ltKOHnXdNsggihGSEkiiAIxceJE9OrVC8899xyOPvpovPfee7jhhht05wwYMABffPEFZFnWWWy+/fZb7XcrOnXqJNxM0mjhGTJkCGRZxqpVqywHFCKykS0dBgwYoM0M86xevVr3XXVB6t69O44//nhXnm3FkCFD8Pnnn+O4446zdUkEFOUnEongX//6F7Zu3aopQxMnTtSUpGHDhmnKEgC8+OKLOOaYY/Doo4/q7lVXV6ctxLdDTXsn6Zbqet6FaPfu3aYZfHXGva6uTrfwOh0r5+uvv462tja89tprulnuTF0kAWvlLdtyMmTIEDQ2NrpWxtIpS05J9z7dunVDVVUV4vG4a+/15ZdfYs2aNXjyySdx0UUXacfnz5/vyv3tUPO4urra1bZAlK7dunVDRUWFsF59++23CAQCJkXXCWq9C4fDOW/PRDhtgwYMGICvvvoKjDFd+hjTQ21TVq9ebbLirl692rX+giDchNYkEUSBCAQCOOuss/D666/jqaeeQiwW07naAcC0adOwY8cO3dqlWCyGBx54AJWVlZg0aZLl/YcMGYL6+np88cUX2rHt27ebwkBPnz4dgUAAt9xyi2mG0G4WNRvZ0mHatGlYvHgxPv30U+3Y7t278cwzz+jOmzp1Kqqrq3H77bcjGo2a7qPuJeIG55xzDrZu3Yp//OMfpt9aWlrQ1NSkfR83bhzC4TDmzp2Lzp07a243EyZMwOLFi7Fw4UKdFQlQZnqNaf/CCy84XoPQq1cvHHTQQXjyySd1bk3z58/XQgvbcfzxxyMcDuOBBx7QySGK3KYOSPm1OGqoZKeoM9v8s+rr6/H44487voeRDh06AIBpoiDbcnLOOefgk08+wdtvv236ra6uDrFYLC050ylLTrF6dyuCwSDOPPNMvPTSS/jqq69Mv2dSd0R5yhjD/fffn/a90mXs2LEYMmQI7rrrLjQ2Npp+z7Qt6NChgylNg8EgpkyZgldffVUXanvnzp2YN28ejj766Ixcfbt3747JkyfjkUcewfbt202/u9meiXDaBk2bNg3btm3Diy++qB1rbm42uW0eeuih6N69Ox5++GFdePA333wT33zzDU4++eQcvAVBZAdZkggiB7z55puaRYXnyCOP1M3Mn3vuuXjggQdw0003YfTo0dp6HpWf/vSneOSRRzBz5kwsW7YMAwcOxIsvvoiPPvoI9913H6qqqixlOO+88/C73/0Op59+On75y19qYY6HDRumW5MydOhQ3HDDDbj11lsxYcIEnHHGGSgtLcXSpUvRu3dvzJkzR3j/bGRLh9/+9rd46qmncOKJJ+JXv/qVFgJctWSpVFdX46GHHsL//d//4ZBDDsF5552Hbt26YfPmzfjvf/+Lo446Cn/9619dken//u//8Pzzz+Oyyy7D+++/j6OOOgrxeBzffvstnn/+eW0fIEBZxDx27FgsXrxY2yMJUCxJTU1NaGpqMilJp5xyCm655RbMmjULRx55JL788ks888wzurKTijlz5uDkk0/G0UcfjZ/85Ceora3FAw88gFGjRgkHjjzdunXDNddcgzlz5uCUU07BtGnTsGLFCrz55psmS9aUKVPQv39/XHzxxbj22msRDAbx2GOPaWnvhClTpqCkpASnnnoqfvazn6GxsRH/+Mc/0L17d+EA0QkHHXQQgsEg5s6di/r6epSWlmr7MGVTTq699lq89tprOOWUU7SwyU1NTfjyyy/x4osvYuPGjY6sfSrplCWnjB07FgBwww034LzzzkM4HMapp56qKU8i/vznP+P999/HuHHjcOmll2LkyJGora3F8uXL8b///Q+1tbVpybD//vtjyJAhuOaaa7B161ZUV1fjpZdeSmvtVKYEAgH8v//3/3DSSSdh1KhRmDVrFvr06YOtW7fi/fffR3V1NV5//fW07zt27Fj873//wz333IPevXtj0KBBGDduHG677TbMnz8fRx99NH7+858jFArhkUceQVtbG+64446M3+PBBx/E0UcfjdGjR+PSSy/F4MGDsXPnTnzyySfYsmWLcM8it3DaBl166aX461//iosuugjLli1Dr1698NRTT5k23FYnimbNmoVJkybhxz/+sRYCfODAgbjqqqty9i4EkTH5DaZHEMWNXQhwAOzxxx/XnS/LMuvXrx8DwG677TbhPXfu3MlmzZrFunbtykpKStjo0aNN92FMHG74nXfeYQcccAArKSlhw4cPZ08//bRlyObHHnuMHXzwway0tJR16tSJTZo0ic2fP1/73RgC3KlsVuFprWQW8cUXX7BJkyaxsrIy1qdPH3brrbeyRx99VBjm+P3332dTp05lNTU1rKysjA0ZMoTNnDmTffbZZ9o56YQAHzVqlPC3SCTC5s6dy0aNGqWl2dixY9nNN9/M6uvrdedee+21DACbO3eu7rgaJpcPHcyYEn73N7/5DevVqxcrLy9nRx11FPvkk09MeaCGPn7hhReEMr700ktsxIgRrLS0lI0cOZK9/PLLlqHhjcTjcXbzzTdrMkyePJl99dVXbMCAAaYwyMuWLWPjxo1jJSUlrH///uyee+6xDD988sknC5/32muvsQMPPJCVlZWxgQMHsrlz57LHHnvM8T1E5fMf//gHGzx4MAsGg6Zw4E7KiRX79u1j1113HRs6dCgrKSlhXbt2ZUceeSS76667WCQS0c5zWr6dliUA7IorrjBdL8qTW2+9lfXp04cFAgFdGlrdgzGlPl9xxRWsX79+LBwOs549e7LjjjuO/f3vf9fOsSpzaj3n6/+qVavY8ccfzyorK1nXrl3ZpZdeqoUs58+bMWMG69Chg0keq/pnLAPGEOAqK1asYGeccQbr0qULKy0tZQMGDGDnnHMOe/fdd7Vz1LZg9+7dumtF5ffbb79lEydOZOXl5aZQ+MuXL2dTp05llZWVrKKigh1zzDHs448/NsluxK59ZIyxdevWsYsuuoj17NmThcNh1qdPH3bKKaewF198MeU90qmDxvrjtA1ijLFNmzax0047jVVUVLCuXbuyX/3qV+ytt94S5slzzz2n9TOdO3dmF1xwAduyZUvKdCKIQiAxlqdViQRBEARBEARBED6A1iQRBEEQBEEQBEFwkJJEEARBEARBEATBQUoSQRAEQRAEQRAEBylJBEEQBEEQBEEQHKQkEQRBEARBEARBcJCSRBAEQRAEQRAEwVH0m8nKsoxt27ahqqpK28SRIAiCIAiCIIj2B2MM+/btQ+/evREIWNuLil5J2rZtG/r161doMQiCIAiCIAiC8Ajff/89+vbta/l70StJVVVVAJSEqK6uLogM0WgU77zzDqZMmYJwOFwQGQgFygtvQfnhHSgvvAPlhXegvPAWlB/ewc950dDQgH79+mk6ghUFVZIeeughPPTQQ9i4cSMAYNSoUbjxxhtx0kknAQBaW1vxm9/8Bs8++yza2towdepU/O1vf0OPHj0cP0N1sauuri6oklRRUYHq6mrfFaRig/LCW1B+eAfKC+9AeeEdKC+8BeWHdyiGvEi1DKeggRv69u2LP//5z1i2bBk+++wzHHvssfjRj36Er7/+GgBw1VVX4fXXX8cLL7yAhQsXYtu2bTjjjDMKKTJBEARBEARBEEVOQS1Jp556qu77n/70Jzz00ENYvHgx+vbti0cffRTz5s3DscceCwB4/PHHMWLECCxevBhHHHFEIUQmCIIgCIIgCKLI8cyapHg8jhdeeAFNTU0YP348li1bhmg0iuOPP147Z//990f//v3xySefWCpJbW1taGtr0743NDQAUMyC0Wg0ty9hgfrcQj2fSEJ54S0oP7wD5YV3oLzwDpQX3oLywzv4OS+cyiwxxliOZbHlyy+/xPjx49Ha2orKykrMmzcP06ZNw7x58zBr1iydwgMAhx9+OI455hjMnTtXeL/Zs2fj5ptvNh2fN28eKioqLOUIBAK2YQAJopiQZRmyLBdaDIIgCIIgiLzS3NyM888/H/X19bbxCgpuSRo+fDhWrlyJ+vp6vPjii5gxYwYWLlyY8f2uu+46XH311dp3NYLFlClThAkRjUaxc+dOtLS0ZPzMVDDG0NrairKyMtqrqcBQXiQpLy9Hjx49CrrgMhqNYv78+TjhhBN8u/CzWKC88A6UF96B8sJbUH54Bz/nheplloqCK0klJSUYOnQoAGDs2LFYunQp7r//fpx77rmIRCKoq6tDx44dtfN37tyJnj17Wt6vtLQUpaWlpuPhcNiUibIsY/369QgGg+jTpw9KSkpyMnCWZRmNjY2orKwka1WBobxQFMVIJILdu3fj+++/x3777VfwtBDVT6IwUF54B8oL70B54S0oP7yDH/PCqbwFV5KMyLKMtrY2jB07FuFwGO+++y7OPPNMAMDq1auxefNmjB8/3pVnRSIRyLKMfv362briZYssy4hEIigrKyv4YLS9Q3mhUF5ejnA4jE2bNmnpQRAEQRAEQSgUVEm67rrrcNJJJ6F///7Yt28f5s2bhwULFuDtt99GTU0NLr74Ylx99dXo3Lkzqqur8Ytf/ALjx493PbJdex4sE+0XKvcEQRAEQRBiCqok7dq1CxdddBG2b9+OmpoaHHjggXj77bdxwgknAADuvfdeBAIBnHnmmbrNZAmCIAiCIAiCIHJFQZWkRx991Pb3srIyPPjgg3jwwQfzJBFBEARBEARBEO0d8rch8s7kyZPx61//utBiuMrMmTMxffr0nN1/48aNkCQJK1euBAAsWLAAkiShrq4uZ88kCIIgCIJor5CS5ENmzpwJSZIgSRLC4TAGDRqE3/72t2htbS20aO2W+++/H0888UTennfkkUdqbqoEQRAEQRCEu3guuh3hjBNPPBGPP/44otEoli1bhhkzZkCSJMtNdvMNYwzxeByhkHeKWDQaRTAYzMm9862slJSU2IbCJwiCIAiCIDKHLEkG4jIryL90KS0tRc+ePdGvXz9Mnz4dxx9/PObPn6/9Lssy5syZg0GDBqG8vBxjxozBiy++qP1+6KGH4q677tK+T58+HeFwGI2NjQCALVu2QJIkrF27FgDw1FNP4dBDD0VVVRV69uyJ888/H7t27dKuV92/3nzzTYwdOxalpaVYtGgRmpqacNFFF6GyshK9evXC3XffnfLdZs+ejYMOOgiPPPKIFp79nHPOQX19ve79brnlFvTt2xelpaU46KCD8NZbb2m/q+5pzz33HCZNmoSysjI888wzwufV1dXhkksuQbdu3VBdXY1jjz0Wn3/+eVryGN3tXnzxRYwePRrl5eXo0qULjj/+eDQ1NTmSHQA+/fRTHHzwwSgrK8Ohhx6KFStW6H4Xudu99NJLGDVqFEpLSzFw4EBHaU0QBEEQBEGY8c40vweIywzvf7sr9YlpwpiM5uYWVFS0QpLEeukx+3dHMJDZRrZfffUVPv74YwwYMEA7NmfOHDz99NN4+OGHsd9+++GDDz7AhRdeiG7dumHSpEmYNGkSFixYgGuuuQaMMXz44Yfo2LEjFi1ahBNPPBELFy5Enz59tI1+o9Eobr31VgwfPhy7du3C1VdfjZkzZ+KNN97QyfL73/8ed911FwYPHoxOnTrh2muvxcKFC/Hqq6+ie/fuuP7667F8+XIcdNBBtu+0du1aPP/883j99dfR0NCAiy++GD//+c81Ref+++/H3XffjUceeQQHH3wwHnvsMZx22mn4+uuvsd9+++nkufvuuzWFQ8TZZ5+N8vJyvPnmm6ipqcEjjzyC4447DmvWrEHnzp0dycOzfft2/PjHP8Ydd9yB008/Hfv27cOHH34Ixpgj2RsbG3HKKafghBNOwNNPP40NGzbgV7/6lW16LVu2DOeccw5mz56Nc889Fx9//DF+/vOfo0uXLpg5c6bttQRBEARBEIQeUpJ8yn/+8x9UVlYiFouhra0NgUAAf/3rXwEAbW1tuP322/G///1P23h38ODBWLRoER555BFMmjQJkydPxqOPPop4PI6vvvoKJSUlOPfcc7FgwQKceOKJWLBgASZNmqQ97yc/+Yn2efDgwfjLX/6Cww47DI2NjaisrNR+u+WWW7QQ7o2NjXj00Ufx9NNP47jjjgMAPPnkk+jbt2/K92ttbcU///lP9OnTBwDwwAMP4OSTT8bdd9+Nnj174q677sLvfvc7nHfeeQCAuXPn4v3338d9992ni4b461//GmeccYb2XZZl3XMWLVqETz/9FLt27UJpaSkA4K677sIrr7yCF198ET/96U8dycOzfft2xGIxnHHGGZriOnr0aO33VLLPmzcPsizj0UcfRVlZGUaNGoUtW7bg8ssvt0yve+65B8cddxz++Mc/AgCGDRuGVatW4c477yQliSAIgiAIIk1ISeIIBiQcs3931+8ryzIaGhpQXV1tuYFnulakY445Bg899BCamppw7733IhQK4cwzzwSgWD2am5s1ZUUlEong4IMPBgBMmDAB+/btw4oVK/Dxxx9ritOf//xnAMDChQtx7bXXatcuW7YMs2fPxueff469e/dqysbmzZsxcuRI7bxDDz1U+7xu3TpEIhGMGzdOO9a5c2cMHz485fv1799fU0gAYPz48ZBlGatXr0ZFRQW2bduGo446SnfNUUcdpXOTM8oj4vPPP0djYyO6dOmiO97S0oJ169Y5kseoJI0ZMwbHHXccRo8ejalTp2LKlCk466yz0KlTJzQ0NKSU/ZtvvsGBBx6os3ypyq4V33zzDX70ox+Z7nnfffchHo/nbC1WJjDG0NASQ2UZNT8EQRCEO8gyw77WGKrLQ5CkzDxzCIKHRikGMnV5s0OChGBA+Rdw6f4dOnTQXOEee+wxjBkzBo8++iguvvhibV3Rf//7X93AHoBmLenYsSPGjBmDBQsW4JNPPsEJJ5yAiRMn4txzz8WaNWvw3XffaZakpqYmTJ06FVOnTsUzzzyDbt26YfPmzZg6dSoikYhJLi+RSp7Gxkb06tULCxYsMP3WsWPHjJ4ZDAYxf/58fPzxx3jnnXfwwAMP4IYbbsCSJUtMylh7ZHdjG774vh79u1RgUGexCyRBEARBpMPm2mas3dWI4T2r0K9zRaHFIYoACtxQBAQCAVx//fX4wx/+gJaWFowcORKlpaXYvHkzhg4dqvvXr18/7bpJkybh/fffxwcffIDJkyejc+fOGDFiBP70pz+hV69eGDZsGADg22+/xZ49e/DnP/8ZEyZMwP77768L2mDFkCFDEA6HsWTJEu3Y3r17sWbNmpTXbt68Gdu2bdO+L168GIFAAMOHD0d1dTV69+6Njz76SHfNRx99pLNqOeGQQw7Bjh07EAqFTGnVtWtXR/KIkCQJRx11FG6++WasWLECJSUl+Pe//+1I9hEjRuCLL77QhXRfvHix7XuMGDFCeM9hw4Z5yooEAK0RxQrZGo0XWBKCIAiiWGiLybq/BJEtpCQVCWeffTaCwSAefPBBVFVV4ZprrsFVV12FJ598EuvWrcPy5cvxwAMP4Mknn9SumTx5Mt5++22EQiHsv//+2rFnnnlGtx6pf//+KCkpwQMPPID169fjtddew6233ppSpsrKSlx88cW49tpr8d577+Grr77CzJkzLV0OecrKyjBjxgx8/vnn+PDDD/HLX/4S55xzjubadu2112Lu3Ll47rnnsHr1avz+97/HypUrUwY4MHL88cdj/PjxmD59Ot555x1s3LgRH3/8MW644QZ89tlnjuXhWbJkCW6//XZ89tln2Lx5M15++WXs3r0bI0aMcCT7+eefD0mScOmll2LVqlV44403dJEIRfzmN7/Bu+++i1tvvRVr1qzBk08+ib/+9a+45ppr0koPgiAIgvAjDEz7RBBuQO52RUIoFMKVV16JO+64A5dffjluvfVWdOvWDXPmzMH69evRsWNHHHLIIbj++uu1ayZMmABZlnUK0eTJk3H//fdj8uTJ2rFu3brhiSeewPXXX4+//OUvOOSQQ3DXXXfhtNNOSynXnXfeicbGRpx66qmoqqrCb37zG13obCuGDh2KM844A9OmTUNtbS1OOeUU/O1vf9N+/+Uvf4n6+nr85je/wa5duzBy5Ei89tprush2TpAkCW+88QZuuOEGzJo1C7t370bPnj0xceJE9OjRw7E8PNXV1fjggw9w3333oaGhAQMGDMDdd9+Nk046yZHslZWVeP3113HZZZfh4IMPxsiRIzF37lxtzZmIQw45BM8//zxuvPFG3HrrrejVqxduueUWTwZtkBNR/hj1YwRBEIRLUJ9CuI3EWHEXq4aGBtTU1KC+vh7V1dW631pbW7FhwwYMGjTIMjy0GzgJ3EAkmT17Nl555RWsXLnS9Xtnkhe5lKeQ5Kv8G9nwQxPW7WpEt6pSjOzZAW+88QamTZuGcDicNxkIM9FolPLCI1BeeAfKC29hlx/fbG/A1r0tGNClAvv1qCqQhO0HP9cNO92Ah0bsBEHkFXVepqhnZwiCIIi8ok75U99CuAUpSQRB5BXqwAiCIAiC8DqkJBGeY/bs2Z5ybfOaPH5Hm+0rbk9fgiAIIo+ogRuoayHcgpQkgiDyDPVgBEEQRG5g1McQLkFKEkEQeUUmv3GCIAjCZciCRLgNKUkEQRAEQRBEUUDKEuEWpCQRBJFXaJ8kgiAIIldQ30K4BSlJhK9Yu3Ytbr/9drS0tBRaFCJDqAMjCIIg3Ib6FsJtSEkihCxYsACSJKGurg4A8MQTT6Bjx44Flam1tRVnnXUWevfujfLycsfXGd9l3rx56Ny5c8rrHn30UUyZMiVTcYVEIhEMHDgQn332mav39RPJjox6NIIgCMJdKHAD4RakJPmQmTNnQpIkXHbZZabfrrjiCkiShJkzZ7r6zHPPPRdr1qxx9Z7p8otf/ALTp09P+92OPPJIbN++HTU1NY6vaW1txR//+EfcdNNN2rGvv/4aZ555JgYOHAhJknDfffcJr33wwQcxcOBAlJWVYdy4cfj000+130pKSnDNNdfgd7/7XVrvUExQB0YQBEG4DYUAJ9yGlCSf0q9fPzz77LM6t7PW1lbMmzcP/fv3d/155eXl6N69u+v3TYd//OMfmD17dtrXlZSUoGfPnpAkyfE1L774Iqqrq3HUUUdpx5qbmzF48GD8+c9/Rs+ePYXXPffcc7j66qtx0003Yfny5RgzZgymTp2KXbt2aedccMEFWLRoEb7++uu036UYSO6TVFg5CIIgCIIgrCAlyacccsgh6NevH15++WXt2Msvv4z+/fvj4IMP1p0ryzLmzJmDQYMGoby8HGPGjMGLL76oO+eNN97AsGHDUF5ejmOOOQYbN27U/W50t1u3bh1+9KMfoUePHqisrMRhhx2G//3vf7Yyz549GwcddBAee+wx9O/fH5WVlfj5z3+OeDyOO+64Az179kT37t3xpz/9SXfd5s2b8aMf/QiVlZWorq7GOeecg507dwIA1qxZA0mS8O233+quuffeezFkyBAAZnc7Jzz77LM49dRTdccOO+ww3HnnnTjvvPNQWloqvO6ee+7BpZdeilmzZmHkyJF4+OGHUVFRgccee0w7p1OnTjjqqKPw7LPPOpaHIAiCIAhraOKNcBtSkngYA5qaCvMvg9r9k5/8BI8//rj2/bHHHsOsWbNM582ZMwf//Oc/8fDDD+Prr7/GVVddhQsvvBALFy4EAHz//fc444wzcOqpp2LlypW45JJL8Pvf/9722Y2NjZg2bRreffddrFixAieeeCJOPfVUbN682fa6devW4c0338Rbb72Ff/3rX3j00Udx8sknY8uWLVi4cCHmzp2LP/zhD1iyZAkARcH70Y9+hNraWixcuBDz58/H+vXrce655wIAhg0bhkMPPRTPPPOM7jnPPPMMzj///NSJaMGiRYtw6KGHpnVNJBLBsmXLcPzxx2vHAoEAjj/+eHzyySe6cw8//HB8+OGHGcvnZ7TodgWWgyAIgiAIwopQoQXwFM3NQGWl67cNAOiY6qTGRqBDh7Tue+GFF+K6667Dpk2bAAAfffQRnn32WSxYsEA7p62tDbfffjv+97//Yfz48QCAwYMHY9GiRXjkkUcwadIkPPTQQxgyZAjuvvtuAMDw4cPx5ZdfYu7cuZbPHjNmDMaMGaN9v/XWW/Hvf/8br732Gq688krL62RZxmOPPYaqqiqMHDkSxxxzDFavXo033ngDgUAAw4cPx9y5c/H+++9j3LhxePfdd/Hll19iw4YN6NevHwDgn//8J0aNGoWlS5fisMMOwwUXXIC//vWvuPXWWwEo1qVly5bh6aefTis9Verq6lBfX4/evXundd0PP/yAeDyOHj166I736NHDZOnq3bu3lm/tDZrtIwiCINxG7VqojyHcgpQkH9OtWzecfPLJeOKJJ8AYw8knn4yuXbvqzlm7di2am5txwgkn6I5HIhHNLe+bb77BuHHjdL+rCpUVjY2NmD17Nv773/9i+/btiMViaGlpSWlJGjhwIKqqqrTvPXr0QDAYRCAQ0B1T1/B888036Nevn6YgAcDIkSPRsWNHfPPNNzjssMNw3nnn4ZprrsHixYtxxBFH4JlnnsEhhxyC/fff31YWK9R1XmVlZRld74Ty8nI0Nzfn7P5ehjoygiAIwm2Y5qVAnQvhDqQk8VRUKBYdl5FlGQ0NDaiurtYpA6ZnZ8BPfvITzXLz4IMPmn5vTLzPf//7X/Tp00f3m9W6Gidcc801mD9/Pu666y4MHToU5eXlOOussxCJRGyvC4fDuu+SJAmPybLsWJaePXvi2GOPxbx583DEEUdg3rx5uPzyy52/jIEuXbpAkiTs3bs3reu6du2KYDCorZdS2blzpynQQ21tLbp165axjH6GkXZEEARBEITHISWJR5LSdnlzhCwD8bhybyslKUNOPPFERCIRSJKEqVOnmn4fOXIkSktLsXnzZkyaNEl4jxEjRuC1117THVu8eLHtcz/66CPMnDkTp59+OgBFGTMGe3CDESNG4Pvvv8f333+vWZNWrVqFuro6jBw5UjvvggsuwG9/+1v8+Mc/xvr163Heeedl/MySkhKMHDkSq1atSmufpJKSEowdOxbvvvsupk+fDkBRkN99912TC+JXX31lCrDRXkhakkhZIgiCINyBvBQIt6HADT4nGAzim2++wapVqxAMBk2/V1VV4ZprrsFVV12FJ598EuvWrcPy5cvxwAMP4MknnwQAXHbZZfjuu+9w7bXXYvXq1Zg3bx6eeOIJ2+fut99+ePnll7Fy5Up8/vnnOP/889Oy/jjl+OOPx+jRo3HBBRdg+fLl+PTTT3HRRRdh0qRJusAKZ5xxBvbt24fLL78cxxxzTNrriYxMnToVixYt0h2LRCJYuXIlVq5ciUgkgq1bt2LlypVYu3atds7VV1+Nf/zjH3jyySfxzTff4PLLL0dTU5MpoMaHH37o+ka1fkELAV5YMQiCIIgihPoWwi1ISSoCqqurUV1dbfn7rbfeij/+8Y+YM2cORowYgRNPPBH//e9/MWjQIABA//798dJLL+GVV17BmDFj8PDDD+P222+3feY999yDTp064cgjj8Spp56KqVOn4pBDDnH1vQDF9e7VV19Fp06dMHHiRBx//PEYPHgwnnvuOd15VVVVOPXUU/H555/jggsuyPq5F198Md544w3U19drx7Zt24aDDz4YBx98MLZv34677roLBx98MC655BLtnHPPPRd33XUXbrzxRhx00EFYuXIl3nrrLV0wh08++QT19fU466yzspbTn1AXRhAEQbgLWZAIt5FYkfu8NDQ0oKamBvX19SZForW1FRs2bMCgQYNyukjf0ZokIi+kkxdnn302DjnkEFx33XWuynDuuedizJgxuP766129b7rkq/wb+WxjLeqao6gsC2Fsv2q88cYbmDZtmmltGpFfotEo5YVHoLzwDpQX3sIuP5Zt2ou9TRF0qSzBwf07FUjC9oOf64adbsBDI3aCsODOO+9Epcsh4SORCEaPHo2rrrrK1fv6CVl1tyvq6RmCIAgiv9AefIS7UOAGgrBg4MCB+MUvfuHqPUtKSvCHP/zB1Xv6jSI3XhMEQRAFgLoWwm3IkkQQRF7RIhDRfB9BEAThMqQsEW5BShJBEHmFJbUkgiAIgnAF6lIItyEliSCIvEIWJIIgCCJ3UB9DuAMpSaA1EkT7pGDlnqobQRAE4TKMggIRLtOulSQ1ZGFzc3OBJSGI/KOW+3yH7iRvO4IgCIIgvE67jm4XDAbRsWNH7Nq1CwBQUVEBSZJcf44sy4hEImhtbaV9kgoM5YViQWpubsauXbvQsWNHBIPBvD5fpmk+giAIwmVU7wjqYQi3aNdKEgD07NkTADRFKRcwxtDS0oLy8vKcKGGEcygvknTs2FEr//mEXCIIgiAIt9G8FKhvIVyi3StJkiShV69e6N69O6LRaE6eEY1G8cEHH2DixIm+25W42KC8UAiHw3m3IKlQCHCCIAiCILxOu1eSVILBYM4GjcFgELFYDGVlZe16YO4FKC8KDwVKIQiCINwm6aVAfQzhDu1zUQZBEAWDui+CIAgiV1AfQ7gFKUkEQeQXWpNEEARBuAy5cBNuQ0oSQRB5Re3IqDsjCIIgXIMm4AiXISWJIIi8IsuFloAgCIIoVsiiRLgFKUkEQeQNfkEtLa4lCIIgCMKrkJJEEETeIL2IIAiCyAXM9IEgsoOUJIIg8gb1XQRBEEQuoEk4wm1ISSIIIm/o3O0KKAdBEARRnFDfQrgFKUkEQeQNZvmFILxDLC6jviVaaDEIgkgDLXIq9S2ES5CSRBBE3qDOi/ADq3fuw9INtahtihRaFIIgCKJAkJJEEETe4EOzUphWwqu0RpU49W2xeIElIQjCKeokHPUthFuQkkQQRN4gSxLhJ6i8EoR/UKsr1VvCLUhJIgiiIFBHRngXxv1PEARBtEdISSIIIm/IpBkRPoCKKUH4DzV6KlVfwi1ISSIIIm/wg08aiBJeJem2Q4WUIPwG1VvCLUhJIggib1DXRfgBbQE4FViC8A1UXQm3ISWJIIi8QTN8BEEQRC6hXoZwC1KSCILIG8bOi5QmwotQuSQIH0LVlnAZUpIIgsgbxrEnjUUJL0KhhAnCf2j7I1G9JVyClCSCIPIGzdATfoCKKUH4F9pMlnALUpIIgsgbNPgk/ADT9kmiAksQfoH6F8JtCqokzZkzB4cddhiqqqrQvXt3TJ8+HatXr9adM3nyZEiSpPt32WWXFUhigiCywbQmqSBSEEQKKLodQfgWqreEWxRUSVq4cCGuuOIKLF68GPPnz0c0GsWUKVPQ1NSkO+/SSy/F9u3btX933HFHgSQmCCIbjO525H5HeBkqnQThHyh0P+E2oUI+/K233tJ9f+KJJ9C9e3csW7YMEydO1I5XVFSgZ8+e+RaPIAiXob4rNa3ROGTGUFFS0Oa5XUPllCCIfNEWiyMWZ+hQSm2+1/BUjtTX1wMAOnfurDv+zDPP4Omnn0bPnj1x6qmn4o9//CMqKiqE92hra0NbW5v2vaGhAQAQjUYRjUZzJLk96nML9XwiCeVFYYlGo4jFY9r3COWHiSXr9iASl3H0kC4IBfNn7Ke6kSQaiyEWjxes36C88A6UF97CKj8YY/q+JRKBJEl5lS1Tlm6oRVMkjqOHdEFJyD+hAvxcN5zKLDGP+LvIsozTTjsNdXV1WLRokXb873//OwYMGIDevXvjiy++wO9+9zscfvjhePnll4X3mT17Nm6++WbT8Xnz5lkqVgRB5IeGCLC5MdlxjejIkEc9wBd8vVcCY8CwGoaSYKGlaZ98WychJgPdyxm6lxdaGoIgUsGY0naqjOrE4BMdCd/slRBnwNAahjJq8/NCc3Mzzj//fNTX16O6utryPM8oSZdffjnefPNNLFq0CH379rU877333sNxxx2HtWvXYsiQIabfRZakfv364YcffrBNiFwSjUYxf/58nHDCCQiHwwWRgVCgvCgsu/a14cut9dr38QNrsOC9dyk/ON5bvRuMMRw5uAvK86glUd1IsmjtHrTF4hjUpQMGd+uQ9+dTXngHygtvYZUfsszw/prd2vdjhnVDIOAPLemD735ANC7j8IGdUVXmKQcvW/xcNxoaGtC1a9eUSpIncuPKK6/Ef/7zH3zwwQe2ChIAjBs3DgAslaTS0lKUlpaajofD4YJnohdkIBQoLwpDMBhHKJhsdkIhJQ8oP5KEgkEwBoTCIYTD+W+iKS+AYDCIEJMQDIUKmhaUF96B8sJbGPNDlpm+bwmHEfSJkhQIBhFCAOFwYdubTPFj3XAqb0GVJMYYfvGLX+Df//43FixYgEGDBqW8ZuXKlQCAXr165Vg6giDcxrjvjCfM2B6DIjQVHkp6gvAXvq6zTPeH8BAFVZKuuOIKzJs3D6+++iqqqqqwY8cOAEBNTQ3Ky8uxbt06zJs3D9OmTUOXLl3wxRdf4KqrrsLEiRNx4IEHFlJ0giAygAb+hB9IeqFTgSUIP6LUYX9YkgjvUlAl6aGHHgKgbBjL8/jjj2PmzJkoKSnB//73P9x3331oampCv379cOaZZ+IPf/hDAaQlCCJbTENO0pp08EtEKWUKDxVPgvAHpj34CiRHJqgeFtTeeI+Cu9vZ0a9fPyxcuDBP0hAEkWs8EifGF1BaFQ6yIxGEvyiKuloUL1FcUPBdgiDyBo377eHTh5KqgFDiE4Sv8VNf4ydZ2xukJBEEUTCob7CGOs7CQe4vBOEviqGuGgMbEYWHlCSCIPKGsSMrho7NTSg5vAUNWgjCn/ip7lI/6F1ISSIIIm/I1Bs4h5KqYFAxJQh/Ydpewod12I8yFzukJBEEkTeMfYCfZvvygT66HaVNoaC9qgjCX/i1rlJEU29DShJBEHmDIrY5h5KqMOgGLZQHBEHkEGpjvA0pSQRB5A2TJYk6CB3M4jORP6hMEoT/8WM9pklE70FKEkEQeYP6AMJPkMsjQRBE+4WUJIIg8oh/d0XPB7p9kkijLAg6ax5lAUH4AlPkVJ/0LuQ94G1ISSIIIm/I1As4hpKqMJByShBEvqA1kN6GlCSCIAoGdQp6+NlPSpvCQMlOEP6jGEKAE96DlCSCIPIG7ZPkHL+4ixQzVFwJwp/4perq3e38InX7gZQkgiDyhnnQSZ0CDw3KCw/lAUH4D9OaJKrIhAuQkkQQRN6gfisNKK0Kgs7lkTKBIHyBX2sqo8gNnoaUJIIg8gb5jTuHkqYw6CMMFk4OgiAyxy9VVz8pQ3gNUpIIgsgbNOh0DqUVQRCEM8i9jsgFpCQRBFEwqFvTQ/28t6DsIAh/4pe2lCzX3oaUJIIg8gZFt7OH1sMUHtrQlyD8B8UEInIBKUkEQeQNcwSiwsjhByhtCgOtESAIohDQxJj3ICWJIIi8QV2AcyitCgMppwThP0wTcD5sQant8R6kJBEEkTeM7kt+7MhyCXWS3oLygyB8gk/rKrUx3oaUJB/REomjJRIvtBgEkTFe7A/iMkN9SzTt66JxGQ2t6V/nFFoPY4YxhvrmKGQ5d2ljVOMJopC0RuPY1dCKXQ2taI7ECi2Ob/BL80nuvd6GlCSfwBjDpxtrsWTDnpwOEAgil3hxTdKanfuwdEMtfmhsS+u6r7c14NP1tdjnoqKk21fQA2njNbbsbcHSjbX4fm9zzp5ByinhJT7buBdfbKnHF1vqsWRDLeLU/wsx7cFXIDmI4oKUJJ8gMyAakxGLM4oQRvgY75Xdtpis++uU1mg8o+vsoAG6PblIcyOkqBJeQi3zABCPM0TjuSv7xYQf21I/ylzskJLkE/jKQ9WI8CvmxbWFR61bmXZQuerXqL80o06i5zJtKN0JL0OTpGL8miy0T5K3ISXJJ1DdIYoBL3qKqCKl20FRh5Z/VFejfAX8oCwmCgk/cSNJyl9yt3OGX1LJL3K2V0hJ8iE0OCP8islaUwSF2c0Bu87Vi7pPE7Jm9cvhQ2hml/AggYCiJZGOJIaShcgFpCT5BJ1JlpoDwqd4seRmOhDORT0k14vCo4s2RZlAFBC++AUTpiQK3CTGtL2ET5JJt5TCJzK3J0hJIggib3hxTZIqRcYdVK7WJOXmtr5Gc7ejNUlEOyOoWZKogDqBJpMJNyAlySfoZzcLKAhBZIEpTKuHynLanWouZNdZkjyUOB4hHwNEZvGZIPINX/4CCUtSnNoFIX5NFXKx9jakJPkEaheJosCD5TjbuuXBVypatOh2+QrcQJlLFBB+okSzJFEEcGf4pO5SG+NtSEkiCCJvqP2BGqnJS6Qd3S4XMtDu67awPARuIAse4UXI3c4eb7pypwdlrfcgJcmHUEUi/IrawauuI14oyszwN+3raZ+kvJGPNevk/kJ4Bb70qUoShQAvMpjwI+ERSEkiCCJvqAN/L1mSMo5ul4MeTX9P6jKN5GVNEi1KIjyIGt2OJk/EeHm9K+FfSEnyCRQCnCgGku52aodf+LKcdOFKTxa1HuaqPnogaTxHPvZJovaV8Ap8OQ8kRmsUuKG4oC0HvA0pST6BotsRxQDT3O0S3wsoixEvyOIFGbxMvts+yg+ikPD9Pq1JSoFpTRKlE5E9pCQRhA9picTREokXWoy0UbutgIf87bQ1SR5yuwNogC5CsyTlMnVoQ1/Cg9BmsvYYU8WLdbctFse+1qjumN5LiPAapCT5BKpIhIosMyzZsAefbqz1n3leXZNUWClcQU16N3OAdl+3RwsBnh8diWajiYLCr+FUXZRJR3KGF5Pp8+/rsWR9LVqjyQlOXXvjRaHbOaQk+RDfDYwJV5EZQyzOEI3Jvusw1UGn5KFFyEkZ0l2TlFtogG4m74EbCMIDSBJFt0uF1+stY0yzIrXFaLMrv0BKkk/weP0n8oh+5slfJcOT0e3UAAwZu9u5lwc0q2iPFmQjb8/L04MIIgWaux0VSkd4rW9si8nJ9kTn0kvhNL0MKUk+QeeGU0A5CCJTGGNaJ+GlNUmZ4rVOuD0g52EClix4hFfQJpUgaRNLpCSJ8Xq9bY7wLnbelpVIQkoSQfgMv65P04WzVaPbeaHDz3JtkZuvoMtbDySNl+AXrOey3Pi1fhHFDbnbpYfX2s+WqDjQEnkPeBtSknwCVSRCxa+zULzUUjFYknJ+f3/mc66Q82RN97M7K1FcaG2AlLS+k44kxutVlY9GayWrx1+hXUJKkh+hmkQk8HrHwMMPOL2kI2UbAtxNaD80a2hwSLRXJCQ3kyV3OzFeTxWKaOdPSEnyCXoXEKpV7Rm/lgVeUnVW1AvSJ0N5pylNHsJRE0l0lqRchgCn9Z+ER9C7KNM+SengtXZZtyZJ18bQxJiXISXJL1DlIXwO3wFIgmOFItvodq7iBRk8ij5/8rMmifKDKCRq8ZMkSYtuF/dEQ+U9vO4aa7UmifA2pCT5EI+3BUQe8VNZ4GfMvORulym5tuL5KW/zQSHcjPxkqSWKm4CH9pbzA16qu7G4jCi3N5LVfI+XZCYUSEnyCVR5CL+jhf8OKCFtAW+Ua83dLtN9klx8B70Ro/Bp4yXy526Xu3sTRDqo1hF+TRJFtxNjrLdeqsdGK5Jl4AYPyUwokJLkQ6getW+KoSH1oiUpXaUkW+XK6f0JhUKMDSkPCC8gSckQ4BS4wRleSiU7VzsvyUmYISXJJ+j3T6Fq1Z7x60JPtXPnw397QX4PiKDhhfTwKvkKqODX+kUUH6JgN6Qk+Y/WiH4XbKsJOcpa70FKkk+gukP4neTu8d5CHXyn20Elo+LlBqrzemTdRFHunkMDFcIrJNtMiYtuRxOlIszudt5Jo+ZoTH8gT20ZkT2kJHmQ1mgczZGY5e9Up9o3fg8BrrMkFUYUz6K3YuhTpzUa121I2N7Qr0nKYXQ743fuWbG4jIbWaM6eXSga22JoixVH2ZJlhvrmqKcGyW4Q4GaXaFmSv3DabvupP28vkJLkQZZurMWSDbW6BZo6VxOqR4QP4Rche2lNUibVieVhwK7fcJDh0w21WLJhT7vdJyVfbkbG/OS/rtregE/X16K+pXgUpdZoHEvW78Hn39cXWhRX2FTbjKUba7GtvrXQomSPakni1iQB5HInwqhgeCmF1DVJar9HAXr8AylJHoMxhraojHicIRqXU19AtDv0g+eCiZE2SUuS4GAhySAAQ76DNcRlhkhMRizOEGuvShLXHBYqBdoSYXyLxeoCKO/EmKIsFQPqrH0xvI86gFYmliSt7aQId6nxUt+YjOxqDuNu9ZnwBqQkeQzL0JC6z1STCAU/lQTev17y3MqkzOtVztYkcTfmFaP2Wv/z9d4mdzv+M7M4ycdoa/IKLIdbqFaWYhxwBijCnSVeThKvrsclUkNKksewshJ4uQEg8otffe1VuXnfei8M+FUZvJCsVg4j+dojyMt4IXCDXGQKBVB861uS+ef/F9PeJdFmJiPcFUYeL2NOEu8kkmYRlMz7A3pHSkIEKUkeQzcYsqo+VKuIBH5VmPxOPlwe+fuSew10a7Fyq1wb1yQVd9onLS/F8Z7FbEkKJgbZ1B6kxov5r04Q0may/oGUJI9h6atKMw9EAr/mv9qv8771XugUMgnlnbNgDRZ7AemDuOTk0Z4nf4EbDN8FvxVTHhSbdayYXNGShiSlwUwOsovnHdsDvKu5+TfKSy9DSpLHkC0GSQSholee/YMW3U7yWHS7rBMx97kQpzVJehejAiVBMaZ9sa2zUstJMbwO32YCyTVJZEkyY4pKWSA5RKiyBATR7fTneUlqAiAlydMwi9EwTTwQKn4qCwb3euWYh+RPZ0YvH8EayN1OT94sScbvAuWsmAYzxWR5AbhAFMX1WgBoTZIdXk4SljQl6b+D1p57HVKSPIZVh6Xvp6kmtWt8mv1aPyF5J7qdlXtbevdwRxbzfZM3jlPgBlfyytlzDN+L3NVZLjLFr5jexzixFEyM2IpNsc0FXkwir/R7hHNISfIYfnWlIgqEjwpJMsIPf6ywZNqR5qOeWq5JytHzvE7eotuZAjeYP3txAJYpakCMYnmnYg7cIEkUAtwKu8mNQmNyt7MK3JAXaYh0ICXJY1iF+iWTLKGin9n2UWHgPA68tCZJxQv1yom7XXtd6Oso8qcL2CWvr+qbQ4qtOBWTAsFb3wGKbudbDPmo+4my0tOQkuQxmOWXlIcJwtPIgo6i0AP+TJf65nuwTJYkQJYLLUFmkRC9TrzILC/FZO0zWt+D6mayHqgL3sPaAlxo1HxMHQLcQ0ITAAqsJM2ZMweHHXYYqqqq0L17d0yfPh2rV6/WndPa2oorrrgCXbp0QWVlJc4880zs3LmzQBLnHsY1fr61GBA5xa9WRb7D96AhyRXXOzfh6zyFAM/fhromt50id4HWp6v/3zAZ0tz/72JEVZaKyVrmFnb11iuIPCiKfc2j3ymokrRw4UJcccUVWLx4MebPn49oNIopU6agqalJO+eqq67C66+/jhdeeAELFy7Etm3bcMYZZxRQ6tyiqzCW7nZUldozfs19Q4Af5VhBJOGen2FdstrDLFt09+Ld7Yp9pO6AfDV7dvmZjJxWPJlgFWnLr8SLaY2Voc1ULUnxoni59oPRbbIYFfhiJVTIh7/11lu670888QS6d++OZcuWYeLEiaivr8ejjz6KefPm4dhjjwUAPP744xgxYgQWL16MI444ohBi5xSZxkKEgNZoHDJjqCjRV1k/lREtUhO3mWyhYRafC4WVLhSLp29Vbo7EEJAklIWDLkmXexhjaGiJoaospO0Jo+LmHnJxmaGxNYbq8pBpnYCXF4DngmJb3lJkr6NDDQHuppLe2BZDOCihNOSfdkKEMUW8VG+NE4S03tw/FFRJMlJfXw8A6Ny5MwBg2bJliEajOP7447Vz9t9/f/Tv3x+ffPKJUElqa2tDW1ub9r2hoQEAEI1GEY1Gcym+JepznTw/Eo0iFo9pn6NRSbtWPR6Nxgr2Ln4nnbzwCowxfLxuDxgDjh7SxbKMeB21DMdjQUQDDLF4DNFoQPutIDLFZa5eSY7liEbjOamPsVgsed8Y0+6bbp7H4jI+WrcHJcEAjhzSxdGzvVA3tte3YtX2Bgzs0gFDunXQ/cangYRAVnJ+t7MRm/c2Y3SfGnSvKtX9xucBkOg7JJb8TWY5b4PzmReRiL5sBQP+aE+siEZjkBlDLOZOHhWyXqhlPh5XyrscV9qdSMSdd2uLKe1Eh5Igxg3q7ILEuccqP2JRpd5KkgTGcl9H00GtX/F4ELF4TFc2o7Fk/YvHsmvX8o0X+oxMcSqzxDziNyDLMk477TTU1dVh0aJFAIB58+Zh1qxZOqUHAA4//HAcc8wxmDt3ruk+s2fPxs0332w6Pm/ePFRUVORGeBfZFwU27VM6qQFVDFVh5XhtG7CtSTneq4KhS1mhJCTyTUwGvq1T8n5ER4aWOLAxUUYGVjFUhgspnXP2tALbmyVUlzCUBoHdLRK6lDH0KmC15NO2PMQwpNrZdZE4sKZeua5TKUOfDikucMiuFmBXi3LfcAAY3lFpnjfuAxqjzvNclU+SgFGdPNHEO0J9/46lDH0NabphH9AUVaN8ASOyeK9N+4B9UQk9Kxi6GtrS7xuB+khSUdivRimvAPD1XgmMFVcbvLUJ2NuWaF86MQR9rCMxpuQRANSUMPSrLLBAWVLXBmxpktAhzDCoKlk/3GpzWmLAugYJwYDSt/iZbc1AbavS5jEGYRtSCPgyWV3C0BCR0L2coXu58jvf5qv5TOSe5uZmnH/++aivr0d1tXXH7xlL0hVXXIGvvvpKU5Ay5brrrsPVV1+tfW9oaEC/fv0wZcoU24TIJdFoFPPnz8cJJ5yAcNh+dLN7Xxu+2KpY1Mb0rUHXSmWWc2tdC77dsQ8AsF/3SvTv7H2Fz4ukkxdeoTkSQ4f1tQCACUO7Yl9rFCu3KGXkoL416FJZane5Z/h+bzPW7GxEj6oylJcEsXFPE3pVhbHx808Klh9tMRkd1v4AAKgqC+Hwgc5mU1sicVSt3wMA6F1TjhG93OnZNu5pwrrdyprM0lAQRw9VrEDLNu1FXYsy83VQv47o0qHEkXySJOHY4d0cPdsLdUN9/57VZRjVW99e82kQCkiYNMzZe4lYsbkOtc0RDO1eiQGGtvSrrQ3Yua9V+z5uUGdUlipdZfnq3ZAZw7AelejXKXdtcD7z4uttDdjRoLzvpP26IhT0b9BbWWYoW7MbANC9qhSj+9Rkfc9C1osdDa34elsDOleU4OD+HbGpthlrdzUK60cm1LdE0XHTXoSDAUzcr6sLEuceq/xYs3Mfvt/bglBAQkxmrqVRtvBlskdVGXbua8WQbh0wsIuiwW34oQnrf1Da/I7lYYwd0KlgsqaLF/qMTFG9zFLhCSXpyiuvxH/+8x988MEH6Nu3r3a8Z8+eiEQiqKurQ8eOHbXjO3fuRM+ePYX3Ki0tRWmpedAYDocLnolOZAiF4ggFlWwJhkLa+cFgVDseDhX+XfyOF8qDY2LQ8j4UDiEU57/75z1CwTBCwRDC4RDC4SBCwRBCoUSZLtB7yBJX34IhxzJEmZTMg5Dz61IRCoU5eQLafaVAEKEgc/w8Xr50ZStk3QgGQwgFQ8K8CARDWhoEA1J2MgYS5U/wnGAoqKUdoE/vYDCIAFPKcj7SKB95oaY5kGhPfKwkxeJyRvXZCYWoF6FQTCmnYeVdSsNhy/qRCcEIS9wvy/pUAIz5EQyFEnVaAuLM1XY5G2SZcW2xuX0LhUI56Uvyia/GUwmcylvQ1pAxhiuvvBL//ve/8d5772HQoEG638eOHYtwOIx3331XO7Z69Wps3rwZ48ePz7e4eUG3iNZynyR/m8WJ9IjFk3HhGfPvQk914T2/Tr7Q8rvxfFej21kEJ0g3BHih0zVTmPbX/AJuhj3WIqCJZLB5jF/T1Y58hVbPB8UWhMJIwOXodslw6f7HFEHOIy/Fi6H2fVbDPI+ITHAU1JJ0xRVXYN68eXj11VdRVVWFHTt2AABqampQXl6OmpoaXHzxxbj66qvRuXNnVFdX4xe/+AXGjx9flJHtAIqZT5iJGXp+v+6fpUW3g1RU+yS5KgP/mRMoztLLc+N9RDu9exlRXshppoEdqpLkRPHSFDcXn+8l3EzXQuNmBEQvYIyKFkzUY7cmDIpRqdQiyHmkBPDthtrz+XWisz1SUCXpoYceAgBMnjxZd/zxxx/HzJkzAQD33nsvAoEAzjzzTLS1tWHq1Kn429/+lmdJ84dsUXmoUrVfovHi2F5d7Sx0lqQCySIinU413/UxnuZoxrj3jV90JFXsdC086aIqnaJ7mkIJM/3fYqOYBsrFtjEuv20CAKiBB2WXMo3ZVTifkbQk6b8XGl6MQArfLa/ITCQpqJLkpBErKyvDgw8+iAcffDAPEhUeJ2lC9ah9EY0bctyn9vlkh+8dlwiWYVrmSmyrfZLiaW6g5qNiYcDawuOmW1hcVicezDeyaoP11rnsnu8limkz2WLfZ1Bzt3NJSSomBVkl4OEZIYmzc4koBsW+2PDvCs0iRT9IKh43CCJzjGuS/ErSdcS7nZinSKSXLDNL5cnyUp8OFu2sNumuy7J+BoOqI4kGiaZDmkx+SknnFNNAudjySLO+J74HNHc7d+6fXJPk/3RT38FeDck/fJEUW7m8IikhgpQkj+HEjafYOgLCHt6SxAzdmb9KQtLdzitqUqZrAHM3+26eGDEu0nb0PF074q9SoiCw8Lh057SDYEAdSLovixdwMyBGoZE5z+Qiei0N99ckFWEieaVzScD3MaJ9mv06odVeICXJY1gtPKWK1H6Jyfo1SX5dn6bKGtCtSSrsC/gh/YyuNc4CN2Sm/BUaVVbhWiGTspjZm/GBUERp6Ycy4SbFFd2uuFRZ4zobdU2LW8pNMa23S/Yvqiu3N15Kn4cJ2QomDZEupCR5DL1i5M+BDuEuOkuSjwtCUnTJc4trgfRk0Q/F3HsJkQJsUpKcWD88lK7pYLWOnHeRM56bLqmVAnF66/PGpwkswMrF248Uk8LHo7ooqwqAe2uSElbSokorBS+/ktWkdzHlQ7FASpLHcNLIU0VqX8Rsotv5aVAj2iep0ORK2XEDtZ6bQ8A7uFZwHz9hlNnVyHZceopm5E3P1v76MCEdUEyKRbEHbggG3A14U0zr0VS8ut2BErDI/pxibWP8DClJHoPWIRFG9O5B/m1I+T0/vBK8IdN6lSuXR7EFJX03M7/u6aPKalRehMpMhs9ItSZJlAfGc/2ToqkppoFysfWTRnc79a9bliR9XfB32nk2BLjW7yX7PJ07tEfkJMSQkuQ5nFQeqlXtiaguuh3L2QA91yQ7MW8oSEa8mpYZBW4Q0NQWQ2s07oJEucNqjYSbA3k3BpheLSuZUOgNWBljqG+OupIvVvsMFgt8eGt39koqvkTiVRFPwQUssnRxdVnk5oj323yvQ0qSx5AtKo/f3WeIzGCMIWbcJ4n/PY+yZAsfotUrehKz+JzOhW7mgcjNLJPBo7G9iMZlLNmwB8s3781OwByTXJPkwJKUYUPIK53iABGG7zbnFgP6SI35f8nd+9qwdGMt1u9uzPpexbeZrP4dglzDaZw8yYRiUiq1/sUjfYsKn4f53B8wLjMs2VCLpRtrc/+wIoaUJI/hVysBkRtE61H8WiyM7hD8MS+QzqAqXy5sDJkFbjAqFZGYDFkG2qLW69s8hcmSpBzgd6x3w93OifIlVtw8VHCzQBQQI9+0Jspkqwtls9BWsVyRjG4naXXADcubW257XsIrG5Wr8G7mdr8D7pbZaFxGPM780+Z7FFKSPAaFACd4onHr8N/Kd/+VBivf7ELgRvK5mQfG9GCMZRQC3On9vYZoTyLAXVfNuGw/kLZKIR9WtZRYWc3yKoOW5+66QRZDfoneIZTQkox9QyYUk1KZShkpFGq6SpLERd4Tp3auyqwfxwlegZQkj+EkzCyV9/ZDVOBq59cGz4vR7TJ1m8vXpEWmliQYBot+cRmzXpOkHODdjTJ9l1SL1c2Kg1lx83o6OsVoSSvEe1nleSYU2+ao2gCbG/qHgspnUd+Q9v2LK7kAcJakAsshQhRUIneKUe6f0R4gJcljWM/sUClvj5jCfzP/Nn68u51XIhDlctFsJojSI+sQ4GDCCG1exrQmKVENgoHsrZCpLEmWMvkl8dLA5G1VCCXJxUdbrektJkqCyrDNbmsIpxTTGq6kQpn47pHXUdPVSVRXV/fcs1jTTqRHqNACENZYDYaLtfEnzJgHyP7Ne97twO/kKxcYy2x23CsDhEyxsiSpCnY275fSkmTMXab7Y/rsZ0yWpAK8WVKBz/7Zsr6j9D2MK/cqoYSSFHU7GmDWdyssaloFPNa/JPs9q99zk/J+7wO8AlmSPIaTAREV/vaDG37nXoGfUdOOFUaU5PNdmHxwsz6KXL3M7nYO2gjDVgJ6V7FCp7o1qmhW+yQF3HC3SxHdTk0szdqZ5fO8jBfeyU1Lkn5/sOIklLCmum1JKhaSXgreejcJklBRypVniF/afK9DSpLH0Jfl4m/wCXuM4b/NgRvyKEyWpJpR8xP6Tid3mcCYYE2Sw+v48/3iomkVuEFNgoAkHmikg9PADQFjlCyfpGE6FN+aJPN9/YyozQyrliRX1iSlmDDwER7wHBUiSlertHZT5vYwYZAPSEnyGLKDRsvvjRnhnJghPq9xwOsnktGHuCg/BX4Z/WxbwcRIyiDoztRBvRr614mcplN84lYjUkiU46olKftn6EKAC1yWNBkMz/Kzq6sVZne7QuCeLanYLCN8m6miBm4w9g2ZUIQRwL03CWewTCuH8pvwRVYt8gopSR7Dan6aCnn7JNVsob8Gbkn/eq90ZJnOpOazbqruYSFtkyAnLrlM91nvfuf9MmPeTFb5q4TRzW4fFKeBGzRLkuAsf9U7a4zj7EKUDTU7XLEkce9TLHlkJBxQAze4oFTq6oK/08uoUHqlmRNtom49Ae6e0PqxpEcSw4eQkuQxnARroALffjC72xkHvPmWKHP46HbascKI4llE7pTqoF5di+DIkmRjOfJymms2BYOQMm9JctPdTuQKww1q+HP84rKYDl7qS9yQxIknhr9ITiypqJakiCtrkrK+hedIriX03suJghZRCHBvQ0qSx9D7kYpLNhX49kNU4FLh1/zXrAE6h7vCYlIgHCZuvoJo8YEb1PDXmTzPLx2mVahyYeCGDFPe6T5JxvGMh5MtYzJZ7+Y2bq5JKrLgdkI0dztak2TA3EZ4AZH7rlVSu5oFvs9Pb0BKksewcuPxfwNGZEI0Zl6TZPfdy4jC2XrtBZzWs3zOUmqWpMSC7bQtScw/rhf69s88gAvwu9bnyN1OPZZ0t7OWx+8YLQmFeC9VAXZjPVEx7fsD8C5kSdzdJynrW3gG0+SGR94tqSOJ1+Lmaq8+L7fzfoKUJI8hW7iCFEF7T2SAaZ8k5pm2P20EE2oFx+3Za7cRuts5WZNk6Hj9OMDn5ZRFCnaGpAoBbgxVr1m3sn+05/CCIuGmCHEPvI+baG1mzvZJKq70ArzVvwD6ycFUIcDdfW7un9EeICXJYziZ8aUC335Q90kKBsVNvxcGOU5JzvRJpj1oCoWxjtnJE4vLaGiN5lYe48w+kgO/YMZrkgqdys6xcpfShwDP3O0QMFqSrO9iXD9QiDRti8bRHInl7P4mS5LL71XfEk1p8VCfaQ5HzlDfHBVGILS8VxGEPW6NxtHUZp3nudonyUddiZCkQum8fYjLShnLdz9q7W7nnhx+8R7wOqQkeQyrRosKeftEHdCpEY0YmG8HArooP4UVxRK7znLV9gZ8ur4W9S1RXcLnsoNljCGeWHsQTsfdLsV375KUlG8LtTVJAbOFJ13097WWwBiJqhBt8Geb67Bkfa1p7ZBbmCwJLj5mb1MESzfUYvXOfbbnaSIYnr29vhVLN9Ziw54mx89k+pGhL1m+aS+WbNiDaFzm3ifZYvLtQLaKkt8VIzucvNu63Y1YurEWuxvbcidH4q/S75knunKVBX70HvAipCR5DUcDICrx7QHGWHIthvPoz97F6DMOD1jC0hgjtiXWh7VF48jVWMwq9DUABAPic1Lek/nT9UIkc7abycoy04eJFoe3054lOm6ULVcwplgV4jLTLMpuk8t9kpqjcQBAazQz2VsT17dE4o6vcWol9DKtsThkGZZ5HgxIWn9gdMdOF92krE/TSyXZRiS+O3gftYy1RnJTvwCxB0Wqc115rsVnIj1ISfIYVjuG+3GQQ2QHn8/6qF7ic7xOckZN8owpKZ3ky9fAmId3NdICCThyt7O2Nnp5MGRtPTfLnMlbGNesiO6hPjdgsiTlF727YW6enssynSy79g9RZTC7/imkY0UrhkAEor2ejINrdc+0bJRnfhKumBCF2bYiH1ZicR7yVp7cWHz0Y8YizOg8QUqSx6D9kAgVPvf5gD1+be+0xfdcq+O1V7FLW34Bf77ygB8cpxPa1k4x8nL5sZoA4GeJswkfbwp5bZMYJkNSntMtH5Mh5nVA7t871T3VsmlaH5j4mk4wBr+7GBnlF0W3A9wJA+6FyIZuYg644uCaxN98KNe8m3leJtw817v6E1KSPIaVJYmHin77gO8wA5aL9v1TGqw6/EJiXpJhnZ7avHgeBxfxTJUk4yyizkLjXVK3eZxFNYMXMStJdjLoownmfdDBPS5XlqRcBm5Q753qjqleLVNLkh8H/bLDehrWItxlbkkqtsh2mqdCGh1Mcl+2HKaFaLbT4mdXZfFJm+91SEnyGFYVhEyn7Q8+lwMWpno/kezEJOECVj+RK4uvucNU/gYC5kAC6dxJb5XwR6JbuRhnsw+KqnSqazrslKSAjSUpPzPBSXI1053LgbKq3KS2JKmyiH9JT0lybin0IsZ9nvj1LDzJCHfZWJKs2wg/Y9zfzI58WJJEyls+0jofluj2AClJHiMfUU8If6Bv2MR75Pip8ePdIbyyKXo66VmIKGfqAJF3MXO0T5JNO+LlImO1ySK/TkgS/O4UNVJgMJDs+phhYKoiGdaA5TvddAO3HD3cqES4uybC2Sy91Xmau10WSpLfcNr/h7UNZTN/X7NFvHjSTvmeTjuZu3fnLdPC6HY58kxgeWg/2gOkJHkM/doBqwED0R7g81wfEY4/xz+IZ9QK+wbpdEia2xXLXQdk7Nj5TVTTsSQZZxHzbQXJFKvZT9WrKJ1F2SJUS1I4kNptLxkly0w+yq3ekpSb51kFS3ADNa1T3ZMZ/hqPp6Mk5dMVNhcYtwDht03gUdckRbII3OB3hdKK9JoIJQ3yFfAj2YbnV4MpdD/rZ0hJ8hhWA+Aibc8IG5KuFvoFn74tCur7ZLX03l3SSss8WBSM91aVg3Q3UdW3I0zfSfqkAFkO4tJyO9SjDriDnJJktTedsZQWMihA7pQko/XGveeoZTelu52FlpRJ4Aa/u5AZx858H8CjRreLZbUmyfDsjO/kDZJR5NJvJ3O7JImb6HJ0vrvPBWj8mA2kJHkIY0hOy0XMVODbFYoVQdzw+6ksiEKhek1+p/Lkax5QZ0lSn+fEjcQ2AIXHEp3DapJI20zWpeh2oSDnbsc/n/tsnPXNd1nNh8U4izF26ntrliRntiST66u6JsmhS5kopLXfXMicrnUsccHdrugsSdoknP67E3KZFswoF+wnwN0qs371OPEapCR5CHPdYIJP5m9EcaKf1fY/OsuYRxYlmdZB2CoX4mtyiRZogNuIMF1LEj8jbfrNY6Sa/dSvzUofVUkKB8Xudvo1SZk/xw14/SV/liT37h13GN7Oajaf/+7E5U50ioeLuhCr1zRODKjudlntk2S41MvtQjpkslVCPt5d4rwB8oFeESuSzC0ApCR5iFx2WIT/SPqj8wM6g7XRJ8MAXaQmn6p8/GAuHxsAKt95S1I6m8lyn5E/y1fWpBBUvzYr/Tfh3e2SSpB4MsqY3vmemc2HYpvLPsapYudkoOpMSfJ0yXaEleunEW2fpCwW0xRDeokQ1WsrtLqdy8AN3GfRPkkm7xC3nluk+ZtvSEnyEHaVxe+b5BFZYFi070dfY51VzKFvdj5wY6F3LjtYdQzEW5KcdKO2FjGfFBr+Hdwa0KmWOZ2SZHHrgKF3tAqqkw9y9bi8bCab4jwrS176liTzOT4p6hq8dYdBb33nCScKZzaWJFN6+SytjKjip9O35MOV1rjJLZCfyU1yt3MHUpI8hF2H5ZuZYMI1eF9mv1pfVESzaYD3BjF24lhGt8uhBMkQ4GnuJG+wQvhHMeI+CywpurVZGdxfW5MUSB2ON+m2k/uBlAj+cflyt3P33srf1IEbxIoRP5B0ErxBPYVXbv1iaVcxKuJW8muWpCzWJBnT1G9pZUR7nQyigOZWSVL+8lZwWLQ5uZLFJ82/JyElyUP4fdFpLmCMob45CjnFTKIsK+cVU5ppbb5hGtEv60t4jPvPeGRJUlrkI62Nz1AH9QFug6B0xWAwumjmlvqWKGKCGe76lmhKi0CqiSHer58/12n919JT4tOTG5hyn41Kab4nqvikynUIcG1zXRffTNtMNsU9rX7VWZIcKAPJICeprYReRXZYT7V9krKIvOFW2jS0RrOyaLlNQNA+WKGek279isZl1LdE0xXNQobcKKt+dMv3IqQkeZhUs6rtgS17W7B0Yy021TbbnrepthlLN9ZiW31rniTLPaLNV3NrxcgdlpakAjfe6UxMaLOOxjAqeZiF5KO6Zfu8XMpb1xzB0g21+HbHPt3xHxrbsHRDLdbs3GdxZUI2C5c2kcsKz+ZE/d9a12J7f92aJO3e3PO5WV+TbAWseLlbk8QpjS4/R3O3S2lJMl9jxIklSeya6i9M+yRZlMdQIoS9LKe3jxSPGxaMfa1RfLq+Fqu2NWQkg5tY7Snl5Jp0X/2b7Q1YuqEW9c3OFSWJ30w2zedlgh+3ffAipCR5CKf+4cVkLUlFWywOAGiOxGzPa40q57VE4jmXKV8kZ8/tzvFHWTCvSfLGKMYcdtjBNQZFNZc5kGwTpLQCFpjd7bjvOZS4NarMKKv1Nnk8rvvrBNGsui5wA/cerTH1/vYz2kmlU9IUA9HAXP8c/V/+PrkkH8/TWdbgblnW9klKcZ6TjdLTWZMU8EbTkhE6JYm3aho6AT6CW6ZWxnT2n7KiRe1306jXuYZPq5RtZYaWpKY25++tU3QFFk7jk92q67QmyR1ISfIQ5nWU+Xbw8B5q35jK91pziSkiBTK5JokPe6z3U/fL61p1+H6RH8hP2TI+Ic4N/NJZi2M78Myl5cti/U7SrSXF9RbKHF8XRGPg5HUp2gldOUx1hXV0u3zgxMKS9TMSf4M50CySliRnA1XTYe64EyWJ8Rsvu2R1zTumMYAYNyxlRhf2TJKqUHVDRLKNMB+zvMbheUZUN8d0Fc18WjjzPalTrJCS5CHsos2011kBtXNM5fOsDn6yiIjqPbgZKL+6j6iYFlV75H3ScTnhLQq5inRmvJVsmOnP9D5OZuvdIPXWOKmUGPsvumQQtI9OXbusQqqLJibEAuVXYc7ZmiSjJcnF56gDyNSWJE4eC0uKM3c7roykEQbaS8iGImblZurGRJMba6CdbxicP9JpKjOdXFUnbZ2slROlTT4mOotpwriQkJLkIahIm1Eb4ahDS1Ix7f0g8rH265okFePgs9CvkomVJZ+djzpo4jfgdbQgmf/MmFARyAVWIXWdKzFiZY6fJRZZgJyuLVB/lyRJc8tiooG5wK0v75Yk7nOuJn/U+6qWJDcfo6WrQ8XV7nM6gRsUS5I/kS3Kvx2ZKihu9JVOIxjmA61up7HhdCZrkmSZaZO36URd1EXmtJuMcyktRe0jkT6kJHkI0w7YVp/bUXlX39VpFJ+iUpKSrX5eF3zmApkf5QKejT5l25lwY75cWXb5zWMB8cDP2SaJ+pnKfHWYVjOzmVh6hWksaf9Znmt/T27iwaYMikKu57sN1j8jR5Ykwzoe99ZDMG5NUooJLovf+aPpBm5IypHyMk9hLGNJpd58brZtqCtKkhrB0APprNXtNEa12uRqGg1TlBuLxB2MS3jlzbi2TPk9N4mXr4mxYoeUJA9hrCxWjVh7mhVQ08DpfhDF1BjoG1eLc3zyviJ/cS+QjlUon/VOU5LUfZIs9tiwwu6UvAzwLZ6ZamBmpcwJ1+cJbuV0DYJkMfHAX5+O5S4X5MeSlFCSXF6TJKcxQLO2JCW/OFqTxCl8Wt6lFtVT8IN1fTj6XKwZ03/PJK286MGh97xw1t6kIz0/Fsk08rnd/Ecu+hnv5I7/ICXJQ9j1A7q63o5KvJomcZnZzvZ4sbHOFqNVgT+mffdJYUgOTpWX8ZqypOLEDcJomXEzC3jFGEjOoKcbPtZuvUEuS4yVWx2D+Lj5BsmP+oG2QFkUPTeV1YJTtkTRAo3lVHStQcycwXRpkdvZ5mA6GrgDeKXGqeKqfBaXU2fR7ZS/Em919Vl/YFQY7cTPdp2qqS/JIKmcrjvLB6K6m7K5sXAPtoNXkpx4uOjaLsOx3MLXQS/kkD8hJclDGAfFVrNq7Ql+cBC1aZCKMXAD/yr8Ogw/FgWrBciFVvIye3ruZU662yl/AwGktZO8voM0WktyJ3/Sx1/8jNQzuxbXJf5a7bHlfN1Qso1NhgA3y6dztxO8U76tcbl6ntq+amuSXHpOOkqd0TVURLohwP0a6MZc/s0TZSrZWpfc6CvVNPfS5GQmRtF02kR+HOJkFUBSebOY4DHJ4lgU++cy8WciPUJOT7z66qsd3/See+7JSJj2Du9THWfWw8f2VN75xisWZyi1KLHFaUlS/ioDNn0YcOM5XofvKJS/3hjFWFk8Up0rXOzvojxK+jD9mqQ0InY5sYjlAm3gZWHJSufRssAaobcSwPS7U9cufQAI80WiAY3DZZGuwUuVi3aND+iRbvTEVJj3/GOWdZ5Zfea+pKckObckeA3R3mCpcGtNUibtmNPgHHlBq9vO16RZNFe26NztHCS+0FXYgUzZ4oUsKQYcK0krVqzQfV++fDlisRiGDx8OAFizZg2CwSDGjh3rroTtCC2amY0bSHuD7zTs1iVpjZ1ftAYHJMuDfxciq4g6CuWH/Mtih1X5MQVCyLGOp94+GaLZWWQkFf3AkxW83CTrZ4rzLH7nIz3arTdJHSQgAZee/CVJi1WqtU+5T9BczwTzbasamt+txxiVGsZsrDsWkw/8D44CNySU2GDAv/sk6aLbcUqsMOmyDHPuanQ7DzTkxvETf8zmIgDppQW/HYmTwA0quk3U82Dl8VvZ9yqOlaT3339f+3zPPfegqqoKTz75JDp16gQA2Lt3L2bNmoUJEya4L2V7IVGogwEJsbiNJakdFX5+NtnW3U4z++dcpLxjnNXO99oIN+AXVQPpbYyaWzKYPTV+d/ElzBMl6i+SrXJguo+pE86P9TG5b4pYnpSBG6wGD5olSTxgTFcJ4yNNWQUZMIerz29ptbKquAWfF+qaJPfc7fTf7WfOxZOB6VqSRBsFe6CBSQvL8i90t3PvWcqB9O+hudvl2crqFpmE949xZdFZ4AZBuRTIoH13qRL60ePEi2S0Junuu+/GnDlzNAUJADp16oTbbrsNd999t2vCtTdMIUwtGkwvzNrki3QtSU46U98gnEXMTYOaN7zhZafh1N0unQXVbmB0f9JbkhwMGA1W6HwVE2u3N7HyZHsvweBZb+Fhws/28iWVUKG7HaeMma81nZZT+Oflwt2Ov2dSAXfnOcYgO3b5Y6UY8FekE7gh3XD5XsIcmMfJNZk9y50Q4Lwc3klrp+HRM3HT5y1JzgI3JGTij+WhXLbXMaPbZKQkNTQ0YPfu3abju3fvxr59+7IWqr2iFuSAoMNqr4Wcb3ijDqZtimpNUuKvcRM6P76hFnkq8SYeWZJkwtrdK/1rMhNA+WNMHv2aJMe3sfgtlyVIVYaMg2Tlr139tIu2pX12uPjZXjrxPkjK7yz5e5b70GQL/9jcrElS/gYC7tdH83qX1HIYT0zXkqSeE+RnFHyG0app6aaM7MOcuxECnM/nQs9P6qzADvM/kyVV/Dgk3cANxufanZ8tuXbXbS9kpCSdfvrpmDVrFl5++WVs2bIFW7ZswUsvvYSLL74YZ5xxhtsythuSM2HKX8sBWzsq8DpLkoMQ4L7UICzQu1oljhnPSXGPprYYWqNxdwXLAFE4c/648Vh9c5TbqFD/PVPisnIfu7V+TqKyKefkuKAZ0kmZHU9DS+JgTP9WuWw/rCxJzPTB+lrRqcL1BoJBgGN3O0niJqMECNY15HvQYaE7uIas1UlxMIxsMK4hsu7LjMoUE/6W7j5JqZ7rVdJRhrMNJ20OrpH+PfR1wv4G9S3RnHp6JOu20/PNZS0uM9S3RG2vSzcEeBLxfoemds+lJLJyYyXSIyMl6eGHH8ZJJ52E888/HwMGDMCAAQNw/vnn48QTT8Tf/vY3t2VsN6gVVRiOlQk/Fj26EOC2lqREI+e3XtEG/cBQ7GZkRzQuY8mGPVi+aW8OpEsPfgZf+Ws9QN1e34qlG2uxYU8TAGBrXQuWbqzFptrmrGRYt7sRSzfWYte+tqzuI0p+9/zIFYzudpbuYVb3MbQX+XIVs5qrSM7YOn+6fhG78tcY6dH45NSBG8yWImEUPd0+SunL7gbpDEAzQeee5vKaJLPCazX5YP2d/8lRFLHEX4mbUPBbb2C0alpNLlkdS+9Z2aeOro7anLensQ1LN9Ri9Y7cexrp9pRzOCmjfl6zcx+WbqjFbps+gleMnCi14v6C+5zyDplRREOhguI4cINKPB7HZ599hj/96U+48847sW7dOgDAkCFD0KFDB9cFbE/ws5yEglMlKenOk2uJ8ofQl5kZZpht3jcSkyHLQGvMC5Yk5a+Tsq1avox/WyLZvUdzxHwfU/pZzXjzn1nuOyBjKqXbJNgN6HO6T5Jm0RFbCOwmXq0UK/43STIrL/rnphJQvY9Y2bK7PN8+/vwTctGuWe1d5gai6HZCGVJ8T97Puau1bkLBZyNF48SAcXJJRKZvaHa3S/9Oenc76+tbY3Lib276IlM+OyjUon7U2OeIiHKWJFlWnm3Xr/GTncY1lcLrcljXifRJW0kKBoOYMmUKvvnmGwwaNAgHHnhgLuRql2g+4jp3AaUi6St0+ynw/Ks6CdxQnGuSxGZ6/VlmvJQWRncpu/UemjXCoPhm+z6xhJKtn/00DubFOHHjcmNuw0qZ1O394iQZDApEvlwvUkW3Uz6LBwfmdo2ZfksVRdqhjiS0FOmeI5nXfOjunYeqpVOScqAlJdsX88a52eK0rprXoemVBO1+DgajKrr1Zo6k8A7pWBiyDXPuRpmyigxpRNsnLQ8Z4jQEuLHsyTJz1NcYxyExmSEcdFguhe524gmlbMmX90Cxk5G73QEHHID169e7LUu7R7gZntMZ0iKFb6zs/H+tZrD9jGhgmM6eN2pyeSJJBFYxy1OZ+G+2SlJEpCRlcEuWBzuCcdd4/ex46utN3a7DwUy2aPc2zlLzA16nVgWhJYk/Zs7HVPVf+5lLT5HLkD6wA9P9zRe5HuTYuRZmi7GpzsSSZKxlqdaz8M/wqzeG5T5JOXgfNTmF7v0OsVJqzeeZz3eTDAxJwrLHr02ywrgVSTrl0slxt6AQ4O6QkZJ022234ZprrsF//vMfbN++HQ0NDbp/RGao5TjIjZBEZbu9lHe+kwD0Zm7RuYB/92sQkewgrTcStWv84trgzn3Z0kVOq7NP5CUz/s1OBnUG0O4+1oM5+w7HrSQWBSgADIEbkIYyIPyeuwKhBTkwq2mcLA6tDIIv/IBe97OFBctKvgDn+iK6RmjpSnHvXJITq7CufXF3EG4K3JDBmiTjJXaBe/hr/bz5ts3rm8h2LyjjeqdMbqOzJNlabTJ/RroY3dOdIjOmKTxWRU2WGeKGcYjTvd/4ACmA2ULt9kRFvtr8YidtdzsAmDZtGgDgtNNOMzRIijk8Hi/8Ggg/IhsaLUBtyCR9A9ROyruxoXLibgcoDVnAOBXvY/iNLxWcFQAvudupmKLbCc4xWo6MfzNFtUTGBQv1k/JkMJhDsp66h3XgBvX5dvqmnVKXD0uS3TMtLUk216SMbpemfPy9RLPh+kAZgvs4fF426AbMOXxgLlpKx+52dsp0hvfUhW/3WWdpXpOUKPeCc7N1kVQVWXXz+kxwGgJcc8PNUXYYb6v0l/YpI2pv1ENWZY1X1MOhAKIxObXyzuWh3RokScph+virGniKjJSk999/3205CCQLcipLUnvB2FAZzdx21wX8ulEGBz9gMx7Tvttcr4/a5cyfP1doEwCJ73YLq40zbJrSlIUpKS4zzcroReVRRZTngBqxiTvP4X3Uc/MdDtbW9cZKEbW1PiWPiyxATt2Sk7O24rD6/DON1pV8uSyq8MU9J/sk8e/qurudIS8dKsawSeOUbk26vDPfzw+Y2kOL9sANTJvXZ3QPfR9jRSrlw030Ie3tZNL/JjOmlVtrJUnpRIJBCeGAhCic90u8R0hStuQRRWr31Hpm8ZlIj4yUpEmTJrktB4FkhU61Jslvs2OZYmyo4nFmaSVyMlPtN4SdPpwP1oyLagvpps8PTlOeq5V5/exjNntsWG0AaLXpaSr5nAZ8yBTjwCUgwWS1t7MBmMaeeRrgO00/J+jyKcVgMZkfKQbSWhvLbdotMEmJ6lve1yQJZHD1/lql5J/pzoMy3ajUSmEFnK/9SGUF9DJpuUhlqdgaxxuZlG+n/W7OLUncjZ12cyJZ1HewKmvRmHI8HAho45CM1yRpfxMTiC5HZCym9dmFJCMlSaW5uRmbN29GJBLRHaeId5mhFumAoNPKdYfpRfhOT/0ckxlKREoSl0JethSkg+g10hnE8OsCCp0ixiAUdmsgtHDRCaHdWJPEu0TYBW6weoRxkoKx3GicgnErAHVNkvk8y/vYvmPuSoNx7ZFo/x2nVoXkJq78AEgSDyYEk0li+ZKI1vkllXleITPfNC8TVboBqPvPS5Y19wM3mEOAi2+cjiuo00kSiQu74beuwDixxeeRkWz3glLLVDaBG2RR5RGgTTTkqN4Y75qJkiwzllKZUy1JoaCEkEMlSZPJYj2l9nvCRdAt2uOYMRdkpCTt3r0bs2bNwptvvin8ndYkZUayIEuaYtCeC7cW7U9tjOIMMVlGiSjeSJ5myvOJaMDGd5zKd+uXNbrb5Wb1gTOMlgBbF0JVOZL1EwTZDBRjnCUpkw2HUwZucLnMmdztBGuS7LCbkc+XJYm3Xurd/ZwJILKiG9PBdE3KeyZnz4XudnwbbJQjtciuwnSBOnJwf3XiwmCldANjXbWcfHDgYhkMSojHWVFtFG6F081Zgew9A1RLbTbLd527hOavEjkNRCLqd9R3sLQkJdZuhYPJdcJOy6WxnhnbtyzjcJhoj95HuSCj6Ha//vWvUVdXhyVLlqC8vBxvvfUWnnzySey333547bXX3Jax3ZAMAS5Y4G4zM1ys8D7T4YBSVK0i3PFHi8WSpMLvIA6IZ75FeDEdnPi/GwelbgRu0G8AaH0fx5HXcpS0IpdbQF1Dw69VTENLgjNLjhtYDfKcuOWkcksBjOHwzZ/TezfrGXQpaYwQypePqsWvwMzFICdppTAfyxaTkuQwz0Vtm9MZe7G7nffaQDuMZUzkEmm+Jv135NvAbIIcOVXqkl4BGT/KFqflS/ebYE2Ser6V4qO6bYcCAQQThSxV0Avrdk3/g/vu8O1vzJgLMrIkvffee3j11Vdx6KGHIhAIYMCAATjhhBNQXV2NOXPm4OSTT3ZbznZBspFXB8XO98QpRnilMRSUgKjeIsCjH4QVR6IZQ7SmiywYcBQK+85KTNL1wX52zwn8Hlt2GyA66WxFp+R6MKaOY5xamI0z8vkaLOoVIwYIXILSVUR17nZcKHSR0pJOaHQ1Te02F1aOpSe3W+jatBxvbeBkoXs6mKqqAwXY+F2VJehUSeKuFrlS+gFmKItWWwIA2Vke+GvUwX4macXLa9fv5trdjke3+bpdv2Ns+2Huc4yobtvhYMDx5J1IGRK1XdluDmx6bp4ndYqVjCxJTU1N6N69OwCgU6dO2L17NwBg9OjRWL58ueP7fPDBBzj11FPRu3dvSJKEV155Rff7zJkztRlU9d+JJ56Yici+gFcKYJgJM3Um7aDUM80dQNJ2tLa2JPGNdc5FywvaJKLR3c6hVdEu1HW+MYa3t9P7kmtRoPublSUplrw2E2XLOHjLtW+9aJ8k0XFH9zQoVTldk2ShTOoHUxbXWrhe8UcliNPAqp20ki/AWebEAxbzoEX3Pimekwuyie4oQjcp53KgA9OaJIs7G/sxvZKgEEp4EaRnScpuvU6hsJvAMZKNiyTflmYV3U4QXMXueTmzwBsVEYvj+msM3+WkfBZzsdokbTgoacq78/27xMdVAoYxX7bo2yu/1QTvkJGSNHz4cKxevRoAMGbMGDzyyCPYunUrHn74YfTq1cvxfZqamjBmzBg8+OCDlueceOKJ2L59u/bvX//6VyYi+wpjuF8Aphpd6EFvPuAH1iHN3S71lGqxKJDGGSbtuMPrU82Q5xNt8J+Gr7gxYEM2s+l8+HjjbK0T0t28NVuM6ZTuOMbWcpfToiBWzJn4FP2VFm0cf1yfDulNAugtUuKBVFJJNS+yznezIprpdvX+NlaKrO/t1N3OdJ35x1AwzQXykpNWxpuYLMCc0m55TQYFQ03LbFwTTWHe7RQSFya67LBSROyv0cvCu9hZyalO0oaCAc0N1HkIcPNEVy7HKmRJcoeM3O1+9atfYfv27QCAm266CSeeeCKeeeYZlJSU4IknnnB8n5NOOgknnXSS7TmlpaXo2bNnJmL6DvFmsgUSxgMkLWsSwkFFSbKatdG726W+d1xmaG6OoqYinLWcuUNQHixm20XYRXHLN0bXwXRCges2LMxwo2Debzxuky7891hcRlMkjppyfRlhgusARYFvjcZRVZZFmVItHYbpK82S5NAN12g5ylf2W1msMnGHZdpfXrkxB1TQnetQOZTAhz42n6tbp6POguvex90UbY3GEZcZOpQmu2TjnIDMGIKG4XJLRAmSVF4STP+hNlazbDFbkixEcPA8bTCa0q1JdH9/daDpGAuzWXfFW1Qzxem6M/7cvOVG4rXiMkN9cxTV5SFTn2OUReeSbZERWnS7gASZOQvcYPxVbcNNIrtszvVb2fcqGSlJF154ofZ57Nix2LRpE7799lv0798fXbt2dU04AFiwYAG6d++OTp064dhjj8Vtt92GLl26WJ7f1taGtrY27XtDQwMAIBqNIhqNuiqbU9Tnpnp+NBpDLB5DPB6DHI8jFpcRiUZREmCIxmK6RikSjeo2nS1G2iJRxOIxyHEJYAHE4jG0tEUQjZaYzo3FYpopPBKJIFoiThs1D77dVocdjVGM6VuDrpWluXuJLIgkykMsFkM8wBCLxxCNBhGLxRGLxwAAsRizLFdq+gFALBpF1DTsyh9a2Y7FEI1GIcss8T0OBn3dUM+VEEjU25j2Hq2RiKYwp0NLW0S7RyBxX0AtN7Hks2PJduLrbQ3Y0dCKsf07IRgAl5YBBBLlMSlzFF/s2IfapgiOGNRZN9hNh1g8hrjMEDfIFYvFEIWMeDyGmMwQiUYQksTPYIwZZIshGpe1Y9FoTFhmnLZTdkQ5uaORKAIJn1k+nSPRKKJRc/2MRPXvHImq+a+Ud0mSEI1GtXtFYzFDPsqIxazlj8uMqzcxxOLRRJ2K6d5dqXNB7jngnqsoJRJXhtxg6fpatETjOHpoF4SDyXvHY8lIsW2RKBBKln1ZZvh43R5IAI4e2iVt96tI4l3j8QBiMfW93Xkvc16K81xNb/15ibxI9HlMDiEWj6G1zb4PV+8Vjyl9qDFvM8WNepHOs9SJwGgsypXrGIyPV9uIWAbvGOHa2EzTKhKTBXknVtbVusSYlJP8iCXaiECijYgn+si1OxuwtzmCET2r0Ltjuf4+EX3Z4/vLiEW/2tqWOIfFwWQ57XKpfZYZIpEoJDnZj8TjMLVr2cC3xTGX7ml6Rh7rhts4lVliGaib69evx+DBg9MWylYQScK///1vTJ8+XTv27LPPoqKiAoMGDcK6detw/fXXo7KyEp988gmCQXFlnD17Nm6++WbT8Xnz5qGiosJVmd1m4z6gMSqhTweGnS0SYjIwtJqhLAR8vVfSzdSM7MSyCt3pB+ojwPeNEipCDB3CwO4WCZ3LGHoLsvGbvRJUY0H/SoZqsx6lQ03rXhUMXcrcl90NtjcDe1oldC1jKAkC25okVJUwROIS2hJjp5IgMKxGXIW/bwTqI0ohGVaj3KNQ7GzR55/MgFV7FdlGdGTg9Z7NjUBDRHF3GtWJYU29hMSEOYZ3ZAhn4CS8aR+wL5p0dxjViZmOA0DPCoauifKwYR/QFJXQt4OSdusblPM6hBlCUjJtASV9NzUq+TKwiqEyQ2OSWs+7lDHsaU3eX00jtZzvV8NQapGffNoCQE0JQ5wp5R0AqksY+ldmJl8q1jUALTFzmVvfADQnjg+oYqgSpE9rDFjbkJS7Q5hhUBUQiQNr6pPlYUcz8EOrhC5lDL0SbcGqvRJkZl8f4kxJP0BpP/e2AdubJV167GlNHutcCmzcJ6EsyDC0BlhdLyGaKIcBSbmHW6j5zufrV7X6Bt5Y9uMy8E1dog51Ygim2R/UtQFbmiR0CCvvqra1g6uzeRMFPq0A6zxvigIb9onr31d7JYABncsYalsldCxl6NvB+plqm963A8O+qFI/vdy+i+D7+Y6lDPsi1vVdrVP9KhlqUvR3RlrjwNp6CcEAUB1m2NsmoUc5Q7fy1NeqRGVgdV0y7/p0YOhkMd9obNPdxthGfFevtMWhABCTge7lDN0N79YcS7bpANC7A8O2JuV7MKC0uUb4NI/J5vZDBF8uO5Ym26r9apT6rLbVZSGG1gzzU4SaBoDSB/TLUZvvV5qbm3H++eejvr4e1dXWjV5G051Dhw5F3759MWnSJEyePBmTJk3C0KFDMxbWivPOO0/7PHr0aBx44IEYMmQIFixYgOOOO054zXXXXYerr75a+97Q0IB+/fphypQptgmRS6LRKObPn48TTjgB4bD16GnF93WobYpgZK9qrNvdhLZYHIcP7ISqsjDKVu/WmU8n7dcVoQxm1P3EjoZWfL2tAZ07lKCmLIwNe5rQt2M5hvesMp3bYc1ubQbugN7V6FEt7hnVvBh76GFojDIM61GJfp28qTyv2bkP3+9twcAuHVAeDuCbHfvQtbIULZE4miLKDFF5OIgjh4gtq19sqcfuRsWqeuTgLpm55LjE2l2N2FTbjP6dKrBfj0rIMkP5mt2Ix+Jo27hCVzdUuQOShGOGd0PNuj1oTYy4Mn2PZZv2oq5FmTmSJAnHDu8GAPh8Sz1+aExanod2q8SALhW6a0b2qkZFSRCfbdoLAOhUUYLSUAA7Glq1644c3AUrt9ShORLHgX1q0K0qM+tk+erdkBnDgM4V2FTbrB1X63vVdz8gEpcxblBnVFpYq+KJtFXpWV2GSFxGbZOy6Xe3ylIc2LfGdJ3TdsqOJRtq0dimlE0+rz7btBf1ifS3st7ua42iZuNe7XunihIc0r8jWiJxVK3fg2BAwuRh3bBudxM27mnSyhIAVKzZrby3VX1oaUHsq69RMbgfkMj/7fWt+GbHPl16fL+3GWt2NqJHVRl6dyzDiu/rUFkawrhBnXXlMBSQMGlYt4zSSITavqv52haJ4Kvn38VBBx2EYChoSk9Ace+s+O4HAMDE/bqmbWHl29c+Hcvx5dZ6dCwPY+yATlm/T9XaHxCJyQhIEmTGLPN8b3MEyzfXad/5+lf67S4A0OpCz+oyjOpt3Yer/eeo3tXY0xjBjoZW7Ne9Ev07Z9e+u1EvnML38z2ry7CnKYJoXBZap5dvrsPe5ohtf2dFY1sMNRtqURIKoGuHUmyrb8GQbh0wsIuNFmqgJRJH5fo92neRtUaF74uO2797WrIaEeWHsY1Q2yFJksAYw6AuHTC4m/7d6pqjWLY52d7s170S3+1qBGBdv9V27MA+NYjJDKu2K/Xn4H4dLeXly2XP6jJUfvcDonEZ4wd3RmkoqLXV1WVhNLRGtfOyZfH6Wm2c0L2qFKP7mNv8bMln3XAb1cssFRkpSd9//z0WLFiAhQsX4o477sCll16K3r17Y9KkSTjmmGNwySWXZHLblAwePBhdu3bF2rVrLZWk0tJSlJaaG+NwOFzwTEwlQzAYRCgYQmlJGOFQCHEmIRhSrgkG9APDUDickduRnwgEYwgFQygJhxEOhxAKhhAMhYRpGAyGAEnpXKzOMdwcoSAQCha+XFgRDCnvHA6HEA4rZSMYDCIYAkKJGaJQKGgpv5QoTwAQCiv3KRShxLuUlCh5wxjTZAP0dUN577h2PBAIaou3A6HM3oNJQYSCyUmGYDCEQEDS6pwalpUvO4ocTJE9lEzLYDCoXae9XziEYDCEUFBCIOig/FkQDAYRYMp78/cvLSlBICAhFApBhoyQTRmX4rLu2mAwhCBkhIKy9l528mXTVippoHzmy5xy3L5+huIwyK2U7SiTEmVfUtIlZG4LgsEgJCl5jYmbb0b4T39Cv9v/gu0/OgclJSUIh+MIBUMIcNeEgmGtzpUk8kD9PRgMIiSrM82Sa+0GY0xr39V8Vdf0BENBlIRDkGVzHWZSMp9DoTDCofT6g1BIaV9DiTpl176mi1JnAwgFJcTizDrPQ/p2QD2Pbx/KSksQCkYgBazbOkAtYzLCoTBCISVtwiH32vdcjyH4cgAk2qhgHCEEUFISNrV7Sj2QlbxPUy61roWCAS3v071PRJZ0eWfX7gX4vihkXh+UCXx+xFjA3EYkPemE5S8c1pc9KZCUUZJgOc4IBZnyjEQZDaRRLtV2hCGAUCiMUCigPTMcDiEUZa6VWaWPSsqQy7LrhfF1ujiVN6NRdp8+fXDBBRfg73//O1avXo3Vq1fj+OOPx/PPP4+f/exnmdzSEVu2bMGePXvSiqDnJ3ThZ7PZBKFIUBdPKulhv7A43RDgfthLSVgeAF2ZsF+o7p135JbeK//rNkY1nGsI1KAL3JDhO8UMofGMC4mFYaWZhXwWz3AzgpNRnmTAC3sZRL8pdSN3QQfMzxIcdxBExCqamzHCl2jBespX+uwzAED3+f/VDqVKS7s22M1QGKL9zEQhmo3tmj4qX+aL93MRuEGVP2SMQGKSwbj43yxAUHv/VMIl+gubQDdexlz+7WXPRs8QtXvptgvptHP8mblofqxCgCefaX6o8ZAx0JH4mmQZCzgMAW4sl1bh6Z2ELc8U/9QC75HR1HJzczMWLVqEBQsWYMGCBVixYgX2339/XHnllZg8ebLj+zQ2NmLt2rXa9w0bNmDlypXo3LkzOnfujJtvvhlnnnkmevbsiXXr1uG3v/0thg4diqlTp2YitudR65oughOYowpejKjvGAxIaTUgTkJyqpHEvdyJMq48aMeM59hGtzPfq1CIIjdawQyf+e+Z7hVj3BU9zpiu8VPS2KqumaPJiTcdVY5loySJok7x+744GcymjHyXsXQOsChzjgZJxjQ2KKnJNBDcXzvX4ubbtgEAOn36EYJyLHEfc1o6rU9uIopCyT8rGFCsMXbRxDIpcsZ0dRN1TkLTkSwnt8Tf+fcJBh1GtxNMKhW63UsHYf5q72SdR9kpyJnvkWXcksF+M1leoc8dyYkU+0h2omNGZScuM82DwXiNhOQmx6n6JNMkj3Zcn3Nu10N9/++jiuAxMlKSOnbsiE6dOuGCCy7A73//e0yYMAGdOqXvx/zZZ5/hmGOO0b6ra4lmzJiBhx56CF988QWefPJJ1NXVoXfv3pgyZQpuvfVWoTtdMaALk5yikffy4N4t+IG1Xbhe43En7UFclgEp6OlOVL+DvLWiZIVuM1m3hMoQY0fh5FxAKQNONiK1Q5aZOSQx0/8VGQ200M/MPMg3KU3csWz2c1Lh08moMJkENWAKE8/Srx+ZYlRwRVgNpoxyJzegTLQDieN2gwnLd0soSaGmRlR9uRI4oE9y80aBkqLso6Sf8XW6iXO66NLDoCVIkpRs+1wOTsmnqyRIi0zh61rQYtZcxUrx448mLUkOBRDknR8QvZ/dXlaiyQLHcOU8U0TtjOW5hjbdGMo+W1JODInS1nDQ2EcI80NLN0mzJKUKAa5h8AYw/eyyYi/a/41In4yUpGnTpmHRokV49tlnsWPHDuzYsQOTJ0/GsGHD0rrP5MmTbRvlt99+OxPxfAs/S8E38l4eyOcSfp+kVI25sRFORZwBQcnbjYdIsUhnwMvPcBV6JklkFbOeweSVIqZTOpxuKMnDbySrrpFI3ic5GDVKYvUkobWJO99xp2lzX115l8wfnWzcKJIteSQ36MumWKlI9+lau2hoA5KKborBQFsbsCe5wLzzkg+BH5+cnIgSPUsZaZtkzwUiS5ZaPANSdvvhOHmufmPd7OHbX3Um3nka6hVjIGmNSlX3vdyWO8GkMObwWZryhcxdLc1KhU2bxH/O4YuJNmxVnm/Xyyg4eR8+3UIO3e0s+xHo04JWWHiTjNYkvfLKK/jhhx/w1ltvYfz48XjnnXcwYcIEba0SkRkipcBqcNseFKfkQEHijgkaLua8sVbvm7QSeD8h+V3R02lCc+UelAl855LyXBslMJP8imm7pEtJFwnDfQKCATFvbTIOxEVSqOe4siaJSyndho8ZDtzzZ0kSKyy6NYMONoQGeEuS8l1NE/N6A/6z4N6Jjc9VOn/8oe5+TtMjVwM9sbtdsi+wXJPkUp4qLlfuzeyrg03eTdRSwbN4J/6wZkly7NaUuv8sKDt3Al98kfI0kZsvj9XalnTJNOvNa+RsztV5NbifJ8Y72rURVsccKX3cxEIgg3LJ/zXitrtdvtr8Yier8GijR4/GUUcdhfHjx+Owww7Drl278Nxzz7klW/vDYmavvZZvpg0U7E3R5sGV/X1FC6W9jGRoVp2a0ePM2Xn5gJ+1VnHSJ5j8xDNo7aOJBWjhYIDr2AxyCTouNZ2Zg26d9y/PdN2UblaREyeg05HSHxjlc6BouQ7OgQimU5j+r9XscMrHJFztWLkSnrh65VKgqUlLV72Swg/w9c/JVSUSucWqfznPa4GlIbuBp6hOulFU1HsE+LW1Fve1Gmjz56vBH5xWK33eeZCTTgIOOQRYt053OF1LUjZDasYXMMdPNN6D2X63unMumiOjS675d8Exw/salSSR5TKZbMkJN8bs23zdMgroxzJ6l3r9+dmSXmkirMhISbrnnntw2mmnoUuXLhg3bhz+9a9/YdiwYXjppZewe/fu1DcghOgCN3BrcDw5G5YHhOnh6Dr7s7wU0MAOJ4MYu7IhmqEuNEJlxGZG0omfeCqiqiUpkJyVNypbQkudOjZm5lk5YbprVoD0ZTQiCRQj/rjtgESQnvlaOK2Ty2IywnJNksUg0WiFNE6YpGwfE0qSPOYgtPTui0A0Cnz4oTBipjYIkswDLvMaDPcHM0YLN7/2wX5hfHYyOHHjdIpatwKB9NptQPwemrtdipfUuau6HK3PNWIxxYoUjwMLFuh+ElkKRX2AkUzKIT/Yz1TZsrNsms/NT19kVEREz08Kov9q6msEawB55TLIPSR1hDuBAucwfzMlV2so2xsZrUn617/+hUmTJuGnP/0pJkyYgJqaGrflapeoHZSdH7q6n0t7KPRJlxP7WRbjkVRp45ek0+U9NzPqNO9lD5nMhJYki+6Zfz9zx5X+i6jhv8OhAKIx5bMpBLjg2Zo8pu/iMqgez2TdlPE5vOtFIM0ONJX/fW7d7cRyZOL6wbs7AkgufDaUG2b5JYGqJPXujb29BqD8388qStKEYy3l1AVKMcrhMrLAkqRbk2T80SCX4CdH6GaxXVwQ4bTd5s81fudls3KRNcIXk1wMOl1h2zZFQQKATz4BLr5Y+8mcRmaljyebhf5G60Ym90nL8qUrq+5XJPMdUxcA4zXprEkKSMokQCCgKFNO12PxkonGdoB77Qyz+EykR0ZK0tKlS92Wg4A4BDhgHDyZzbTFisgvX/TWqaLUGNFHg/ZuOvKKhaVCYXktMwyiCvueaYUA5wR34gKRCnVNUjgQgBxQPqsDU8bVOcC6Y2H6Xt42Nd1Yk6RzseODXQhkM2K2Nuq/53SPMAtlSL+Pmfj52iDX0MYlB7+plWphOVeVpF69UddtAHr/+1ngk09sFQP9ehrzc9TvbgzGRZZtXd23WpOkkyX9PM3VLLZat4K6tbUWMljIxMuW9toPyar39ACbNyc/L16s+ykdywxgXR/SJeMQ4BYKrvjc5OecWpIctBFWx4yWSpHl0ngoIEmQYY6eKrrGbs2RXR+fMXlK82In4zVJH374IS688EKMHz8eW7duBQA89dRTWLRokWvCtTeEfrWGwu16RfIwasXmF647mel3up+G1f28QnLQqH9/JyJnas3IFaJ3EUUXM35PpyO2Ql2TFApKpgGnaEZVk4M/J8VjeetupkqIyF3IKFuqTZUBkaj2C8DdxDJwg17HFF9rGLQb3elEPv2mZ4puripJPXuh/qCxyrFPP4WUsDDqL+HzIPn8XLo861yREs/XTxCZz1PlSl6XPrzy6WbIbLXtCQSyceZSMG7/4DQfUq2FKhibNiU/r1oF1NdrX80BiJKfhSHAs0jaZN4n/0/7HsbJF5sQ9bkOR22UxVl0O/0xo8uc2JKk3l95QNDxhrJcKrtsMbKi0BOjxUJGStJLL72EqVOnory8HCtWrEBbWxsAoL6+HrfffrurArYneKVA0jpGfWVy2ySbD+qbo4J9ahjqm6O2s4P6fZKS1xlJNXMOKB13fXMUjDGdJalQydgWi6OxLWY63hqNozmiHLfax8Rq3QdPurOSuSbVwlr9ucnPTjou7Tcuj3nUe4S56HamNUmCZ4sCA6jfRZ4x6jE3FFR94AbBmiSbkit2SU2hSNjQ0BrFroZW7NrXikjMfrMe/QSElcIkFiC5J4zevUo/oEv1TMEJmiWpF5oGD0OsQyXQ1ITgqq90z+GvN7psOZmcyRTRPklM1/aJFRgrJdQp6ezLlw58VNJU/ZWx/RdFNAxyZlXbGXu1/CC7wA1xmaG+Jer4/GhcRkOrw/N5JYkx4NNPta/mNtuZ9JnlvfLXOAGXDnaBRMznWl/nCoYJFtPPovprUvIMZVG4JkmdvFC+O9lQ1uRWJ9jeRR+R0fJWaWHVFmfCvtaoru3f1xrVJh+LnYyUpNtuuw0PP/ww/vGPfyAcDmvHjzrqKCxfvtw14dob+o3jJNNxP/JDYxuWbqzFmp37dMd37VOOr9vdaHmt1tlyzu2ilLDahJJn3e5GLN1Yi1372rIeXLjB8k11+HTDHrTF4rrjyzbtxZL1tYjFZZ37keUA0aJs5HPPDSfw76Li5J3MgyjrZ2yqbcbSjbXYWteiO65ZkgKB5Ky86m6XOEddHC9SJoyGJPGAmZM5w8TmL7OObic42eY+QEJegfLnhOZIDJ+ur8UXW+rxxff1+HJrve35Vvp7OouIjUqBNnlkWJxl9R6mAQFnSUIwiMaENSmUGKCKZNYpSPbiZo3o+SJFw9bdLJOBcuKvMJJfFqhtT5AbXaR7X+18SV/+beuWbqCc2uJqxeod+7B0Qy32NLY5Ov/rbQ34dH0t9jlRlHglCdC53NlakmxumVFkQ91YIzPSmYjLdxAB42uJxw2G70alycaSpKIGb7C1JBkUOH3bkrvEcGK9d0JLJI4l62vx5dY6AEBTWyzx3b4vKBYyUpJWr16NiRMnmo7X1NSgrq4uW5naLerMhV2n5dbeCPmiuU1RAlqjemVA/d4atZ6N0C8Adt7piRq3lojyvOZI3GBJKkxKtsbikGXz+7dG44jLDNE4080yqRjGu5bYueYUAtG7WJ+c/GgKAW7TGallqjmiL2u8hTZgsFKoiKTiunWBhcmYvsnPbu+T5GwDXrEswnPTEE+tN+pz7QaC5pDA4kdaPl7LJ/331NHtLEVSSChJ8V69AACNBx0KAAguWWyWTfvCuYoxscxu1SmRJUtTYKB3N9M/n/ucyUCZn8VO+2oH93WyJinFQFtK3EeNcOekbvGz8pnQmpi4ak1hNdXOd9CXaahK0kEHKX8/+UT7ybzmLHlAtJ7FjbVkeqtbemXI3MdYn8scNQCZY24jDBMqGdRVYV/D9SUAEErMBNhbOBMyGQPO6FyE+PPdT6Bsmiq1fLdElPLdEhWP6YqVjJSknj17Yu3atabjixYtwuDBg7MWqj2i22HcsL9EstNJHS3Ia0TiIr//5DvZh7VVlST7zQHNM0Dme6nuVbE4y6rBcAumySMbjif+cgNxfvG2+T7i+5vcGzMX1SXMM5dWCj//Pa1d3RM/Gd0A9G6bqpKkv0Y0mEuGYzZ3XHazjm7vk6TPegeTBdZ9u9XPKW9VXhIEoNQfKzcLs3Im1pJSBW5IWpIMGkMC0wDILm+amrR1H/FevQEAjQcnlCTNkmSWh5+osjrHLfRBKFnimLntM6Wbrqxm/vxsIpyJ0Oob9K5FIkx5h2Sd08sontzQX5v6/k5IKt/OrtW32SlQAzece67yd/Fi7QZ2kwxOnp8W4vF5erfQLIZmK7z5cUz4OV9kMsmRymMAUFy4AXOfY4dhDkg75mYAFfN2CpmnuXqlWvfkZIFvF2SkJF166aX41a9+hSVLlkCSJGzbtg3PPPMMfvOb3+Dyyy93W8Z2gdG0LhpAGjtuP6CGX7beA8WaZLQ/ccNihajxUwfbUVku+D5JjDHNahjlzFq83PxaNEl3LRwlgt0i2kJgVEacnAsIAjc4WBwcixvKGvdsbU2S5m6nKlDWyoeVgm91TiYb3hrhkyntNUkCpYFlWObVc0OBAEpCSnfRYjGDaK+38Uqk/TONCisf9dPJ83THt29X/lZWglVVAQCaEu52gTWrEarbm9IiY7WZsFtNhy4EuEB5t1I0sl8Mn7zKTQ8FXsFLKYFR7zOMv7QF8pK+3treSzeZ6ERi053SutbxZsOMJS1Jp50GlJUBe/cCK1cKL7cwNHDHMs+zZPqKn+cEnTs8xJOT2rlcnc9FTCE+77k/3O+Cep1CDifR7dSNju2UJJNsqQJRuZA+pntkcU817YzrBduJjpSZkvT73/8e559/Po477jg0NjZi4sSJuOSSS3D55ZfjkksucVvGdgE/GNRbksRF0S8FVB2wmjtDw6yEAHXwoMym2gxiDceEliQ5OYDmm7PCKEnJz3zjarRiaF91SqKz2cZ0XCHygTbQ5d3I1A/GssEdMCo8TixJMVlsSQpIkrZOIh13O5OSITjXjc0SrdxrRGuSHLu2QC1L/IDauYD8QmXVmtQaEStJdpYO/WGLNk0ddFnUdclyACSWGYDmaofevbXz4p27APvtBwCo+XK5Pm0sJiZyWX9EZYu3olu5momsnpk8V4K7Hgp8Ptp5AAAixU9/viqX0QIsvlfiGsl+0iMVRkU19QVIKRsAYM8eoLlZ+Tx4sKIoAcADDySuT+R5QL1t7gpd8t3s+1Y7VHlDqiXJKo9N5TZ376X2L6bodhk8UqSQG9so1ZJktybJav0XY/rJADcjTLqZwkavC5NFqcjJSEmSJAk33HADamtr8dVXX2Hx4sXYvXs3ampqMGjQILdlbBfw5U3ZqTx5PNmZcRXJJ+VTVQKs9viwew9+8bIW3c5ipld/nfkcTUmSmdC9JZ/w8vGNK9OdY5hJ5ExpTmROJ/JQzmEMHZYvRaC1xcaNTHe6hvE9nFhpokZLEvc8k9uOWreMLl7cbyJLgkkK7kC20e2MgTr0lqTUHWkqWdOyJHEylYcVJcm45svqvsziN6vnJzdq5Gdak6lvNTssfN/WVmDRouTMfe/e+sHK4YcDAKpWfSmULZVLn917pItewVYHIKoc1kpjtujrhYv35WRPtYZOUwYD+u+8bPzvTlxZdUpfBu2e1jc5vNbx+WpZ7NlTsSJddZXy/ZlngJ07TRZTpyHAs1E6sgrckJiLSqXAOpw7yYpU9xT9nirZ7JQ7Nd3UNUlO3O3UpHYzSIoVVp47Gd0LeqXIqDQVO2kpSW1tbbjuuutw6KGH4qijjsIbb7yBkSNH4uuvv8bw4cNx//334yq14hNpYdxs02oprf/c7RKdnsUsqF0Dbwy3qRwUnaf/bqckReOFd7fjnx/TWZL0A/TkbKp9pgvdC/PRMznltdcw6qwTcdDlF2p70/DYDepNa5IcuNuY3e2Sg2+j2442GDPcQ/mNmY6p97OzXma+T1Lys1U9dzLjn8q1JB3pku2SpFmSrN3txHXc7rPofL6+M2Z2tzMOvIVty803AxMmAD//uXKwd++kQgwABxwAAOiwbk1iIkotD0mFTDhRlYP2V2SFFO2TZDfwyaTE8daEbO5jhO/LUk3qJZUhvfLPTwwC/EA8df1Xn50p6VqSHJ+vKkkDBih/jzgCGDcOiESAhx7S8jeoKcX8oNz8Qk6CuFjKzFutBcecoFmSgvbO8G7sdZcK015qpiAJgmss5LXaJkJ0D82SFHdWLhXZ+N9E7U326WPqU7PTkrR7KEsF9H1nsZOWknTjjTfioYcewsCBA7FhwwacffbZ+OlPf4p7770Xd999NzZs2IDf/e53uZK1qDGacXUdtK53Vy/In2zZYGVJUl/A7jXiWsNn3gTUDlGDYGVJKgR8J6Fbk2Q4R/2ui+4H0aBd8AyDLlLQV377bQBA508/Qtn/+3vK0/lOwrxPks11ibeMyuJgGBKsZ+VF6yeYoXNIPsf62YqM2aU2P7g0ypYqWpgI3q1D+e78Yj7tVEuSpZJk0stVJZOhZNcOHPSzH6Pr+++kHIzp1knwx7W/RiuPgHfeUf42JrYY6N1bb50YORIAULlujVB2Yx6IZXOnVokmbfRKmbjtyzasss49zW6PhTQRBZ2wurGx39Pew6CUWg1cdfeCeg1viUxHcgXj/lypsNpPzYQatKF//+QxdVL5b38DmhRXPKeWw2y8Svh6nalCaZl3xvNSHnAfs2ub+aFW8qpKn10fmnS3U4bQRhdv0XUmRdeg1OfCmpt8VOaJrh+X8G2UTwahWZKWkvTCCy/gn//8J1588UW88847iMfjiMVi+Pzzz3HeeechGAzmSs6ix9Jv1TDjk40bQSHQ1iQZ5FU7fPvNZJW/AZ3bhqCxM11nnAFi3JokGYWOaaB3t7NYk2S8yDC7ns4zCg4X5rbixhuADRsAOFt4bHK3c2BJiseZrlzxlgjVbUezJBkGY6L7MRgsR8zcQegsSbK7HUiAa6WdBGs2zSKCZSwPP+BVlSSrNUkmObgBf7f33kLXRe+j/z8fsXbLSfzlBxMyS8putc7ANCBobgI+/1z5klCGcNBBesvJqFEAgIoNa4F43GTBMD4vGbEtF5s+itq05PO0vb1sLUnpCyMaKLuzT5Ly1xil1UKKxLn670YXS82SZBe4hZ+VzyKoudGalwonfRkAsyUJAM48U/m+ezeqb78FgHlNUi6sl24olMY1SVavn489+9R7BtpagY8+AmIx4e+iY8b01TaIFYwjVNRL1Hc3uniLrjO729nLlQ1O1y47QRe5lTFTAIdiJy0lacuWLRg7VokMdMABB6C0tBRXXXWVZXhiwjmWLiXM34VRUwJMs6DCw4ZzlF+DAfvO1m7AavxuWpNUgLTln6+3JHGfGbdPUqpoOIJnmEKAF6oMNTUBX3wBANg3bCSkpibgtttsL+FFVZXsYNDsgmJ7naxPS0C/viM5W6wfiIjLl624QrmysVZKfKQO6Ad8TgboqeRNRzReieTd7ZzMzDLub0ntHgBA+dbNlnnIu0UKZTAtyrZoRD77DIjHFRe7lSuBr74Czj9fn9cDB4KVlSHY1oryLWaZjINsLT9dnvHV3Ruc37+23sPZPkmZjKxy1yYk0zn1miTlbyprhJWiKEL33EzSRbOAOjzf6YkiJSkUUqxIAKoe/itqVix1pBACgnqQBm4olMlNg+1dIZ14PrhBxcZ1GHXGVODoo9H5qcdSPtOqvVGtQ3bKXUZrkrTHiMu6m+vNrdribO+lU5J8MlGfLWkpSfF4HCUlJdr3UCiEyspK14Vqj/AbpwIG96rEORK3otsPilNcToa6ttooz+499G4b1lYH4zFj42Y0hUdlTukoQEXnO1Wr6HYy08+mpjvT66a5PSuWLgVkGW09emHDz36lHPvuOwA2g03BoDHkxN3GykKX+CvBukNP1je1XFormcJADibFPJOBCycPlzaBNMcwJumYoY6kIRo/iC0NBRAIKMfaBBttmmcvk2kZrqsFAJRt3wo5Yr0hLaD3KpZ1kwXm30XPDSxZonwYPx4IhxWrkSTpLCcIBoERIwAk1iUZ3tcYPMM4G+wmujVJhmO2+yTx8mXx/Gzd04zwHgBWA0LteZoM+u/a+UZ3OwebduqPZaQl2dzR+vSUaSdSkgBg2jRgxgxIjGHkH69CKKavH6nWJ2ZDVoEbEu+r7ZNklccutI2pCC5bhsPPnoIO334NACjZsM4gg2BSJ/HXypJkN9Go1hlHa5IM33Uuu9wEUC5tDdl4NujmYlj7C9wQSudkxhhmzpyJ0tJSAEBraysuu+wydOjQQXfeyy+/7J6E7QRmiBRjhbt7o+cWnQJgYf61q7zqOJcfsDiawTbO6hvGc/zG6AWxJHHPt+r0GTey1b+/4FzGYOwynSw6zQuLFwMAGg4+FJFuPZRjO3YAsO7kdSHAZeNspfWj+J+iMQYk5nP0A06mu49xAK7dy+45wjzQf4/LDOFMvY8NA3SRpd528Me9E1OLkUHJc4oxLHlZKIjmSBzNkTjKDC9oXjOTFCdct1e5hyyjZNv3wNDu5mfx5V2VnVnLywx5qBJIlDkccYThXZLvAQDSyJHAihWoXLdaODuqd/vjjrlcmUSDRu2InSVJZ3lO/7lWQSqyhQ/2YXyWSQZOCee/J3UkSfi7+GbJa7IK3JD469gazNTzU1yghqPv08f82733Ivaf/6LDhrWo+Wgh6sZNdvjwDPPeYkImvXvo22brMO+Gviizx9lS9uRjCDU3QQ6HEYhGEdzXkPKZqrjBgKRTcsIB1ZJkOF9wF3WfJGVCmGl7Rokebl5Lqe/j7aVNDzebKP3+jUn35/aiJKVlSZoxYwa6d++Ompoa1NTU4MILL0Tv3r217+o/In2MPtj87KFoFtMP5ZN3ebIbQIng/bt1+22ITjbMaBmVIjuFoRDpqA/cYLVPknmgAFjNlpoxzYJlIKcrqErSmLFo65oYGCeUJBU7dwy1HGguEA5HLjrrIdcRWW1KaRwkGmfPUvl4OwlDnwqrATrfgSbbBbv7KFhNuKQjGr++BIBthDtrNzqgZG+t9r1000bbZxoHuSZF1qjQGh4W+JSzJAnk0y5PrFdSI9wJnyW41u1tGIzuLPzzbC1JGSq+xudaBanIFF7xsZvcAZJyJ5Ug/fur767+bh+4QX+N3XPtsFK+Uz3X9nTGlH2SAKBbN/PvnTqhcfqZAIDOb7yq+ylVpNtsiqGub0nzRnHDBJbV5akmMd0guHEDAKB59EHK9wZFSQonNsAWP1Jf9lS0wA0W4wZ+jWg4mLzWaq8kY7m0qmluTn+7qZgaPVz062/9MBLNjrQsSY8//niu5Gj32K1JUtH7Wnu/cFqGt0ayElv6MXOflTC41rNVWkcbkLSGm5/ViTtYVJlPdIEb4ooSLEmSaWaYdzmRbN5fhCfKB2Na0IaGgw5FRFWS9u1T1irZXKZi7IidhgDm13rxdSto2G/FSqHQR7PTB24QKU126+DSxdhZ6qLbOQncwJUb9XumVgfjYFVTkgTBG4y3TSqcSXc7AAhv3mQrd3LQziwnC/jn8XlVtu17SDt2KGs9DjnE8v4AtOANHRIR7ozo3e24a1025otDgCt/A3zdN1xnVOQzxRwumWW1zjgZ5AJaYlsqSdx7AlyearIlfrfYUNcKJ/uJWZFUepy2tepfm/P37QOiCTe6Ll3Ep5wyHR0ffQQ189+AdMNcMHVpg2VWZJ5HosmAdBVt9Wx14skqb/KxsXkwEQyoeeQBqFy+NKkkBSVEY+J3M1oxVUIOXDtVJElCMCghHmeIyTJK0rA78O2yqK1xlSzuaZzE4dPFA6OMnJPRZrKE+1itSQL0BdE/znZAxMJKwn+3ahD4htXpmowg19jFZIa65ggYY47CxsZlhvoW81qJWFwWHs8GY9ub3EuKP4fbRDOlu535mNl6VoDmbONGYNcuIBzGvpGjEa/oAFZRofy2Y4ewMFvJGeL83q1nr5LHRa6e/IAz6W6n76SMgzT1maYnppgd5TuSSEzGvtbUZUg3IcId58u/k0kS0+y8QclLdT2PyZKkRrgTWpLEcjAGhPfu0Y6Xbt6Y+sHaoNkc3c5oyeEfW/P5cuXDwQcD5eUWt07cSLUkrf8Ocjyuu5ck6a1ZYpc4d+qUvjjr2wIl2IhYhmwt4jqlNEvri+i+OktSCnc7yaBMGY9rA3EH0S0Be/fsVCSj1Tk736jYClGtSGVlgNoGGmg6bBzaunZHqL4enZd86OzhyCy/9Fbr9K8HknmRck2S8bvbXVEshsD3Snj15lFjFJn21QMASoLWlqTkBJn+eMgicIPIjRRIuudFY/ZlXMVKgXfDMmj1zOxCgHNKkWyc1FE+72uNOgpe4UdISfIISVOu3pIEboCTyu3Ka8QsIrfxWM0+qYNMSdIPWEQdl8gMvnZXIz7buBc7Glpt9zBQWb1jH5ZuqMWexjbd8W+2K8frmiMp7+EUY8etNi66gTm4gYLuuMPBrXGPh0IUGHUB/UEHIV5aBkgSWM9eyrEdO4RWESs5g1xP5iSKksjVU7Ekid127JQP0dOMx+z2sPl8Sx0+3VArVCxEGAfowuh2NtcbZ+f5Y1bfbe6me67tXkk2zyjhLEmlVpYkfuDG3SOpuOj/inzja75IKEnjxpnvzykFAIDBgyGXlCLY2gJs2Ki7p7FkajLkYFWo3WayUgorejaI0tuV+wqUL+sBdHICg/9uclEyTG44fm764ifLlYOr9Xlic76qJFlYkQBAloLYdcLJAIAeb7+uHbd0zzKkWSZkoxybAjdYnMeMfZHbo5fvv4cUjyNeUorW/YYBAAIJS1KJ6m5nc3nQoCWFLNz2VYz5obrnGffnUzG2O0KrkSS6c+a4ab2z2yidAWiNAZ9u3ItV2/TrwIoFUpI8gimWvnZcf55xxs3L8EqSsf1ItWGfuWHhFERBRVXPUc+va1GUmqa2eIq9NZS/rTFl0Gcc/KnHG1r0+y5kg7GjV13DdAskZcYNDu33ZhF1Op7YJ+nbb5W/Bx6oZRLrqQ/eAJiVQxEhTgO2sgzyR0WunhLMs/J8GvPfdbP0zLzPkLF82lmSWqNxMAY0p9hfSL1iwAN3oORnP9UeIlKY7LKXOTjXaekwKurqLKsompOlH3xzM4ItLdrx0u832j9L0odqN04SmRWY5HMrNiiRE3HggSnlQzCI5sFDlXt++w2AZL6FAsmImqocqmxGebNFFriv8IquVd3XbWDs4tqAbO/Ep1UqldLk8pRiksSRC1SWqqyoDbA8l4k/m3CiJDGGXVNOAQB0e/ctSFFnUSAzsiRx12TqWmneJ8mqXdYfd30Zy/r1AIDWvv0RT6yJDzc2oEd1GXrVKNZku4BPxve3W5PU8/UXMfpnFwB79yoHn3sOw355CYJNjbYR7gCxW6uxreblcpNs7mkM3KBzt2NAJNHVOp0E9BukJHkEyzVJ2n9mtwivY5xZEe0QbzU7ykckA+wHJ6J9cNQ1EzFZtnW3UxPX6OahyZHIGOHMeYaYQpQLLEmKLHrFWSSf1bF8+IGnZE1ircewYcmOskdP5e+OHcKybFUeAhK3yaLFu/DHdftPcQOx5B4kaoYrf+wG3gyCvDHMdBt/F+3FFUvhjsAYA+JxDPjbPQg98TjKtiouJHzEJN7CbHsf2O8tk667ncntyWbQYeKHPbqvZd9bWZISz+ImO3hV1hRMQXCPik3KgAnDhlnKx9+nabjichdYogQYUcuNqgyarkXmg0ordJMEiS+6iIwQW1GyrdN6y4v1JFS6GNtuJyRdQ1UhErIlvqZa92IXNCRt0rhGFL5diKokde1qe7+9Y49AvKoa4YY6VGxSwlhblbdsyqFwcJ7mPbR8Ni4oM51neLbbnVFCSWrp2x/xKkVJkurrMbpPNSpLQ5aiGa2YKlrEOqOcX32JkX+4Cl0W/g946SXl2I03ovN/X0GPt14TupvpNqA1WcL157rZrKi3DrgwwufFVAI38H1rsqcsxBAjH5CS5BHMFTY5Cyxc3OeDImmcWdHNugmO8ZiUJP4+hnOTDb65AYrFWYrADfq7WEWFy6mSZLkmSSGT6FNOZlxzTmI/JAwblny3nkklSYSV1LzbkWXYdC4B9fskJQfZvP+8vgPTW11SzRBryoOFtUY0eIo6yJOSvbWQErKH6+sAGNYk2chkktdm7OK0dJjcnmwW0FvtUM/27AYARKuqAQChhvrkTKwFfLoarVmmwaH6eySC8q3fK19ESpLh3gBQf8TRAIDg++8DSJYbdTbZNKDhJ2ts38A5+oXQvFootn6Knp+RNUF9hiTZtq+Z3tfJHk9mi6xRNv1fJ662+snE9N8mVVAh/blJbM93aElCMIhY334AgNId2wGkdsLKzJKUrNeS4Zjzeyh/U1qSbMqtK6hKUp/+kKuVNgbxONDUZOtGndywWexup7smFkPZTy9FQN3DatUqoK0NWLsWAFDz+WfC6HaiJBF5xWQTQEOEyEqWqXKq7wuZfgKQ+90T3is5gJQkj2BtSdIXPB8ZkkwzK6IFf9ZKkvI3aUmycbfj0s7Y4EXj9pYko7JmZYERRfPKFKM4WjoZB+aGjt+I3cyTln6q9SXfSjVjmiWJDR2aHPyoStL27WndjldwnEREjApcPXlLI6AMTs2TE2KVwsp6CYvBm6isp7IkAUC49ofk54b6xCPMliQnuZnKhckJxoGEVQh10WO077uVAWJrrz7JMPCJaFS68/mBmzZyMw+Yk+frn1O+ZRMkWQarrEwq4xb3V6k/cqLyXp8tBerrtbqoLsY2Ds55Ry63ZsSdr0ly5XHcs9R3ytF9HbgmioKM6M9PlLu03O3ccUVzcm2qyRSNHxL12lZJUv7Geyv7KJXttG8jk1UkE0UwcY8sMt9oSUrVl2vPdrsr0ixJAyBXdFA2igaA+vqUz+y0ZBEGzToPJbt3asc0dzuZq+P334/g8mXJC1etUvq3RANZ8/mylO17cpLH/ndX0scwfsrmvnp3O/133T2LU0ciJckrqO4/yeh2CvxMqqvTfXnAOLNiVZ9E/vRGlyF7S1KyUzYqSTGZIZ5oyNRFnPrn6O9pNRveEnVzTZL+GarFTbfGgDHTAMKIvZJkGHzku7zs3g00NACSBDZ4SPI4tyaJGwdrWMmpd5UTn8NfqwXD4K1FkHRWGb7Ymf3FjZ/FZdmqYzP6bSsy2WcCA1CasLoAQKihDoDRHSR1fhotL2m5xplk0g+k7cqTWZFMyLFHGSBGO3ZGS98BysHEwAaMAUuXAi0tCddihrIvViDQ1qo93zhgNg4O1d8rNimKV3zIUGHlEA0Mo737omngEEiyDPm997WyFQpKKa91C9FAW/2rX5MkbpsU+bIbKLu51io54Zc6vbT3NLjSGi2YyTVqFvfhPku8eSQDjH2C7bm8W67dBQ4sSWp+xvv0BQCU7lQ2n7UcVLtQFs2urc5Q1mkqn0NcA2W3RYfdOVmhKkn9Bih5r+7VWVeXci3vkL/MRfW7b6P3v5/Vjoc5V1utvP373wCAHdNOV75//bXyL0GHdWsQ31sneEYSowWc8RNAgt+zQeRKmGmq68ZqJksSgyw4r5ggJckjJDtFveXEWLldmBzOG8aZFdGMKSB+FyvLmvFaHt41RSUak6GKUSpUkvQDLfMu24njsnsLE80hwNUBvfm5dtgtzHe60V/OUNcj9e8PVlamHZb46HbCgaxY0gCnAFsHbkge1xRPXhGSEjPznMtY0goJ3fmmNUkmBUAdxImtW/q9bJXfnIRIDe/hLEmJmVDRxrJOBsV2M7zp7gGjpr2admJLknn6AoA2ix7t2Aktffsrx1Ql6V//Ag4/HPjd78AY0OuV5zDoxMno+/D92vPNkc7Ez1XXcMhDh9q+i94yJ6H2iAnKde++qx1XB37aeiA12qbg+dmid81Uy21yksMqsptjK4YFfHroLPVZthbJCb/kfa3uqB43rkkyKvqp9kmyXJPkUGbRfRy523GnZO9ul/jbJ2FJ2uHM2p5N3gPpu3ID+rLIT+KJlFhT25n201KQsEprEzAdOyp/6+ttAz5JDQ2o/lKJhqmtZYQ+2p3Wzu1ULE2akrRli7ZROgBIjCG87DOTaE62ajBfY3mJY0RtnRvudoqSxNcR/W/FCClJHsHKrY5xv0icI4EfymPEMCjUd+r2nZFp3yg7/3bdQFjf4EflZDSWskT4YtGl2iyeoZXnn+WekqR/RiSxv4JRiUyZxzYDZvVexvCmeUO3HomTr1dSSVJxMtjjrUCWjTF3WA0aot9vSz8BIVSSRLe16fitUlc0IZAq+hFjqS1JTlwyrBYkG5/lBGP66AZEVjMKxmtVS1KnzkklaZ2i0GgLoF9+GWAM3ef/BwBQ+eVK7ZaWaa0qtIm/SUvSflZvo3sX9XPteMXlLpBQkkJBTmkwKM96ZcIdREE+eGuMMTy2CDdksZt1T4dkf5V6vQuvDPLfjWebAq5YPDP53Mz6yWwVT0vSsCSpSlLpjoQlyaKVyS4YvbkupPO+fPuW0pJko9xnTX29lrYtffvrLUn19bbv12HxRwgk9ker2MgpSaKxxq5dAIDmQUPQpgYfSrRdLKHBly1fahLPWC4BcZob1wVmS3LyQSxLOhj7Mqtxih/GpJlASpJHMK/BUb4rhTDZoOXC3SNX2AVuSHXcFDkH1u/OuN+NA8NYXNYUn9KwdXFX72EK3MB9dSV4w65dCK1TFAjbWXnDAN747qk8SlRLRtAw+Mgbush2SSR1rcjOnZCMG2jYoFuT5GCgFI8rYbtFnZRoXY3IFSL5WWAjMSgPRsUtbuhIAOt9NPgXKOGUJG1Nks6SlHrwJxrQJ6+3F8GIMfQ1v2GzacNioxzqh0R0u2inLmgaMlw59tFHyuLq995Tvm/dipJvvkanTz8GAJQkBoj6eqC37mgTHIm/FRsVxSu+n1hJEilbEoC9hx0JFggg8O03KN25Xeduw09WKTJkPgC3wm6SiF+TZG9JykQY80DZDXSR+VJ4PhgHc8bzjFEV7SOVqtdYuyimwr5EC853qlQ5iG6nleeEu11ZCne7bODrQib358usfg87wbNMqepiX5SwIsW7dkO8Q6VSM3l3O91z9XRYtFD7rFqhAWXMEeDXv7a2Kq7jACKdu6JlaKIN27IFABCdcqJyj2VmJQl796LyW8UtT7Sm0mglV+TMPn2Mng7Z3Sv5mZ9Y/P/svXe8HlWdP/4+87TbW3LTewdCChASOgjSFLBh2bWuva2Ci2tb7Ktr+YqirrpW1FVXRKpK74QQAiG999yU2/tTpvz+OGU+58yZeZ6bRAn88nm9kjvPzJnT5pzP+fSPeBrBwy83OMEkHScQMgX8d9n8Ei+BJWkmcdV9bkCu46VPuhTdTpyEv1lEcxIEQFFIi6rSoSYpbZgixUlDaN+OSfCGV70Kky86G9W7dyhiTBLPtGnTX8ZcD+UkgKYm6R++WiSTNHu2btoxVjjuuy7S3V2R1+IIDceJNzuKe9f1ddMAefDZfJtMDQ2tKkjqVwzTEppxhg/KaZIAIEsCN6QFkzRSZaASGliejVRbEAogxNwlJPWN25dSk+Q2t6Dz3IvgpzPcnv9//xfo6VHlm2/6JtLDQwBCKbpPCQk1CLMd/lyazHjUB846lvCe4zC4jU1wFy0GAIy781ZNMh6O1dr0MQF7agTRP0LwJ5mzHBGLZIzpWBHjYd9ZWYaSluU35H39m5fzrTTvh8ztyCDOJDwOdLPchBcqMbeTUU4nS5+kMoEbjkLzZ9sLI5kt9d0cU7tqY/iN35XLxsqDMNt1p04L7xFzOz1wgd6RuscfUdfZ7i6ke3sU/aUJJoSpXZDNwq1vCJkkAaV3vovXt/pZ/WMMDiJ91jIse/3FmPf5fwPLcz9LU8gj4Vhpcmndx8LX0KTbTHO7wNizLzc4wSQdJxA5LMh9SvS8VBRJvh+EkbGUPXn4vNyGopJUBTFmJ5qU1zJBhRLvCNUkpRxHe1f+TZKOH7UmKQiAF16Ak89j3F/vQE4wbSU3ahqmazns40qSEslxlIs89HcDam5HZpFls0qamm0/HHktySdJRbiKM90x3i15fkTjA4TrkTLxEXOfCidMVhvRJMmAheR22TxJCAxNUo/oO9EkxbSn1WOYMGn9Vb4flY3PNHsFqEYv2n/bbyZ9klpa4DY0oktElMMNN/C/4oPU33Gbejfd2wNnaBA0cINNEiv/OkODKhqYOytZk0SxqLwafvf7AAAz/vvbqNsTmt4wY11oe/EY7Smb/1rIGLLI2jTL8mcjb9ecjmOlIVO426HfLK5Sfa2awTiUmWeC1p2+x9858lNSl5qXL+9XWn4E0e0gottl+vuQGhwoHwL8qBYiiwiIKgHzfE7KYZe0bo8aBJPkTZ0a3rMEbuDtEjhwAFVbNiFgDH4DL1+ze0dUc+kHytTOb20FGMPwbMIkNTSAvepKeLkqnrJh/nzg8su5EOjTnwYTIcIn3fob4LzzgGJR7z8RVBxLgzsbPXmk804/n+cbgRsIffoy5ZFOMEnHC5iSs3IO2sf7gpT+SIyFydn0aEwh2M1N+F/HQiDGSqyhH5ApEaEq73LmJu04SkqcNu07AntfaJ+PWpPU3w+ILOpj7r1LRduz5Veg/bBqBKhDpuW57LdNKv53B98PmSSiSVKJ7YRfUkaEXaX9j1vXmk9ShTmgSl5gPSxsASBMsyCzT7EHTIyZkPx+9H4leZJo4IZ0f5/WN9r3JLBLicU9WaZC/BHuLbIPYzQbceZgTEjRvRZOIB669Cr+QEho8ba3WduuOnRAm0DZBxturNmzCwBQbGyG39xiH4vFtEVeD//z2zB80cVIFfKY9sl/5aaAoEyp2YtjA+ZaDhQe4n/16HawlhW/Rty27dseC9DwsXEvtmzMGGXfyob/N+qpxCzVWo/GeJZ/WdcCxpQvFIDBQX5dgU+S09CgcoolaZOOSpN01Iww/xvmMYyf7+R1e5TwHA+8UJrF86IxBj1wg6ZJIu8J/8P+k09F8dQFAICaPTvDADVqbgOFp/wxPDJrfva8sJ6TT0a6qgpdIt8aNmwA7r0XWLIE+P73AQDbP3wD3No6YNUq4Mknj9gUdCRgExwfsSbJwDO2QDPm9csJTjBJxwnE5kkK6AFQPlrQ8QKS8E851AkyfB7EXEswQ6IDiB17QJ5LCVAm7ahodso/x2FICxM3GeLXJIrjiBbgGGiSOkICuH7LBtQJZ9EwXHVYVGOSYpw6QwIkythFE+X9A1fM/v3cjjudBqZNU7fVKIRfUqbDpkmyA41uF0coUWd3gGtuFOIuowkx51dbn0SbYUIccSAl3rq5XXk7kxxlklQy2ZERsXFaaX5gjgx/mKH4gXiNXlz+MqeLm1V6LVyD2P6KyxGk02HBG24ICRsAXiO/zh06oJk6KgI40sfQ1G5o2oyygiX6fjgfDIe/fTPcmlrUrnwauP12822tD/zO0e+puASxVFKvJ9a1C5qOjFA2xlRGMFcpaOkHYoQIqg/ir6nxjmiSyux9CeYaGelY9H1fQfmYaw2kqZ3jhFqOhLocxlAYywVJVQfb/i7mI5rA4AjqjwZW0uvV2vp7HT2+DzzwAACgcN4FvB9gWuAG2jdt7Yjk0V1Lz4MrzHNrdm1X45HrUdckcVPx/ByiSTr5ZKQdhnXf/DFW/exWlP7yV+CSS4DhYSAI4L7rX7DzQ59A/ymcEeNRXfllAF2g9ffwPWM4+npNc7tI3iRZ7ngnSo8QTjBJxwnYormZQM6c4x4kQZhNOdaklmaIZRNshF4cU0Cfy/I12ZTmgA0IJsnRJZPmoZzkHF0o+RVrMawgD0sBzX+9AwD3VaEO6mY/rN88AanSdxUz+I9EYNIfaeZMIJ0ODyfZX8kkHT4UeTX22yY4sJvvSkbYJaYBdKqsocRNaZtB/cQySTFSQbWuAEz8w69wyqc/AjY0lMgoBX5gTSarCwqMftpriu1ruT0UWxNlkpRPV7xAgb/LJ076JElNktvYhODii3mhCROAk08GLroIADA0eSoKi08HwAnEiBZv5UpUX/1q1K9/gcxxEDJJU2fEj8UQRNFh+UGAwoRJaHvdW/iNRx8VZeXz2GqPCqL4hiwcSOEAfW6v50i6pwg04+/R4gqKuyv3SaL3ooWpH2Ela/dYyIYqmYdywj4AId5vaSHq9ChQM8XCuAkAeK6k2Oh2RyEwtQkMRlJPYAjhkvxFkxJtHxWsW8fz8dXUoHDGmeF9Ym7H+2Z5dxVPDNu7eAk8YZ5bszvUJGmCIKlJam3lf5uaw2TVJ5/MGar6OnQvOxeliy8B/vY34FvfAt79brjf+CYAoCiTaB88WPGeOBrQj7ajowHoex5xo5APKQ31cvRLOsEkHSdgO8ABKW2wSWdGvhgHCi4K7tEHH+jLl8rmfJGJM9Mpxy7V0xiC6FjUgRH4wPLlQLEYGylJSxgqylRnUhFTs5TDFOOkAjcYPgDU5p0Sgcos52i0SUSTBAD1d9+urk2TO98YU5KdvTkfdAypozhIRwK9w6WQAdiwgf+dyyVukQNZMklWnyQ7aD5JZSjWjGAMuU9SACc/jKbnVyoTKpvZXsQXsAwTLyEksvX7kgHzgwAzfvhtjL/zVky87X+tppUK+vqQKhbUTxm4wUYkJYaDtggYZD10Dw0UXBzuy+Nwfz4WL9hMssoF0NDeHRwEK/AxeS2hGZz7rnfzOq69li/wN70JAHDo8mvgTpAE4gFNi+cMDgBvfCPS99+HiX/8jdZO7XbOmA9NnxX7wSIBIKATmiXPR+/CM/iD5cu1cSt8RCqgaKvk+ejPl2Lnoujan5fXJJl5aMi6PMYESRLR3Z8voehW5nFvN/Wx99XmPxdhjKEzUUm5eJRJ5hGKE3WmpxIuqYLyFUS2A3QTNskkJeVKOhqBqWadEkNEJ31zM+qlk/Cdo+f1kfQ3QO9QScfZQhuE889HkMmG/SHmdoCFSSgW1RnVP+8U+DN5XrWa3dst4wFhksaEbZzHc6vJv2l15gRAKgV84hPAT3+KQPg7USZJH5e8IusfAfIlD4OFI09gr2liE7R8gxXQhHG+0rxOQ5748uORTjBJxwtENEnivsYA4MjtS4uuj2d2duK53T1H1c++fAnP7OjChra+xHLSKZ7mHIlzcrWNRc7H+C98Bjj7bOA//zN07jUdxglCkIR0VSaqSUo7TBHQaUOiF0pD7MSxzLF0LJikoVMWwE+lkF27BjUHeBhR1zOStBnhqc0DkeM++zFJD7Ajtc0fCfQMFbFyZxc2HeznN55/nv9dtIi3LcopRs9gkiqRxjLGkFIBQGIILvE3KzVJHj8WZt78X1j0llfzaGoI1whlWKyMPOlTHFNiOvZLUD5JfoBMNyeSJv/6pygV4wlpZmjWMv29gO9rwudK9n8435Y2xEiLro8VOzqxZl8v1uztxQt7e611JQVuSAqXr0CseS9XhaC6Ro3l0CtfhafueRJbr/8PfuNNb8L2x57Fjg/fAG+8TKYpNUkcGr90I7BrF3/Wtk8zla3fuBYAJ3ripsY04QIIk+sHcL0AvYu4FgurV3OTGfUcYh6ikSYBYO3+XqzY0YWBGMLmhX09eGZnVyTXWkT7Jn5Tgpn2V892T++PfIPHCeZMGCy4WLGjC2v391RUr5wrTXMZ1weEZek981vpYaZthLgpiUluNw4qFY6MqHwFke2AEIcwAHmRdDt36EBZc6mjZZZt9Q8XPazY0YU1+3qs72gmlaDChISyMrjDEfSxrTePlbu6sKtzMOy3TB9wySV6YUOTFGESNmwASiW4jU3Ij5+kAr3U7NqhCGJlbUDM7bzRrVAV/upXwMaNPBE2oGgN01JAtlkU/kw4QL8nPeP17/Dc7m6s2NlZUQLyZIgXFxRdHysqoAnp97Lh/CCm7MsFTjBJxwmY0l9Na0JW3pFKyAquB98/+oSo8v1y9ci9RBOz6QxIskTUDwI0rXwKLT/7Eb9x++2JhGzD2ucx/e1vxKTO/RjTkMPEpmol3ZHgMIZJzdVozAYY05ATbcs6OVATLHoYSyR4VOZ2gmDMz5yNwVnc+bN+ywbVlk70VF5tHKE1Ul+WI4Vhc02sXs3/SiaJSuEBJelL9VsY7ZhxU5+kWE2SXHPEVCLwgfqN6/gDYWJh829g2oYzGDcECcybvdtqnfT2hgkL9+4Cu/tue0UAmDiMpRSZ+T6m5zwVBZH2M2l5xH5/chAPFz1tTHHMv42QjpMaWxnJjjCRLHMchb8GCi6Gps3EIDmCCjNnI8hk4MlkmofaBMEcoPG5Z1D30x+rstUH9oXrangYtTt5FKn+efPLCgQoDpURLwuuj5LnIz9+Eryx4wDXBVatSva1INd9w5z5jcOL+RKf7yEj+EuU4A+0urlgzJ5IuyJTrwQwNWs2wZzsOwD05ctLtuO0s+XN7WhZM4G6PgflNMnixcR246Cc8O6IylcQ2Y7XxStIOQzFsUKTJHIl2SAO91QCNq0q/e7ym8fhBY/0VeuLjYE1vvGRMPQyaJLsDyuVwB57jD+85BJ9f0Y0SXo/pBBv6OT5AGPwZ8xAwBjSgwPICtNgra9Ck+SNIZqk6mpgXhjAIV3GykE3twshTig3XOL0WqXa20gdRJtL66WgaMIymiT6ns3iZcTa15cYnGCSjhMwF7XmrCvKHA3NK6V7R2sPbEo649sLJU02X5JyB3wwOIST/+P68MYLLyDT1W4tHwTArO98FfUP34/6X/8SCyY1oTqbimiLUg5Dc00Wk+uggjooabSolCI52k6oxUgadRkgBOPgTB6NR5oJRYhsQ/oWoXephNl4WdckySJ/P+SlghQA3JRhnWBKFi/Wuqf6W18PQJhPGWBD7vw3K2tuJ98N/c0CBAhQdWA/LyASDyqCUyPozLrIdcLUKU2E8b1UHzt0P7Ts978XW5cjNGvFCZOAqioAwMyMTpjGEbJ63+Xei/bV7C9ifqu6LJokh9rra3WY7yJc800t2nqUhz/NHaVMXieIZJoHD8D3+d2x997FC51zDn/Wtk99mMyGdWC+j8Ko0Si2jo1d6zZNUrXQEOdLHjeVYQzumUv5w6efjhBYNhOykuerccTNo1wPpqTZlmuK+yfKfcAbsws87LiqYjDmI9acWfz1vKAs0Ubf5VowydQn71k9VDERrFjWXVJePcXwHSHeixPkVVI+9mytMEcSDTCkfJIOtsWKRY8mKqG2nuU92h+pCY8ZEu2rrCeuvJwj0w94ZP3V+9O8ZQvY4CDQ2gqceqoqxxgsgRsMwZIQ4g2dzN9juRzyAufIhNRaXi6pSZLmdpb+xeFE+dNmbsf3OlSdocVNyHhUkjzZBrZ6IzSGSlNRro3weVRTFlfy5QMnmKTjBOKi2+nLjiUioyTwCJI5Gm5faV7K1FGOULchZApNP/weavbugjthIjCHMxSNy5+IvAsArP0Qmlc+xX/s3q3uZ4gmiZriAVFiM2SW7P06GimYAhuTtG2z6gcl2k2NlWkSQwleE6hEMiJF+zuAJAB9P+AmCKUSP6hE7ooQYYveCCYpNRBlkiQ4BoVPv18skyRuU6bc9/yQSRI5NawhwKEfJHFmlyaYjGpEICDyHpXqG+Cn08g+8XgYHt2sq12UHd0aSkO7u63tJfXJpv0xQUoEw8AecUSsqIustnIBNCT4QcAdqwEUm5q1A1uakdgCWXgTQ58kOZ6a3Zx4wZvfDABI5YeRFmaMmXVrAAADc7lkOJawsxDe1cSMVpoIB0sFkyT8kmQfADthSqXt5TQmZhj4CGNp1KH6atEkHS3Yvq0NtITaZS0I6J4izHVct9W+IbcCu2Awad2F5ZlqW9Y1EtDPpZGVj22rAiaJ4qIUYyiMD32SyplDHs2SiPv21KfSBnKvpNR82wlxeu9oIq3KbyFx/2gpiHvFKwDH0efAMLeLaL6VJkkwVwwYns4j3FXv4LhZ09xKTZIwt7N9DzkPZsJw+avUSjRJZXB4nNn9SIDuhzjBWjlGWNVFnpcztzuW+Ol4gRNM0nEC8T5Jx4bATXK+O5J6ytVAbeo1J0jI6wQiNJ9H8y//BwDQ/fkvA69+NQCg8anHIu8CQPVf7gaTYhHCJKWJT5KN6NbaNpAwBcehyQ6PAgSTVGwahQGRtbtGaJK0ZoMAU772ecz74ifBKvhWpsRT+QSASHL/AUxSAOj+SMYkq08gmSShSbIRGinjIHKoJilW68H/tvzp91j87muR3rQROHQQTkkk8NuxAwgC1D71OBZ++O1gB/nhN/rh+1Bzzat5oAApBNDqTTK30wk3qb1U+01okoamTEffqafxe888Y63LET5JpdGtQHMzv2kySRVEKrJpTFRfDS2a6m+MgoBG3JIQF93O1KYBANq4uVBhzDhNai01EpRpkP12RTLNbE8XMDQMIEDN7p384fz5CESerar93J8vt5YzSf3zTuH12IeigBI51VnOJA0VPUXgsLPO4g+XL1e1aUIfo748MaGLD0/P70cksTZNEvkd5m2JMggaPj0CzKTeV2eOfW3R3+VyxWmCpQpytNkYNS2BMLmvJfiMgVCTdGRalrgzqqLycd+gEibJD9eX4zAUhV9epo8nVbaBXZA6crCdEaGWwf6OqUlSwXAsL5j+S0dyFsk6JO6vE3hFWitIYGChgGlgAPA8nYHzfaVJGjzpVPWOvK5d87zWV7/khn6VIrqdbWWVy+OlmKSODqAUWgfYmBmKIo6UVKMm7nFMGRWcJwHtg2luZ56NL0Me6QSTdLyAKQWHZWFr9qUjRIyadOIoFrJ8tZzEQCeYosgxUfrwu98h3dGO/LgJyF/zOuWY2fTko0AQHXntnX8Of8RokkyimxkTrOUCkJoRhWiIT8Ax8EkqNTcrTVLN9q0ccRNmePztv8ekn/8Qk/7vFjQ+tyLsMxkCS1Al2cyt/iHmdgFCfyRyeEWcqg1zO40hEX9N8yIa3S7yDQoFBHffjdb778HJn/lXTPjYBzDq6cfR8PvfgO3eE5YbGgIOH8bom76J1kfuQ9PvbgEATP3FD5F54D6MeeAe1VdzrZabPzXnZnAJoj2URLyaIwOkT5I7ymCSdu9WYdVHQhhFo9uF697UJAH2tR0Yn472wWYqxp8TomQfZ2S4+VBoeltI0CShoQleTS0fQ9s+oFBE1X7xHefMQTBlCgAg18Y1hDmhSeo/6dRoXbR/lnsyIEvJ9dU6dpacwXN8HTiA3IEDse/Ke1S7Yo+8FhISJUPSbAsBbkskbfMDswkXRgIRE+8YQb/GJJXRJJkMepKGAdCZcJuVhK5Jks9t6zRGcJLY2+QXKnk3LmKrBhVEt5NrT+G4unoUWrmzf9MjD1jfOVJtGX0njpcMhaH2ypUmSZnbxTNASvClGImR9zfUevC/NQJXYsYM0U8CNBdVX1+4rnxwk+v+fiCXw/CMWaLvwMBiHtWy9rmVAIiZe2cnHwBj8JpHqfImxAez4b9LzaN41LsgQKrD7jZg87k7Us0M/b5xwo9KNVZ0b5WLbvdyhBNM0nECpnO77pNEDs0jE5BpkuKjUYmGDERyORra1SplslHG/EXgO98BAOz9p3+Bk8vyMJuZDHL796J67259s3d0oOqJx8LfBw7wDOcAMkSkbYYDN+dRUykbEhbGjk4KRvsKcE3S8ORpCLJZpIaHUNW2l0tPESB36ADm/Nfn1Stj/nZn2WrNPilizzkaq/XKwaMHqhG0ASCmpBWY26l1Y2AmhjBRcCSM9vveB3bVVVj48Xdjwh3/p27ntmyGs3e3Xnb7duTWc6I6u2UTEASoEyaPORJu1yR+YjVJxhgj0m7ik6OI+BgmyaHmdpJJam/nEZROPx3o76+IMLI5ZQO66aunNEmESapACgwkmT3q7QZBAOzdCwDIjx2vt++Fe8xklJjD4Apzo1TbfmT37objefBra4Hx4xFMmQoAqGrbC3geshvWAyCapDLaHIoKMiknEuAlXVcLLFwIAKhb85z2Lh+DjgtoMIYkRhNAJFqVLQQ4vSW1MbboYcdKasuMvxHNNGmonCYpVthXpq9U4i17YYKTYG4r7xjNjti0vFxAodiGkXAmjsDcjvr47H/DPwMAxv38v+0vHQVy12gKy73QhNr+vm/0N5mBhSgbX6ZsfwPZL/63Vvr2TJ+ulWMMQDarfDrR06OPT+Le+fPhZzL8HQADIqpl1ZZNQF9fqMGVEUdHj+aCE9hNFOMCN6h1mXKAsZzpTbcfUv2JBDXCsTG3k0AFvOaWot82qRX67IS53Qn4x8KXvgQsWAAsWIBpH3s/j9hi+CRRKSTdSCNdi3FR244Uyvsk8b8OJSro+1RzQx88/DCwdi286hrsf8NbOfKtqwOWLQMAnPbuN6DponOBp5/m5f/8ZzDPQ/+8+fCrqvk9Ib2mxE+c6YdNc2CaFMZFlxoxKCapGUE6DX9OGLzBF4T43K98Gpn+PhSbeU6Z1vvuUdhM0ySB5LcwmrGFD/574i5lh+3bmaSIE7bUJOWHwVw9MIHsZkQLEqdJuvtu4JZbEDgOehYtQcc5F6H7UzysdG7rJjiCSFfw2GNICRO23JbNyHR1INMrfhNzO71P8ZMXMs+C6TCT93YSJolqkiwNyRDgLmWSnn6aOw4PDHBfphjTCa2/hLlX4HmYc8OHMfEH/4//VJqk8AhI9vUI78VJhIMAyHa0Y/5H3onW++/RNUljJ1gIYQ6S6dWYCWFyl2prQ24n9yXzZs7iPkeTJwMQwRu2boUzPASvulolki1PkOudqMmm1bVKWTCLS5lzB/eLOgPru0B5nySKe02fBZs2LpJ8GXGapEB7b6RQ6TtH4pNkaqfKBdMADMGg5cxL9EkyBDGV+O6V688IeaR4PFFBdDspNKAWD/ve/C74mSzqnlsJrFgR9+oRSfI1TYNlT2rnoWXC5Z61RuM1IFwTyVrFJJB1+EEADA2hSpohS02S+bFohDt6BhJLB6r5Lo0Zi+GJk8GCAHjmGbXfHKH1wZgxidq3coEbGJhKfZEWeD6iSUKU0Tpyc7toX5OEH0l0TdIzM/Lry5BHOsEkvWgwMAB88YvA2rXA2rUYfeetGHP/PVGfJPKKlvhthM1RRHdMfJLKVEERo5K2a4EJwrLa5v3jHwEAna99I9zGpvDQeO1rAQDVbfuQWfUscMMNvBM/5mGBD15xDUoTeYQaaXJH8yRFNEmy7SCKYM1IgA5VWScPOx58X0kUC02cAQpOOhkAULd9C+/D4CBaH74XAPD8j3+HUn0Dcu2HgKeeslYZp1UMLP3+u8Fzz4GJAyu7bw8/lLJZ4KSTwv6Iv6ongkkCgJRhb08l0abTdiS/UU8P8P738/euuw7P/vYurP7J7zD4L+/l/dm7B6lNm/T+3nabuqzavhX1WzaGv0XIaa3T9p8KTCbUDFPuCJ+kUnMLBmfNRZBKcaJp/36u9dy8ORyj0CRpTJJMmAgAO3dW5JOk+kakiPUb12LsHX/ExJu/CXheKLnWGOlopbZkn3H+BwGAaf/zPYx+4K+Y/j/f5X1U5nbjNfxFQWpXKB6QfklO2z7kRHhvX+QzCURAkFzbPkX09M85mZuzJECcYEcGbwAIzhAETdbI5UWJStlf6pNk85ej81TyTZ+ksF5aJ2CaOMYzCOZ7lQIVAtEGzSHQ32U1SbTOIEDq6aeRGuiP922h64vMgZ05199JAtOculKIC7EeBxURiEeiSQJDcXQrDr6Kn3vSuoLCSHBBHDCdio70x7gdPjc00ZX4vipfxiPosFz3vh+oXGlBY6PCk5H1QoI3aGf3RoHv58/XNO4OY2Ei6aefDqNKSrO+sfFRM+nYTCGIBMZAmKQwibqNmaFzf8TR7WLwCIW4SL6WymLBFnjm5QYnmKQXC1au5ITzhAnABz8IAJhyy48jjqemOvNIQVfhHnk9spqyPkkk+aKpFYhGWSE/HuD21z0XXQqAIPF//Vds+tPfsPrmXyHIZIAnngBuuglYtQp+VRXaXv9PcCdxCbNkkihjFNEk0fk1hmIyggws6msyUujtBUS+nGKTQOwncyapdttmBADSWzeDBQGKLaPQf8pCdIg5kIwjJTC1sy1mPhn7O2uSbrkFOP10TP7Iu/k4XuCmSTjlFM4oqf6F/QEA5HKAMHVIm0wS8ZMwfbAigRtuvpkHBpgzB/4XvhgWHj0KhVHc/j/30P0AgKIw38LKlaqYU8hj9KOhvX/uYJiThE6XjZFW/VIHsCQaiGbGD5QmqdjcAj9XhWERsAMrVgBnncU1bnv2AJ4HR5j7lUaNDpmkPcSnaseORIaG9hfQ57BOBAhxSiXkDh0gJpmVSegpxOWrYr29mHAbT9hbs3snWCGvIkPlxyVokjxjvzEoc7vMjh2o2skj23kzeQQqTOU+SVVt+1QQjAGppYvpM71vooLqrEWYIoJDyITHPp1Trc7A8EmyMZrRsZrlFX4KqC9kCLbvfrQS3FgT70i58JrnVolvTPY929cDvPa1qL3ofJz0hRvKnmF0XnWcTHFeApFtEJtHapYeHXuZc66cNN7zwuArZUKAA9GQ2nvezoVAuPVWFdL6WADtqU1wUW5cpg8VSyhrmuYdCUETapIAJlI5YPr0yIdWYyGaJG3vSJ/l6dO1NcMA9C4UiaSffpqY2xEmycLQSIgN3EB/CpySsmiSqEDLIzjiiKPb0b5WIPxI1hYlNWSelS8/NukEk/RigTQXO+cc4AtfgJ/NoXHt88g8w++HmiRdIlAJkWQDv8INUQ7km0mEI23DIYRanBZK1bNrF7BtG5BKoecMHmFKIdZUCkNnnImOV1yG4de+gd/7xCcAAP1veDNKzaNQmsyJJ8UkpRzVdjRwQ7SvEkKfpHAMplnViEGaXNTXw8twBkJqkmq3b0EQAJnNXOshgzocuvRq/s6tt3KukzINxhgo2HwvjnnghrY24GMfAwDUP/Ywsu2HMPr+v/BnF1+sFbXm7SER7rQpVYypLuWkzLY6REQwA7z73Qiqq1XZlMMwOJMzIylhuz5w1nnWYYy5P0zuWnXoIALByJoEaNzsRTRJBKN6QQAmNUlCezhw0nz+8MYb+TrN54G//Q1YvRrO4CDc2joUpk4PmSQKO3ZYNcwmBAgA30fTJ6/H1B/dBCAMNQ8ANft2h0xSGVNSG2EQFw6/4X9vUUxveqAf1evX8jpyOZUnyZbvx9SuMMaQP5Ob19Y8cC+qtvOwvP5svi8wZRoAwSTdfjsAoGtp+H3LrvUIk0TN7XRNUqZDMkmSodAl7wXXL8us0HmK5knifyV+CkgdtJvlo9uNHOQ7EdO4iNBFZ8ySkk8GPpDu6cbi174SuOMOAEDTqqdj8SYVRFFzLFu+tKTodnF+eCPPk5T8O9qu/VpBT09YSQKT5MYwHQNzT4Zb38CZLSFwkHCktAB9R2P4ybVm9VEBk5QU/dXUso+ot88/DyxbhnmXnYslb7ocdc88pZikgPgjRbpIciVpOFMySVOmEAsHBsdhOpMknqaouR0pb0LEykG1SeZZapIOHdSeSbCd50ccuIH0NU74UamWaiTmdkfpQnVcwgkm6cUCySQtWwaMGYPDV78eAFAlkk1SZzuKBI/U1poeLEeqwgUqN0egiNEkJM3XVD0PPsj/Ll0Kt65OvB+Wk5eDH/qI9mLPez8EAHANczsgJHpSprmdTuvo/THDnzLqE4AjA8EkBaNHh3WcTJkkH9lN3BRgQBD4XWefDz+d5gzJ/v2xTJHZJZuz/TGFIAA+8AGVh4IFAcbdcxtaHrmPP7/22uQOAkBDAwAgbSSUpYSbaeJFNYOeH4SJ+caP175LijHFaEoYOFtnkvLjZB6SUHvklIoq9455gJUlliSxawRCcDrD6HZAGFwAGzaELz/wgNKgdp95DlgmHcskVQJBADSsfR71P/sxZn7360j39qikxQBQTZiklGNP9gzohJItcIPG27gumn/2Y+39+uWP80cTJgLC1M7mGigjvtHmh8+7EKWGJqTbD6PhWY4rlbmdiG6X7e0Gdu6EX12DjvNDxjzuW0UCiAjQze3EM2luZ0h9TQ3nkGF+Zpekk7GaYdMNYjMIon49QCU+SUeAmGLmwwRzTEkmdwECjHnor6jatxuYMAEBY6g6fBBpkS/MVh4Q8xoEaFj7PILBQSujaF13ZWCk05Lkt2GvvwynKk3tGhqU9twGJtNBB+4ZeX8kVCIwiQONQbacbeUChJjaISVosVDJZmqAign/fB74p38CVqxAzaYNaFy3GpN++n2VFDwwgjbQflBzO5WEeHBQ5W3D1Kna+c4A9M89BX5VFdDZiazwg0y1U01SdF9KSKu1GTM2BoVTUu0hs5uknQKO3DXCSjOawuAKo+iVo/O0xyeYpBNwTCAIwkSFIifH/ne8DwCQvuP2ELGS4oBUCx8Z4Vupk145qFRFq+cV0SUZttwgAEIm6ZJLFCNHzeSkpLG4cDFw/vn85mWXoTh3HgCE5nbERCkj3o8wSZa+SjAT6TnkJDliSYklDKwzexb8TAbp4SE4O3fxaGsINUl+rgqlUTw3A83ULQcQZweexKAeE3j8ceCuu7hJ3b/8CwBgxg+/jdTQEDBlCrBkiVacmv8pEJqkiLmd6qdOUDPikwQYTNK4cbrG1cIkDZ11rvb74BWvsQ5NRriL1XYaYB5uDEwj5pj47r747r3ELEzBQw8B93OzwK5lgpmL0yRVYPsfABi1PIz42LD2edTuIEzS3j2aJilOS0p/0WFaNU8PP4zsvj0oNrWgfwnHafVPcSbJEzlfTAZDgtSuaLk9shm0X3w5/y2TvIpgCqypEaX6BvV+/8WXwq+usU2FPp4YIocyScpcUmqSlE8SkQjL+hANZJBkbgTY8iTxv6GU3a77sAa/KUOfl4NICPCYuszfScEb/ICvLwDAa16DYCb/ZnUbN8S+I2Hq97+JM998BWqWnoHsurWibxT/yzaio6UELy07Yrxn7vtyxbVvYCldgT8SYGGS6LMGO5N0NEA1eEn9oWUpSLPRiCbJUlbeSlWAuzT44heBTZuAceOw46s84EzTM0+ByWTcGpNkVCrN7bq61AhTMohPfT3Q1GSYdjME2SyKCxYBAHLPPQsgjESnaZIsUxYXeVEbq2SSDh+OPgOsqqQjDtwgq2QJ+7pSgXdCO77BJP09U428WHCCSXoxYOdOLtHIZFQ+mYE5JyM/biInCLZssapItYR7I1yLx84niUoyy7fnsKg/T/QQDninhDQdl1yiRWiToDZ7EHB/lNe9DvjOd1R9rmFuB4SaJDNwgz4me9/puZuULK8ikJokclg62SyGTl0EAMg8/hgyBpMEmJm647Vhtv5L5E/HckxAMvjXXMPNxkA0Qm94Q2zHtNvU3I7c1g4u8cVVzgqyliJMEhEkOAwqWS/A/YHcKVOBWp57x5syFb2LQ0YuYAz+yZx5oX5JrQ/9DQs+9i/IdHfGHlYmkUEZAd91wbq7+I/R/Lv3zSZM0nvewyM3dnYqAQFnkpjOJMk1s2sXmDQHTPiiQRCg5emQSWp5+nFU7wsFB9WauR1d23o9WmJQiyZJ00iLPde78HQMn8xNCuuf5RG5vAkTVDFbkk9Tk8SLMBy69NWqTLGxGRB+ZgxAfvwk9az3Vdfo44+0oN83e1CVCc1yTU1SuqsDzHU1nyRag6lVseHWgNwLAp1RMiXyQRCWN33yaPm/B8QLXfQb+UQmKUD1PoF/p09HIKJc1m1cYy8vfVdXP48p//0dAEBq2zZMv+piLH3tRZhw6QXAY3wtJyWTDr8t0/6OFKKEZOXvWs/VCiLbAfbADeqZZJLMxNIjZTqMzs770idR+/2brEFDyvokyf4a+9mGl8K0DiM4i1avBr7xDX79ox/h0LVvRbGpBemhQTCBK62aJHkhn23dqsanIp1OnQowpmkrZZmiOAcyW7l5cnYPWcsJjGXZEOBgEZ8k/jx5No5FnqQ4qDTicbL/q84l/R3R04sGJ5ikFwMkkXnaaSqevx8EGJZE/s6dVhU4YF/0Q0U38eAC7KrVgYKLQoJ9uQ1od5I1Sfyvw4hNrLgXZUoArFvHGceaGmDp0tAMxSJJDALw0Ol/+hNw0kmqPneSmL+9e9WJJUMym4EbKLFmjiOSTFaTtvMyJc9HX74UO/4IKCaJaJIchv5zLwAA5P52DzK7dwEwCHyRUNDUJJkZ6rX+a3MvylSIvfrzJRTdMly0DKN62mnA1KnoE4wegKipHeyO6EqTNBinSQqJd6YR6BxlecViSIAIgpaX5eOmjGZ+/CQwh6mD012wQJvj/MTJCGZzU67cARHyGcC0H9+EMQ/8BZN+/6sRaJKIWVB3t9KCsFGjeUCCpmb4Z5zB1/kNNwAXXqje9caNw+DMObxOyiRdfjkXqLguT64qOxgDbGgQjc8/q36Pv+tWHtpWgGluF+cQT39afZIoQUCS5han87C8TiEPgJjBwm5375o+SUKL2LXsfGVqNDRtBhg5rfITeJ1BdTX6L77U6HcA3w/QO1SySkujwgamksoqn6TRo4FUCiwIkOnuJHtMF1RJvJtN8/fKaZL4eKO4WOWQAREUkHeSgmvIMSfBYCF6RsSdLXH4RK5r08RQL0uYpBkz4Mt8U5vWx/aZFYtIv+c9YJ6H9gsvRemyK+AUCqjfshG551cB/83zBCX5hZpaQs2c2mJm1N5fwOG+PLoHi4kS9fLmdvZ+KBipJkl0nPY/TpMUaghGTplWb96ASX+4BXWf/xxYX1/kuWZWn9BfxzC3s2qS5PpJ+H4R+POf+Rl+9dXANdcgYAxdy7g1ACvxczfRJ+kUatYsaACp4RTmuvQV5e86k58D6e3bwEol5Pbs4gXmzFFvJGqSIjiUvKM0SbpvmQQb81XO3G646CWav3JrEjszbcuTNFBwcbgvj8P9eUUHlNMyBaTfJ/IknYBjA9QfSUAQBBieNJX/oFGsiGOcvjn5Tc8PsGJnF1bu6kpskq5dzw+QL3lYsaMTL+ztHVHXK/dJEkiUSKrlvai/RxBqkS64AMhmY+zyYySdci4mTOBhgItFxVRkYzRJ9FdUgq4qVmMwJbnr2/rwzI4u9FfKKCmfJH5YSo3IwLkXAgByf72HR7ZrakGpJWSkNE2SUWWckIjagI/Eh2246GHFji6s2deTXPD55/lfISU+dOlVAID8+InA0qWR4oq8tJrbxfgkkfJ0nCqM7AHBNKbTwKhRmpTPYQylltE8yzk4Qc3AABEdzVuwEMOTpsLL5gAAQ7PmIpjEie7cIWluFyjty5j77orXJJlMEiPEgPjmbl09kMkoAnzwrr9wM5I5c4BLLlHvFi54RVghZZJOPx2YNo2Pf+cubZ5sUPvM03DcEoIcH19OBB9wG5sAICRioSd7jnPYpxpJ+Q5/TgrLHGDNLSiKTPYSZKQ6sx713Ihux8ty85f+S18FABiaOkOtA8YYhicK09orrkRQU6vVFwDY2TmIlbu6cKA3T+5bmHUB1VnOJClNUioFjOF7L9dxWBsrHYI0PavNpSJjkGASDiVNk8T/UgaASrglWH2SKpTgFl0fK3Z24rnd3dr9SqTNtJyco8Qw4AE0JinUJK2LrXfcPbfBWfMCSs0t2PClb2Pw1tuw/a4Hsf0jn+QFhA9KGFUxub9x7UjY0T6AF/b2YM2+Xqza3Y32/gLp/siIvLK+i0dobkc/iSf2bYRJCrmkEYMMQ808D6nHuabOpBEkJAVuSBvmdkk+eSMK3CD9L885R9XRTYOzMMY1QvK3+KvmRPj7YtMmMJ+vV5VYXLwXMjAhDvSEsCy9Yzuq2vbyPH7V1dy/zrIvJSQFFVEgksk6g4MqYBHdg7Z9WE7D88yuLqzY2Rmb2FvWze/Y8TvAtdcFl9OEa/b1Ys3eXrwg6IDEPRHo3/PlxyKdYJJeHJB5b4Q/EsA3i8YkkfsUzPslz4fnBSiU/MRwkaaNcb7k8TbLaKBMoP2pRJOkhaG21KHKUlM7PyQUbDbacQcTS6eBidz/AV//OnDxxZj+7BMY21CFsQ1V2jsUIcX7JIVlTQZNEgr5UpkT+wc/4M6nAun70mRI1De8+Ax41dVK4zA4c47WuRLRJNnMb3in9CZtuW0qAalVTFwTg4NhVLnFi+H7AfZd+za0XX0tNn/ua1ZML9dlXHQ7G9B1U7tjG9emPPtsaJYkNWtjxwKOE64JFjKgg7O5tig/fhK/94lPAG94A4pvfyePljidE/NDs+ciEOtG+iShtw/ZHi54qN+yETkRYS3STxvrKm+JyHbF5haNefIbmwCREJVGAixecGFYDWWSFi9WSRMdoW1MIorrn3yUj/v118KrCqP+9VzA28p2dap5dxwWOjZXyAgqgoK+IIjBUmMLStMNJknkPDIDN8h6Q6YhZMrkXB26/t9x+FWvxZ53fjB8D8C+f/oXHLziNfC+/GWrT57UmmhajwSmYNqoWoxtqEJrfS68qXIlHULJjSZ0DhCoOZD5lcoFbgD0MOARcztyj1FCx9DGy/YrgaGiC983k95G61ZDi+BnfkNqy5IC/wR9/ch2CcZg+nRg0WIAQO2u7cDQkPWdxhdWAQAOXfvPKI1qRcAcDC8+He0XCg2hwJ2pGJMm2mVm/LUMJ6IJozjcliA5CcrmibH4otogwiRRS4e/g08SDaSRfvihyHMtcIPliIsL3GCbrtDcTv+dCJJJEnjPDwJ0nXW+ejw8erQ1zYT68tOncyudfB45wRyl9hBzOwIMwOTmGoxtqELDqTy/X3rbVtTs4qkHMHu2OGOgjZVC3NrU1mVdHf8HINtxWPM/jDMPTZoq1w9Qcn24XhA5sylDV25f80dBJFKnpHGS+uAToU65si9VOMEk/aPhttuA557jkspzufpYSg+HNE1SeGjqTulQ94HKo9bRDeEF4eE+UvVopZokPQS4LmWKvFcsKLtz7o8UFog1tyOgmdFIBHjzzcBDD6H2Na/GqT/6JqqMlU4PIfMQkER96B8TDZMcGH9j4ctfBn73O5XryBdRzhQDU5VD9+mhRnFwlh5wwJWapAMHIlXHHUyh5M5OXMWBfM8MY6rB2rW8snHjgLFj+Vqqb8CGr92M9gsvjTGFkf2xaJJIJCteVhKIYflJv/oxcO+9wOc+FzLNB0J/JNoG1UD1nM61Wn3zF/J5OO884I9/BBNmrer56UsV0yJ9ktLSzELAqL/eYZ0OmyZJjVOaoDW1ACDJcekUnXIK/9fQgPwrLlFjQHU1X8uNjdysURALqV07RBXx36jhCc4kFS++BP3EFHLgtCVwxfqTWjKq6TXxhzXsNaj/DClPzO1KkyfDT4eRvEpUk0TqkiZucr3RbygJqvzEKdjw7R9hYO7J2voZmjYT6771IwRz56q5CMOvhwe3zWzIRpC01GZx6qRG5NIkIa1YW1ITJ/umEeDG2o7g085OOEbQAhryPBKJkkpmLQxlHP5N2t6SgAoCgtvIC6aJWhSfCIK4Ah8YtmsnAPB11tgINn4cCqNawXwfwerVwKpVPGoZaad+E9cyDc1fqO5zoaEwn25vB/r7E5ORamcAdPxuQsQkCnRO45/ZIClcOoAj1ySR7seb241AM2NAuiNkklIPPRSpxySgKfh+oEy1ooEb4oUE1O+uLFiYpOHJUzEk1sSQ0PJKiAS+SKWAeTygU43wL0pJczupSRLvMgY0i/2fnT2Lm9kODaF5pRBmC+1ShBEjoEWntAS9UOtR+GdWHbKc55ZpSNJM0W9kanfp2OL2tSk4j9BBQaBptm0QGPWeCNxwAo4OOjtV4lj8+78rrYfSTkwmTJJ4xRbKkYLNvt0GGpPkB5FcQJVCxZokmofFeNfcSLlVz3INRWsrMH++dohp0e0qORSEWRJSKeBSIYn86leBX/0qvq8xB10YMhgwAyD4aiwJ4HlhyFH5njgs5bAcxjQJmRmVTTe3o3MR/h83HsrcVXKUyrWQmMBOmtqJgCOJ0Xwi/SE348zt1KESzlHDauFf8+CDyPZ18+tDBpME+V6ordj1wU9g9yMrcPBVr9M1GALrbbnhC1h+xyPovugyBJP4XpQhwVMiq7uEUX+7KzowRL8AJaIZCf/NiIJJW2+McQHBxo3wx45TYwBjPPHt+vU8fLDUJMnwt3Gf6NAh1GzgkcGKF1yI/kVnqEf52XNRFDmGqvdzgiGVYLNOvwUFq/09YZKcTCbEZQDcmOh2kkkqmT5wzO6kb/M30fvJIveo1kZVFU8/6yA1SYSgNNuQuCxl08b5PnDhhRi19DTM+9InlY9WSUsWCe39AIHVh6+8T1L8MKjmxIazTawStw5iE2YSSO3m61OuMwDol7nBrr0WOOMM4O1vV/Uw10XdFp76YEgE/AgCLmP36hvgtQjmYudOpIQppE2IExepT9ZHQZmKpaLjtVo5JID5ODI1lTJJpmaGPosJAX6EsSkAGEzSxg3IHj6ozZNubmfvK0B8qMRv29JQe6QCJhsA1zhKSwHhdyTXnDS5GyR+qPS5Zq0gTO6qRI641D5Dk6TOd/JSJqPaVInG58zRxmHVJJGbdH4i70wJE2EHAREKxnzLRME3QZvx/obhiZS0tv0gxDuhxq/8t+I40NbuywdOMEn/QEhddx1w+DDfvCIqGBBucCU527cPrMjtpAOYC09f8FrStwTLLz3vAdEkHYV9d9IBIh+l9u/DuLe9CaMefzBWk1T92MP84uKLuVpbPHci2p+w/3pbhKj4yEd41LuHHuLah099ihe6885IH23SWSA8IKjZmhndzvxrhc7OyAT7wt+ISsVpIsyBmfO08q4gnKPmdlGCULUhI0ZZGNQkUIxfkMAoyaANwtegkjwO1rxNytxu0Mq+yeSSqcEB1AgiCq6Llvv/yp+bTJJFA+Vn0ijMOwnQmEUi9cxmMThrHg/qIHxccocOIPB9pIVEvPPsC+CnUqjbtB7LXnMhFr/3zUj39Yb9jGiSQvM1ySQVm1qsjLaClhZu827eb20NzUfFwe2IfsXO+m23AQB65y9CMGYs+hedrh4Nz54XMknCBEUPSmLuK4AVCzjp3z4I/PSn6n6iT1JTCxyH+xABALJZuCoqnf4dZOhtmTuIVkfNV0LeJkpJ0EOamsTa9mcSkWMFxSQZmiT6HUX1aZt27e67eUAaAJP+cAtOf8drwUqlstHtiOVo2K4F9+nESfw+pFJmJRyLLR0FWbVkKpK2vGTii1M4IcoA9M/jzA9rE5Ejb70VEGGca3ZtR6qQR1Bbi4JYM/TM86TQa8eOivw+bJ/WLB360zjW59q7ZRBnhKE0a6swup2ZL0t7Vsbc7kgI00yHLrxrefpxvU1Sadz5yBgN3JCwNuR61s6shE6LNYSmJmV2LIvvfP/HkH/Dtdh+zTV6E5JmoJtbBG+o2rIJzHWRauNBecLADTH4QDBFdTu2ar+VMMbSZW62zK9t61O9Ixi0qgP7I+vOpv1MmidNk2QySWRscfjO1LKHuCg0Haat28z9fYNLOsEknYAjhqqODrB77uGU/y9/CeRC23e5p0otoxHU1ABBAGe3UA2TNWgSGUDlmiTTLE+TFI0gGL+2bRJek32p+s8vo+bev2DaT28mmiQdah57hF8IJ3aaw4VCnNpYk3ifeSaPeifzKL2eJ+nFww8DrltRfZRZkOVMQtLUNllBZkhvbARmzQJyObhCdU+l4gNzT0Zxzly4jU2h1FUA1SSZGKgc8nOoWqMCoN821uTOYJLMcpU47gIg5nbxmiTGeI4fGpmt+S+c2WUHxdyKsKoS6LfyfV2rJsGkQxgANpGbQaSKBQQdnUgLiXjf/EXoEL4RdVs3YdRTj2D0o/cbb0frAwAmfJJKzS1Gzqrk/Wb9ZBFNUkwdt94KADh82VVgYOg74yyUGpowMHsevNGtKE2dBiB0rufJZPmrNnO7luWPYezdtwEf/zgwPMzfUfNLylNNEmMYmiaYpIkT1YRrpogAakQggDBPkhw/0wjiaOQyQmwhfO6Q/Sy/uy3fS8VbQqwtzdyO6e+rtW3TJH3nOwCA4VdeBre2Do1rn0fTcys0TZJJ3HEGL2xLgo0xrTQdQ17zRYq+G5qoybrsezpdgSYpLTSwpanTVd3dZ3Ln+2D2bB6sKAiA734XQRCa2rGFC+Gko8EvXFEPduxI9EkyJ4DOXVSIJMaTio4nyvSUA73EkWqSJB4dUXS7mO9VCUgmyR/H13jL8sdiNQJxTBJl6JL6Yprb0XtWMEztqMlXfuIU9P30F+gXjI7ZR+1MlJqkrZuRPXyQp0/IZNS+jl3Gc3RrDtPcLs6U02GW9Wm2oZikfdpjE69ISApSQvG16Wdnw3XmtzGDc8hfaYfiorAMteqh17SLJ8ztTsARQ370aLirVwM//7kl2abY4A4Dk8RQGd8Ded/0NYoDU+NUabblSLsJyJOC5wfIdLYj8/vfAQBqt2+xHtCpgX5Uy3DFgkkypasSkhLWAXZJMxYv5tKovj7g2Wet5ePM7SgBExK45t+EuZNM0qRJ3BZ/61Z4Y8ZqY2Ei0sCBu+/HtoeeVhHIJHitIpns8DDSAyFDoREBMQe1oxGT5aHst3VdYI3IdyLM7UwG29aOScQCiE8mS2pwGFNO3TjtNABA3ROPIN3bA0cGWDDM7cx2lNRTe25ZJ7kcCjJx7759ytxueNJUrPv69/H8L/+E9gv4+pT+PLZqqKZBJpItNY/SmbeYj5G4lgReYO3tkdxSCg4fBh55BABw6NJXgzHAa2nB8jsfxbO//DOYw1AUZnCSSXIS+hUEQI2MVDY4yDWzZNxqjZRKioBTTNJUHkkQkydrB7amScqGRLHJDIUJee1zoq9/WX+IH+Q9ysSHBEmFbJLySSLmdmQlSbMwAFF/mdWr+bdIpdD97e+hZxHH+dX792ghz224zm5uF7Zpjoffjx8GlTIrLTl5zoy/EabC0AQnrdOU0HQWBTPOAHSdfQGW3/Eo3OeeB77yFV7wF7+A39WFOsEkYfHisH2CBTxRTzkmiRKb/K/OSFOQayJjM7czcWkZS4sIU3WETFJUk0TWQ4y53QjkXxGQgRuKb+ApG5qfXa49TyL0TdNAQBdMmWDuEaAMrov4I+mPbTjBaq0gmKTc1i3KvBiTJysTFU24SkEwRQpMc7uYbsv5sOMccaGZ2yX7+9Bx2YCuzYhPEmHoyu1r2VHbHNJ1QL9fnOnkCOTtLxk4wST9I2HyZOAd74h9zBhCYoj4HlDiwVzwmiYp0cmPXgeJNsdJUC7JnIQgACb94VdgBW42mO3ugiMksvSt5pXLuYRn5kwlZaHmYhTCsduZAivtk0oBr3gFv5YR9IwK45CHFjBDMVRGmaS5E2FWMWYM9yuZPDmiVZEqerepGaUx4yJV+DV1iqHIxDiQx/Wfr5dkxpKCJsG1LYotW7jTdW1tGE475lvo/RF9tprbRTVJdRvXYdqbrkbDE4+g8QXB2L797cCpp4KVSmh96G9wZK4JySTJBJxgViRP246sE7GvCkKqGuzdi7SIIjc8cQr8mlp0Lz0HvQu5f49kMGymDPSeo5nbkVDbRyJta2xUEbJq9uy0c6Mit8jAqYuQnzRVrZFi61i4Tc0AQDRJInCDk2BuFwSols7OgAo+EnFS7uJRAAPGUGpogsM4k3b4imuAT31KIxTot8mlwySuJUNkSgmOpP3N8SO/pvNranzp+ComLhWTFOY1Mfsgq4/469x0E/977bUoTZiI/CRuzlm9d489up1tzZJ2yiWFjltTns8jn5rt0U9djmeURaV5WoQQ7u3l+Wx+8QulgS0Js04mOOPBWXMRVFVzXLxgATA0hNT//AT1MjT4okVaYBP5rSo1twvHk7DPBUiclVb23PFnYdnADZHflPAMKo5u5xpMEu27YpKMZLK0mZGC1CS55/DgUbnDB7XB6+e8/q41h6HsS4ImiZrPJ3bZErTBVp+1DTpxM2YAuRyc/DCanxVpV4zw37zvxkIhmqRSQ4h3E+kM2AU7kXUpNUlt+wxBRdRKyKzLBHr2RnySCEMXhzvoPvYJHpUaVsBgkghTTLXKtN6R+ri/FOAEk3QcgGYSpJgkoUkyDjNTCupXyOyY2ZUrZXZMCGKuTWCFYUz6/S+1e7kt3IGSNjf+jj/wi8sui/S1YnO7ckSnzEVjMEmy9jhzAop4qU8SlQAlzp3UJIn8CEBUq6JLv6N1MQZlHpAlxBp/ZsfWVCJUqYkXfQ+IMWnZLkKizpunTrxoyFPbIamPGYBmbqe9kc/j1E9+EHVPPoYpH30vmqSWcdky7msGYPRjD4QJ+ZQmiTCGpB1JfNC2bZokxhiGpoi99+STyAifHZng2ffDEP00z1CU3wqZjlCT1KJHGYr5FOUOYXl41+zabl/zwtSu8/Kr1ZjM3hVFssTq3TuQGuARwyTxYhK/QaCPFXfdBeTzGnHkB4EytXObmnlkKMbgNjVj403/A1xxhUYo0B5lUo7KHVXyfKIRMnySgujb+tB0RpibifAnWuAG67sJYAncQN+nGiuHMI4AQlzz/vfDD/S1Y8uTlCKESUAnwmjTNA2r3rsbVft2xyJj01dBfmM9YirT/kbwq2TkSB814u1Pf+Jr433vQ0Zokrzp07Q6VZuM8VD8ANJf/xoa163mDxctUgP2ybx6MmHojh2q/SSLCRuYxT1PZ0gSfWvLNJWoSRoc5Dn7gKMM3NDELyLmdsmMcywEATJdfM/6IgKc47pIDfSrIkn0gcnQAclWHraUFInzWoZJsn1/q7VCOg3M5Wkgxtx3N7+nmKSwWJImaWjq9EiBuHDdEi/aBIyqCuKTRDtRjqG3gXleyxQegH6WxAmXTX9NU+BD2zfPVYXv1H96uy8nOMEkHQegSUGUud0u9dy27myapErDRXp+oKuER7CwgwTkScu0PPwAcp0dCCZNQv7iVwIAcps3anVU7duNMQ9yR3wV9Q8xRDUAwI6IyxKXkklavpwfXAbYzIxoP3VTqcDQymTX4e8AAN/HSURBVMW0CeiaJKO86QcA2FXvDCD5Wg5HC8AiISLricWUKVePdS3JQ5oc+COJbmf1STLM7Zq+8VXUCofZdGcHMn098LNZTkQJRrp5xZNIH9KZJAlSchYS/uIbInqgh+/wp+2vuJz//vnPwIpF+Ok0CmMnqHLDylRtD+KAHkop8b1KQosTt34jdcTpOhSTtCP6bN067ncHoOPyV4etGYS2N3EihqZMh+N5aF65XAgADC2IAD8IdCapvx+47z7NHt2jTJIILx6aYvD6dAY2fDflMGSkxsijGiNmNa2K298RTVIQfnfTpIRPSYVcklhbqcEBpATeoNpZOkbN3K5YBGSQgpNOgh8EGpOk4179fYAIiUhXbOZMrFjAmW+8FGe+8XKgkIcNTDOcJA14PDGFSB+1eZV+iq4L5rrwUyl4EyaF9ZrCgbe+FTjvPLCBAaQH+uGnUsD8+VY/Il8GANm1CympHbSa24VrzGyXAl1PMrcVHUqc6XUcmM+1XzJoQy4H1NQk12P44dJ9onySCgUVPh2I/15loacHToknQfenTOV+0ADSIi9cEATaOoucL0k+SVYmif+lQrvEeY34JNnr0/pknKsKRPCG+i0iDL+RIwmwaJYnT1aJuIemzgzxWBk6w+rjZs7epEkIGEOqWECqvR10dm14KYm+MPdBvhi1daQaqoiwwNAWUjPfyPnJ9HMzzhz6BJN0Av4uoJmBGOZ2+nNK9PJ7nuXAtYGpcToWPklJEvHa7TzhaHDxxXBPXQCAO1DS9yb/9udgvo/+8y4C5ocBC+Ii/YSaJHvDsb4GM2dyW+BiEeyJJyLlzY1u0yRRUxCbCY8VLJokkwEMNVR2RoYxpoi1THu8AzkFM3lfpRAXAlaBZJKampLLRerlf+3R7Yi53XPPofEH3wUAtP/bpxGkuM/K8KkLOaGxZAn8unpke7vh5HkQATNPkpwU+W1pJCYJkcAN4nfHBZfAy+aUBig/fhKCdFqVk9Enc4cOwCnkISPwmcAY4AwNIiVM9oamzRKHDH8+kv2mgZBw1uzZoe891wXe9S4ecv7qq1GYMj0yZtq3rrN4NMWWpx+D4+jMBYWAMklXXsn//v73APQwsWHQhlFauwFIGUgGNqw/m3KQEQlKae4gBp0gp/fD65DhVJ9e01pw0P0DomshEerqFHGbFT4c5veWtWtaiX37eMdyOWDMGARBQBjs3VrIc5spkm192NZOqrMDmb5eZHu7UbVju3UIphmOKZm2MRVm8zZ8rG17ySTJNidM4om9LW3wwTjAz36GoJonOh6aMRuoqjLONoGDJ0/iJtOFAlIioiX1X5MQBEDDmucw662vU36TNlNjm/mQnidJ72q5nRqZK3qD+iMlLDqqLU1bNElBXV24QIg2qeJ1bIIQ3pXqG8CqqpU5Waa7U4xBL26ej0o7b2GSrDmsYrT8VgiCMLqdEf5bgu3MiRWsXncdBs+/CD2Lz8TgJZcpdwdaQwSHOw4PtASuSTJN7OPAFriB4j4AQCYDX1qG7N+jP7fMTaUuFICZLDq8H5+oVqdjdAsUIbwi5up0/9tSNADxtNlLGU4wSccB2DRJ2LFDrfQkCUYlgRtMB8GoT1LlC1vz54x5zQuC0FFy5kx483gW66qtm4EgQOrhBzHm3rsw8U+/BQAcfs8HtffjpEKh5Exvr2zvGQMu51oC55ZbytYXziNF7iERlGSvrYFkkjRNUoiIaC+CwM5wMcAaiphi1Lg8IBTZVfKJkySqACpikuzR7SzEKUkmq+AHPwDzfRy8/Gp0feLT6PjXfwMA9F0k8l2l0yice55eR20t77u4JQ8E2ZRnPdCj9t+MAV5tHTrPe4W6R3P9AJwJcGtrwYIAVW37rIealLjVbd0EFgRwx4xFcXSrxlDFfYqyGlGiSdKm+dvf5kFJmpqA//5vbS7M3FoMTIWcb1n+mLZGIlLxw4eQGh5GwBjw6U/zm7//PbB8uU4QGJokNdeBOa5Qa+U4vFyaapLIzNhCIWv4wKJ1oD5JKvrkEWrMRYPE1PWwalZjJgK9v34QALsFYzllCsAY/CBMFJ7t6kTQ18+jVW7aZPVJ8i2MvY3QSROCuUbkgjFBEk612zYh17Yv8o0rIbTlGw4hclU9vh8ySZ/7HALG0LtoiVV4oDU9ezaKX/1PAEDP2ReIvhBGU0I6raT/MigEYDPzBSbe+ls0PP4ID44EqDVC11WID+KSm0aZrySIC5oDYMSJZIGYde+kuE8iYA0DPmKyVJxLxZbRAAMCEaI/I3wLI3jAPB9Ff9MGTo3ri5R/0HM0dl4PHeJRNB1HBTkYyRkTMaVesgT7/+8OPPubO3Hgt7daGS/rFjjrLABA76IlkfYcyzcCQh83jUmSbVDNoDDhzu7bZ62HQmJwLOPZUDGM3mtjTHUBt6EtDHRhZqi5FvVAZ0Dj/ANPaJKOMTz22GO46qqrMGHCBDDGcPvtt2vPgyDAjTfeiPHjx6O6uhqXXHIJtor8Ci8n0OxphaMq6+tDprcbgH5omAtedwK2128uZM8/8sANlZjbUTMdNmMGvLnc7rlq6ybgJz9Bw1VXYsH170V6cACDM2aj9/xXaO/boucA8Qi2IodsYc7HbrsN1e1SKmwfR+j0DVWv7pMULWsFaW5HNUlGUAqqHbPVxBgUoZYxzO3iCBzab106mwx0KNbADdJxmDBJsaHCLf3RDhfBJDluCaxY4hHSxP7f/6Z3cI3HDZ/B8jseRceHr1OvlS4ka4WY2plhok1JV0SYTSaPE77896FLr1L3pYlUWJChYPglmfXKeuo3ioSu8xeIsZM1NJINR0EwSdXCOT4IAk5sf/7z/PlNN/F8SyGXZGgKOHPYvfQcBIyhbvsWpA4ejI1ul5I5b8ZPBM49lwfPCALgXe9CppgX74RMkjQrTApQIbsjTZ3kX9cLFEUhianI/rdMCQ3SQPGDnAOqdSjLhNpgAje3nPaz7yPd1xt5N5ookzBJgrj3fJ4YVQbPyOzZyXPCLViAqs3cDIiuR7p/JdhwldPbo65rtscwSUMFzPzu13HWNRdiyduuhi+YplCCTfeBfWIoARrxPdm5k5th5nLAjTdi+5PPYeMXvqknb5aCIGM9FD/4YTx19xPY+W+fi4xXk7ALwlZjkix4NycSQUtNhG004dniWH1SowK45L0a6YaNSSoTtEHNrxOu4cgalTiXapJCLnBkIM6l4qhW3s5ozsRlujmTVI4psaXoCAWO9rNU9rfseSRN7SZPBrJZUVYHq7aKEPgmxPUtCdj3v4/ldzyKrrPODwUu5TRJleRJAuBLJokEb4jTssUJT4HoOWLTJJWjEfR2wnfMtBCM6VYTdgHDETDsLwF4UZmkwcFBLFy4ED/4wQ+sz7/xjW/ge9/7Hn70ox9hxYoVqK2txWWXXYZ83m5//VIFStSguponkQSQE+YFWqQSA/VrWo0Y4iuiPjc0SSNBHro/jv29IICKisWIJinT2QF8+csAgIHZ89B15jnY9NmvIWD6Mgzts/V64xAsRTSxsGgRcOGFYJ6H6ffcI+qzS7+kXzWVgFNJmW5znAC2wA2GyY9jIewoMDCrTxIdaxzTmHJ0M8FyUHYtWTRJlUUe0glJANyUSUB2eBjs4YeBri64o1vRffoyAJypGpw1FywTmu6UXhHDJIm/sgU5r6G5gN6nuLXSceErlT36sEgwSyFP/JJsVTDRdv2m9by8YJJMrc4RgTAByfZ2I9PTxb/7f/8391VYtowzMYiuMdo3BqDU1IL+k08FADgPP8TDgBfymPKBd+LkX/5S+T1Iv0gZNhw33cQZ9s2bMfUH3wYgmH6lSeLElklIU1t32ScpdZV2/CWfBm7g90yJrU2RFIS8lYYvTB/MxGhWSfCJTyDIZND6yH04842XInVID56ihB40+MUeoUU3nMTdaZzYb37sIWDDBqBUwvif/0j0PTkZpS0PU6qnW11Xb7UwSb6PKe96C6b/5CYAQNXBNjhrVvM+hQ5aCuLM7SgBGmHWpBZp/nwgk0Fx6gz4VdUaQRW31wIAQ9NnqZyBqm6fYHiG0Lpi+/YweENEgh2g6pBgkiShbfQfIEEbyFg0oZetkyMA7WwaaY4kYnMZCVJiYZKOGMQaLrWMBgPRJHXHaJIAHsHyta8FbropjA5IAnkkpRGg40hMOgtE/JEAmzl89LUwjUr0WSiIjO9XBHI5DM+ZCzCmytrwDAVrCHDLoe4JDVl2/160fOcbWPraizD5wrNQ/c63c5Nps3wsXRcy10DUtBZBgKbPfQqt3/2m6L+OE5nrYt4XbsCUX/63pn2X1hBAKISnqSL4b10Iafbp5QQvKpN0xRVX4Ctf+Qpe+9rXRp4FQYCbbroJn/vc53DNNddgwYIFuOWWW9DW1hbROL3UIaIqFtLL3GHOJNlyD0ioxGwuQshG8iTxv/35EopuQmPQN1rcfvDzeeTkgTVjBlhdbUhw7t8Pv6kJK397D577xZ/QvezcCCKJU51rCRf9AL1DJc2UsCzxcx3XSEy77z5gYCBWk2RKjqhkJRq4IWYSgiAxcEOYJ4nWY5FAMYQ+SR2GJilW8ivfHRlRTluXiF5bExWY29kOBVPLAwBIpeBXc3+PTH4Yzm23AQAGrryaR0gj/deI45NORqFVMJ2aJkk8N94xHaIlaFJQ8o5XVw//2jfy4Z62NDKWgpFniFab7ulGZvNGMEY1SaeqcnHrTY2hHEVWU4NgEneIr9m1A0E+z5kkALj+etUAlcKbK0D2QZrc4YEH4DCGUU88jKa/3oXZt9+O9Pnn82hiQnJfmCKYpOZm4Ic/BACMv+WnSPd0a4EbSsLcLo7YpoevzFEjmSWqEZdg+iUxyzejECdw8Azt74i2xTXXgD31FPITJqNm727Ufu876pEfBEj39qB+3WpN6xXIoDsypYFo3BOJUSf+6X9V2dY7/4RMZ7tG3NnMU215ktKESarZxn1Ah4puSCytXo3mRx+Al81heIZgsB9+SNTDi1QyFVSIFwl1/vzz/K/Mm0atIuLqMX6HJrLM/kzku8GTTyaa+eQOidxpwlTdZgJGrRRs+NPsYzmlb2L5EZrbaSG1za7ZNEmK+B8hYSqYpIJgjpRPUk+X8E3Ri/tBAHzsY8DttyO4/npkn3oyob/xRLMWSCju3FzL8SaNMGftD8x7YRtR0PEi7yURmsQghDgz5Lhz15Zs2abR8YVva/3TT2LUN76K+i0bkdu4Hpk//B51WzZG6i1nIVST5ULEYRK4IQBQt2Uj6n54M8Z+86twhgYj5vRNzy7HpD/+GrO+81X4+YLhkxSWk2Ome1oFqfj/gbldunyRFwd27tyJgwcP4hIZmQxAY2Mjli5diuXLl+PNb36z9b1CoYCCyM0DAH19fQCAUqmEkojo8o8G2W5c+8VSCa7nwvcYSqUSUuPHw3nhBaQPtcH1XPXcdV2kmA/Xc1EquSiVSigU+TMAKBTtYywUXVUGAIrMh+8zuEJqUSwW0QcfT+3oRFN1BqdPbU4Yixu+FzOnpW3bURME8Kqr4Tc1wRsqoX/GbFTv3wsAGHzbO1GoygGiTyWXafWE8+Fp912vpMa+o70P2w4PYM7YOriuK+anhFIpFdt3XHYZUjNnIrN9Owr/93/wLrwGruehSOaQtx+I9eKKfrjwRBu+z1AsFlX5YtG1f9feXmTEOiw1N3NzMkB9r8Dn77meS76np/UDAFzXRWnUKGQAZNoPqeee68BJOfxdV/8ORbcE1/PhuS78IBBlgrLrv2ispZ6BYTy9swstNVksntKEVHc3HABufT0CYzwSSqUSzE9QFPPoufpcsbo6OMNDyA0OgN1xB5+2K14drnWH8bki68D3PXQsPQcT774N3rhx8Mnecj0XnthDvqfPpWu07fueWsfyHdfzEAQBhr/7PbS9/2PobByn1qiEYZHvJrd3F1+fbri3Ft7wAYx++nEM/P521G3lh93AvFPUeDxP37smyLo8L2ZNAXBmzUJq3z7kdm6Dd8tepNrbEUydCvfVr1ZrjO8HX7QZzoPnpeC6gOu5aF96Dqb9/AcI7rsPXqmIpqceCb/L6tUIrrgCbNHpAID8pClhf668EukFC5Baswbj/3gLiid9Bn5HBxwA+cYmvkfInJRKJbI/XaTFN2VBitcZ8P4NF4pi/J7Yx1DPAE6w0DnxxBiLpH7PS4X7QTwHgEKhhCDtqLrcUgnwRyAfXLgQO77wdZz8vn9G9S2/RPCh6+B6GZTcEk755AfR+sTDGHr0cbjNnAnyd+1CCoA7YQKCUknhs5KQINfs2Rl+z2IBE373C3iLv8LXrB+gWCrBcz2u9dO+qYtSyVH3WFenqqd69w7k+wfw1J4+OA7DebNGw3/0ceQAdC05C/lLLsPkL34a2UceQqn0KbUnGZxIG8UkfOJ5CmeWUkDq+efhAPBOPRU+wZl0DfN3+LfKOiEVpfasw3GTJ3BhsVRCyRXP3BJKV16JzHXXIXjkEWQ6DmGovhn5QglVBM94Pd3I9POzHkNDKO3fL9aDz/sq2i0I3B34TLVH96P8VmrspRJKIs+UbU/aywtN6OHDSAHwmpoUnrJBviDOk3T0ewN8rfsNDXyeOzpUXa44LxyfxeILGzgHDyIFoNDcwnFESzNSANJdHZymKOj0Qu6eu4Df/AYAwIIAYz7+IWz8w70ImnOqXXk+Fkt6X0oC5/H+lgQ+8qznBACkli/nZ8wZZ6gzhp63/LfQPtN2SiW4fsDXi6NT6p7aO+G6lmetiVcoBGLdFoolZFig1nYphs6QZ06+UIp8R89Nh21P5ELwGmFq27nkLNQfakN2z26kutojNEChWAQLou3JPVyVSqPHczHguSgUinAcPqa61c+ostm9u1Ca1KL6UCi6aBY433FdOOvXIT9/gaJ35Fjk+e45AXyPqb6p81VI8D0RfvzFpLNHCpX287hlkg4e5FqUscRUSf6Wz2zwta99DV/84hcj9++77z7UlAnD+feG+++/33q/rwjsGWCoSQdo3wAscl1MBdC5+nmsmjwbjdkAvUWGPdUB0gw4MMTQmA2wpw7Y3gcMuxxp7KkOsLE6Wn/eBbb1UVUp/ycVBO2bAqQYsLOfIeMAh9bHiwM29zDI3IT7qgO0WtprXPkcLgTQNWoMnvrrXzFYAqbXNmIMAN9xcO9Jp2Dzs6tU+ap0gMPrw/cPDQPtwww7qwLsJJ+sM8/H3pDl89BVYNhdFWDIBYZchsN1ARqzsV0HAJx86qmYvX072m6/HSuqx6PoAbuqAnTmufQkCIC0A3RvCrBvEOgpMOyrDtCU42MHAzo3B9gh5nN7LsDO2mg7tW1tuASAW1WFvzzyiLp/cAjoyDPsqgqwrQboyAMHxfcs+uG3lNCUC3Cw2I3LAaQ7OvDcM88gcFKozwRwGNBbZNhfE2B0VfjOxm4GLwD6tgbwAmBHH/+uPZuTxTxy3gE+J7Vpvi7TDnCgKcAFe/agCcDKrVtx+C9/AQDsHgD6i2Gfu7cEqDGwyrZeIO8xdG4OUJcJ71/opNAIYMpzK8E6O1FoaMBfXR+dz67CnuoATVng8DDQUwVsF3XmPaDznEtxQUcHDpx0EgZFP3qLwF6xhw6v1/cFwNd4A1kbW3oZZHRk+c76bm5a0b81QEce6Crsj8zR0NAwZgJgWzbjmZUrsbMqwMEh3s7ZG9eB+T4ar/swUoUCSrkqPLBnLzq3tWF3Ff8W3QWGvdUBxlj2TfswcGiYoSkXYJdlTQHAgmwO0wH0L38Cw2ueQRbA+osuwvb77lNl6PffNxjOQ2M2QDbFv3EKGSyoqkbuwAGs/8mPsfQRntdnzXveg3m/+x2yW7YgJ3xr1hUKWCXmGQAmX3ghTluzBuN/9RPccebpePX27WgGsO5wBzY/uwqdmwPs6udt5rfzPvQWGdpq+P48MAR05YB9a8I9XZ8NMOwyuD7QsyVAdVr/hozxuiRs6uFle7cE2DvIUPCg8GR9NsBAKTST6d0SIJPi8wIAw9uDWJOZOOhrqMb48RPRfGA/er7+Fay66GrsqQ7w5vU8ktrOH/8Iqy7hGshzN21CHYCnDxxA51/+gt39QH+Job5QwDmkzm1XX41Zd96JqT/7AYbu+RPGTZiGO9/zMdTlHPSXGEZXhWcGXd8HRP7VcRvWY7qoy/E8PP7Tn6H5rntRqK7B3e99Gxbf/mdMA7Bp9Hjsq63DWwBklz+Fv95+O4acLLb1MaQcYGArnyiK7yhep+tp9wDfN12bA9RmgEtXrEA1gCeHh9H9l78ofHCgNkBLLvqtqghuGCzxMyeb4rhJtr+/JkBPQccZF8yciabt2zHwPz/EqvMvj+ASd/teTCNzu/y3v8XKcSdF2u0pAPsGGWozfC22DfL1skdY/+4f5HtUwsHaAM1iHLbzW35bCR2bA9SLfp2+di0mAdh4+DC2k/1jgjz/q9MBOoUiQc4FAOzMBagfGMBUAJtXrMDWyVxQU/LDM2l4e+Ui/DPXrMF4AFsHh/Hcffdh9sFDWAxgcOcO3POXv2LY5d8FALLDQzjvsx8GAKy68HLMfmElGnbtQMN//Bse/5d3YWNVdAz0LHd9/v0BoLAjwOZehpJnPyeY6+LKFSvgAHi0UMCAmDNZt4TmXICJtfr3oLg7a/ATh4eBw8MMO3IBtgu8WvT4GWDiFQpy3Up8tKMvmc6QZ/m2bICdYj1J/NZI1pizvw1XkffuPf9yXPiX/8MEAPtWPYsNaZ1O7dsaIGdhKA8MAZ15htFVATryfH4GtwVIO8CufuDCB8Mzoe2Rh7Cx0K/OnbwHnPfgver5zttuxebObkWbDLkc9+4WdWdT/JyUa3JfdYBDw0ypolcLs9tdVQG2vLhkdsUwNDRUUbnjlkk6Uvj0pz+N66+/Xv3u6+vD5MmTcemll6KhoeFF6VOpVML999+PV77ylchkMpHnh/ryWNfWh+aaLE6b0gTnmWeABx7AzGwK+TNOx+i6HDoGCpg2qha5tIPNh/oxpj6HUyc2YsXOLgwUOHc/pbkGs8fWRervGy6hcXc3GGMIggCOcIqWSQ3nT2hA2mFYva8X2bSD82bFO5rWb+tQ5lczRtdi+ugoNVfYxiWlbM48XHnllegdLmFXez/wtz8D73gHlr7xTahr61Pl63JpLJ3eon5vPTSAPd1DmNpSg1ljwvHs7xnGpoP9aK3LIZ1iONCbx+TmavTnXfQMl3DqxEaMqc8lfgu/qwu4/XZM6e7GsqVLMVh0MampGvt6hpFNOSh6PrIpB+fNHo31bX042JfH7DF1GNdQhbpt3Kxo8eQmNO/tAQCMa6jCKROi64o9KUwSJk7ElTJ8MoAth/qxt3sY00bVYmZrLfZ1D2PzoX6Mra/CcMlDX16XboxvrMLJY2oRvPvdcHwfZ02fikLrWIyuyyHtMNW/KS0hZqrZ0g7PD3D2jFFwfR/P7OpGLp3CubOSzT62Hh7Ani6OOCY0VqOpJoMNB/qQchgunNOKtDBXXPLKVyJYyk3Rnt/bg67BoqrjjKnNaKzW1/jTO7owWHRx2pQmNNeEp4vX2gocOoBZTz0OAMi8/vU494ILsa9nGNNH1WJGa3RtDRc9PDW7E21XXYUL57Sq++YeWrW7Gz3D4VwumtSIUXXh2hhF9o3UntJ52901hP09w5H2x04YBXz7KxjV1Y4zl5yBqaNqsfUwD2NeI3LVtAiNaenUBTjvggvU93Y9P3FsuzoHsb19EBMaq3HS+PrIcwBwtmwB7rsXSx/5G0/E29CAud/4BuYSE8i6rR0oeT7OmtGCDQf60SvmYVxDFaozKezs5BEFe155BcbedRsuWrUCNQf3I3Ac7L3wQpxUXw985ztKEzrtkksx88qLw05cfDGK//s7NHS048r+XjS5fB6nLV2Kuvmn4fQpzVi1h5uCXTSnFesP9OFwfwFzx9ZjUrPOHR7ozWPDgT6Mqs1ioOCh4Ho4c1oL6qvSeH5PD7qG+NqSa1BCw7ZOVXZdWy+Gih7GN1bhQG8erXU5dA4WlanIGVObUZNNoWZrh+pTXISqJHA62oCPfARnPvIABq+/EdNG16GurwcAMK+nG2csOQOB56FWmFktfeMbgenT1R6Z1ciAn3BzRb+hEVN+/WsMzl+A2r27kd2zG017dqPv459CesnpaO8dxv7Nz6szo2OggBf29aKxOoMzhKa/43e3af278JkVyDzM884Nf+3zyO7n0bPqX3UVFlx+KfLf+gqqDh/CFY2N6DvrPDTu6tLw/cYD/WjrHcbM1lpMGxWuz9ot7XD9AGfNaMHa/X0YKLhYNLkJo4Z6kensRMAYznrve4H6erywrxcdAwWcNK4eE5qqjW/VjPqqEDd0DxXx3J4e1GbTWDajBRsO9OFAbx6zWutwsC8ftlObhbN+PfDZz2LJlnXwrv8sFkxsRCvB9e1/vkebi7PHj4e35MxIu209w9h4sB+j63Jorcuq64WTGgFA9UHCSePq0Vqbjj2/V+/tQSfBf7RfKeFrPe+cczCXnAEmHOzLYz3BXfRbAMDk5mpMWvkI8OCDmDt2LGaLugqur86ki+eNsVVthdR//RcAYNyixTj7sktRNTwI/OTHGIMA06+4At3DJawW59vE2/+A2p5uuNOmo/MbNyNY+RTO+PA7sPT+OzHlXz+M1ksvBAB0Dhaxem9P5CwvlDzUbu8EYwyvmNuK5h2dGCp6OH1KM5pqDFro+eeRLhYRNDXh/Pe+VznbSNwuYXRNGvvXPa19j9wmbop+7qzRyKV1LbENrw4XPdTv6IzgFQpN2zsxXPLUmSbPFHPtSaD0yQKxnvZ0DWHr4QGNTug62Alc/68AgPzck9Dy9n9B/aZVwMb1mDuqGdVncA2+pNckPjRh88F+dZ7s7hqCHwQ4Z+YoVGVSeH5PD2be+G+q7KlVGTjnX4AZ3fuB2lr0I43m3WHagAXFAsacd76iu3qHS+gZLinaqC6XRmN1Rp2Jc8bWYcuhAXiuh9WrV2PRokVIpVOY3FyNOWPtZ9fxBtLKrBwct0zSOOFvcOjQIYwX0b3k70WLFsW+l8vlkMtFF3Amk7EyKP9IiOtDKu0inUojk0nz50JSVN1xGOlUGsxxwudpfp1K8bLMSSEtpAwslbLW7xQD/n7aCXN0MKhs96l0mofjTfG/SfOUSqWRDngdjuiDCd4eLoEuTpnGx+wCPRe8Eqv++hROv/gMpIdc0RbX1jpGv510CulUGtmsPl+ZDH8vlU4jJfrLnDRSaSCdCsL5S4DS6RwBOevWIc3EmFNppFNp5LIp+EUPTMxBStzPZjLIZTNIp9JqnuW12XcFglBiY8boY1N1psV6KIk+pJDy+TgoZNIZZKqquP9NWxtqOjvgjZuIDJmDdFoft+OkwBiQzWbAPF+sF6fs3KTTaW1cYOE4U6k0mLCHT48eDYi6+PpLa3WY7aRSfI1mjfXvigh3zQe4xsa54gqkRB/ivmVA+pROp5XdeDrtaXORyWSQLoZzmc1m9bWUTiMtrBpkW+lUGowF2rc3wRfO9+nBAVT19SE7rom/57qRxLiFUxdq43FSAdKpElKWOeJjyFi/pwYnnaTaBwD2zW8i06of8k4qhTT4986k02pN8XrD+eu+8jUYe9dtqLnjzwCAwfkL4dbVAR/5CPC97ykn4mDGLL0/mQwOvOO9GP/t/0T9j38IJqJFei2tat+qb6Tm0rN+02zGC9d/CkgHTJXLZjNIFziuSaV0vJROp+AFDOlMWtTPkM1kkE65Ap95yuGWOSk1t4DYFyP01wPAc1HdeCNye3ej9blnkD1zMRwxR84zzyCbSiHV2QlWLAKOg8z06UAmI9Z/GqmZs1RVxQsuQLq2Ds/+7i+o37Qei2/+KtgLL6B+324Ulp6JVJr75cm1nMn4AmeG+CYjGLTAccB8H5nf/y78RD/9KVLbORE0fNqZqMtl0b3sPIy/81akH3kE6fMvUmeCrE/u/3Ra36dOKoU0A3LZLJ9jV6yljVztwWbORKalJSxr4O5MOg0vYEgZ9abTgb5n0+H349+U4Iw3vQn47GfRuOIpVPf2gE1p0eqSQY5U3Xv2IHNWtF3mcHybkzgilUaK4HBz39MzznZ+8/0d+oJoe1eE1E6PG6fwpQ2clCvOn0zkW8h2U2J+U/39SIkyAfO1MhWD8JV1W8fxORDWOtmeLqQzGTjFsN7x93PmM//Wt8OprUfPhZfh4GvehHG3/wFjrvsI0i+sBqqrkc0EGl0iwQ0EvSLO1HQ6jbTH7Dhu5UoAAFu6FBlCw0n6SAJzUmrMmUwGvh+o57lsRkXMlJAV35me1aWAif7G0zuZTBoln6kx8bM7iKXjqrIcl1E6LNxT4XjTzc0oNrUg29OFrvd+COl0RgXPyPX2hN9U0GvmnKp5EHstl80gm0nD9QKxXtPIDvShbuc2Vba2bR/c3h5kzjwTqK5G1Wf/A4w4EFVtXKfOqmw2g6wHpIuBaiOdTot5LIl5zmrfJCVotriz7XiESvt53OZJmj59OsaNG4cHH3xQ3evr68OKFStwlohh/3KBiNOhCtzAHSxpNBfzcHdHELghQ6SnuhNfGByinNJed7i0l5aJcAtTpgEInXgHZ8wCMpmIk71Zjc2RFdBDeYYJX0cQuAEA5syBm82CDQ6ies8OVQfvp+54aYv2QvvHy8S0Ywn/bWuLOhfbqlLNGmuCPtMcUsl82J1Y48GMCEYTfJZcF+jt5T8S8yRF65XO0qb03q8NtYQBY8BFF0XXhgHUQV7PR6E7u8dFRpRg1SRU4ghdVYX8GC7AWfSWV2H0m1+H1OAg0gNRqVT+5FP1yGCyr2W8WxM/G3Fo9l5xMfDe90bLkP0QjeoX3ug7/yItymDP2efzi8mTgWuv5W1UV8MbFdUsd731nfCyOWSfWwUMcIatKPMkkTaDIJxNa7AFGRUuQKSclofFeM/m5G/uXwleEFTkqF0WamqA8/kc1e7cBufAgbDOjg7U7N2FqgMi98mECYowVskoJ09SCZKL518ELwhQah6FrrPOBzvtNN7Erh326HaWqGBpsR/7554SKZ/6EQ/oMTBzDoLGRjDG0LVMfN8HHrCHAFf4xNjTJM+NltRWRvGbFTJ/gYHfaL3mtjIDutD2aURXADwh+OLFYJ6HJW+5Ei0XXwA8/XQ43v1GzpkdO6zt0sANDsG9RwqRYBT0R4WBG/yjDNzA+zGCUchksqNG8+8vAjdke7pEXbxYurcHLcu5ln/oqteo1zd98osotI5FeusW4EtfAmAPLAJEoyjG7VEA4fdctky7XS5wgxkcwoSkAB1JmMDsqzUAES2fEJ1S6w9j2PpvN+LA296D3te9ibch1khWRBgEQnrNOlef/jTG//t1YK4Lh7EwAI4M5rD6Oa149d7dqHp+FTA0BHR2ovqTXMvUdSY3AM6tWwtfCHwYwnlRydhhz5NkwssxcMOLyiQNDAxg9erVyp5x586dWL16Nfbs2QPGGD7+8Y/jK1/5Cu68806sXbsWb3/72zFhwgS85jWveTG7fcwhkudHEMTZw2GGce05QmRMo4vERcELQ3baP7fvB6pMOWRrMlc2cHbvAsA1SYDOCNC/qZhDKo7IpzyVHkEmGXlpkEqhT+Siqt2wTnskI7bI6HmUaKN1V5SI1xL+W9YNRKPbmQl/JUSYpPaD6r4N+dNvwpM/Vk4I0PZdP9Aijrm9/eECG2F0u7jIQ349UcsvXAiMHh0ljgzQmCRLFCEJcWsnfK491doMgnhGiTGGvgUhQVt9/71ofuZJRbAGtbXIn3Em/HQGg8vO1SPNlfkWFRE6M2agMGYcSg2NKPzwR9ZFHxsCnOnz6tTUAFeF1vHdZ5FEvTfcgCCbRc/ipXCcKN4IWsfg4FWvD2+kUnDruDmJFukNFvxGgEYrM8vZIhBG+hFEx2tGXPJ9e5SpIwIRfKGqbR9SBw9ojxpfWIWqtr1aOdofJ5vF4Olnwq2uweArLwuFQSkWJgrevYPsl7Bua3Q7kUev57Qz1b3Osy+En06DCafk3oWnw3EYUoyha5n4vs8+C3Txd6t3bVe4yiazCgwCVEX88gG0iQimAjfx8tDqAsi+ikvdIP/S9m3f6x3vAADU7NuD3KqVPImygFQb10YXRBQ/7NhhbVfNucM0pszsf9zvKJj4j/wYcQhwO5PEgLIhwCsmToeHeV4rAAWRJ4mp6HbdCDxPnWmtD98Lxy0hP/dkFGfPCfvb2ITNn/kq//GznwG+H5tOw8z5FcMvc1i+nP81maQygjjzzDPBKkxUz+IRgimYMNerCbbIi3H74cBr34ydn/+aSjfhtehh2BmL5vpTsH8/8PWvo+U3v8CUX/1IJOYWzzZvBrZtQ+3zz/J3hRVW9b7dyK1bE/ZBmEjve8u74GVzSA30IyXoNpoPTdGeZO8D9qTHdLwvJ3hRmaRnn30WixcvxmIRPvT666/H4sWLceONNwIAPvnJT+KjH/0o3ve+92HJkiUYGBjA3/72N1RVVSVV+5KDCFMgmaSOwwBBWsyQRlONCpCgSRK0rZY3x2hfIqJyi7xsCPAgUKGDSyIErnnAm9LG2GR1xupUiDgIY/p7lJlJ7rqCXpGcsHbjOq19PaFjQO7rjJINCUbAEv6bthVqPMLDRc0LGbf64kZYeAq0CyMOuUrr0RjgQPmsAYDXKSRcuRxA9l+IRKN9Mftk4tWAaDF8kf+oEmLWlivFXANRJin+d9yesAEDsO7r38eqn9+KvoXcdDPT04V0P2eS/KYmHPrjHXjqr08hP32G9r3NsKqRNhP6oyCTwXO3P4jldz4OT+yv5L6TcRqaJcdhwBveAADwclXoXXRG+PC007Dn6dVYc9NPrf1xGMOetxEt1qhRCBzJbBImKUgelw0HyHKpJE0SobZC/AlRl17WJdKjo2aSxJxXHYgySQ2rn0V12z6tHO2Pwxj2/PL3WH73EyhNmqprzIWGsGb3DutetRGhaZFMtuf0MFT99o9+Et1nnqt+9y44XRE9hbHjkZ89FwgCpB9/FNW7d2Lxqy8ALrtMb0PDA7QPhibJwiSFRHGUS4pjQFQIftJ+uJ9JPR/9KHbe9QA2fv4b/PdDDymT0JToy9Cys/kzI1eSBI1JMvoBRBm5cnlfzMeqfLGomJGKQ4A7+l7VwJpM9ghABL3yM1l4dfVa/5jvI+jtVf0Zc99dAIDeV18TEcC2X3gpgtpaoL0dWLdOhbCPS8wesZwwp7W9HRDmoViqp16QZSPh56G3yVgUz2v1aLRLvOBGQpRugTYGE6Q2x34u2c8b2SepScoIbZ7jMJIbzZgsokGd8f1vIrttC9IApv7PzWg4YxFw0klo/f0tAIDC63kwmer9e5Fd8wJ/SdA/geOg86zzMTh7LgCgSjBR0medti2DfUmIY5JO5Ek6xnDhhRcqYp/+++UvfwmAL8YvfelLOHjwIPL5PB544AHMmTMnudKXIETyYowZAzgOmOch29WpbTq6wUxiwJaFnNbvMLuZEc0jEgTJBDVFltYN0dUFRzjEySSU5uGriBpH/x3tr95Xhxy2yoSF9L1SM5o+ySRtWCvq4PepeY9PiC+Vx0M8LpcsDkCsJkkRTI5ep5bs0kbAG+Z2NlMqXj9hkqi01N7L2HddL9DG6XV38wuiRQLCA0FqKW3TYTPBAQxzu4sv1p4lmU7G5UqhbSRrjmLMMirQujmMwa+uQffSc5EXeW8yvWH44aCxCay+AfkJeiJampUlKe9ZJeCObkWxdUyCRkq0yaLzQOfVYQy46ioUPvhhbP7sf8LL6r6cpYmT4dXWWecq5TAMzj4JQxeI5L6jRlkZ3ADJ5rCKEPCj8x4nWed1kfpVGfu60DRJR0ZahiCZJKJJKookug0vrEKVhUkKCP5lTU0ojJsA1/d14lhqknZth+f7mP29/8JF3/0WIEz6bESozJM0MPcUbP/wDRj+jy+gb8FpOHRZqB3sXXQ6UkTSPHAON7lLPfQgxv31djjFAvDCC0BPTyw+SQ30Y/6/fQDOz3+uM7VWJikqEInTMpgawLB9olWnfXIclJacibbX/RP8unru8yOsUNLCr3FoqYgfuG8fWJEHHqE4SZtzC26MMHJIhuiYBEgtkuNEcKYJKtl2nCaJIcbcjggjyvRTgfRTmzQlbCSXgytxcUcHfJ+HlB/15KMAgO4rro7QFkE2C+/cMNeajeGk/QqFgvJ+DOE/bx7Px0ZAzk86NpGwrNu+t22aJPOZ/T251vU+x72SZG5nbYfQGKa53ZSf/QBT/+MGLiQ3zwsxVwFjSBULGH3lpVj4iiWYfdNXwTwPcF1khY9e8fVvQOA4SOWHUfME/574wQ8w8L4PYsu/fwlefQP65/FcflXr16q+KlrHC/cond84c7uXIxy3Pkn/f4KIOVI6rYjrXPtBhaDosgygS0iBqFpaAj0YbIgkCAINCcaZ0cUlfdVASPAKrWPBqnl0I2YgRhOpxUmGItIKcqjJMQWwINwy0Cuyedds0DVJjFEfCWL+ow7xKJKObVkySTGaJDk0erjIujTbdHlhMbdTfbCYi8hxMBslUAHw/Erh+vK7evhFHJPkSEIo2hD1aaAQCHM7L51GcM45Wv8TNUmO5TsYa6icJkkn4vS/caaPZr/cJn6YZ3q6ke7r5e82NmmHMh1PqDW0V14pIa/qsTBbGrMNcw70/qcYAzIZFP7fd9D2+n+y7HtDeENAWu52fvR6IJUCTjtN97/SCJP4ejTNhDH+RMk67WUZzbTr+xHfiCMGpUnaj4wgRDou5pqY2k3r0bD2ea0c749o2pDQagS78OvJ9PUit3UzZv70ZsxY/gTSS5YADz0U9UkqlZAe4JqKUmMTdn7oExj85KcAAO2XXAG/uQXutOkYnDEHjJjP9J1zAW/nkYcw5t67wnFtpEksdXwy6Xe/5AzV52/UEvYmM0lRgj8iUDI+iY4L7Wsm5TAE6TQGzxEEuvBZTu3nTFJ+wULuOxYEqBKME22Vau/UnFqsMUIBXjLiVKaUZnnJJDU3R00iDJCEaLzmlIV4VwqrDKjYJ2nrVgDA0FR+BkqcIP0J0d6Bqjtuw9JrL4XjltB3ygLk58yzJ3AV2n+ZkBqwaJIEjjKFV5HqtvBkyLAE5TLpgTihatyZYRN+lUsSzPus1281ASVQybkE2IUGfkuoSWKui+nf+U+M+c3P0bR6ZVT4LcwS91/3KZQaGuF0tCO3Zxe8bA7dN30f+P734WcyKLSOhbdoMdyJPAF5SmiesWQJer7+Lex963sAAP3zuE+j1CTRsypsW6cdpTWHCS9DRdIJJul4AKtPDTGv8ohvCCUWTAlDPHPD/zqMWSUAflB+Y9N64n4DUIft8KSpEcRo9lchPUt/6HsSqEZKHk4+8fiulP7pmzoVgeMg03EY2fbDRPXONGQflYLxC+qrE8eYxvskGUQE4WGSCIzEwA2kfmqaOVLQNEl+gCJlkuThTKR8dM2kHUtnoM9PRJPU0AQAODh7HidsUBnDaz+M+F/1rQzMlqRJYsY6TeoHfc9t4oRFpqcbaalJamrUzOr0gAF6X48UaP0m0FuM6Xsisp+MdR0Vgsjntj7wm4PnnAds3Yrgxz/W29WYeHHfMhZqd28SxomO7JQR1W9ZhS5JfRgRCF+jXPshZPbywAX9py4GJkwA8zw0rlvNy2lMUigYkeN1iR9oymFAdTUK4ycCAMb/4ZZwmIcPA695DRy5vuRAiEbBrW/U2ik1taB7xSocvv8RIJVCijBnvUvPARwHqa1bUb9lQziuDRus2gC/WMTk3/2c/zhwQBFacZqkJELSXK0mfrXhM7MauSakRgwPPAAMDKh+eRMnAkIIVrV3txhPWKOa8xQxt7P0yRYowwZmedWUZJJGx6fTkKCYgKT1LvFuT49qhBapGKUIZmRIaMG5RQJDSeAytvwptL73HUgPDqDn9KV44eZfcdNzy0QErxDa/8ceAysVrf2Ial/sjI4KCmQxTZRNy6h1JtMQZ3kiwRpUwhDI2N/TGb8Qz9jfsZ5L8h0NEUffVUxSdxeyhw/CET5DLcsf0+e+WARW8RyTHVdcjaf//DD67rwHO/73djz1t6cx8LZ3AR/+MJ5/aBVW/PF+sEwG7tRp4fuTJgGjR2u0WP+8+QCAmlXPINPTpfkkUQFnRMBmgRPmdifg7wJWx3aTKPZ9tHzm31D/H58GwJFMRJMUs0A9gkRsBA/VmtD+2MpRsDZ3550AgO4zlpHgBIy8E0SQmkmcxUa3I8guNLeLPi8HXi6nzFvqN63TmDLqsCiRk+x/RLKEmLkKAmCfMLuZNEl7ZDKANmmmTuCLgtJPrf0geWJneGm9phYvCTTiyAjcoIiymKANKuhFpD/xTNLQVdfgwKWvxjNveEukDxVpkhKkdBFNkkWrEgcBYta2Aa4gXKhPEhqbNMmlVZNUpu5y6zgpQpRJYGqmm4aJppxH27rW+xntkGbyOH06guowT1ds9y0P4nAAoEsrozySxtFqdZnmLp5PiZWjZJNaW+FXV4MFAapXc2KlOG4C8M1von/JWehZfCbyb3wzIKXs0Ik4Om+mL0p++kwAwPg//wEAsOnSKxC0tgL9/XC28XC+apqE0KJU34AgzUPx0uPAHTsObvNoVb8ctlvfAJwZBnpQsH69lUlxbr0VVYdC36vqbZzI9j1fmQJafZIs2vB4IRvT/lINrAlyrqRGDI8/rkzI3No6BPWNhEnaFXmfni02/5io6VbyZjXLR5ikMv5IAAncECOdZwwh3i2VePCFIwXJJE2bGdYNoCQjU/7612C+j+7TlmLtr/+Mwtjx2nlLIbVwAdDaCgwOIvXMM/ymKSQz1kPseSTPl8bGSDsSN8T7JPG/seZ2Fs1NnKaSgskoEKWKFSi9oixdEpgx7bwVTFKqkEfd9i3qfsvyx/W98MILQD4PNDdjaOpMFMZNgH/xJRi+4EIUxo5Xa6kwfjyKrWPAAJQokyQ0dXQO+05djPysuUj39mDO12/U6ERJYzos9JFynPh5e/mxSCeYpOMCqM26AsO8avL//hwN//Mj1N58EzKd7QCCqCYphruh6mqbT5IfmOZ29nqSCGAAwOAgILJkH77sqogdMn+HSt9EvSZitTiyAuSwRUggaxqfEciJg/lcelK7Y6s2bwoR+9F+yvrL+iQdPswRGWNRJkmaZygGMhyTDdlHNEmdHSpyVdgHUr9tLSGe6ND6RiWufqAx4YHwf7AxSZwIszMASZGHvImT8MK3foS2eWEI40qI2Yo0ScbrZnWOhYizOa6bQN8rEU1Spk9qkpo0psM2nniGtbIjJol8M33bIswF6YccS5zUPMmMxSQKNeaMhR5YfgyBZdbj+xZNM2044VA2CR7z+7m+X5GjdkXAmDJfkSaWxTHjgH/6J2z54z149jd3oucnv+ABTmQfyb6m+MUUBkkmSZrR7T19CQLhP+mIcNtqj4ocPG5DSFSaOJx+P42pveQSVW5gIY/UiA1EqwRwX5/bbkP629/kYxDvV20VuZHa23nQBMY0bbkN/8gzJxrdTv9ulICOwwNy/oZmzgHGj+d49o9/BADkx47ndQgtXq4t3tzOcWI0DNDPnnJ4MzDLy9ZGwCTZhYLGSq2tBYT5OoRpoU1bWxZMcztxWzFJ67hfSvvFlyOVzai6bX42qXQKEL6kqYe42WNc4IaIUNCsTmqSLEyS0iQJ6aFJ51jpJwLM+p3FM/sr+nvSTaAMY0XpFVOAraEyus5ll+rrEGR5ovX6jWtV2Ya1z8EXeAaAFibdV77SLBo0gpyHroVJCtNyAEEmgz3f/j4Cx8H4u25F7m/3EH+sEG9SOiiWSTqhSToBfw8IDwRyU4UBP4TqPbsw66avqkdVhw5YNUmxgRv8EInYopLYCBRrPTFqbgX33AMMD6M0bQb6582PRLQBABmcA0iyMUbkPfo7CMK2qSnNSCiggDhg0/mXTepEhiQm+TOPMg+2ynfv5n/HjwcE4jPHZov2Y86LNqTRo+GLvCvZjsMR9bfqT6U24BaIMMF0Tdg0SQrRkqAEMWuE99f8npY+VNBRa6hVo/fl2oqLziMqi2VXaD2umItMb7fSJAVNTbpZKDnAw2hFMc0qqWMyxEY9QrKpEmP6PelXRNd8slSd9oH/pfnKaLs6AScP2mg9tu8g303ySbIRPo6FeQZ0gcfRKpIAoDRJD8pREkxCnEZOY1aUuZ2vRR0FgLyQ7gOAn86g/aSTVWJxZy8PLa6qFkxSqbE5fIcGWjHM+ULmLFCErZ9Koe3D1/MXNmyAXB3pnTuA004DXv96OGvWwMvmcOhqHgWxautm3p+DwtRu7FjuQxsZqwWHGWCud0buxzG1oRYZahz47ncBAIVx3FwRIhF9prNDa0fOC8AjkVk1DIawpSw2MsqrT9DB266ESTL9oGh9gJgDxnhQA0AxtJUJXgiUSspneIisNQAoNev97Fp2vjJv84PomubaBKa+gfPYo7wfMWe5LeWFBpbzJaxDfLNUnDCH/40TrNF1BfM6AR9EQoCXwc+az6E6OytkzBhTppkN68NQ3Y7nIfvkE2E5ySSddZaxvyH6Gm3PFQnQAQAiknRIa/AXBxadjoPv/hAAoP4/PhPiMi1HWkhTxAmkX34s0gkm6bgAqx+JYJKqDrXh5BuvQ4qo2HMiqhK1r+b1xNXP/zpOvLmdbkJmryhiLmEWuPVWAMDAVdcAjCmkT9sMyHtayG16wFuYBVpPEISmcEFQmeo8AjLfyYF9mlmdIsCDkFJWEhRFnIfVWOdKMkmWEM2m1MsmzdSCChAxqzuWH/659tAvSbwd6Y96bSTatQQGhfUIaRZlkjxJcBBNUqRO/rfSxLaV8LvRg8imSTKIatjXEn3HRtiboCUVFtLXTG+P8kkC0SSZQRRiCYQRQpwG1gSTkTaZl5D5p8RWCFSKGO2DzqjRvpgS7iQGxervJFpMim5HoRzxwjVJet1HA+7EkEny02l4o1oB2M0gzeTO1GRICrnkvcKMkHDtWXQ6vKoqJcxhe3aHbfoBYZKawvtauxTXkPxGAYDzz8fQR/4VWz79FQycKRKz790LRyREzq5fyytoaIB79jnY/Jmvou9MHlo7t2UT77PF1A6Iat+tD42foSlWKFyIWzOaFvmGGzgTIpIZ58eN519XBMvhFhc6A6FpbSz7yDybyoYAN8pHAjdUYm6n8GhIjtFhqzPgFKFxN7V+lcKuXYDnIaipQUEkxJZ1S00SALgtozAw5yRtrZqMnCSucSqPjMZ27VLv+xbhVURbaE5roiYpPGfk70qsJxRYGN7wnInHB6bFgrlebaAENQZetG6HQF+bgUjaXb+RM0mBmOPqxx7mBXp7gcce49fLlhm+jiKZrGf0FQyuyFcJINQkibNTBVwKgLb3/yu/t3ULUoMD+rhYqD2KSyXD63n5sUknmKTjAHxD+g9AHT4tTz2K5pXL4VVXo7iQSwGqDrVx8yzxXjZlV0NLUCYGLC66nZkglf/tz5e0XDly/ddu2Yh0X6++IYaGuCYJwIDIzm3TJPkG0aDqJv0ph/RoeO4jdcoOSFJIeiDTg8FEpLK7VINnnXKZid7CJEVstIk0sxxDUZJM0uGDyO7bi4zIMm8/MGzfucyBn/CYycg4Nk0Si2cAkky2kszbkohiKo1XfTfqjAZqiLZu9kONIUEuq2uSaOAGfsgHTU3aoUzNTco5gycxE3of4udNZ1aiFVGiQAoEUsY+7M+7KLrh3MaFAAcIk0RmjCYepF20DYsRYUp4T2/D9m74rcrvGy1y3tHzSHCJJqk4eiyYGAA1QSy6PvrzpYi5qVq7Xkh4KiZpesgkdS49l/dV4ClpbqfGY2GSPFOTRM4VzY/PcTDwn/+FfW95F/zGJq7xBpDbwrVEaYFXcPnlGLz/YbRd+1aeXwlAdjNnkpyDMUySBf9QLUvvUIn4a+hMON1/cY71mhBrwQLg+eeBszkD1z9vPm9LaPYyHe2ywnBeiGDRFo5arqVKze0ikdfkgwoCNxRcD4f78uqM1QM3WBbqySfzv4RJGomlgIogN3u2elG2QpmkgXPOBxxHI6Dl0qrJpvW+SnPytjaVs0pjRtTelH9jNmCCJknWIdNMmG3ERsMVYDtnKklAb2qrKzHZlXPmmcyKRThFcRdjUGulej/XGg9dxM1iax+4F/jtb7l2d98+PkdLl2qm+yl1tujMGRjgzp0Lt7YOxclTgGnTeP8Ml4YgCFBqbkFBCHxywiyTgmwjjo7U2n0ZwQkm6TgAa/x9cfg4AvFsu+6zKJzJM1HnhCOtJBJDtbh9hdLoOfbDS9ckBUGAwYKLFTu6sGZfr9bP+vUvYNnrXoFTPvVhndi7/XbOKE2fjuFTF/G+a4hB1s1rAnSkpmmyDL+dsI4ocUx9nEYClEmymYT5PiHwlUZMlyzx8VhaT9AkRRhAMi9yHdj8ZQDAHcuJmdrtWzD9svMx+cpXRPyT4gI3yDaSINF3xHKIUUl43GFdLvKQCZVI/G0OvHG27xLifBvK9cME+poM3JAq5MMAK01NWjAOysCHXTi6k0RWYze3C4yy0f0uwbZGCh7wzK4urNnXE9HOafWKe5IQN8tSpjl8FkPExNzXNUn276kHBrFWA9cL7Dj2CMGdPEVdF8aMVZVSfLp2fw9W7OjCQMEl/dM11a5BqBQnT4Gf5ia1nUvPBUOIp0A0SQEQ+iRpmiSQa50Ji5gC0mUiiO+M0BJl9nEiDVOnqnkbnskD3aQPtCHV34d0jCbJbrbNG+8YKGDlri5sOcR9riJrxoILI5okM1fO5MnAo49i18NPY99b3sXbEpqktGSSCEhTaRq4wZw3oHJtrYRI+Qo0Sc/v6cGafb1KIJGOCVSiriWTtH59+GwkC1owSYFIXEzfLzWF/ew790LeH0fmvguDjNTlBJMkBzxuHJBK8ZyOUnNnaDSjI7LgrhFokvg98lyZhMXhF9kX0i9rr3QIUzYY7yS8FA2drXoRuYrQDqP1tTL45n9GwBiyO3cAb30rN5WcOhW47z4E9fUaQ2/uC23/1Ddi+R2PYvvdDylVoDmngbg3KPZ5ZrOuraQCZKKEjYz7ZcgjnWCSjgewSkLJ4dN9+jLsfcu/wJsoTPAOtnHpjkAOGRlZLLBrk2w28UAomYma2wH5EmfOhoqudr9p9UqwIMCoJx8BhLM6gkDZheOd74Q8J21O4lQqpZnhybObEFWRwA3mQQ+pSZLjG8GJIRiYbG+3Mtdg0CWupoYq9EmyHQIEEpgk05TQJs2MMzOS5nYTb/0N0j3dSB86iExPtyG50w95OiPlEJjVsVVUkJLOo4RJoj4VcUxNUuShXIavv5JGWJWX8KlQ7AmhVs0AJUmaJdWWhZGPAjmoa+sQCD+xmj07+c3GJl3LQV6rXOqbvI4To9vJ+Tb8jWS99HdYJtTmFPi2x2DRS9QCptR+Npgyk+BFjBDIMp6wl3obtj4wOsnqnr0FupePBZdEfZIKY8YR7WVIdA+KiRykTJJBzEQc9jNZbP70l7HzPR9Fz8LTNSaJSZwC8d1ldDvqk2TgxdCCABrjDhj7RZhxZYUmKbNPaK2mTFH7129sAiZyn5+67VtUIl15D9DXgk0YJ+diWJwt5rlXiYmbNZF0Oo3CvJPDBU01ScQigJtpi3ocu/bb7FM5czsTv1Vqbuf7AQbyfD4aazKY2FyN2lzaWlaBNLfbuFFpbUYEQjsQzKJMksClTeE66j2bh1enPkByXKPrchjXWIXpo2t54VQqdA0Qfmr000gtWZoQ2IAFB1YQuCEuOXo5c3sLqigruAEs5/0IBHhmdLs4CPchi2gd3QWLsO26z2JwyTLgnHOA972Pa06XLNHWPxW+uEa7DHxeCuMnwm0J6ze1b1KgNzhLaIwFLpDAwNBQlcH4pirMGF0XawYbmxLlJQwnmKTjAKzEyOjRcCdPgVtbhw1f/n+A48ATUZVyB9tAE8BmiBrahtTjkslmCBKka5uG/KRhoIMgQPVuTgw6rov6lTypGZYvB555hkd0+sAH7OaDhBmgCMpkfMzNT0H+0n1RgsjziqChAV5DAwAg27ZP9EdXl5taEFsy2USfpClTIo9McxQqzbQlXaUIuSQ0SdWivwCQ6e3S6o+GXK18Vmz4rSqT4v21MEmU4Ys7/JIiD8m6iz4j5UX/E/qZdqLfwdRAme1Fk8lGW7CaPsaYgsk6ZejWtLThbm7UCCzarzDim31clUutQ4GDCVb/RtJ3etcWGEEyrK7nJ9rgR7LRG/OvmbioNWkfTzTUP7P0zw5J0RMVbqGBG44Bl+RRJql1LGHMZZ9CfyOpJVC+HASHmCYvjAH73/xObL/us2HnpaClsxPp/CAAMafS3I5GtzNMpinBT9eMniyZKQ1FdhOPXEc1SZpmRZSr3b4FaZFI1xb+W5UPW+B9lSZIok7z3KMEZtxeiAsDrRHKQpPkFAtIDQ6ouuj8pMoQ3JVrvvXyqq4yTJJkFFMphiXTWnDS+AbtuY5nxMX06fyMzee5fxGMfVYOhCbJJ5okCUPTZ8JPp+EvXIjCJH5u0Yh9KuBFimH+xEaMa6wKXxYmd5JJogI/l7yn9Zc2HgQhk5QQuCHFmDX4jbyOy91jw5cjCgEeSMFCJe+I+hPesa07ABEmyZ88Cbvf/RFs+9NfgSeeAH78Y5Uvy9xrFPfQuuPOf/m+0haCz8+A1CRt2aiVdxzOpJ4ygX/7uPP05ccinWCSjgsICTKy8BwHhx56Ak/d8ySGRbhOf4JARsLcTpoOZNPhZ7RFuKPSLkr0SeaKqtNlebnJab4gPwBqdu1Q5RqeeJRffOc7/O8//zMwZozVp4hKWSniMPdwMtET3fBHE7mqKBywc8IGmJF+ekQCaTMHkRCQuVIQo0miksykaD+xmiQRtYlCpqc7xicJWv1mGzaweeJIRkaGO9aSyWqBG+x1JEUeqhZ1u35Uwp1Ey9pCgJsaqCQzs3L3zDDaFEziKSDzAQCssVnTclAm0aYJ1eqq4BDW+2mpoxyTadmTtE4pEwkCzijJvptQjhjQ5kA1HUfE2LuaFLghrD7+W0lNuRYC/Oh5JLjjJyinaq5J4qDnWOP3ZEJmk/Gjmh7FJBntMAYuWRfCnGolqQ9izO3CuaDR7RyHaXPp+UbiXskkbU5gkhxGmKTNSB+KmtvFa5IEAy7mQmmnDAYjbWGS4iXWutRaW/c1NUBdHR9TZ7saq2fgWGuOLnJW0nrjQD6OlC8T3U4ySRIHmqDhL3mdSkUi3FHhY1kwmCQ6t6UxY/HUX55C/t77SQTA8MxWAjHbBpJM0mG+JuicSRwiaQ1Jf2hzPjAQSghtmiSLRlQ782LM8yXY8DroeomBSJqDCqa4ksANZt5I9ZwwSe6YsXBEyHfbeUEDadAQ4K4hiNDOf7JGTNwjrYmkJimzUWeSbLib0pIjNU99KcEJJuk4gNgoUqNHo9ga5qDwhGlD7tABwdjw+5T5SZIuO46O5OJCfJrJ40oqmxpQs3u7ut/41GPcTva22/iNj39cb48elKRuXRWsS2vMzU8hDqElhRhOAmk2k9sfapJ0aaY+joqcFfv6QidUg0myMYA2wjmuHemTRIGb21EGN/7AKIu/pESOEFTyEKfR2yTogRuiEj69P9HmsunQOdg0wRmJSQN9T4KOwC0I3sIgUDCJH1WWXjMGv6VFe47mJl0jZWnzaA+SJGYrqv0k70GfVzq2MBhGWF5qQWzfwpQIm+YrlIlR3Yz5pKZppPylm9vaX04SqmSsQViOHlgmg8IYvhe5JkniB/68QOxH5bWca0rkmz5JsfhO4BGpQdY0SVoI8PBdzyc+SUyPakq1TAxQEcrS+/Yid7AN6e6usF1aTph71W3dhEwZTZLFiCAMF0+EbgDBr2oNEsbX+GJaws6kjSRM7rKdHRFNkpm01UI7h+dpOawpx0DL+74yh4xlkoplmKS4hWpEuKt4PQ8PAzKM/KwokwQA+YlTEDQ1h1oGYo4fGN9Kg0m68JbOp9QeSlrDek7I8zKTCXNBEfDJ5lUBCrTnyQIQezJZJL5Dn5nBEJLeCQMomHUlHDISRhEmaeLkWK0pvafwSkTrFfbVLtwVjLDcC4Huk5TasxvO0CDpf7T7WhAgEgDi5QYnmKTjAOL8NkypjT+OH8ypQh6p7m5l0pEmUjFb0jeVnJUxbbPSkJr0gDWZJimd8PN5zdSrdstG7lDo+8Cll6rD1qYZ0zRJhKAKmSfZdqCemRCHnGxmapVASWiSqtr2wRkaRG7NC4kmH3HVa0hMRqFqbgbq62PLhT5JIdEkIY6At2qSZNQ5AeZhRt8vh7/CwzF8KZtmSLFAJbi0JZNNp5hdWgfK9NpnT2qq8opJSj7wgJjADeKvNYqSpS6dgTcJezqPpBoW7VdgMkmNjSrQhxY6V1vr9g9RVgtk9N1WSyRwh6ZRM3yStGtBoJJKCwmaJDpG+lcVJQfzSJIwmuUkQRvRJFnWW5wmSQvCcgxUSYwx9M1fBAAiH5zefpH4i8hrWYbi9JKrhwA3e6aKGkySHwQISHQ7G9McBLoEnvqdaUwjY3xPi6S1rQ/fyx80NgKNjbom+MwzAQAtyx9Dpv0wf6AxSeF3ZjE4jJeTfdQFKDYzWvNdxwnHYU8mLV4QJncymAAtL7+BnXgU7cQQuyaY5nm+D070S4ReTpOUtTNJFLQ5oMEbtm9H1Z5dkTFY4Y47+N8JE6x9MiPQAjQ8NPFvs1GMIpdX1cH92vsANBpFHwvpMPVHsuxPG7OvW0/wv7EmkgnfOQnbUtM+M51D7DtqHeiMldYdxZcY1ipUkzR5MtnX0TpoxGLeV/GexX/KFmnUpi0MwPNlBa08wl3tjjDCnfX4tpwfLz8W6QSTdFxAnN9GxNysKge/VSD/A/s1J9QkqQOV+FOCRJrp2aLb2ZgktnMHmO/DralF/7z5/OHy5UBVFfC971naI30nFCh15Dbtfu3Zx+V8HD2BQ6EkolRVt+3DSV+4AZNfeR7qHn0IgJFbxUZ4E9BmPClog28nIkzQ5y38QTVJ+VMXAgAyPV1Wczv52kgSDsrnNF9H2nFQNTQIJhsh5hAUUYeI36jTwmxQkJLUoZIePjbpS9MwylHQmU/zOrxneZNoeuK0k6YZn/RJAgC3rp5HehK/gyAcEGPH7iBJdCovM9/0ts2czSX+YdKcMonJNM7kiLkjZTjjvmlcXwFC0EaehN8qrh7K7CscdoxQyLqv34wVf30KAyfNj+CHAlHHyWuqLZHlC0bo5wgjKC9I4mtAzDVhkmwRtTyNsJX1R9eNakPkT2l9SDBJwp9S0wQvXIjht/xziAvSaWuI6+g49BuhT5IsH84NYGqSomCNMmoGB1GapHa1Nk0TIy0FhZLA62UqTZtA/XeUP1J9fSSZuIQj1iRJJumuu4B583D6Gy4FKxaScUoQhCbx73sfAsNvUCsKwpQ44R5LjFI6SfpKH1B1SIhqksIuKZCaJIupHaC37ah5tjyPoWYpUyJhJP5FZl6mxHcMBr7SqJoMDKw13Eve5Cn2ICUCzETU8sz2zXYZnXMdP9D3uMZf7Euxxuq2b9F6GO1zCJWGzH8pwgkm6TiAOKGGTfruC4SUPdimpDQO0STZQrBSzQ6tkuZBoAesHwD+UB6nfvzdmPTbnylzO0dExxmaNhOdZ50fVvTlLwNz55L2oghVXpmqe5O4LisVOoZQEj5edVs3Yux9dwMAqp9+EoA9gESsJotihkrCfyf4WgDxDut+YxO2Xv85bP/IJzF89rkAbD5Jep9HAvLdDCEuM2kHVYPc1C6oruaOwwIo0RHnQFxOgi8lqfmir72fxESmLERhxNyOMpqWOpIk3UBUM2UrxwAEhEkq1TdozFAk1xY5dG1QydhpP2wEnKqb6WXlLX3cUUbSteCPJCYzzCEi29D3SmBqLSyQFK49bRD4JiSZwFBfOSWgsNYyMmAA/OoaDE2bSe6Ec0JzTCmTRdKw0lYLAjJlOLVHwGSSvECLbqckzkZAGRMXUKIrsnYEk9T8zJNam+a3G/z6t1CQJuDjx2uUadxej9Mkmaa4KkIXyc1n++5azicDVHHJJHV1aP619H1as6zKFOok0Xx6omDyfgXhv8tpkmJxgDS36+kBXBeZvl5LcnEDaGClD34wZBYsOJJqjTT6wJg7DSSTpMztwlmT31IFbrAJihKCNsj2AV3Iawaaks9tYGPMKiHmqc8aLZ6EQyLBHhLwExfGkXqFBgcA/MlTEoVhpjCUMmd6YBZEaCzarxQN3iW33UlhgBazDgo2i5eKfONeYnCCSToOIM7xMOoPwRAIv6TsgTZNLW4zuZCgENz2rUgfDhFqRrM51qUsuUcfwtj778Hcr30O7El+cDrbtwEA8tOm4/ArX8ULn3MOcN11+ngsiMGaXJJRRGTMhWVllqP7R8oXuCKKT93WTXBKRQBAVuQKKREthay2Ip+khMh2NgZmJP4yjAG73/0R7Pzg9fBE8r9Mb7f2rs0sIiRYrd0n4xDriURLzDgMuQHOJPmGpI8eplYzCpRn2qQkVfkkVSB5U86xNkmyYg6SmSC7Jimsy8awcNMF/R1qbufWN2plApA5ZwYhdRQQSjijzxJ9kpg+r5TgCbUR0TqtTKbJFMcQA3wOkr9pkn+YYyFoabk4Ey9ZrxxjyYsyK0cLEUJFEfmUSIzidpPQrFSTlGsTPiXt7WDCjK/U1Ew0RKRvhk8S7YNu8ixeWLyYl3FLWpvUZA8AWEszNn7+mzxwxRlnGPOhz0McRPxPJRNnkUbbajKZTPMdAKG5XUd76JNkaEhsJmZmn5L2qq7FJD0dCZMUo0mioE3njBmcOc1mlf8O97tK6OhNN/G/IrCSTbNL2/At50ASsS+ZpOyhA4Dva+tQagUz4kCy0ikJ4b9pWebYmddw3Vlft9IeoRAsfq2GfU0266WQZNFj1suLEBxC1os/ZUpo7mcRXJmBNKj1hxn4xCZ8MXGD1l8ZoGVbGAbcGg2W3IrzxXo5wAkm6TiASn2SAMCXTNLBNu0AtknXw/oDVO/djdolp2PMa1+lMJ5kkmg0Jtmf9K6dAAAWBGj48PuB4WGktnFNUn76LPQtPB1P/+UJ4IEHeNQd2p6F6aOSZZu5hxkWNilEcxyMOHDD5MmRexmRUZ5KM0ekSZI+SQnmdlr+F0t9mqYJ0TkEAF9EVTMDNyRlvC8HyoqGtJ9yGHIisp3f0KSVp9Gzwu+o12kSWSZUi1xJkmiII7YpJIcAR6S9ShlRG5+XZArGWPgdAMBt0DVJXAIZJeLjzpHKE57GE3BJh7/J5Dkx15H3Eg7ISHhco/0giJrimZAUxY6Gx9bah94+vWd7P1wrR88lmUIHZty3gcYkmXg+ZvJVMSFwybVxnw8mcHN+7HgE2Zz6dmaEUtMMSfkk2QIjCE2SAqlJMs6mlMPQcdGleO7+FcCvf629Emc2HtUkBbF1VwJJZ50aD9EkSUjUJBl/rZHvEkCT+peJbFd0fcXgxUe3i4F0mufK2bEDmM9N3rOdHfHy+9WrgT/9iV8bwkwbBAiJ8rTle1ij2wmNouO63LyRzFnJ1CTJdmiHLYnKKVD6yOYrVs5awdR6U0hacdS/iL6Z/I7e5/Ad+5mudammBm51Db8/Zapm7meCaZVCP5UXWPa30Rb1JwZ0nCCZpIYNa8BcnsvLkYGbYsZ0InDDCfi7QqxPkiVHSzAhNLcL7UqTfZL8IMDYv90Bls8js3kTqg5ws420mb1clvcDpEQeBgDIbN8G/Md/KCapMI2HJB+YOov7I0XaE/23aEwiUkyD4DClfeb4k2CkUmK/tRVeNqfdS+3YDlYs6HbxTB+DCVZNkoVJsn1nm2kKM36ra/LEl5qknm69DQDMdTH23/4V+PzntffKapKgI05AmNsd4MSZS5y0AXv2erMJkxAyQZqbDBs+SUlgDdyg1pQ8NMowooaGyISQudE+QHSNUZ+k+saICQ8lpJMOvZFAJYdnyPgZ64v8toVpTmpPv0eYoCCqeaNauXIfNUmaGxK0MXtP/LVp+ajwqHSMfZIo2NacCXQOI5qkMoygSnx96ABYqaSYpOFJU7V2NZ8DP0DEuZsQ8hHNwKRJ8MhaDs3t9I8nxzo8eRpQW6s9UxYECWuO91OW17+JjQC3TWlSdEtVXgVusDBJFqGXqRGtxH/QFpG0EnM7ietyGSc2oI2GdsxJGDuWJ/G1BKdAEADvfz/w3vcC7e3AO9/JuZ5rr1VMVRBXL3Ri2XYGW9d4Os0ZJYSJ7nlXAjgHD2Hxe9+M3Hf/H+D74TlBJ7ZCTZLD7N/FmpeRgO38q4SYt9EsQGXCEDOZrP49bX3ksP26z2DvW94Ff/78RLPSSCoRxqz7gmlnFhWihLQj7ScAsGXLEIwejVz7IbQ+9Deke3sw8ZwzgI9+FBgaImONjvvlxyKdYJKOC6AHPQVb+GF/kggDfrAtlPjs2oGskDKaqlmZm2fMvXepe42rVwGgeZKifUqLpLHtF17Kb3znO0g/x98rzJil1R8Zj4UZCNXkuo+CaXebhPDK0TcjpX+Yk0J+PJ/PwWkz4Tc0gnkeanbtUBIw2U86BhPUYXngAPDss/xaOtgSMB2pbX2mmgjbc1VXMz+AzcANnh+g9YF70PibXwJf+hJPOkgJ1gQIJYjU3M5B1d5dAIDilGnGePhfmpjRJNzLhWetSqdUvwuuF/FtsYEtV0qcJoO3bVlLFnPEkLAHIZZIuUhdeghw7pOkJ+7Uo9vRBqKQaNJCIMlWPTD6HTmcY4j1RE2SzWnXIDCjzBl5rr6NvRHNNNQoE2uKZjAGXLhg4E8nSlAfCx4pygSI9pKYJEM7SyEMTmGvF2PHAtXVYL6Pqra9cHZKJmmKVk730SPmdqI9SnRFcAFjKJ26IPytAjfoY6N43ISkxNEUQtM2UbeUhjvMIhiMVmbPk2YADdwgBXCWkOtxGtGklBoS6KMwBDhCJskS1AIoH7QBSMZ/CixjxMaNwE9+Avz0pzxi4QsvcGbt+98P+x1E94JsT0u4y1gEf8QxddQvSc6l6wcYf+f/YdRTjyD97/8OvPrVSHfzudFwV5nADdQ6wuaTlJRmQvYb0NdsJbiWaqCS8rHp78TjZhuYS3j/296DzZ/7GpyUk6jNtAXHCk2LDcEG5DhIu0bgB20MtTXw3vs+AMCUW36COd/4PNIH2oD77jOltuE7qhHLIF/icIJJOg6A2txSsC1gX+T2kYEbarduRN0Zi3HSay8Fc92I1MEPgOo9u9Cwca261/iCZJLsm90PAmR27wIA7H3Lu9DzhjcDvg9HSBFKM2aSsrb3+V+bX4iUPAOC6BTPA/VuPMIr79A+MhKIMSAvwoAfvvQqlObyRH112zfH+PbEzZe4+MEPgFKJ+2nZmCSLliwqPTYk4jESKK9F+iT1GH0JMOXX/xPeuPVWa59NoIiYrot0iiG3dzcAID95qvaOHrhB1qPXmxgVCfzQlbmQ80Xf6lRsgi1XinnolZPc2fsTMjc2aav1+9PcFg2NgpEKH9N+xTGS0V4kr+MkfwlToxOpWzvYmPU68o7llKDlE/MQVSCBTcUcvECCKZqsPqF+zSfJ15O6HkuQVSYxB3E+SZTwjDKC8mVHJRGt274FKcUkTRXlogSuF4Qm1GH/BAHn24lEV0TMBBD6JJkme5a2JNjwvm1c8gww/SJo/bb3JFg1SSZ1RgM3iGe24AO2vtF+JO1V+kgrX6EmKSn8d8KWCEFqkro6wn22fHn4fFDkubn5ZlUWsJu/ymuJT+W6jMMXEVC5ktpU/SXPR8vTj4dl/vpXNH/+s9F3ywRuoOvYZm5XzlrBLEchCddSX79KBVhUgAfYhQm0CnXuWnCXvl8Nus6ylq2aJFJ3YLwL6AJRIByf+4EPwk9n0PT8M5hw+x8QMAb84hdaHivNKqECX6yXKpxgko4DiPNJimxIBgRSk3SgDamOwzj5sx/nZnSHD6Jm1zbdthR80UotUiAikzWu0TVJkf74IZM0PHkq9t34n4DI0VNsatGc1ZMTnRmdR9RHwdxcSVF0ypE3R0L+7Hzfx3Dg6jdgz9vfi9K8kwBwh0WbRiMWQQbgyfp+9CP+O8b225Ty8zqjTFEldJzUYGR6ujXsX7XqWTStfjYseOutsQyMrW+A7rCbdphaC4lMUgzhLpdjkr9BLsULKb8klCE4yeFtEmvye40kBLitKdu3MssyBvijaOAG3SeJ9k8L6HCU50hSPWa+IrO/9Hc5vy31nuUefTdAlDmjWrly463EETquSBxhDvB+m0E+jgWLZGPG4vpA+yLBRtjY6tXg5DDilCPN7SZPjWW+afAIUwtEmVoKpQVck+Rns4rJMAnQZAY9JLAp2MbFo2nFS8Pj3qNlKjG3y/T3AcN50aaFSTJMsQIDXyVrkqJzXJG5XUWaJHIdty60MOeiL08/zf++//3cPOpLXwLe/Ga935azTYLNjEtCrBYJCDVJB0Jzu9LgMJpWreA/vvQl/vz5VVofACSa21F6hocAF2OgZcpYK9jw5Ug0SZrfYxkEYtIzdnO78Ie5vOQ3STE9XYspk7AJH8MIpboVjLnGqSDdPJeVf+DECTh05TXq/sAHPgycfbbeV7pvE/DCSx1OMEnHAcRFf7I6SU6ajMLoMUjlh3HWK5eicf0L6lH9pvURpsXzA4y9nzNJ7OMf5+U2rEW6lLfXD8A5dAhOfhgBY8iPn4RCQyPw4x8jcBz0nL5Ue4821ztcguv5MRuY/9Xs4aFrILoGi+jLlyLvSjjWQmAGoGfJ2Vj/te+j1DwKrmSSYkJfRgJrUIT461/zw3HaNOA1r7G2Z/oI2NpgMBgz7ToEv6mZ1+WWwAYG1P1RP/0hAGD4kkt5xStWKJ8iG/4aKLgouJ62bjJiXDxJLENaMEmDkwwmiRAd6jtGotuVJ05F7AYMl7yKkaxJKJmHkc6IRt9PWl8BMQo1TR8jrzUb0e2YXTZpMk9BwM0LBwqupXQyJGmkkqPbUYLH1JLFt2efK3qA6wEqRAkAUmuQ3EZcyHv6LGKKZsyBfc6Zsrk/1nmSbJBEQ9oiCZr3o+bW5IcI/Vy7fQtSkkmaqJvbUVNr02yKtqVLmsNGSsvOhp/OYGj+QqU6Ms+muLXXO1xC95Add8dF17LF0qgkeENyCHDxflMTgkyG3xN+Sa5NAEf3vIUYTjJRNrXEme5ONN57N7BFnB9Hk0i2knWqmKTQ70ppkq64AkPf+n/If+ozsYvepq2iwXgA+xluBZlQ9tCBcB6fehKpQh7FMWMVo5basxsIAuRdD+39Bb4WEwI3mH5fNia9nLWCHrxAnBcV2IVZffjKavn5X2XhIPsQ07cQfzHZAK/H0ec74jduEaxLX2LXiMwbMokBBgsuDvcXRJ8sQkB1fjLsfueH4KczGJw+C/2f+4JlrHY8ZjMP7Bkq4nBfHof78ugZKkaeH89wgkk6DiBuk1sPm2wWq3/0WwxNmYb0MDd/C0S29LpN63SJg+si9ZlPo2H9Gh6y9frr4Y8ZA8ctoXHT+niiRfgj5cdNQJDNchvXq6/GgZVrsO7r3+f+FcZh2T1YxMqdXdh0sN+q/qaO/dR2Xd7f3zOM53Z340APl/rZAzdEnbP15/HPKinvCnM7nUmKPyQ0qdHPfsZvfvSjkWh/EuK+s66titqBW/tbU6M0g6lunlgSa9ag8Z47AAB9N34JOO88AECr1CQayCtf8rBiRydW7+nRjgypScqmHGBwECkRNn5woh7WXAZuoCHATfxYzvwLALKSSSp6ZQ8VCSahZB565Q5327wqRi9ILqd+A2C5LNwa7sBeami0lqPlJfgB8NzuHjyzs1Pl0qnUpKMynyR7JbZEmknlk/qj+W0oIkJ/R48+Z68oKZCJZHLiEkXazBlpvaZ0tZxJzpGArDKJwKfN0sAoWqTLhHmQmqT6TeuQ2s8D74SapDKEm/HNpbmb2aY/ZSqW3/0Etv7qj+E9Y//a6ugdLmHlzi7s6uDmXaaBgl2TZDe30yN/2sdljW5pFmIM7iied8YR+MsWXTTOOV+tkwqENnLtLfzIOzHr/W8H1qzhD0jeGwr5EYT/BhIIcxK4IQjANTIbNgAA3CVnYsXOLqzc1RV9L2FMpnZP0/IlrTNpbte2V1WfevhhAEDfORdw803G4AwNIdvZgd6hEl7Y24Mth/qTNUnaNyHfy1Imlkkit02NYSXCIW79YiC4GFChsBP85bQqjH7IZ9I6Q0WktAi/ZTmzvxqTxMI6S16AFTs7sbGNR6qj+TXD8nKfAwNzT8byu5/Ayv+9B6ipiY4j5mw0j6XuwSKe3dWNNft6sWZfL3YIPPFSgRNM0osMRddXEsBsWv8cpk2wPBD7TzoVK/7vPux563ux68OfAPvMZwAA9RvXhQdHoQC88pXIfOubAIA9H/g4MGYM2LJlAIDpW9fEMh1pI3qS3HSlqdPg19RqUnG5IaR0rG+4ZFV/K00SRR6EsOkd5lLIqkwKLXVZTGgKbV8pJDNJIyWA9PLeSVyTVLNnJ1ixqPWbl7YTcIHvA2uFz9erXx3bWpyzpCnRqyRwA3MclSsp1d3FfaHe9S4wz8PhS14Ff8ECHtEIQOvf7rTW0ZcvIQiAvOtrSLipOoPxTVWY3loLCP+HUkMTSvUNqowMCALR37iDPDEJoQBJM7q+H6tVjb6jH0YRTZLWXrQ2/XBg4l3KyNvK2QmWktDqeY2SSYruK5OYDYIA+ZIH3wcKroeRQFIkoejhr6+lmmwak1qqMbO1Tq8zwfcunvgImTWTmFYMp1beWk3ieh/XWIWxDVURfCC/A5XERrVNDFWCEC2ULMlGjhCizLK+fmzl4kKAx2nRIlMlNEl1WzeB+T6CqioUR4/RzDhtYM+FRYPn6P0dnjwVfn29umeaTmtmlvKoEbg/lWJors1gSose9c7WvSCwC40oAxmHBFJisbpanqQo3vAEE8EOH9bK0zbUOjVMECvJ+0JDT6d27kTT6pVcGHnOOTwnkRBSmVAUEW/M857CiAI3yDDnzzzDJ3b6dAw2j4bnBSiU/IgWwppqQPwwrR1sfidWEKaa9ZvWwy/xszz78EMAgKHzLuJ5nYS2aUJ3G2pzaQCcXkgK3GDmQUs70e9SLmAIvR0Yf5N9ksI+hJqkZDBzlpU7z8zlNbO1DpNbalCT5fOTFQLXfEk/I2xjlnMzVOLWCZm0o+Eked6kHIammgxmtdZZBUtyHBIfuA2NdmsCcq2bBuqjkrRhOsXbrRPf/qUCJ5ikFxloONCKQ24C8OobsOXTX8bhT3xGJQKs37SeE+wAtwF+5BEE9fVY8/9+gr0f/zQAgJ11FgCgac1zsfWn9+zmfRM+KNLp2Sa1NZ1iqclUXJhlGipWHdziAJveWovTpjSjsTpjHXccUjsSAbH5TjBhEtDQAMd1UbNnR6Q9TRrc24M6mWytbT/3SUqleEShGIiznTbNnljMMxPVSr8kp7sL+MY3gOeeg9vUjE2f+xqf11fxhL/1a1cDvh9ByPmij5qd25A6fEj7to7DcMqERoxvrOb5OAAMT56iYXTNnCdBk1Qu8hB95vl24s0Gcq9IExqbBip0Nre1adtros8x/TAJUtnWwGzOXA+RqI82Qpr2g+axSXLytUE419HykShzBhEMAPPGNWByiy4ZpPNRlUC8af2A7Ef0OytiwXQitkAS8VWTTePUSY1oqNLxgZ0JNeplZUyajhEoxtxov4poCuJMU+J8cCJTMn06/FyYriCYPkMhi6StotVJpNI28yH6PWFc28KcSy2u/MQNVRmcPrUFrfV6WoU4TZLtnKhEQCSJQRqB1LZf/VYRrEAySWKjUV9cqjCyhvSuYE8yAFV3/BkA0Lf0HOCJJ4Df/AbI5SJlfT9QZ53pNK/Vadm3EZB+Vz3dCFw39Edatkwjquk8AeT7xnwX2malfouYOxduQwNS+WGk160FuruRWc1pjOHzL+BlZvDUIbMG2jF/Ihe4DZe8xMAN5hrJpGVuR9pnMZyY/plmzvRvpZqkcrmYJETMwCH7FpbR1qjBRE1uqcHccaGQwkyRIcE0i6RtD+Q5k1Qj3jX73FCdwRnTWjC5pSYi0IsLnGIbNovZt+aOkWNsrsnijGktmDO2Hi8lOMEkvchQTvVuhos212p1JgWccgqCdBrZni6w/fuAVauA//ovAMDQT36Gw5ddHSI7oUnCo48CpZJdkySDNghNkucFmqSNE4u6xMT0DQHsfiH8cCTSIdt4kiAGRx0Rk2SrRCZSW/s8AOOQID/m//uHsOBV56N+41o4W7fxmzNmABk7cwfE54DS2SBWEaHAAAQir0lu9y7gy18GAOy58T9RbB3D50OYQDDPi4QKBwB361Yse+0rsPA9b0LgxxwaJJIWld65pHxSCPBy5l/8Gf/r+QEx26rsMAo1SVGJXRhEIJ4hkmOgfaRrNCnaFhP9XPutH+HJvyzH8Iw5kbbpuxE/Hrl3jDkrt5bDuY4+K2efHwd0Psw9GBuZUNMkmRJoDrrpor2eOJOzSoASGearDmMVj2UkEKcxMuvWmaTwfhyTREcQmatUCoWZs9VPaWLNkDxnWlsa42rZ7wlEs9IkWSTG5QUh0QdUSECjJ+pMo71CyeRQB/WwJUKsCSYivWM7gDA0clo7U0NCWDu7KggBTonz3O23AQA6r7w6/gVAy78XF12W98t+rcGoUQgcBywIgI720B/prLNUcAjAwiSpeqPzYJqu0W8QE+dJvOBgeNEZAIDMymeABx8E830MzpgNJs4hySRhxw61L10vQFChJgkI/WVplOtKQ4ADFk1SIpNE2pAR9uKLa++YAizTpF71pwwPLueJfk/aH5uAQfq5ynfL0Vi6IDCEcnQIfU/3SdLLVUIDHM9wgkl6kUEu/qo4JskkzIzf1VkHqKpCac5cAEDuuVXAu94FeB7wpjch/2qOtNXhdtZZPFLd4cPArbdaF27GYJIAfsDQcLBm5BfXQrHZCMwgoEg6unHKMUnHcptFzYqgzOUm/+4XvLMWBMKKBbQ8/QSY76N5xZMqyS7mzEES2Ahv3g/j2kLAm9cA4Dc3AwDqH76fm1fOmIH2q98QtpHJqFwd2Y72iIgne+/f4JSKqN+8Af727aINoxGpSZo0VWOAzIzfcclky0Ue4n3lf7kmqXx5IEmTROtlWv0UqASNGeUJrxY5KCJVMcCvqcXw1OnWtRLpi8C4dL+YkZDKQVKEsQiRo3U1gSgj48xlnIok2TZ/DjNghO6TFFNPQp6kckCl4jbmpVK/j6MBM/KbBNq2Tmzar8vNeXHuSera1zTW8XOmM6DR72UD+siq7TEYCNteoRCnSbL5kiQF8ZAgmYuSZm4XLVd6xcUAgOb/+1+gWFTMAo3eSYlaWy6c5BDg/FnVvj1IP7cKgeOg85VXxpYHQsYulWJRXEugItPxVAqlFo7fnUOHNE3SECGqXc8+Btt6i0TH1Mok92no9CUAgMwzK4A//QkA0HH+xSFTSpikdMpBNu3w5MgyQWlC4Aa5RuS384Ios17OLBiw+CQl7B2b1rTcZ1HRNCvE6eG5Za84TpNk8+czAzdImjJKM5pMkp2B0+bTdoYa14rGiwve9NLkkU4wSS82SGQWZxZiO+QoVAvb1dJ8bhM87sZPcf+Y1lbg5pujIZhzOeBDH+LX3/mOdQFkSfhvCdxfhF9rUWaERMN2mDgWiZ2e7T3qc1WVSV6SsflfjgX7xAC8//3wclVoWL8GTc+tsEpqGjashVPiPkv1m9chtV1okmbPNmvUwLNIf8y+c8Yx/pm6ZqG5Xd2Tj/GbZ58NHwbBJkK35zoOR5BXzWMPh2N78EEAPPw52kkG9xgmKZK9XtyP5HOoQLMhv7jnBxUzCnEJJTUbeha9p7Ubw6z6hJOPdDthmdFH0W+s98UjhIu5d8rmA4t5j4N+IB1JBLuM4xiEZNz8iRaJJokZc15J+NwjkTBGibroV+Y+STrDl2DhVHnbZfoEcIKFagriNElx0lrbmi3OmaeuJZNUPphNlAHRzFotbdJlZSNwTAbCj9NCW9qQEPh2DUAlIcDl2tSJ/2gf3Ne9Hvkx45A9fBD4wx9U+YzF74lqkhgja9veBe1Z6308ME736ctQGjUm/gUAJVf0ocxCZLE/dHBFnrb08qeA7m6gqgpYuFAjqku+aW4XPypT+BXnS2eD4dM4k5Rb/iRw990AgEOXXR2aN0rGXpwp1dkU0oP9YQUNoc9r2B9o/ZCMAP30lWgqokKbCoR3ZC3SVA5JQAVHSe2EQuPkA08KWkyfJM+y5yJCGmluZ/S5xmSStP7b67Obp+v4jQrCKZQLrHG8wwkm6UUGiczMhSuBGYeoueDlJiotWAgAyBxs4w9+8AOgtdWuiv7ABziztHIlGp9/RqvPKeSRFnUMi0SrAJfa2ZPACk2SIa0yzwCa3yAMr6yXqc6kKiYQAXso15GA9ZXRo9HxGh7wYMotP7EikEaSh6hu0/qKNUlxQQxMixttDizEiQS/mZvbpUSUQ5x1VtShc/x4AECu/ZDemVIJDSueDPvw0INoWPs8llxzkfJlwv/X3puHWVKVef7fiLvmnlmVWZW1Q1FQ7CWyFKVo24IUaDMgtK3IT4G2daTRUXEZ6RlZ2pnBsWdsW6WxfWyl7VZxsEUZRmhZpBAtEFBEBWlAoCyojdqzcrv3xvn9EfdEnHPinNhu3C3z/TxPPnlv3IgTJ+Ks73mXAwg+SaukCQN/Fr5K6K8iycTpID1NkiRAG0+X0tOZearnGCdviiDh743C9HXUUoRWC9rJo+6e/r3c/6KpkO+TFI+w6Hb++w5eF/ZKJQfgnOWZtYReJwyKQTMdOT/uMX1KjZjb6TSIHNvigpKg0clUF+3fx/0vCJo5s6CpW/0F1FXc4H34ZtcAUFt1mHtNRN605nYGwVU3cdOtdKsTwahJqq7cTSated2DK3iaJKEN+ZoB4bxyGVsvvtz9/W//FjWuSRIGJ08wlPIr1JMwjVv9t4X33AUA2LnxvMg2zPOcDzG143mIQ2XUjaBX/H+uoIaTTwaKRWlSrY7NegHZxTfjkv+7n8MzNXmSa26X3/oHYGICM8uW48AJJ/nPyjVJdRPunkIO+QNupDX09WlN1dXxjAuXWnO7kNmsmnVdfdGhRpeLKhdjQCFDfnRlIcLnd5OquZ3GdF9tO54mW0lctVoy7YUVNb2S3oUV3I9JzWsWC1TtoEuzPXeI8kkKi4QmXletC0kAgD/9Uy+ymXYlf2wMeNe7AABLb/4HKb3y1i2wGEOtt89T5QNAteZIA6bqkxS1Gi6ZCLHgcQAox3CyVldrveORV4anJeZl13veDwAYu/dODIgbs3Ihqb4ZL+CGCy88+Vv3S4SQZLSdljoj2cHfvDprgQkbmQIATj896MRa1yQVX9kpdV4zmx9C/tCEG40JQGHT/Vj1tRth1WrAI48AW7e6hcWFpGUrpcmTFwWJC0mGDjIq8pD4m2iCFjWZ9VcUzSuDqmASvK9eWDVN7APR0wLfQ37zhAdZuJOfIZhOaL41MzLVwThuu1AjjBWE4A1R70/ySVJGlKiVUvXecfPr1zezpoqnK2rps1jMDKZh1e/nH8nbljRpMQZuMGmSdELS0b6Q5PkkWfGFX3E13X9t4S9E12epptaRm3ka0vX8PAwTcXMI8PpEWVi4090sn7Pw0p+9C7VyD6xf/hKnn/9HOOWS81D499+5J/zoRzjmz9+O0raX3IURb0IrBKIJlZIA1Grof9KNbLpn/Rmh5nkA9NqsCML6wmpdSCr8pG5NcPrpcBwWLiSpY4SAn3/eX/m/RU5yR0ZwaLVvTbHnnPMAy/KFUi4kbd0KzMygXMghP1EXkjT+SG5+5Lzyfp8xXxAx7T8oEtg0mB+PKAa1v44qtaDGysuAlqgAErzvmqk4UhAc3bxOnSv6gRuUNAN+mvpsmszw/HNlgcrUZkxuBt0CCUlthIcBBuL5JOlWp7l5mnPSq90wzaOLXC1SHWMHUt9YdsGP/h/KW1/0Dh/21S8CAA4dcxxg+XH6RZ8k0RyBH1PNnkzmRozJ4YLF0+L4Dxjt11M0QNMkd3btMdj1hrNhMYaj33Ee8KUvSfce+pUvJNm1GvJ/2OJ+iTC3i7dPkvJdkz8OGxaEpJ4e4IQTgpMaT0jaJe9Sfo9rXrfrjzei2tcPe+8eLP7RHf4J994LbN8OTE+D2TamlyyTN6tkek2SOnOPijwk5rWm7O8QRpwVO10YW2h/l/Noirylao7U+8mTPf1x/lHySVKCT0SiEeY4Jt+gQGYVbGlF0pbKNSpqlOvjItdtVZMUVp7S5CthMxaf1xRQQfINSpZ8LPh9JE1S3tZGUQPiRrcL5rR62GrMjC1GbWQEtdVHCNeFtC3NvUy+f14fLVyvm+Coptb+tFqfD91EWxwvZE1StHAuChjcL0nXcvI5C5XhBXjpTy8BAPQ/9+8YfvwRWNdc4/rs/sf/iOEH7sXyW26u+yH678SrvyGR4xkYel/8PXJTk2C9vZhctTrSXLii0WbpMEVVDaRXF5Ksan1T6g0bMFN1pHwEzO20C0p+3wcIpsqacjfm2QL2rzvZ+75r43kAhPIaG3M1RowBL77omtsdiBKS5PyICw+VEH/UYOZQP1ctoPBnUi0WojoQ3xpBjpIazI4stJko5m3k6u9PNKH0NPdCNbKVvqRUX+gSs5zLWYHQ86agErqFEek6qe/w+1+zuV0wjW6AhKQ2Ml1xOzPb9iu0Slh43LJonjY0iM23b8Jv/u1BLzQoAOPePDjuOODss2E5DlZ882sAgEU/uQdLb78VzLLw/CeuA+BHEqrUHGkiqnaqauCGYMCJegOC3EmLHW8cIUlMVpqERF6pScuQx5xl4bc3fBE7z3oz7ErF3SD2rrtgWxZK219GefvLYLaNyboNNgDXFpxH8THgd2z6yRx/Dt3gpcs790kCAJx6KlAoBAUx0SdJ6L24D9LuM/4Ye099TfAG99zjb4q4cqW3ez1ThGJbEZKMqvawSbL5JyOmwA2QOnarnkfDfb2JgHy+44SYSYifAwKTZsapnBcYdKHTwurzq+Zbb24nr3jqIliFpQm4kxretsLyIq4cqgNhYB+jsPJPs8BhEMLUgRtQAygkvlXw3obFFVnQtCRNt05YUT9HaU+tfB4Pf/ce/P7ezWDlHu8a9aqc5AsV/CwGbpDrc3CSoz8P9XRkTZKpnYk59CPT6YUkOYiHIT3L8p6xqm5PId6rntgzH70G++66B7/+7E3uD7fdBvzt3wIvvAAAWLD5ATAovrJCOqbFC4e5224AgHPCCUAuF2lux5+7EBoqDrEHNO6T5HH66QEnf2PgBvGz0p50wUjC9rrj5+4/sS4kLV+OPcefBEB4VsuSgjf0ipokTdAGNz/qOOP3TdUaL/s4miTUz5X/R6H2tZFRV4U8mELtixky/i7gRbgTylW3MbIoQJpcF3RzLJMwpPMpN2Fb/js2bXybZiG7EyAhqY1MCVqkWPb6SkUVzUhyloXZscWYEbULiJikfOQjAIBl//pNDDz5BNZe8zEAwI6/+Evsr4fzLOXr5nyOHObXaz9Mvg8nzCleFrb0z2NEOD+Ok28SeBI520J1cAhPfP4fsfttF7sH/+VfYFu+Fmly7XGYOu10/+I1ayLtEXQdG6BqK6yA0OT/JqcnmdvVQ7sHNCCCuZ3HxASKjzwMANhz+uux53R/08OX//wK98O99wJ///dumuec4/2uhnz3Azf4QrBInMANup+iijOwH4VmsNH5ioiowqpO+IgOg6qvgyazIX5Yjm7n/o85bof6JMVxYtYh5jFv294EP44G0PVJ0g+EcSYBSQQF77zA5EU+LuZP7leyH6h1e3PlbVtyzjcFJ0iiSbItC7OjY5hdPC4FFlFPFSdLOU3e1OA53v3r/8X1b50mWK1/Scxp+Hgia5L83+P6mfJ362mSNOOcbVvI2RZYsYiDp27Ajre8FfvOeIO7CvKJT3jnDT75BKzde9zncRwsv/kfkH/LuW7AB5gn1IwxDDzlmto5614l5cMEn9hHmduZxoBAenVNEgB3s9ZlywJCkhoCPKyjCQZg8YmjSdr+lgtx4O3vBLvxRlTrEegk/ysxDHgxh/zB/W6WDJokvz/zj/n7ZLnmlrpw2MG8yeNT3CiqPE1xy4vQ88VgD4LfXXBBLT66MOC6cdXkuiC2Xa3vu1jXDJokXYZNVhZq9Uo7JnUKJCS1kakIfyRAqVjKgChe5+0bo0rxGgc/j40bMbXmKOQPTeC0P9uI0s7tOHTYEXjpqqu9dLhqtipqkixRk1S/jxplzNApOI7sDCxmK46QpFspTEtQk+T+996VZWH3O97tfr79dlgzs54/0sRJJ2OmHlEQQKQ/EmD2z5E1R8HOx/us9FROfZ8kAG5od2iEYh644ZWdfuf1k5/AqlQwtWwFplaswitvOBtOuYyDRx+PrVdd7WrFtm0Dbr/dPf8/fci/p6JJ4u/Km7Squ7vH6CBtK/h7VIcaFJLMJiSmlLyJdf2TTsujphcattfwWadVqgkmMGER+rT3MQxGgByhS/yvflYRm1I+5/sRhOVE1DyoExVViAlLKG4edYTNSVvlkySVe/3HYt5CIa+fwMRZndflU/Tr9CZ5CNaXKMHLEcztotD7JMl9f1QRi3koeBogv72awqOHtQM/3HFdm+Bdoz+Pm7Xves8VfqYLBcwuXQaLMeQf2AS2dy/WffAyHHHDp2D/6EcYu+8uKW0VBl+TxDwhyZhlAMJeTRGapLjVtDImRNOrL5RNzbqmd1zbZtwnSSOI8f5bp0mKMpeyANT6+rDj776M6lv+xDsujdNChLtS3sbCevCg2vIV0KFbfMkLWkTxfcfxe/U3k/XzHPpMyrgWp1zEEPmmehm8kfkn3n+JfmZef2sI3GAyMdZrkvRlHBVIJjA2GkwI41iTdDIkJLUR3pn11sN461DlAHHg0O3DodpQh67yWRZeqQ8aFmM4eOoGPPb1f0Wt1ONV9GLOX7GT7f/r6UOeNPPjpkmva9Ygdjj65zEhJisHbkjeAgM+DPU0xIF66uTTgGXLgIMHUbjr/2H0/rsBAIdefSpmT1jnXxxDSFJN1Pz7yp/jPIllAWxUMLVYv15yPtZpkrzOq25qt+f01wOWhakVq/D7nzyKx77+r0BvH/A6X7OEN78Z1tFrva88jYCQxH9X8qnbMFJHlCmH6XxvP4r6cTEV1ZzOlIYqUEiaJGXCqSZlyrW6CbT/WZ4kiveLbwLCB6PgBWGa47A3LIcA98NXxxEKxcANnmbRm5RE3zsqtLD+3vI78Fe+gwJCs32SdAKQ69el968xa3r0dUZNQy129fWJply6IBFioBBZwKt/ENLXaZzUCWccv0PA7a/9hQinnpYi4BkWiFRUYct4z3oZ8OhgU288C+ABMC6+GPs2upE8i/ffi953/BnG7v+Rd21ppxsR1BSMgTkMA79zNUnsVe5YECV8cvPAqCh+UU7zXnoLBU1SfaFsata9x0ApX7+nfuFKV8vCzFej+mhx4ZSb+OVsSx7vjqj70j3wAKyXXsKiO78PADj07su1aeqioxaEOYlYl+MEbggI9hF11lbaTByTMd1iWyA/Cfo8XYQ77eKF8KXXsDCk832Xx8xgX2bKrypkq/1CMK/dKSWRkNRGeGcWV5MkqjQBxdzOpEmKUEXvf9s7seWS9+CZD/8XPHPLDzC7aFya9HiaJMeRBgB1NZF3CDxPJnM7aXXF8htWXvCDCENMNa9MYBumnoa0mpmzgYsuAgD0XPEf0ffCc5hZOIoDbzoH1TVrUCuV3RMjgjYA5nDYqsmWKaKaunLDRkfx/F98EC995GpgyRLJkV8N3FA4sB9seso9ds89AIA9p7/OE8KnlyxHdXDIvceZZ/oJfeQjkgmgWZPEJ63xnlnFVF9MGAM3aDp5s1+XfFxnxhYQiiz5s05zpV6n0wxWQ/dJ0mY38LvOqTztgGQKXx2+Ouu/r6h9ksLN9sKFAx1+fVSu1JSH+zzRQl9cwuqE2J/Fim5neMG68hPboFdlNJeb0pc0Ucpk2E2q/ruQlk77bYpsaqor/B6FnB3wJVQfM+5iSd4zt1N8kpQEC4rTez6fB77yFTcC7H/7bzh4xhsAAL3//E/IP7AJtZ4evPLm8wEApV3h5nbW9pdR3LMbzLbBjj8h9FxOxYtuF3/qFfZGqmOCkMQ1SfVnHewp1O+pjz6h9mVA0PfGNGkOS4+BmUOdn3++G7zhkUeAjRthV6vY++r1mDjhVdo0fc2Wfyzv1SFZkxSWPXUBQNTEhqFaLMTpPsS5WFxhLOxn3YayOgshsyZJOK6x1jH5vUdZvgbqhjDHEzH5YncLJCS1Ec8nqWguhrAdyMVVAX6aGk7YtDePn0gJ//5X/x0vvveDyBfdTlVs3DyghBvdrn4v2zeTU8NwDpQKUn78/AmTaEkj5R6Po0UC5M4m32jghkDa7v+c2vjr4dSt/fsBAE//18/AGR6BVShg7ynu6h3WrwcAzFYdHJyuaO+n2yVbvC/PlTwhCX+G5z7yX/Dyf/qYlL6XbwAYHoZTLLrHduwAdu4EfvUrAMCe9a/1tJhSiNPzz3f3rFi/3hOYpPJDsJP2xyD3+P6pCqo1J7aqXV1ZjRpUgoEbgoOemjcVUx0V5xRJJvBGgUmaRMuDrvw5nipJzBNjDFOzNc8UgynnmPIUTNPPq237+yTF2ZFenHSrgTxUnyFtOrYvhCcVYlTfAlk49T/z/iWTYTqG4FjI2a5PTC442bQsP2qosX/X3EMUSn0ZKbiZrCycCddrIsvpyrfqMOw8OI2Zas3gkwQvH0D0qrwXvlkoZ75IENAkRWjTOHnPlMzc/t3z3IfmY20hZ7ma8ltvBVaswOTpr4WTy3nR4Z75yH/FvjP+GABQ4j5JpjzUA9tMH3Ek7N5e99xIISnmPknhyfjpjS3G7IKFqI0tAk46CQAwWbdQGSjXNUmBfZLMmVSDcEh9V4zADYC7eMPvGYjit2IF8D//p/v5yScBAFve/T7smZjFroMzAe2Lzlybp1mtyVsPxNF6Vx0Hr0zMeP1lVHfjz3PkdMKv8d+DqV5GfRfRBW7QWQiJbads0CTpfJLkPlMvFOvek3jIlZHq44FyHpnbEamJ55Mkfxe/ihVetDcXiaqgukYmdlQlySfJb/DyBIl51/TXO2ZTh+oO8H76XGCIFbRBeQ5pYp2iAaoNn38NCJSveY3n27Nj43nYefafuAIegF//7Vfx7IO/cKMFAvj1S/vw8O/3eAOViCkKVKCzscRJY0j+lYeWnKGFWW9l1LVbt3fuAO67DwBwcO1xcMYWeYK2v7JrueYozzwD/OhHgdmnal6pmleBAXsOzeKR5/fgd9sPxnbqlqJaxShLb7VOiXqgE0hMCwT8uL+7vHvc5FQuDgRAfYJqqHi6FXoxPdEEhk8EYtvJC5+rDsPDz+/Gz5/fUze3VISGmEIefwd87sZXuuNs0MiYLzTbcnWJvR+JNmR5CPw0NTKvyUzJpOHOAl2d4++PmyurCyN8oqfT9Jjy6Zssy2aGah3MSwEjNP27tMItpM+3e6g6eOIP+/HE1v3aTZVVjWv0GOP+L+RtL6+mrSnibuugRjgzwceImsEXiA0O4sAJrnBRee3rsPXiy1FZrGzAbZB8cnUhafK4E6X3GBa8wdsnKSoEuKX/HDivUMBD37sPu37yEFAuo1JzvHsMlN0Fy6oaAlzbz1jSb2l9kgB3jAgNUHHFFcAf/REAoLLqMOx64znYcWAav/rDPjy3a0I6tab0Z2KaVWlbkniZe27XITy+ZR/2HqoEnk97meW3GTUfJiQTPU070903LP98flirMcxW3f2SdMEqxLajm1NaFlDO644LZWwYh8M024D7ev3xQBV0Ze1kt2F2hiGaCmMMlapb09W49SLqCmQ+Z+Ow0T7Ylqyy54MBY+4ApJrfmSN8+Z914Vl9czsGvh+2tJIthP8FgCVDZUxMV7F0uCzdJy/YkIubCC4aLGH/VAUrF/Qa34GI+BgN+ySpw4RmUm27S+vAl76E2r9+D7/7y7+qH3d/q/X1YWaZH0CB2w1PztYCvmamiYFOW7FmUT9mq44XDcrNHwLnAf7ANlOvT6WCXJ+qY4tQenkr7O3bgfvqpnYbXueudiuCgXePVasCeawJZR30SfIncFz4PzBd0W4YqcOdRCY3aVBDgItlumykBzWHYdFAWb0cALBipBcWLIz2F+v3lduMeMw/YM6T+JMx+IZGEAuzXdchpj1b5ZMid6EibF+isPc6UMpj6VAPtvW4CQz1FLBkuIwFfUXjNaK2yLRPUty9n2zbQs1hsVsx75d4H6oL0iFO6lYt6IMFC4sGSzHvEB+xjhw+2odXJmYwXDd1Wj3Whz2HZjHYI/cFq8f6cHC6iv6SfgjWvQfdOxUnJ5wowcsUuKG/lMfS4R5MzFRxYKqCg9MVrcmqqlXWrfaLLOwrYXyojCVDZbwyMQvAb7fqxDtuxFLRL8XNhP4adWwNaKxh4bn/9EkcfcctmP30fwdgo8K3TfB8kgx5eOJxAMDUscdjSDjuMH+xQcVohqYQP8qjG9W2tnjQzQvXmOVtlOvP7jjynIAJ1/rpuP9rSrmIryvKd1CsF96iiU6ysm3gG98APv5xsMsux9hwLw7NVDE5W8OhGXlxkedHFPy9snec2Obc/H1yK4/eUg59xTzGBsL7A8+0zxPGo8tF1LRWlXGSc/hYH7btc83f+0p59IUsEtu2hVLBxkzFwVSl5i282LYshBbqc8OcLbsulAs5rFzYi1Le1paHSRiKXlCS56aqCwZHt6dTN0FCUpsQBZGwVSVdRV2zqD9wLJ+zYVluB1WpOcjZbqOLsgfVrUSI2ihxn6Qy8/dOERuEuFJVyts4Ybk4ZNTzZwdX/iy4jV93vpn6CpedzuFbSskw/9UO1BdeiNp/uACVf9/l3l/oFMR5IO/UdXtTeOZ2AdMy8bP7ZdXCPk1+5XypkyYeIlRdRaoscgd9a/v2gD8Sf4aqwZGao5rYBIQkIbwwrz9iyNJ40erirzgFAjf4UpLHUE8htG6N9BUxIggBUZokKKZNYhm434PCbuCz8r4BjWN4xOOLbVn0N3BYMDpV3BZiWRaOWTKA50v+PY5bGt4uZZ8kno6Xopcn91vUBCtmRuuommfd5WKdG+ot4ITeJP2MGdM+SQAwPlTG+JAvlC8Z6sGSoZ5AGstHgotCOm2NdB+vDcomLao2SFSW6PyTGAs66LufLRy7dBCMMdz3u51wHMDRaJJE4Vj8b2rixbyN45e5737PobqQVJOFWy+PMTWfol8KoF8kEc/jqL5AlgXsXX8Gdv+Hc9FbygFb9nmapOLe3bBmZ/Tmafv3o3ivG8Rn8qRTpOdw++Ng7hljgkYrYlIvvu+QN6H+Ml3vc3uLOeOcwHQtIPZFQeE4rl8NX6gFQsbolSuB73wHRQDrAOw8MI0ntu4PBJnwx0z/WF7QJJkixoblDQCOXTKI4V7zApB3r/q8ZdZbjIm8RJpH+YE65Hq3bLgHy4aD/YKJnkLOFZJma6jl3YfQbR2jmxsCwFGLB4xpm8aqKHO7gJUFf8fqhvKGxeFuoUtlu+7HGP1FIa6NNuCbEugiZ5k6K535mu9fIHdI4sBqS5NiP6+mjpSveMyKQlKKNsOvUcMxp0rLkLZpJdY0QRbnuPx965xlTVoV2YQrPuq54r5bIpX65sLFTT8GXnwRrFDAvlefjrxtB3xkTPdXw3v6K3zBybguWls8IcnwYBpU89K4+17EStMw6bOs8KyZVuSg+ajbTDaJPoknX1ECQKiyYtzJVhrEhZKAcKYInPE0ifHLT10I8PuFeNc3gq5eZJNweJqSJsjriy0ETEDF1WBRSBKOm4QUfkx9v1qNlKzEiTZ5Es5RNRZeHtNqkryL9Of53xUBVxD4vL5tZAFQ9+MsiVFBRb76VdgTE5hYsxaTp22QnsPUjsW8Jtq+Ikb98hbKFBN+3ZxAp921vN/c/7amPUVHt3P/i3OCuBPjvLAYK6LzXfP3SXJi30f9Na55vzpvifM0vI5XBKuZKKE4CjF4Qxw3jSSYothFL9rIfYL3zaRJIiGJSEJctbsagjgM7mwtamt00WFETIEQ+G9iZ+6ZtkDWonhaiJBOtKDpBNM0GX6Nq8kJHk+VmPfVPWAKQ6tOFAIrqkKnGFgRE76HBW4IK2N5xcf/xlOeElYRRar1vTR6bv8+AGBm47mo9fUhZwfN1qI0SXyAVcOZixGvdOYpUSt9SRYDAFmgF99tI92wNrpdyMq2SROp/ib7JMnv272fmk70U6gaQJ7vUPPajMco/xYsMBCqk66oW/t9R7xMBoQkvvKtedfNphm29mHFxyAvCqj9hxx4xv/Ntv2AEVGhs8uh5j/u/7g+SdK1lnz/wHYIlhUrwl1gnyTD46jja2CME8yEvXdqW8DSpQBck7tA0tUq8IUvAAC2vOt9gQU7U154W41aGE2CulCnLpTp5gQ6fzSOahKeyCfJ8t+lyf/WhOhnJMLTETUxouAXpcXkSIsFtiWZsYfh3avG7xNdbrz+itqnqJDvUYgbynoWIzEFvSjkOY54PHxMtpTPatRLTlxtX6dCQlKb4AJHIPqLQpKKxRu0qK0x7c3jpx9coRF/47uWA8BMzW/0/iRIWC0JySwfrEQf0jTheD2/IcsyroCkxdMk5fQDg7qyok6qxciC6opY2H4OaVf71Wf2VpiUzrMytlj6fvCKDwIAcrbtmTHUauGDjWnzYE8DUD9PDOLhXxtdPklNJ8WJVFVYWW8Ez2RQ0PgFBSNx4DCXo+m4p2ERJgP+hrgJ8sonm0o6qn+IKYR8FvgmmMGB0A8JH09KShq4IZ+zURD8TXSapGYNymqyWd3HDqlb4u9hIeptpV9U21VczXEcTZK/MWd8cxr1/nqXlWiBmS/eBaJbKpeo46tJk8REJ3tAEJK2BzUvt90GbNmC2sJRbP+TCwN1z7SvUiWmqZ36HOELZ/KPk8oEWjcn0F1r2g5BFbLDEE2yawnqBCD6Qyvjpjd/Ec71NEkRi0IC4q+6vYJMBH3YouGXzFTdsgizsImLpEnii6GFbLxlTPOoqCAqUp9gB/fO5OgiZHYTJCS1Cd65a6O/COQiBk6RvGY1JkrVKTlmBoQkOd2aoPoWJ81xOkSdeUGaJsOv4YETvOMpEjO9T3lioe8oxPvzty0KBwEhSTA7Cm4mG+85TAMnH5OnDWr42iJBSHr1qzG93g1bnrOCnXfURJ8pAiEXKP0OMjhJiDNQxo1qJZ4jrmgnMfkxERBeAz5IwRojXxKcSKqfdXXO3+spvsmgZ9Kh+iTxNDQhfLMeosRAF+pAyO8V1ycpwbYxHtoITsLnlpl3ZHQbOe/B3yUfSEEbIPVWljyhDPj8KJpj0ysKCknBfHjmdiGaCdMz+P1h8CLPhDckPT8EuLJPknKeOr6qQpP4LH4fAl9I2rU9uHjx938PAJi4/C/glHt8LWbE8/sR3+LsByj2GfHxfJI8c7vgnCBOeXmCn3D3qIUs0SSb92Xx972ql4Mjj6O8nsqaJF6HEwRuEH5OooHR+bBFwfMyU6kH5krTuSnw9jgtmNuFbR2TFpN1ju6xvXdhyeeo7YVCgBOp8Bp/RANKMukrKqphII5Pkn9cXTXh16gDiwV51agaw3RQ1Eh56aQRbCw/PUucDCRPyuhbEGYX7+8fIaycKCZogGZvipDOPO57UAdOr1OCGyxh2uCTVBWFpI98BNV6XnK2pRUMdKgTo6AmyZeSkm6OyvPi5yEeOWE1WQxPn5ZAJ25p3rlBUFW/x/nMSRjcDkDQbAlQfFWSJ5kiD/7ERh0I1VX1qDqgi04XhbRhojJgx7lnWgILCxm97SgfS97fCUqPwLm2ZSk+lXIanpBU802ndagmu7oFKd/cDqFpSc+g9qchK9Rhqemc9/XnRUS3874qG3/WhaSiam63fTuwaRMAYOL/u0xKQ/XbVIm7MCrnK955XDCZrsqaJE/jpgkkJKVjSFetW/HyzCI3sVfhQSYAdeFHo0mql2nNYQkm4P4Jur2CTAQ0jwlMoXm02ag5XhzKgpDEtxdphk+ScXEvTKBWzldrWtoNzjsFEpLahG9uF15x4jqyAsLqmiZylsmqT0wzKMS439WOQtQkuT4h/vE4+eP3TbPqz++hm+AnJTgn9tNW76eeY1viZMH9L5rUBcwGQkKiptWIiedOV2tgzC3nkhL2dnb1GlT7B1A5Yg3wZ38mRaYLmOMY6onJJymnrPoyBM3tkmuSIk93rxFWpaVV4JQEyxrhMzWYV3x1Yd0Bff68CH2a803w9NUJhTogyffOdpCShPTAfblQHU949QM3xM+juCKsM31slXlHVreRykrzxvgRMciAvFxS1yQJGVL79JzQb/Pzdag+SbrJMu/iEvkkGawVpDza0XVBtEyoOmZNsji+5nJBXyCvDjNl40/J3E644Hvfc09evx6VZcvr94T037RZq7eRbAxHnTTtdqbqBjIQxwDdnCBsM1mOZ24njoUR2RbHwzTaA12QCV2UPLFMZ5UtAKLyBuj3CorKky4dE6pPUqNBGwBXSLLtug94XeDNSkgyLeKJGwprze2UoE1e+Svjf9gCcTdAQlKb4JPosD2SgISdjGbVyLQ3j5++f9ykWg6YB1h6++MogU8cHBptL7Ylv5t0WqngxAoID0PrabIswSep/o5FPxM16lLYoCF1UiHTSSm74mfmB23QhQV1hkfwszsexM5/+zFQLEphVYMb2+rvLwVmEDQW6iTMXdGUr00sJMVcmed5rwm2Mo2s6mtX75U6Fq5Z0gt6UauxJh+G0LzW/0ttnQV9kiTNSuK7hCOaf5kGwrhmkGkGUJ3ZTFzTp0YI9AlZpRvRn4k+SabADapPkioUqBM2U95VLZ3kqyDkQ/wfzydJ/R68JqdMvrTpCJYJojZJvUY0ddKafHuCjeI74Znb7ZDb5623uv/f9rZA2HGT4zqnmsgnKVmtYmD+GJD3x4CCxrpEJyCrt9N0HzH8fvz+QF1Ei4MuyIRunyTLsrx9qLi2JjKohPA5mbld8tbNqxz3SUoUyTCEHsEHqZC3M9FQAWafpCg/USvwX39iXGuCToWEpDbhOXFGOUMm6WQUO23AvDePl37YqmP9u9qpS/44zBcOojpEscNJO5nVCSk8xUbhKYhRoNSBQYz6w3/hw4+kSVKFpJB9I6SnCHmM4OTMP8LtlNUNbDmzY4vhjCyQ8pYTQoBzTEUoaYqE58wJ7wOQB8ioNOVz9AJGGHzgrDnypDEtwYAaci1VfZRU5AmF/hfd9b5Pkn/fKLT7LTnZhEKPi79yHIwy5dWX2NGn6tcluL/O3M7/37oROat7hTnSA3pzFguqBkrvP2T6bnrhhZzt9fumCbQnPERopcLur7smth+LRkuipif25TrhRPSrkwQtLiTt2Oa/7x07gAcecD9fdFGgbnvjgWHRg7fVeD5J+s/B/PN7CpHtBCFANydQhTv1MyCPc5zozWTd/45usSYG4YGnlHspgkjUfcTfkwhJJh+2MEQrGyAbTRIg5zsrLRKgLrKIn/lihT7/wT7X/S9Wf5ayLnQSJCS1CT5Rjeowk0wetfskGfbm8dP3PwcjIUGbRyncKeJHspFWPlK2F9/cLbixZ/K0lO8xVlHEDkGNNiWqmSuKuV1YhJc0z6GGADcFbRDT5J2V6KcW109M9EkSBy4/BLh/rhpeOM4kMi9pkuLBq5NsfpSeQGh2mLVD0d/11+naiOjoHBf+utR9ktT23szodv5k2axJ8vITkVbS6HaAQUhS0msGgYl4VrcyTFbU+4oTDzX8tOr7qdbpJCv7/P0GIp/Z8iQwSfSq4LsLXhMncAMgbCtRdUINyPhEV6cV8AUbRcMiaJL4D/YPfuBW6FNPBQ47LGDiK2qldMxW4y2MBvIYcroYwnxSs5l42D5JoenWf0sS3U4UDsLMy014AaI05naqsJKrv+VZT5OUvF7HIZUmSclLmjR0iPlO4lcVhWlRJSrIpCm6q2jOKU4FKHADkYi4+yQlCY2sqqvD9ubhWMLkRFx1E38Lhgb3Oz930hzvWdJMhIP5df+rPklp0gtbVFV9bTiirbYUbQqKLXWNSe8/zPwgLKy0MYPCd8aAqVm3DMIGAN558XzmcjrNiP7+3iqhw7QmnOJVweh2xiz555jC6oQgB26oX9pAR6wTeqKSs6TPmgEmcI4eSRsWlVH476uiWXV17x+sv83aTLYmLAiogRu8e0fcOsnknVMu2IJwxJ/XkvLRTUQtlnhCqRPUJnHEvlmXTmBRJKRO8JVrk7aZT4ST7ZMULbRFrWBzvL11Isxt+bik8wVSV/29NJYtc+9x8ADYxCFY1Srsr3zFPeFtb5OuERfuAIAFo23X85lAk5Si/k5Xgvvk6UzY4tzPe4/CeBuF6LcaFTBKBzdLq1S5Zp0ZNUn8FYp7EYXnzT2hmLcT9TWWZUlbgqTRlsbxQYuDOLYnCWMejX4c9/vS8DmB2geLgpE4FyBNEpEIzz45ogElmeSo6uqwvXn84/LvOm1KQJMEfyNXh8WPZFOU9jVJ12DEVTt509fk6YXtc2NyHvaENMuPruftk6RoUHSrd9oVYkMeQvNuyefyiDe6sKCqJkl0hjVpD1UkczqNCaf4nrxd0utZiTMoJQl1r14j+oI15pNkBdpblLbI7IcUbEfqcZGkEe54KqJZZ1UnJInXZDxG+UJS8FjwOcNvHndiLKVoWYK2A/L/zD2whPsG+o1s7qWboIiI9YgvwFgI1rs4JtT++eb89HpCkj4f3j5JIXlWiWPeazLzC5zHJ9U1J9TMlPslac3t6v8ZlIWWgQHUevvc7zu2Y81tt8F64glgZAR497u9q8R7imnpqMS0HnHTjNcfitrFKY01AZ8TiBpnVQOmIzgviMyypNWK2sReh2o+KfaJAY1o/Suf68SNvJdGAyP6FMXyu1OKtxDhdx4XydyuSZokdZsTIKTnVn4X6yJHEpK6ceUKJCS1DMaAvZOzeHnfFByHCXsmhFecJFG/1F2rw/bmUdNXI5UAfiMJOPtaQofI5J3EYz9L+KMYEaPbyRPaFAQmwMLkwrAibQvHvUFRET44VcfBTLWGg9OVUPODqJ2t/d/05zHoB0j1Op47MeKhKaKhCQam9UETr+LvgftHJdml3D0/8nTpmmqIT0JSVPNW1VwtdlAJaeDRfxZxhLjOsSYknoAiCEmCtNKK4YjnU3z/un5EPNeESQMVBfe/8AZqJb1WkJXwmWSHe9EHTO0Xcpp+jJNkc0y+Wm1aTOJVL5kmST0SLgyGodsDSH8eN7cLTnek4COicGNZqCwed6+/+Was/c533ONf+AIqo2PYP1UJhtv3Jonu/9mqg4PTFS9J3j7j+qjE6wfq94QQvKcoCknBPlLVgOlQfZLiLHSJi4ZRm9jrUINMiHkORml0/3vmdjFnsmk0MGpU3ijUvCY1rzTRPJ+koGDkfg4XkD3tvXK+2Bo9M+wuljSy2bKXiMSygF9t3Q/LymGop+CtgERFKAmLtKbiRbdz5A32wgYd3onJDviyOVVgnyTLr/SiH0RUZ1CQItREPIwpv/Xr+EaolmXelyKKsMkr7xhNjs/iiq2nSVIyUqky/GbHARycrmDVwj4v34F8SHkyv5iAVqP+v1rzB6U4naeoxQzutK6/RvJJ0phSiMnw+tdfymNiuhpr8pTGXY0PRqKg0OhwpAreqmZJPdd0P5NTtKktJo1wp3unkibJoAnNEp60ziQmMmCAAu9jkmbX5DfT1MANhnaYZbK69yVpkoSJrniqbfkm05YVfJ+64CQm+LsNOM3zvkDZBDmJUztHN/nm40hUet6k2nFCxwC+eKgTkvzV7+B4WVm8BOXnn8PojZ8HAMxsPBelSy7Bk1v3Y9fBGQz2FKRnUseDJ7buw77JCl6zZiF6i3lhY9R4Nca2LNQYi9UmHId5AoM4BhQEbZtPcp+kOGZz/AzGojex16EGmeDzCndBVC8keVFWI+7D85FGAyMHnIomaG6XkZBUaJKQJH4WBaaIdugvbMn1SWyL/mJOE/vjJkNCUgvpKeQwXXWj0NRidpi2beGIRf2oOSxSoOITe8dxO00nRHvBGSjlsXS4B8O9boevCxSh21CtlHMb6UzF8QafqFWjQj56shjF+FAPpmYdLBnu8dKJO5CoyJ2D/NuqhX0o5aexoK8oHT9stBc7D8xgQV/RG5RMmqTZmruSyBiwf6ri5Vcl7rswncXvWzSEBVXV4KGBGwx3kYXicHM7nv74UBmMAUuHyyFPhXpayU0x+aOKpiSNdsY52wpdmY4zsQj9bLhW2uspxlCse06T/b4uH1nA623VCQ6EC/uLWDRYwmzVgWUBK0Z6QtNaNFjC/qkKlg/3JsrD8pEeVGoOlgyV63mA9L8ZBBYrMrpZlMZR7F9FKwHpHMtCKZ/DqoW9KOSCiyC6jcFNjPQWsWS4HOgDxQUTINkiVVAzHzxnfKiMg9NVLBsOrzOiuWeYT+LykV44DjA+aO6HmKBH8vrLT3wCBz8L1GZnsNOxUPibz+Nwy8LBade0mWuJ+PncnHy6Pi7w86YrDnqL0ZFmVY4Y68d0tRaq/eB9hdgHisIgv5fjuP2/ZVnaDadNdXqwXNDWAR2ikJjFPkl8sU03rxgpAQv7irDsHGzb8uYDJpaN9KDmMCwdCj9Pm6+Ei7vqeJ6VuV2uPhes1pyMze3EeZl/fLAszw1VhnuLGB8sY2e9WflCsmhuF7xHt0FCUgtxhaQaDk5XvY6qGMM++fDRvljp521fszJbc4Soc+ZrLMvCsUsHve86dau6Amdbvu/LdKWGUsH27h+eP6GziX4cLf2lPE5YPuSnwydFDa7nqteP9pcw2l8KnLdooIxFA/KEjA+vqpA0MeOX86EZd8DUTWCjJkfa/FrB1TVTxymaZABy4Aa1yKJU69IqoRrQw+YCuvu9XMhJZRVGLsU74IJVlpokqTPXvBtpYgGzpsn4HjVpiu80fj6DxzxhxWCWmTU8bd//wL9bIWfjxOXDsdNKUldEBsoF5T7hq5/NIKs7xdE45mwLNUfesFnXfxy5eEB7fRKzF9u2cNzSYJmI+yQlDfGrCgi6a+LWBb0mOZjeUE/BmJ4YqU8NYz/41vOAt56H3728D//6bw/g/OFROA7zAiSowgZf3Z+arWGm6i+Eqj6rcevmyoXRCwY8KZMAJo7JVYcZzfuDIcDr/w11ICwvTMhPInO7QOAp97huXlHKAa9aMYxCQT+BVwmrA1HI5pHRz6NmN6t9koD4c8EkyP2HvPApzg1VcraF45YO4sWinI44lKURljuNLrYU7D54J8pXoMQQyllgCZqBqsNC9+YxJ+J/9MztAj5J7molv5cnAESaR8RYUk+IKQpdHKyQCXG8693/vDNXhSTRHj1uqNKw31WfBfVMkwpeFHDc/Pr1Is6+JW6+UE8jfsj3JFU7jb8ar9dVJdx6I8jDYXiYeVNQD/U31RxKhK+eihv0xnkBunfPJxdmLVa2I5Ua3bETBkLVTKgp9zDcs+F0Y6TDz5GFpGjhnJMkcIMJUassapHivPOwYDmJ86EICGnS8wR9May6ksee+iLgZKWG6fq+PFIa9ZvyoADTlRqmZ4N7FTZzvxijZlHw3eXnqBozHWnyKAb0qKWYe6hBJuKOM81GXCSOk5WAoJpRCPBmIY9PjaQjjweAH+mx3WXYCCQktRCufeFq+DhRbpJS9JwfnUT7V3B0qld1JYQf55qLasyNcUVTsKwmbI00vmTrQ+H3dpTVXcAvZxFtyNuMZnQmswzxFalhVeP6joi7yZuE76B/U/znEgX8uPDQrKZV9TSo4ZNV36Iw3xfTYBNW1/nqaVKfJB3ViJXqZpnbmb63A56DVtrAN+O5TU0hp9QXnbldGElCgJvz5re7pCF+k+Y3bj7SIq9+699pjyD88OAIUhr8PK5JqtS8QDpAcH+6LKsLT0oXcZRjK3XGLzKzcN1IHnX+XXFQg0xUY24t0mwkISnG+UET1/b3i2Go2qPU6dT/i31CM+p8qyEhqYX0Cup4ILv4+SLiakzY3jwmdOGK1Q0K+XFVcxE12c/b5k45Lf6kKMW1hpX/pPcG3OGVD1TcNl03oOpekRXxu+48ywo+c3R4U1mQy9vBPSOizMQYmLHjUy9NKvQkDTbAhbQsfZLUvZ+inlH+zdJ/FoWnwCpj3WSQCfskxXgE3eRDt5rcTNM7S+m+OmEgFPd9a/Y9sk83+h4BPzBFzInUJCWp0AZk35P49wbimdvFzoctvwsg+eOIWnadrw7gj3PTFcfbsFVKo34Bjyo3NVvztmQA0pklxs5/PSmdySvH2yrB0yRF9zNp8uiNESzaP1KHGmTC6RAtRF4z9wlDrOP5XHBhrdOQXSzSp6PTJDkdog1sBBKSWoi60p/VTswi4mpM2N48Jkyr4V60N6HGqD4wUZPipCsycfBDDqcRchqbQMrRpnzzxlKIo6aus4hrEhXVz5jN7VzEPY7cvOgcqcMnZ45j3hi3EU0S4A/mcS/jdZGvOGbRD8uhu4MTULms/OPq/XW+feI1AOoh2N3PosVgnMfQTT60mqRmCgtqnjpgIOQ5aKlPUmYLPtH9kU57Yhnqmo5Mze0cJRR5jMTi7JMUF9E3ipN0QiqaEftmaHIapby7abHDGPZNVqDCy433v7NVB4dmfGHKYUhslhgfWVDUlT+f5HtCUqzADclz0khQIiAYeIqPVe3WxCSdt4jZbYa1UNbE8YWMl46LGEp/LgRu6PwSnEOoQlJUtLo08NWYao2F7s1jwjS580L0Cg1KnZRHdWY5WwxPm02jaahRW/rPse8tPK/DmDdQhUUj0gpJKQW8gO18jMANooDDgz+IE27z5Mz9L64eB/yZDNfEJanmyQ95n51KXzWfC9u7JnRR3lC3VE2tuCqfLEpY8GE9nyRDHrNe0exEcztOS32SMpJETUK2iOqHY1nqJCf8HkFzu+SI5WzyhTERbEPp3x3vtxoK3CL0jab2Z1kW6m5J2DM5q/nd/V/I2d5EXzxPnPADzWknYZu32oqQxAl796k0SZpjiXyShMzP1hztfnztIOk+SfK8qXP6RBNZZVH1UXU/U+AGIgE52/IiwQHNaUB5Ya8B3icm6ajkjcX8z57WS0hKFQbidKx8Yptdw6xnq8H00k50RBMDT5NUsLXnAAab8ZjCmpRHSzXjCtNgBSc1pvDdptcg3tuPpKSco+Qn6QTIC8IR93y+ql4LRnVLi628ClXg0D2TXpOkF66kuiAISUn9KnRP6odB1r+HrHubLLUCWeGVRTNVaIZ7NpxOjES9wDw1QUgySech1zeCOJ7owr+HEYiI2UB2MvFJEsztwiJxFW33t0o1PDgKXzjk56lpq+c3Ck8rzCfJpEmS0lEDaqTIi1aTlKCALcvy5i81J36AoGYj7e8Y483I5nZdMMU2jFuJkxHmQpw0fvGdRheU4NxC2uitGZokz9yOhdopmzBN6HhjF9NSfWDiCH28E8xsYpHQRMucTrrrxNUTT5OUl98L33QQMAwaMYWksP65nM9FdkSuIOd+FjtycdIT5fQv7oERCGIg+eEkf6F+pMJ41+ZUc9UM6lScaH/miXi0YKQKUvyZGYPR3EdH+CqwLkfZo2Yhy0idafF2gW9iVkI1iA2lK7ZD/TmqE76qT06sSUrxonT7NSUZY8I2HU6C6msDJC93UTMXtshQVIZqsU+3pDExuKuKmHaaxaMweEq+D5BZUOFCh+eTJKajtuU0miTlkjQCecHzqXZQ65DADY1okprhUpE1pn2S0iKa28XZhqbTISGpxYjal2Y0fq6pma06qZwnpQYjrohoVvnFZ7GseJMkf1+obJ7d0ySlMVnLYDIpCg+8QxDfSyFvo7/kD5x6GSm5cKGeVg4J2uCb2zHPf0ccwExaDxF/cgZjeFfx2RKFnefXpNQkcbKoUepmynJ5GARIzcTcNlwnmUYJ0QVrSWztED7oyBH6kg3wSWiWsNAIPE+t9UnK5l5yjdGnqWpPLEu+MNInKaM24281wbc2iH+tPClL/+50bSdpWYjO5jrhgaN2ryO9/uaq4vk9qjSF8IWlrAgTVr2tEmqKT1JIVtJk0zXfbiwNPs9wA0+5x9qtSUo6T5N8uZsQnCtr5EWWBtqjsODHYR2iDWyEzi/BOYaofclykzEvzbzvp5Emsoh4rjigFjSaJNF8MO4qciP7Gung+UnVqSvma2nwQ2Mzz+xLNHvrKeQk7aFOeIi78h/2jGGR7fhlYuAGSUiKsbKrW3ENq1dpOsV8wrqhNp8sJiA60yXVnE79L58d/E0WnsTPvj8Yj4ClpmPOp/ks0y/zySepqZqkDEyTtOka6omIVnuSwPE6i8AN4nXVFKau0kJEA0Og55NUS7bAIOL1jWChwoNoQV0qyAtf4vk6f1SHNc+BXY0ophtf1LDx3rUhmu+0fYV4WSpNkjd/cbQLeu1AMreLkRXRz7fbNEmNVE9+qRQCXGO50m10tJB03XXXec7l/O/oo49ud7YaQnSub4YmSdy12rQLdximyZ3JTI4LAHH9q7iwldWTe0JSimtlTVK6HPHHFictok9SbzEnlbnepyVeJ2Upn8VzTZHtxPRFczvTaq7p/qLtvklDKZkLpehZ/LKMVxbqKl0WdUr3LoLCkF46Mu03oQurD7jt0ovQldBkKDRUfAzNYBaoE75OGAhboUkK1IeMbhWnH+DHPU2Scm5UXtT9yNL2ezyNWkjAAHMe/M8NmdtlIPB514ihzDXvpCRGdVUWvsKCGQGyJqnZTUT3DtSyiqKxCGdC/5YiHTHwFB+r2h38QNwCJbbvXf28bvBJEse5hvZJql8q1rIs9v9rN0ED2g7juOOOwz333ON9z+c7Psuh9DTb3E7YJ8lfvYp/vWnALdh64cZdOavE7hA9ISkrExXDRDbWtZp0ksI7Q3GvHtEnqVzISauLuomkLPwkEGgjBmcd3gZ9ok9SjH0gxFC5/FHDJimpNEkJ/dWyWhUXCYv0Z0ped1wWwIX0lXckbtKbZDiRNLo5S1pN1wUCaYbMEHg/7ZeRvDbRqnlVoxMLXXqMmdPU1fmk/ZhtW4mj0gXyUb8waeAG8Vogm8ANnHRCktD+YmqSyoWctzG8er7OJ4kxgDXJdExNLUngBtNY35A2QUon/RhQqTmpovM2i3zObTNxc+KWM+sKTVJWfpziQipnLuyT1PESRz6fx/j4eLuzkRnihLnYhFUGcZ+kVE614uRL+FzI61dSuJYkbkfmTYRj5ygcP7/JU8xixZ1f59nm2/7KU81h6CnmJFM4rU9SzAEqbGfsUJ+k+n8GplV/x3HcFCcTlqHjE7+l0Sqk6UhzwoQvC3RaH7fzZ/47NwgelumzJDDJ7zrpKq8uzWLOxlTN35clai+urFDbfCsjykXRqmhKWd/GE5IMvwfblbxZZbwIoxaCu/0kg9+zlmKPsqT5NZHFxMtf/Q7fzDlnuwt8DO6YV8rnvL5HPJ/vqcSYu6k49w02bcCdVf45YRHm1MAN5jTTZ9KqCwdA2sANvvBd0yzotYu8bWMGTuIFvK7YJymjbVnEhVSOY1hQ7SY6Xkh65plnsHTpUpTLZWzYsAE33HADVq5caTx/ZmYGMzMz3vcDBw4AACqVCiqVRoeGdPD7VioV5PN5MFZDzWFgTi37PNVqqNaqcBwLM0Xb/VyLfx+nVkW1Vq0nVUWlUtf8ODxdSGkVLOae71ix7mExNx3m5DN5dua4+a1Vq7HSE8si5zDhWePlX8Wpv5fJ6VlUa1UUYaNSqcCCg2qthjwcwKnBguOGZdeURa3qv/NqyHNUKsJ5lQpyzPa+5+EYr6vWy7RSqWK6Xl5iPsQyd+8fTKNWP2e24g7EbhpyXmv1ugcArGYnLg/wOpagvjJW8/YHytu5huuUWBa1qpterVZ1B+162Tg19568rGr8u/A+TGVarVb8d+TkvHc/W6mgWq2i5jBUK1VUrPCJjJi+xSzvMwDUajkhH+47zbPo+i2VRUwcp+ZNAJkTrw02E/4+1bqZJdWKX89zMd5rEpxazfUnracf1lcAbt2qVq1Y/QeHOTWpH6nACT0/LI2pmUr9fcd/D46jtI0U9weAWr3NcdKURbXep9qWjdmKpR1L+OeCxTBZraJgMVQqFRRshplK8Py8xTBVrWGgVMTkjNu2Zyq5+ntK1r4i86/UB12952U1PVOpz4PqY2ZN7JeEOm2l70fdvrFW/5yibTiON57OzNa0bTlNP9UoNpxE8wz+zpsyx8sYp+q3gaR5FcuiWq2PgVW/3GcrlUBd6xTi5sdirHONBu+8805MTExg7dq12LZtG66//nq89NJL+M1vfoOBgQHtNddddx2uv/76wPFvfetb6O3tbXaWY7F7GpipAUv7sk/bYcCTe12pva/AcKhiYUkvw8JyvOu3TQK7p93rDx9g6Cv46b48CQwUgCE/sA9qDHj5kHtssKhJUKHiANsngQUleGk3wnQV2DUNLOoBSvEszjzEd9WTZzhiMPn9XzgITFQsjJQY9s64mw6uHWbYOwMcqgJLe90Vlj0zwFT9u7pgM1UFnjvgHlzZz4zvcaYGPLPfPe/IIYZSDtgx5a46L+ox5/GVaWD7pIWhIkPBBl6ZtrCwzLCk3hy2TAAHZuV0VSYqwAsHLZRygAWG6ZqFwwYY+oUyfO4AMFV10+kvMBymb6JGZmvu8ywsA70xl2+e3m+hUleiFHLA2qHGurMdU8CuKfcZBooMq/qBp/ZaqDFgcQ/DWA/w1D4LNQdY2sewoOR/H+9lGK23M7GsxPY3XQWerZf1UJGhNw9sm7S8tgoAx46wSDOkfTPA1kP+u56o+BcMFRlW9Pvnbpt0zYVGY/YBSfjtXsszrxgtM4y3uYudqrr1PU1/EJeqA/xun/u+bcstr6zYPQ3MOvDapsrOKWDnlF/WYz0M/Xng+YPusRX9TOqfdYjt9OhhBuP2aiH8/gAwWXX7lP2zFnrzDKtj9p/i/Y8ZZoH91uIi9t9AurLg7TRnAeW82waX9zEMl4LnHpgF9s+6fXjOFr73AaJV1b4ZYKIKlHN+vztUBLZMWKnHGRO8b+eM9TAsVsaC3dNuHzNYZFjZD7w4ARyctbz+C5D7vUb60af3WajUZd40YwDv1/oKDFXHwkxNnoe0i4MVN2+87KPgdYCP/53Oy4eAch5efUiDOEc4sl5/Xp4E9kxb2nrZbiYnJ/HOd74T+/fvx+CguVF2tJCksm/fPqxatQqf+9zn8J73vEd7jk6TtGLFCrzyyiuhL6KZVCoV3H333XjTm96EQqH5rf3BZ3djplrz1P3HjA9g6XC8Gvrszgm8uGcSAHDaYSMYKLe5d8oYsSzy+Tzue3oXAGC4p4CTV40kTu932w/ipX1TGO4pYN9UBX3FPE5fvSBRGgenq/j5C3sAAOuWD2G0X99TTc5Wsfn37nkbVi/Q2r/r+MPeSfz7jgksHiijkLOwdd8UDlvYhyPGXCn9ty8fwPYD0wCA16xeKAWa4OybrOCxLXs908HJ2RpOXjmC4V6/fjz24l7sm3JXZxYNlHDCsqHIvDXaNh5+fg8mZtwV0N5iDhtWL0ychsgLuw/huV2HAPjP8JNnXsFszcGaRf1YtaDX+87b1U+efQWzVQdHLe7HihF3djtdqeGnz+0GAKxdPIDlI277m5ip4uHn3TJcOtSD4d4Cntx2wGurxbyN160ZjcznjgPT+M3LrpZ8fLDslR8ALBkq49glyfu6NGXxwDOvoFLX5Il1ai4zU3Xw4LOvAHDNaV5/ZHR5JcVUFi/unsSzuya876tH+zDSW8RjW/YCAE5cNoSxgfCZzi+37MOeyVkAwOvWjKKYQkr65R/2Yc+hWYz2l/DKxAxGeot49crhWNf+Yss+7K3f/w1HjTVkinPf07s88540ZcH71LxtoVzIYWKmiletGMbCPl/STNtHvbRvCr/bfhBj/SWMD5Xx65f2px5nTPC+nbNmrB+rFsoS9rb903hy2wEs6CvipBXD+NXW/XhlYkaaF/x+1yE8v9vt9xrpRzf/fjcmZ91Vq9H+EtYtjx4DRPZPVfDoi3s9t4TpSg2nrhqR9qVq9XyKMCOWxXQN+PkLe1HK53DGGrf+8PnR6tE+HD7aWWPDgQMHMDo6Gikkdby5ncjw8DCOOuooPPvss8ZzSqUSSqXgIFEoFNreoFqVh8HeIvYeqsBhbiCHYjH+fYvFAvK5fP1zEYVCV1WR2PCy4M9aKORTlc1ATwn5gxVM14B8Lo9SgnfNKTmWkA/z9QWmnhevbAp59znz+Tws281nWchnsVBAPucKGm5dCQpJxaJ7nW3XoxnmrEC9KhQKyM8yL80k7yFt2ygVC5iuW5vk87mG21dRrBP5eh3J5+HAQVH5LtYhhzne+QBQg62tWyWhDIvFvHc/3lYHe+K9h2Kh5qVTLhVQyFc9jY6YjzQkKYtCPg9WN5cqpmxD3QazHO/d5/N2U59ZLYuS0D/z36U6G6PsisUC8jOO9zmN30SpUEA+5wCWW8+T9J+FQt69tv48jfhCFPN5f9+2nJW4LIrMzX/OturPAvSUitp0kvZRxULV7TNzOeRy+fp7ynYOwPt2/57B9MvFmtd3FwoF5HK5QF7cMuH9Xvp2nM/nka+55VlK8awD9fpUddzyzOcslEr6eUgnzOkIl0KhACvvlh2z4JWLXa9rSecDrSBufjrfq0xgYmICzz33HJYsWdLurHQ06l4NSUJxZr37cqfjP266h+WaFb5fSBrTEVMktMB5hk1J42IM3CBGdDMGbvDT0O21pF7bqmg2WYQzFokVAtzw3fT8coAQ/3POsgKh0nX7rOgQ08zblhREoZX7F7ajzDuJVj+xNliIVAbRaeSlNpMOXtbVBoIDZREZ0LRxclzEfq1S7xyzikjGn9PdJ6k1IcB1bd9WgsNw0yHT68oq4mCaouUBMQB//6tOCNxARMODcjmOv6VFnD0VO52OFpI+9rGPYdOmTXjhhRfws5/9DG9961uRy+Vw8cUXtztrHY0aDjrJ4CGe2c0VOy6NhkhWo8rlUsxQJeEnJCNp8+hNBBi0G/TlDJN4kTgDvlR3WtSz5BoclFV0URpNIVKD3/V50YXk5uerbUxn6qjNpyKcmPa9ajbtum87ySpcchp0pmlqXYjCJMAngV8m7tcUF57fLOpL3I24o3AccVKeTeclRvtqVihkNbk4IcC9aw3jTkPR7SLyEgd1oWi+9CvdjijMztZNsJsV1bGVdLQt1datW3HxxRdj9+7dGBsbwxlnnIGHHnoIY2Nj7c5aR6P6qiTprLLafbnbSPuoqkCaZgO9uJok0zXR57onM0C7wXCcTSz56Q5j3ipRcJ8SveDVTHIZrIqLxNljSBUkPSFKSkcveIppiZvJcuLudyVrkmzkLD+scyubrXiv+dRfcFo9gYvaGyhOdsT9+dLmnre7RjVJjdJoP6PLd1aaJN0eTNkLSXJ6sUKAR3ihN6RJMuy/l4TeYg6HZvyIfaRJ6g4syzWPrNaY1y94e3V2cRl2tJB0yy23tDsLXUm5IK+EtWM39G4hsAdOQgo52+sYgMb3A2jGK+dJMsa8fEr7YRn2TJLT4Kp05g2yAXM78XOL6k4Wq+IiOpNGfkQVmgLCkkHYNbWpnEaT1JtGk2Srwl3r2q20500XD4RJsAyfW0FwbzIrsRYgi37dE5JqafZJyi4fsrld8usDmpiclVn7kRaWWrSirnunQU1SMC9Z9d3yQlG6NERtumXNn35lLlDI2ajW/G05WmVm2kw62tyOSIdqspOkk5lvQpK3MWgDSYir/41uotrsDTn5aqK4Oieb2+kRTfY4Yavardo8TloVz+CWWksbTzgKaozE+0obxRo0XKrwlI1Pki37JLWw2cqmXq27b8fQ4mcOmLhaySemuQYFC/E+aTQk/NxszO0a6zvVKwoZ2gn7JsrMX1HPWpMUuKc5HzXFTySqr0+VnwzmD+J4SgJSd8HnFZUar2vNMTNtJSQkzUFE50cg3QDmfs40Wx2JqiVIgyiUNhq4IWycT+sL4Qk48AdK0wqsaVDSmnGoEzYlKEErsGMIeKnTM2iM1N8jv5s0SbYVCKBRihmOWdUkmcwnm42dsp/pZkyBOFqBbvEh6cRU9uNLl/8os78412YxvuRiBJ2JkxdOPiNTOzFtxsR+N7PkAcTzSeLHGKtbAngX69NppB1LmuWU6YgLRWRq110U6uMX933miwPdPDSQkDRHETuaNNHtLKu1k612YXkDdvpn7ZWEpDSBG8T8hJ2XLo/8OnGwljRJtl/mxjSU32w7WD/SCnGNkM9gVVwkLLqd90tAONQe1gpZ6mREvF+5kIvd5lT/r3ZpdOLW3blEO585LLAIEC8/uVx0e4/MRwxfGPO19f8ZVNRGxyj18qz8kQDAqg8FrslRkwI3BEx+NUKScKxmcEiStOCNaJLE+zbgk+SlMV86lTkC18Rys36T/3I3QULSHEW1641Llvbi3UAWT5lWIOXE1YbINuTx7+Nfx7SBG+KYv8SZFLXD3E6+T+P3tEPesSr0BO4W0CQFJ6OyD4/8HuMGbVDzmbfttkWZy2LluJtp9RPrNDhpNUmNFJfavpP5vRraT5p8NKhJVoWKrCLbAaK5neDA3uQKo41+aPtbDdQEn9KoSKZpyCLwU5nM7boWromt1GRNUjePDSQkzVFk7UbyCXUX1+lEZPGckk9SipVI0yQ6K3iKDkP4Pkkht1arkFZIklYjWy8kZXFLXaQ/k4bIqEKK+Jm/b1UDFDf8N6CYxdrZTE7SkDT89Fyj1dp2dREmTJtrTCODiac6eU3yHvilWeQjJ69qpELMepqNdU2IgRu8UOlZa5IC/bIpL+4PrpCkCdyQUbayWCjL2RZK9eBTZG7XXXBNbNVRfZLalqWGISFpjtLToLndfJvwNPK8PQ2aB8g+DiHnSdckvo2nAgfkfHomlmH3Vm4Y6RvRqn2SMu59dcn5K9/h91J/N7Ulfp5tyT5JvZpd5eOg+ja11CdJqkctu21bkTU37bs34LbZxJokO159DkMXQCL+tVyT1fjLy2ZhxP+cpbmd75PUxH2SDPdUEUO2e5vJGtLMSpPU0Jhan7+QJqm74JpYVZPUza4bJCTNUdKqrPmZ80VIysLxupzP+WaKKVtUUzV49TT91Uy5TuQMk3kVO8JJWlpFbFH9aWrgBv5fKZuAZomb3xkmjqbjtu2GG+bfy8X4lUcNANGuiXuztaCdSJx9xZpFIOy+pfgkJUmjgbyr7TtddLv09/fyIUWRTJegFCkyQ00ST9Zx/Ihyze4XTYtG/Li4hYOpvWa1wNXIHILPX0iT1F1wczvPJ4k0SUSnwrUbSVfa+fmt0gS0m0aFG/day+vU04aQ5UJLXL+gJAMQnzxU6rZ2AX+CGPcGgsECTPdJmr9GyGesQdGZrXlzSkG4Ec/1HNFVbZthxZyfx8uB/2/EJyltNMtGmY+aJJnWPnSUL2Ccss/HbO9hBOt0/Gu5SXLmIcBTJideluWkXMybuECVKUp6Rk0SN7czBW5IWIdMZNUf9KacvxDthZurVpR9krq5HDt6M1kiPf2lPFYu7EU5H3/iBQCD5QKWDJexoK/YpJx1Fp62oMHJzhFj/dh9aAZDPYV014/2Y7paC90nx7YtrB7rA0M6P7NafXWnpNSJwXIeS4d7MNwbnnfxjtHmdi3SJBn2I0qLPD9wv6xc0IdSfhoLet02sWphL3YWZjBS/37YaB92HZzBsFL2h4/1Ye+hCgbLcje7eqwPB6er6KtPBI4Y68fkbA0D5fh1J5+zcfhYHyy4ZdEun6QsfBC6mbZrkmChkLNx2GifWw9ilEFfKY/lC3rQV0w//OvyEZfR/iIWD5axfKQn9f05WWiSXYHP7Ruz9Unyc1TVbL3QDEzJ8xX+msPADe5MOWkkh1n1B0uHe3Bopoblw70N5IZoNeo+Sd4myi0PcZMdJCTNYY5aPJD4Gtu2cNzSoSbkpkMxmEQlZXyojPGhcurrVy6MNxisHutPnLb6aGqAAMuycOzSwch0bGEyodPatCMMdStCgI8NlDA2UPKOLxooY9GAX9aLB8tYPBgs+yVDPVgyFJwILh+Ry3rFgnQTgSOEutDKDYlFZFOv7h0Ik2JZrglVO57Ytv0ALLzY1yxK1i8cPR7d3kPzoDx4krZXyudwwvJsxpgs+hlJK5upT5L/uVpfWc+6X5Q3sA4xoeOaJIfxLtxoKtuIRl4OKJM+nXIhuzpCtA51nySmqWvdxjwxqiIIPcZwznOYJGZdItGmFII5XhtCgGcxSc8gWFZbkM3tWnffKD+1uYrvb9b6h87aDy9VHgwmu60mi4AlYr+R1lxam67gb1hr0n4xcc3kuEN9TQrcYBKomp8fYm4i7pPEmO//1s1WBiQkEQTm9gRPnTykF5L8z5Hmdi16oVmHALczWlFtNe0Kxa0GkJhvtEWTJKkA2pABNQ/ty0Y2PklN0iQBfv6qTfJJEpML9WfV7JMEQzVqTJPkf6aNYOcfolknr/NAdwvMJCQR8xq/7XZvI45CfbIkUdRMCen3SQr/vRlkPRB3a8jZtvkkGfIwX2jHI3eCMNpIdLssycInUbwuayGp2ZokkbB6wTVJ4sTVRGPVqz39ENEZiObvs1XH+9wBXVZqSEgi5jW87c7lDl19tt6UDttR0fUs6fdUt0iMLYS/zqoM+aprN1UJOwOzozTE3eNrriHuddXye0sagPa8dfWx2zUJymKRRKzDWZrbAYovELKvL3HD0fN4FA4TAjdIPknC5wbq1HwP5DLfsSzLW2gQhaRusspQISGJmNf4G4XOH7LwSdKa2wmfWzlAZrE5pohXJ7qoUuTaIKCq9+pWLVwq2viouZgT46bmIRC5oT35sA0T/STw6+JGB0yCKhRlH7jBJ0xgFIU1z5leSiebOpXVZrJE98IjRM7yYCVdLmV0efYJojHa6YDdKsQBsJi3UwswUdHrRI1OK9+nJyRlpUnyBOfuqRPyZLH1mqRuHwjT0m5zu3bV0E40t0v7NvhVWZvaAboogM17T2ECnjZwgykSXgOSXLsWyojOgZvccU1StwvL83RoIwgXS/k/JxEeTg3/nSiZCK2BZ4LU4sExl7HmR908thsQ33k7NEndPhAmxe832mFu1/53HYhu1y4hKQOtGn+WLPdIUtP2vmetSZIWrkI0SVLghuA+SXI66fNjz/NFE8Ldww8AZkhIIoi5Q5e341DEZ0trauemE25KYbVpwpy1uV03durtMnPxJkVd+M6yoO2apDa+d3Ei3NU+SfX/hSZoktQUM/dJEvdJCkna0ySx6MANWfgkzdf+gPDb0Uy1BqD751YkJBHzGs9EbA7rksQna0STJPkkhQhJrQ79mrW5XdaBIFpBu8LtduO7yoJ2+q11yl5e7drAWMQS9+lKm0b9wnwT1B+qyVm7ottJmqT6MVMk+Sz2SSIhaf7C2xE3t+v2UPAkJBHznPZNdtpBQ5ok4bNuPuH5p7T4XTbL2boTzJriIq/qt94nqdsHwrS0YzLYrnDvKpJGq00zCTmIRUqfpPp1zfBJUvOUeXnFNLfj76nmMMAL3KA/v5F+z+sPyB9p3lJQott10ziqg4QkYl7T5e03FmIn1YiQFBkCnP/W4gEy75nbZUM3roLKZdPK+7r/u30gTEqnaHDaSSdEMpO1Wenwze2a4JNkqd8zNreLKSTJgRs0G9tm5pMUzBcxv8ir0e26vC6QkETMa3j7ncudelbmdlF7YIihdFuJr/nJKj33fzdViZzdngmr75PUslt2BL5ZUevvLUe3a6NPUpsEcykPGcxgPE1SEx6ipSHAY5rbRabZiCYJ81uzTAQ1Sd2+NQQJScS8Zj44nosRh0r59E1esmHXvK52vUu+ApyVNoN36t1UJ0RBsZXZbpdg3Dm0w9yurbf3kH2jOkCTlDIL/Dmao0lqnU9SrMANwj5JInEDQETmof4K529/QBTr7YjXs24aR3Xk250BgmgnKxb0ImdbWNhfbHdWmkZPMYflC3rQV8w3JEhEBW5Y0FfE+FAZ40Pl1PdIw9LhMmarDpZkdN9VC3pRzNldVSeKeRuHjfYib9stNX1b0OuW+aLBUsvu2Um0JXCD3bhgkAW5DsiH5JOUUlBbMdILC1ZT6rD6XrJeVZcijoakXcz7QpIub/Ln9Hnk/cHiwdaOAUTnsKCviMWDZcxUa7AsYNXC3nZnqSFISCLmNQv6iljQ1z2T4bQcPT7YcBpRPgiFnI3jlw01fJ+kDJQLOGF5dvdd2F/Cwv7um/SvWTTQ8nvm21Tm7YZPyNshG2Thh5MFUVsCtIIshI6RviJGmjQGSH1mk+12QgM32BZKBRszFcc7ZhIqG3ml87U/IHzyOTvT8bjdkLkdQRCxkJyEyZyCmMf4oc9b3w46xd+jEzRJYj465LVIiIJRM+qK5JMUkb4atMcUAny+BWEhiDBISCIIIhaiXEQyEkG0SZPU5Il37HzEjKzWbDp5Tt/sCIBRfqIi5ZiRTalvJwgfEpIIgoiFOCEjx1xiPsNrf9v3SWr53fX5aGd30NGapBYuLEX1yWpkU5P2aC5vrE4QSSEhiSCIWHTCvigE0Um0oxl0ipmbHFmufRnpFPNDHc3225Kj0oWn36sKSYbzO/h1EkTLISGJIIhYiGMnCUnEvKaN1V/2JWmjcMJD5bd5FsEn+52oAckiRHkYsp9o+LkBnyTDZ+rbCcKHhCSCIGJhk7kdQUi0RZPUIZNYvq1Qu4WT7jG3a24Go+pFmE9SEt8mgphPkJBEEEQspFVLGkiJeYwXArzdPklt1Wh1hnDSyX1RK02Uo9Iv5W0l6Ee6dAhiPkFCEkEQsbAF8xoKE0sQ7Ypu1xltj2su2j2ptjtYk9TshaUk2zJYliVpk0zBGjqkehFER0BCEkEQseBjJwlIxHzH3yep9fcWJ7GdELih3d2Bl48O90lqhnCbVLjhfklhZUb9O0H4kJBEEEQs+IDfKT4RBNFu2jExl6LbtVEw4KZb7dYk5TpEWNPRynDtcfxEe4t5Ny/qqfXv7Q7CQRCdBjUJgiBiwcfgdk+KCKLd+Psktf7endL+OkWT1O77h9HswA1WwvTVCHfB9Dr4ZRJEGyAhiSCIeNBqI0HItFlIauec1gsB3m5NEvdJamsu9DR7A+6kobvLRbt+nXyuZz6aVcYIYo5A0x2CIGKRI3M7ggAgBDFpQ1sQJ9vtFFD4vTtGSOrAfqnZ/mNJhTCTT5JnSk1RGwhCIt/uDBAE0R0M9xYxPlTGooFSu7NCEG1l1cJe7CzMYKS32PJ752wLq8f6wNDeSe2Cvs7oD5YO92Cm4mDJULmt+dDRbIE2Z1s4fKwPFuLVhYFyASsW9AbM7vqKOSwb6cFgTyHzPBJEN0NCEkEQscjZFo5fNtTubBBE21k0UMaigfZNyleP9bft3pxO6Q/6S3mcsLz9+dAhR59rjkB7RMK6sHZ8IHDMsiwcs2QwqywRxJyBzO0IgiAIgiAyRvTfJEs2gug+SEgiCIIgCILIGDnIBklJBNFtkJBEEARBEASRMdJmsiQjEUTXQUISQRAEQRBExiTdx4ggiM6ChCSCIAiCIIiMkTVJJCQRRLdBQhJBEARBEETGNHufJIIgmgsJSQRBEARBEBkjaZLIKYkgug4SkgiCIAiCIDLGtilwA0F0MyQkEQRBEARBNAG+VxL5JBFE90FCEkEQBEEQRBPg+yORjEQQ3QcJSQRBEARBEE2Aa5BIk0QQ3QcJSQRBEARBEE2A+yKRkEQQ3QcJSQRBEARBEE0gVxeOciQkEUTXkW93BgiCIAiCIOYih4/1Ye+hCgZ7aLpFEN0GtVqCIAiCIIgmsGSoB0uGetqdDYIgUkDmdgRBEARBEARBEAIkJBEEQRAEQRAEQQiQkEQQBEEQBEEQBCFAQhJBEARBEARBEIQACUkEQRAEQRAEQRACJCQRBEEQBEEQBEEIkJBEEARBEARBEAQhQEISQRAEQRAEQRCEAAlJBEEQBEEQBEEQAl0hJN1444047LDDUC6XsX79evz85z9vd5YIgiAIgiAIgpijdLyQ9J3vfAdXXXUVrr32WvziF7/AunXrsHHjRuzcubPdWSMIgiAIgiAIYg7S8ULS5z73Obz3ve/F5ZdfjmOPPRZf/vKX0dvbi6997WvtzhpBEARBEARBEHOQfLszEMbs7Cwee+wxXH311d4x27Zx1llnYfPmzdprZmZmMDMz430/cOAAAKBSqaBSqTQ3wwb4fdt1f8KHyqKzoPLoHKgsOgcqi86ByqKzoPLoHLq5LOLm2WKMsSbnJTUvv/wyli1bhp/97GfYsGGDd/wTn/gENm3ahIcffjhwzXXXXYfrr78+cPxb3/oWent7m5pfgiAIgiAIgiA6l8nJSbzzne/E/v37MTg4aDyvozVJabj66qtx1VVXed8PHDiAFStW4Oyzzw59Ec2kUqng7rvvxpve9CYUCoW25IFwobLoLKg8Ogcqi86ByqJzoLLoLKg8OoduLgtuZRZFRwtJo6OjyOVy2LFjh3R8x44dGB8f115TKpVQKpUCxwuFQtsLsRPyQLhQWXQWVB6dA5VF50Bl0TlQWXQWVB6dQzeWRdz8dnTghmKxiJNPPhn33nuvd8xxHNx7772S+R1BEARBEARBEERWdLQmCQCuuuoqXHrppTjllFNw2mmn4fOf/zwOHTqEyy+/vN1ZIwiCIAiCIAhiDtLxQtLb3/527Nq1C9dccw22b9+OV73qVbjrrruwePHiWNfzuBRx7Q+bQaVSweTkJA4cONB1Ksm5BpVFZ0Hl0TlQWXQOVBadA5VFZ0Hl0Tl0c1lwmSAqdl1HR7fLgq1bt2LFihXtzgZBEARBEARBEB3CH/7wByxfvtz4+5wXkhzHwcsvv4yBgQFYltWWPPAIe3/4wx/aFmGPcKGy6CyoPDoHKovOgcqic6Cy6CyoPDqHbi4LxhgOHjyIpUuXwrbN4Rk63tyuUWzbDpUSW8ng4GDXVaS5CpVFZ0Hl0TlQWXQOVBadA5VFZ0Hl0Tl0a1kMDQ1FntPR0e0IgiAIgiAIgiBaDQlJBEEQBEEQBEEQAiQktYBSqYRrr71Wu8kt0VqoLDoLKo/Ogcqic6Cy6ByoLDoLKo/OYT6UxZwP3EAQBEEQBEEQBJEE0iQRBEEQBEEQBEEIkJBEEARBEARBEAQhQEISQRAEQRAEQRCEAAlJBEEQBEEQBEEQAiQktYAbb7wRhx12GMrlMtavX4+f//zn7c7SnOe6666DZVnS39FHH+39Pj09jSuvvBILFy5Ef38/LrroIuzYsaONOZ47PPDAAzjvvPOwdOlSWJaF73//+9LvjDFcc801WLJkCXp6enDWWWfhmWeekc7Zs2cPLrnkEgwODmJ4eBjvec97MDEx0cKnmBtElcVll10WaCfnnHOOdA6VRTbccMMNOPXUUzEwMIBFixbhggsuwNNPPy2dE6df2rJlC97ylregt7cXixYtwsc//nFUq9VWPkrXE6cs3vCGNwTaxvvf/37pHCqLxrnppptw4oknehuSbtiwAXfeeaf3O7WJ1hJVHvOtXZCQ1GS+853v4KqrrsK1116LX/ziF1i3bh02btyInTt3tjtrc57jjjsO27Zt8/4efPBB77ePfOQj+L//9//i1ltvxaZNm/Dyyy/jwgsvbGNu5w6HDh3CunXrcOONN2p//+xnP4svfOEL+PKXv4yHH34YfX192LhxI6anp71zLrnkEvz2t7/F3XffjTvuuAMPPPAA3ve+97XqEeYMUWUBAOecc47UTr797W9Lv1NZZMOmTZtw5ZVX4qGHHsLdd9+NSqWCs88+G4cOHfLOieqXarUa3vKWt2B2dhY/+9nP8E//9E+4+eabcc0117TjkbqWOGUBAO9973ultvHZz37W+43KIhuWL1+Oz3zmM3jsscfw6KOP4o1vfCPOP/98/Pa3vwVAbaLVRJUHMM/aBSOaymmnncauvPJK73utVmNLly5lN9xwQxtzNfe59tpr2bp167S/7du3jxUKBXbrrbd6x5566ikGgG3evLlFOZwfAGC33Xab991xHDY+Ps7+5m/+xju2b98+ViqV2Le//W3GGGNPPvkkA8AeeeQR75w777yTWZbFXnrppZblfa6hlgVjjF166aXs/PPPN15DZdE8du7cyQCwTZs2Mcbi9Us//OEPmW3bbPv27d45N910ExscHGQzMzOtfYA5hFoWjDH2R3/0R+xDH/qQ8Roqi+YxMjLCvvrVr1Kb6BB4eTA2/9oFaZKayOzsLB577DGcddZZ3jHbtnHWWWdh8+bNbczZ/OCZZ57B0qVLsXr1alxyySXYsmULAOCxxx5DpVKRyuXoo4/GypUrqVyazPPPP4/t27dL735oaAjr16/33v3mzZsxPDyMU045xTvnrLPOgm3bePjhh1ue57nO/fffj0WLFmHt2rW44oorsHv3bu83KovmsX//fgDAggULAMTrlzZv3owTTjgBixcv9s7ZuHEjDhw4IK30EslQy4LzzW9+E6Ojozj++ONx9dVXY3Jy0vuNyiJ7arUabrnlFhw6dAgbNmygNtFm1PLgzKd2kW93BuYyr7zyCmq1mlRZAGDx4sX43e9+16ZczQ/Wr1+Pm2++GWvXrsW2bdtw/fXX43Wvex1+85vfYPv27SgWixgeHpauWbx4MbZv396eDM8T+PvVtQn+2/bt27Fo0SLp93w+jwULFlD5ZMw555yDCy+8EIcffjiee+45/NVf/RXOPfdcbN68GblcjsqiSTiOgw9/+MN47Wtfi+OPPx4AYvVL27dv17Yd/huRHF1ZAMA73/lOrFq1CkuXLsUTTzyB//yf/zOefvppfO973wNAZZElv/71r7FhwwZMT0+jv78ft912G4499lg8/vjj1CbagKk8gPnXLkhIIuYk5557rvf5xBNPxPr167Fq1Sr8n//zf9DT09PGnBFE5/COd7zD+3zCCSfgxBNPxBFHHIH7778fZ555ZhtzNre58sor8Zvf/EbykyTag6ksRL+7E044AUuWLMGZZ56J5557DkcccUSrszmnWbt2LR5//HHs378f3/3ud3HppZdi06ZN7c7WvMVUHscee+y8axdkbtdERkdHkcvlApFYduzYgfHx8Tblan4yPDyMo446Cs8++yzGx8cxOzuLffv2SedQuTQf/n7D2sT4+HggsEm1WsWePXuofJrM6tWrMTo6imeffRYAlUUz+MAHPoA77rgDP/7xj7F8+XLveJx+aXx8XNt2+G9EMkxloWP9+vUAILUNKotsKBaLWLNmDU4++WTccMMNWLduHf7u7/6O2kSbMJWHjrneLkhIaiLFYhEnn3wy7r33Xu+Y4zi49957JftOovlMTEzgueeew5IlS3DyySejUChI5fL0009jy5YtVC5N5vDDD8f4+Lj07g8cOICHH37Ye/cbNmzAvn378Nhjj3nn3HfffXAcx+uQieawdetW7N69G0uWLAFAZZEljDF84AMfwG233Yb77rsPhx9+uPR7nH5pw4YN+PWvfy0JrnfffTcGBwc9cxgimqiy0PH4448DgNQ2qCyag+M4mJmZoTbRIfDy0DHn20W7I0fMdW655RZWKpXYzTffzJ588kn2vve9jw0PD0uRP4js+ehHP8ruv/9+9vzzz7Of/vSn7KyzzmKjo6Ns586djDHG3v/+97OVK1ey++67jz366KNsw4YNbMOGDW3O9dzg4MGD7Je//CX75S9/yQCwz33uc+yXv/wle/HFFxljjH3mM59hw8PD7Ac/+AF74okn2Pnnn88OP/xwNjU15aVxzjnnsJNOOok9/PDD7MEHH2RHHnkku/jii9v1SF1LWFkcPHiQfexjH2ObN29mzz//PLvnnnvYq1/9anbkkUey6elpLw0qi2y44oor2NDQELv//vvZtm3bvL/JyUnvnKh+qVqtsuOPP56dffbZ7PHHH2d33XUXGxsbY1dffXU7HqlriSqLZ599lv31X/81e/TRR9nzzz/PfvCDH7DVq1ez17/+9V4aVBbZ8MlPfpJt2rSJPf/88+yJJ55gn/zkJ5llWexHP/oRY4zaRKsJK4/52C5ISGoBX/ziF9nKlStZsVhkp512GnvooYfanaU5z9vf/na2ZMkSViwW2bJly9jb3/529uyzz3q/T01Nsb/8y79kIyMjrLe3l731rW9l27Zta2OO5w4//vGPGYDA36WXXsoYc8OAf+pTn2KLFy9mpVKJnXnmmezpp5+W0ti9eze7+OKLWX9/PxscHGSXX345O3jwYBueprsJK4vJyUl29tlns7GxMVYoFNiqVavYe9/73sACDpVFNujKAQD7+te/7p0Tp1964YUX2Lnnnst6enrY6Ogo++hHP8oqlUqLn6a7iSqLLVu2sNe//vVswYIFrFQqsTVr1rCPf/zjbP/+/VI6VBaN8+d//uds1apVrFgssrGxMXbmmWd6AhJj1CZaTVh5zMd2YTHGWOv0VgRBEARBEARBEJ0N+SQRBEEQBEEQBEEIkJBEEARBEARBEAQhQEISQRAEQRAEQRCEAAlJBEEQBEEQBEEQAiQkEQRBEARBEARBCJCQRBAEQRAEQRAEIUBCEkEQBEEQBEEQhAAJSQRBEARBEARBEAIkJBEEQRBdywsvvADLsvD444837R6XXXYZLrjgAu/7G97wBnz4wx9u2v0IgiCI9kNCEkEQBNE2LrvsMliWFfg755xzYl2/YsUKbNu2Dccff3yTc+rzve99D5/+9Kdbdj+CIAii9eTbnQGCIAhifnPOOefg61//unSsVCrFujaXy2F8fLwZ2TKyYMGClt6PIAiCaD2kSSIIgiDaSqlUwvj4uPQ3MjICALAsCzfddBPOPfdc9PT0YPXq1fjud7/rXaua2+3duxeXXHIJxsbG0NPTgyOPPFISwH7961/jjW98I3p6erBw4UK8733vw8TEhPd7rVbDVVddheHhYSxcuBCf+MQnwBiT8qua2+3duxfvfve7MTIygt7eXpx77rl45plnmvCmCIIgiFZBQhJBEATR0XzqU5/CRRddhF/96le45JJL8I53vANPPfWU8dwnn3wSd955J5566incdNNNGB0dBQAcOnQIGzduxMjICB555BHceuutuOeee/CBD3zAu/5//+//jZtvvhlf+9rX8OCDD2LPnj247bbbQvN32WWX4dFHH8Xtt9+OzZs3gzGGN7/5zahUKtm9BIIgCKKlkJBEEARBtJU77rgD/f390t//+B//w/v9bW97G/7iL/4CRx11FD796U/jlFNOwRe/+EVtWlu2bMFJJ52EU045BYcddhjOOussnHfeeQCAb33rW5iensY3vvENHH/88XjjG9+IL33pS/jnf/5n7NixAwDw+c9/HldffTUuvPBCHHPMMfjyl7+MoaEhY96feeYZ3H777fjqV7+K173udVi3bh2++c1v4qWXXsL3v//97F4SQRAE0VLIJ4kgCIJoK3/8x3+Mm266STom+v1s2LBB+m3Dhg3GaHZXXHEFLrroIvziF7/A2WefjQsuuACvec1rAABPPfUU1q1bh76+Pu/81772tXAcB08//TTK5TK2bduG9evXe7/n83mccsopAZM7zlNPPYV8Pi9ds3DhQqxdu9ao7SIIgiA6HxKSCIIgiLbS19eHNWvWZJLWueeeixdffBE//OEPcffdd+PMM8/ElVdeif/1v/5XJukTBEEQ8wMytyMIgiA6moceeijw/ZhjjjGePzY2hksvvRT/8i//gs9//vP4yle+AgA45phj8Ktf/QqHDh3yzv3pT38K27axdu1aDA0NYcmSJXj44Ye936vVKh577DHjvY455hhUq1Xpmt27d+Ppp5/Gsccem/hZCYIgiM6ANEkEQRBEW5mZmcH27dulY/l83gu4cOutt+KUU07BGWecgW9+85v4+c9/jn/8x3/UpnXNNdfg5JNPxnHHHYeZmRnccccdnkB1ySWX4Nprr8Wll16K6667Drt27cIHP/hBvOtd78LixYsBAB/60Ifwmc98BkceeSSOPvpofO5zn8O+ffuMeT/yyCNx/vnn473vfS/+4R/+AQMDA/jkJz+JZcuW4fzzz8/g7RAEQRDtgDRJBEEQRFu56667sGTJEunvjDPO8H6//vrrccstt+DEE0/EN77xDXz72982ammKxSKuvvpqnHjiiXj961+PXC6HW265BQDQ29uLf/u3f8OePXtw6qmn4k//9E9x5pln4ktf+pJ3/Uc/+lG8613vwqWXXooNGzZgYGAAb33rW0Pz//Wvfx0nn3wy/uRP/gQbNmwAYww//OEPUSgUMng7BEEQRDuwmMkblSAIgiDajGVZuO2223DBBRe0OysEQRDEPII0SQRBEARBEARBEAIkJBEEQRAEQRAEQQhQ4AaCIAiiYyGLcIIgCKIdkCaJIAiCIAiCIAhCgIQkgiAIgiAIgiAIARKSCIIgCIIgCIIgBEhIIgiCIAiCIAiCECAhiSAIgiAIgiAIQoCEJIIgCIIgCIIgCAESkgiCIAiCIAiCIARISCIIgiAIgiAIghD4/wGCpw1KD4nAIgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Lambda, Add, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# ==== Constantes ====\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "\n",
        "# ==== Procesador de observaciones ====\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        img = Image.fromarray(observation).resize(INPUT_SHAPE).convert('L')\n",
        "        return np.array(img).astype('uint8')\n",
        "    def process_state_batch(self, batch):\n",
        "        return batch.astype('float32') / 255.\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "# ==== Modelo Dueling CNN ====\n",
        "def build_dueling_model(nb_actions, input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Permute((2, 3, 1))(inputs)\n",
        "    x = Conv2D(32, 8, strides=4, activation='relu')(x)\n",
        "    x = Conv2D(64, 4, strides=2, activation='relu')(x)\n",
        "    x = Conv2D(64, 3, strides=1, activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Dueling streams\n",
        "    value = Dense(512, activation='relu')(x)\n",
        "    value = Dense(1)(value)\n",
        "\n",
        "    advantage = Dense(512, activation='relu')(x)\n",
        "    advantage = Dense(nb_actions)(advantage)\n",
        "\n",
        "    # Combine streams\n",
        "    advantage_mean = Lambda(lambda a: a - K.mean(a, axis=1, keepdims=True))(advantage)\n",
        "    q_values = Add()([value, advantage_mean])\n",
        "\n",
        "    return Model(inputs=inputs, outputs=q_values)\n",
        "\n",
        "# ==== Preparar entorno ====\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "# ==== Modelo y Memoria ====\n",
        "model = build_dueling_model(nb_actions, input_shape)\n",
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "\n",
        "# ==== Política refinada ====\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=1.0, value_min=0.05, value_test=0.01,\n",
        "                              nb_steps=250000)\n",
        "\n",
        "# ==== Agente DQN con hiperparámetros ajustados ====\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               memory=memory,\n",
        "               processor=AtariProcessor(),\n",
        "               nb_steps_warmup=50000,\n",
        "               enable_double_dqn=True,\n",
        "               target_model_update=30000,\n",
        "               policy=policy,\n",
        "               train_interval=4,\n",
        "               gamma=0.995)\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.0001), metrics=['mae'])\n",
        "\n",
        "# ==== Callbacks (opcional para guardar logs y pesos) ====\n",
        "checkpoint_weights_filename = f'dqn_{ENV_NAME}_refined_weights_{{step}}.h5f'\n",
        "log_filename = f'dqn_{ENV_NAME}_refined_log.json'\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_weights_filename, interval=100000),\n",
        "    FileLogger(log_filename, interval=100)\n",
        "]\n",
        "\n",
        "# ==== ENTRENAMIENTO REFINADO (250k pasos) ====\n",
        "dqn.fit(env,\n",
        "        nb_steps=250000,\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "# ==== Guardar pesos finales ====\n",
        "dqn.save_weights(f'dqn_{ENV_NAME}_dueling_double_refined.h5f', overwrite=True)\n",
        "\n",
        "# ==== Evaluación (20 episodios) ====\n",
        "history = dqn.test(env, nb_episodes=20, visualize=False)\n",
        "rewards = history.history['episode_reward']\n",
        "mean_reward = np.mean(rewards)\n",
        "print(f\"\\n🎯 Recompensa promedio tras refinamiento: {mean_reward:.2f}\")\n",
        "\n",
        "# ==== GRAFICAR REWARDS (usando log si existe) ====\n",
        "try:\n",
        "    with open(log_filename) as f:\n",
        "        log_data = json.load(f)\n",
        "\n",
        "    episode_rewards = log_data['episode_reward']\n",
        "    episodes = list(range(1, len(episode_rewards) + 1))\n",
        "\n",
        "    def moving_average(data, window_size=10):\n",
        "        return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "    smoothed_rewards = moving_average(episode_rewards)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(episodes, episode_rewards, alpha=0.3, label='Reward por episodio')\n",
        "    plt.plot(episodes[:len(smoothed_rewards)], smoothed_rewards, color='red', label='Media móvil (10)')\n",
        "    plt.xlabel('Episodio')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.title('Evolución del reward durante el entrenamiento refinado')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"No se pudo generar la gráfica. ¿Ejecutaste con `FileLogger` activado?\")\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlLFEZfvUzRN"
      },
      "source": [
        "# Comparación de DQN base y variantes (Double DQN, Dueling DQN, Boltzmann Policy)\n",
        "\n",
        "## DQN con política ε-greedy (Baseline)\n",
        "El Deep Q-Network (DQN) es un algoritmo de Aprendizaje por Refuerzo basado en Q-learning que usa una red neuronal para aproximar la función de valor Q(s, a). Su política de exploración ε-greedy consiste en:\n",
        "\n",
        "- Con probabilidad ε: tomar una acción aleatoria (exploración).\n",
        "- Con probabilidad 1-ε: tomar la mejor acción estimada (explotación).\n",
        "\n",
        "**Arquitectura típica (DeepMind CNN):**\n",
        "- 3 capas convolucionales (32, 64, 64 filtros).\n",
        "- Flatten.\n",
        "- Capa densa de 512 neuronas.\n",
        "- Capa de salida con una neurona por acción (Q-values).\n",
        "\n",
        "**Desventajas:**\n",
        "- Tiende a **sobreestimar** los valores Q.\n",
        "- No distingue entre la calidad del estado y la ventaja relativa de cada acción.\n",
        "- La exploración aleatoria puede ser ineficiente.\n",
        "\n",
        "---\n",
        "\n",
        "##  Double DQN (Reducción de sobreestimación)\n",
        "Double DQN soluciona la sobreestimación de Q-values presente en DQN tradicional. Separa el proceso de **selección** y **evaluación** de la acción siguiente:\n",
        "\n",
        "- Selección con la red online: `argmax_a Q_online(s', a)`\n",
        "- Evaluación con la red objetivo: `Q_target(s', argmax_a Q_online(s', a))`\n",
        "\n",
        "Esto evita que un mismo valor inflado sea usado dos veces, estabilizando el entrenamiento.\n",
        "\n",
        " Mejora: aprendizaje más preciso y estable.\n",
        "\n",
        "---\n",
        "\n",
        "##  Dueling DQN (Arquitectura mejorada)\n",
        "Dueling DQN introduce dos flujos en la red después de la capa de Flatten:\n",
        "\n",
        "- **Value stream:** estima el valor del estado V(s)\n",
        "- **Advantage stream:** estima la ventaja A(s, a) de cada acción\n",
        "\n",
        "La salida se combina como:\n",
        "\n",
        "\n",
        "$$\n",
        "Q(s, a) = V(s) + \\left( A(s, a) - \\frac{1}{|\\mathcal{A}|} \\sum_{a'} A(s, a') \\right)\n",
        "$$\n",
        "\n",
        "Esto permite que la red aprenda a evaluar el estado sin necesidad de aprender el valor de cada acción en cada paso, lo que mejora la eficiencia del entrenamiento, especialmente cuando muchas acciones tienen efectos similares.\n",
        "\n",
        "✅ Mejora: eficiencia y generalización en estados complejos.\n",
        "\n",
        "---\n",
        "\n",
        "## 🔥 Boltzmann Policy (Exploración suave)\n",
        "En lugar de usar ε-greedy, se emplea una política **Boltzmann (softmax)** que asigna probabilidades de acción basadas en sus Q-values:\n",
        "\n",
        "$$\n",
        "P(a|s) = \\frac{e^{Q(s,a)/\\tau}}{\\sum_{a'} e^{Q(s,a')/\\tau}}\n",
        "$$\n",
        "\n",
        "Donde **τ** es la *temperatura*, que regula cuán aleatoria es la elección:\n",
        "\n",
        "- τ alto → exploración aleatoria\n",
        "- τ bajo → elección más determinista\n",
        "\n",
        "✅ Mejora: exploración más informada y gradual que ε-greedy.\n",
        "\n",
        "---\n",
        "\n",
        "Combinaciones posibles y su justificación\n",
        "\n",
        "### 🔹 Double DQN + Dueling DQN\n",
        "Esta combinación une dos mejoras clave sobre el DQN clásico:\n",
        "\n",
        "- **Double DQN** reduce el sesgo de sobreestimación en los valores Q. Utiliza una red para seleccionar la acción y otra para evaluar su valor. Esto hace que el entrenamiento sea más **estable** y los valores Q más **realistas**.\n",
        "  \n",
        "- **Dueling DQN** separa la estimación del **valor del estado** `V(s)` y la **ventaja de cada acción** `A(s,a)`, lo cual permite que el agente aprenda a evaluar mejor situaciones donde las acciones no tienen gran impacto diferencial.\n",
        "\n",
        "✅ **Ventaja combinada:**  \n",
        "Reduce el ruido en la estimación de Q y mejora la representación interna del estado. Es una de las configuraciones más comunes en entornos como Atari.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 Boltzmann Policy + Double/Dueling\n",
        "En vez de usar ε-greedy, esta combinación reemplaza la política de exploración por una **política Boltzmann**, que elige acciones con una probabilidad proporcional a sus valores Q:\n",
        "\n",
        "$$\n",
        "P(a|s) = \\frac{e^{Q(s,a)/\\tau}}{\\sum_{a'} e^{Q(s,a')/\\tau}}\n",
        "$$\n",
        "\n",
        "Donde `τ` (temperatura) regula la aleatoriedad:\n",
        "- Alta `τ` ⇒ más exploración (acciones casi igual de probables)\n",
        "- Baja `τ` ⇒ más explotación (acción con mayor Q domina)\n",
        "\n",
        " Cuando se combina con **Double DQN o Dueling DQN**, se obtiene:\n",
        "- Exploración **más informada** que ε-greedy\n",
        "- Aprovechamiento de estimaciones Q **más estables o estructuradas**\n",
        "- Puede acelerar la convergencia en ciertos entornos\n",
        "\n",
        " Pero **puede ser sensible a la elección de τ** y no siempre mejora el rendimiento frente a ε-greedy sin buen ajuste.\n",
        "\n",
        "---\n",
        "\n",
        " En resumen, la combinación de:\n",
        "- **Double DQN + Dueling + ε-greedy** → sólida, estándar, robusta  \n",
        "- **Double DQN + Dueling + Boltzmann** → exploración más sofisticada, pero requiere tuning de temperatura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P8mu_eamV5_k",
        "outputId": "9b34fbfb-1196-4d4b-b890-1376c79d7e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 500000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    420/500000: episode: 1, duration: 2.606s, episode steps: 420, steps per second: 161, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "    980/500000: episode: 2, duration: 4.530s, episode steps: 560, steps per second: 124, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1378/500000: episode: 3, duration: 2.631s, episode steps: 398, steps per second: 151, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2082/500000: episode: 4, duration: 4.181s, episode steps: 704, steps per second: 168, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2919/500000: episode: 5, duration: 5.756s, episode steps: 837, steps per second: 145, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3439/500000: episode: 6, duration: 3.852s, episode steps: 520, steps per second: 135, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3961/500000: episode: 7, duration: 3.090s, episode steps: 522, steps per second: 169, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4986/500000: episode: 8, duration: 6.808s, episode steps: 1025, steps per second: 151, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5736/500000: episode: 9, duration: 5.177s, episode steps: 750, steps per second: 145, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6175/500000: episode: 10, duration: 2.649s, episode steps: 439, steps per second: 166, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6591/500000: episode: 11, duration: 2.485s, episode steps: 416, steps per second: 167, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7268/500000: episode: 12, duration: 5.490s, episode steps: 677, steps per second: 123, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8020/500000: episode: 13, duration: 4.527s, episode steps: 752, steps per second: 166, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8816/500000: episode: 14, duration: 4.692s, episode steps: 796, steps per second: 170, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9199/500000: episode: 15, duration: 3.489s, episode steps: 383, steps per second: 110, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9850/500000: episode: 16, duration: 4.129s, episode steps: 651, steps per second: 158, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10791/500000: episode: 17, duration: 5.465s, episode steps: 941, steps per second: 172, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11502/500000: episode: 18, duration: 5.602s, episode steps: 711, steps per second: 127, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12881/500000: episode: 19, duration: 8.368s, episode steps: 1379, steps per second: 165, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13398/500000: episode: 20, duration: 4.984s, episode steps: 517, steps per second: 104, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14159/500000: episode: 21, duration: 4.509s, episode steps: 761, steps per second: 169, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15186/500000: episode: 22, duration: 6.704s, episode steps: 1027, steps per second: 153, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15880/500000: episode: 23, duration: 4.829s, episode steps: 694, steps per second: 144, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16524/500000: episode: 24, duration: 3.821s, episode steps: 644, steps per second: 169, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17189/500000: episode: 25, duration: 4.344s, episode steps: 665, steps per second: 153, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17835/500000: episode: 26, duration: 4.784s, episode steps: 646, steps per second: 135, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18344/500000: episode: 27, duration: 3.015s, episode steps: 509, steps per second: 169, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19273/500000: episode: 28, duration: 5.814s, episode steps: 929, steps per second: 160, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19770/500000: episode: 29, duration: 3.974s, episode steps: 497, steps per second: 125, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20252/500000: episode: 30, duration: 2.792s, episode steps: 482, steps per second: 173, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21271/500000: episode: 31, duration: 6.254s, episode steps: 1019, steps per second: 163, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21751/500000: episode: 32, duration: 4.184s, episode steps: 480, steps per second: 115, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22829/500000: episode: 33, duration: 6.366s, episode steps: 1078, steps per second: 169, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23228/500000: episode: 34, duration: 2.366s, episode steps: 399, steps per second: 169, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23611/500000: episode: 35, duration: 3.498s, episode steps: 383, steps per second: 109, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24411/500000: episode: 36, duration: 4.961s, episode steps: 800, steps per second: 161, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25067/500000: episode: 37, duration: 3.857s, episode steps: 656, steps per second: 170, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26025/500000: episode: 38, duration: 7.180s, episode steps: 958, steps per second: 133, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26767/500000: episode: 39, duration: 4.373s, episode steps: 742, steps per second: 170, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27510/500000: episode: 40, duration: 4.624s, episode steps: 743, steps per second: 161, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28031/500000: episode: 41, duration: 4.235s, episode steps: 521, steps per second: 123, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28909/500000: episode: 42, duration: 5.261s, episode steps: 878, steps per second: 167, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.339 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29475/500000: episode: 43, duration: 3.817s, episode steps: 566, steps per second: 148, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30048/500000: episode: 44, duration: 4.715s, episode steps: 573, steps per second: 122, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30692/500000: episode: 45, duration: 3.769s, episode steps: 644, steps per second: 171, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31475/500000: episode: 46, duration: 4.653s, episode steps: 783, steps per second: 168, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32080/500000: episode: 47, duration: 5.090s, episode steps: 605, steps per second: 119, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32929/500000: episode: 48, duration: 5.063s, episode steps: 849, steps per second: 168, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34093/500000: episode: 49, duration: 8.307s, episode steps: 1164, steps per second: 140, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34501/500000: episode: 50, duration: 2.431s, episode steps: 408, steps per second: 168, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35145/500000: episode: 51, duration: 3.900s, episode steps: 644, steps per second: 165, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36051/500000: episode: 52, duration: 6.796s, episode steps: 906, steps per second: 133, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36635/500000: episode: 53, duration: 3.444s, episode steps: 584, steps per second: 170, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37567/500000: episode: 54, duration: 5.517s, episode steps: 932, steps per second: 169, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38314/500000: episode: 55, duration: 5.877s, episode steps: 747, steps per second: 127, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39246/500000: episode: 56, duration: 5.596s, episode steps: 932, steps per second: 167, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39689/500000: episode: 57, duration: 2.675s, episode steps: 443, steps per second: 166, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40461/500000: episode: 58, duration: 6.055s, episode steps: 772, steps per second: 127, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41954/500000: episode: 59, duration: 9.708s, episode steps: 1493, steps per second: 154, episode reward: 14.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42630/500000: episode: 60, duration: 4.758s, episode steps: 676, steps per second: 142, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43401/500000: episode: 61, duration: 4.633s, episode steps: 771, steps per second: 166, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.202 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44279/500000: episode: 62, duration: 6.694s, episode steps: 878, steps per second: 131, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44794/500000: episode: 63, duration: 3.115s, episode steps: 515, steps per second: 165, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.173 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45281/500000: episode: 64, duration: 3.227s, episode steps: 487, steps per second: 151, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46356/500000: episode: 65, duration: 7.837s, episode steps: 1075, steps per second: 137, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.153 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47092/500000: episode: 66, duration: 4.335s, episode steps: 736, steps per second: 170, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.177 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47502/500000: episode: 67, duration: 2.433s, episode steps: 410, steps per second: 169, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.215 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48052/500000: episode: 68, duration: 3.951s, episode steps: 550, steps per second: 139, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.018 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49102/500000: episode: 69, duration: 6.908s, episode steps: 1050, steps per second: 152, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49883/500000: episode: 70, duration: 4.553s, episode steps: 781, steps per second: 172, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  50541/500000: episode: 71, duration: 38.235s, episode steps: 658, steps per second:  17, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.007592, mae: 0.018799, mean_q: 0.017192, mean_eps: 0.808966\n",
            "  51560/500000: episode: 72, duration: 68.436s, episode steps: 1019, steps per second:  15, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.005576, mae: 0.014946, mean_q: 0.007157, mean_eps: 0.806010\n",
            "  52243/500000: episode: 73, duration: 45.281s, episode steps: 683, steps per second:  15, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.006668, mae: 0.014170, mean_q: 0.007442, mean_eps: 0.802780\n",
            "  52945/500000: episode: 74, duration: 47.635s, episode steps: 702, steps per second:  15, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.007138, mae: 0.017035, mean_q: 0.012937, mean_eps: 0.800143\n",
            "  53328/500000: episode: 75, duration: 25.227s, episode steps: 383, steps per second:  15, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.006907, mae: 0.017946, mean_q: 0.003544, mean_eps: 0.798083\n",
            "  54075/500000: episode: 76, duration: 49.010s, episode steps: 747, steps per second:  15, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.006673, mae: 0.016004, mean_q: 0.015309, mean_eps: 0.795940\n",
            "  54704/500000: episode: 77, duration: 41.733s, episode steps: 629, steps per second:  15, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.008021, mae: 0.015639, mean_q: 0.013627, mean_eps: 0.793326\n",
            "  55461/500000: episode: 78, duration: 50.869s, episode steps: 757, steps per second:  15, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.007135, mae: 0.015931, mean_q: 0.009323, mean_eps: 0.790688\n",
            "  56817/500000: episode: 79, duration: 89.059s, episode steps: 1356, steps per second:  15, episode reward: 29.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.006989, mae: 0.018918, mean_q: 0.005499, mean_eps: 0.786668\n",
            "  57370/500000: episode: 80, duration: 37.326s, episode steps: 553, steps per second:  15, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.005531, mae: 0.015911, mean_q: 0.008588, mean_eps: 0.783043\n",
            "  58010/500000: episode: 81, duration: 42.299s, episode steps: 640, steps per second:  15, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.008249, mae: 0.019841, mean_q: 0.013218, mean_eps: 0.780778\n",
            "  58793/500000: episode: 82, duration: 52.192s, episode steps: 783, steps per second:  15, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.734 [0.000, 5.000],  loss: 0.006168, mae: 0.017469, mean_q: 0.008990, mean_eps: 0.778072\n",
            "  59202/500000: episode: 83, duration: 27.256s, episode steps: 409, steps per second:  15, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.756 [0.000, 5.000],  loss: 0.007164, mae: 0.017197, mean_q: 0.006971, mean_eps: 0.775808\n",
            "  59838/500000: episode: 84, duration: 42.128s, episode steps: 636, steps per second:  15, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.006552, mae: 0.014877, mean_q: 0.010220, mean_eps: 0.773824\n",
            "  60501/500000: episode: 85, duration: 43.734s, episode steps: 663, steps per second:  15, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.007754, mae: 0.019475, mean_q: 0.017441, mean_eps: 0.771354\n",
            "  60843/500000: episode: 86, duration: 23.454s, episode steps: 342, steps per second:  15, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.005846, mae: 0.017367, mean_q: 0.012944, mean_eps: 0.769446\n",
            "  61466/500000: episode: 87, duration: 41.956s, episode steps: 623, steps per second:  15, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.886 [0.000, 5.000],  loss: 0.007154, mae: 0.019998, mean_q: 0.004434, mean_eps: 0.767615\n",
            "  62261/500000: episode: 88, duration: 52.635s, episode steps: 795, steps per second:  15, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.006249, mae: 0.016551, mean_q: 0.016268, mean_eps: 0.764917\n",
            "  62877/500000: episode: 89, duration: 40.881s, episode steps: 616, steps per second:  15, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.007154, mae: 0.018086, mean_q: 0.012399, mean_eps: 0.762234\n",
            "  63517/500000: episode: 90, duration: 42.900s, episode steps: 640, steps per second:  15, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.006727, mae: 0.020213, mean_q: 0.015748, mean_eps: 0.759848\n",
            "  64109/500000: episode: 91, duration: 38.083s, episode steps: 592, steps per second:  16, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.007645, mae: 0.018223, mean_q: 0.017121, mean_eps: 0.757507\n",
            "  64695/500000: episode: 92, duration: 39.407s, episode steps: 586, steps per second:  15, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.006500, mae: 0.016757, mean_q: 0.009553, mean_eps: 0.755272\n",
            "  65573/500000: episode: 93, duration: 58.651s, episode steps: 878, steps per second:  15, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.006516, mae: 0.016942, mean_q: 0.013906, mean_eps: 0.752491\n",
            "  66065/500000: episode: 94, duration: 33.272s, episode steps: 492, steps per second:  15, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.636 [0.000, 5.000],  loss: 0.006647, mae: 0.017092, mean_q: 0.011819, mean_eps: 0.749884\n",
            "  66790/500000: episode: 95, duration: 47.436s, episode steps: 725, steps per second:  15, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.007265, mae: 0.019168, mean_q: 0.009660, mean_eps: 0.747574\n",
            "  68155/500000: episode: 96, duration: 91.505s, episode steps: 1365, steps per second:  15, episode reward: 15.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.773 [0.000, 5.000],  loss: 0.006626, mae: 0.017443, mean_q: 0.009122, mean_eps: 0.743606\n",
            "  68656/500000: episode: 97, duration: 32.720s, episode steps: 501, steps per second:  15, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.006235, mae: 0.014768, mean_q: 0.012519, mean_eps: 0.740065\n",
            "  69121/500000: episode: 98, duration: 32.600s, episode steps: 465, steps per second:  14, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.007352, mae: 0.018042, mean_q: 0.010868, mean_eps: 0.738226\n",
            "  69462/500000: episode: 99, duration: 21.698s, episode steps: 341, steps per second:  16, episode reward:  6.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.771 [0.000, 5.000],  loss: 0.006365, mae: 0.017862, mean_q: 0.006100, mean_eps: 0.736690\n",
            "  69940/500000: episode: 100, duration: 32.674s, episode steps: 478, steps per second:  15, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.006827, mae: 0.017533, mean_q: 0.015798, mean_eps: 0.735140\n",
            "  70445/500000: episode: 101, duration: 33.106s, episode steps: 505, steps per second:  15, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.921 [0.000, 5.000],  loss: 0.007000, mae: 0.017147, mean_q: 0.016656, mean_eps: 0.733270\n",
            "  71224/500000: episode: 102, duration: 51.603s, episode steps: 779, steps per second:  15, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.006426, mae: 0.016524, mean_q: 0.010728, mean_eps: 0.730831\n",
            "  71888/500000: episode: 103, duration: 43.626s, episode steps: 664, steps per second:  15, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.007118, mae: 0.018321, mean_q: 0.014161, mean_eps: 0.728095\n",
            "  72386/500000: episode: 104, duration: 32.586s, episode steps: 498, steps per second:  15, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006645, mae: 0.017394, mean_q: 0.017260, mean_eps: 0.725883\n",
            "  73206/500000: episode: 105, duration: 54.851s, episode steps: 820, steps per second:  15, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.007117, mae: 0.020171, mean_q: 0.015563, mean_eps: 0.723375\n",
            "  73573/500000: episode: 106, duration: 24.819s, episode steps: 367, steps per second:  15, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007016, mae: 0.019034, mean_q: 0.018852, mean_eps: 0.721118\n",
            "  74202/500000: episode: 107, duration: 41.502s, episode steps: 629, steps per second:  15, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.006583, mae: 0.019785, mean_q: 0.018631, mean_eps: 0.719226\n",
            "  74959/500000: episode: 108, duration: 50.684s, episode steps: 757, steps per second:  15, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.164 [0.000, 5.000],  loss: 0.007093, mae: 0.018455, mean_q: 0.024003, mean_eps: 0.716596\n",
            "  75821/500000: episode: 109, duration: 57.487s, episode steps: 862, steps per second:  15, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.008058, mae: 0.022843, mean_q: 0.019960, mean_eps: 0.713518\n",
            "  76277/500000: episode: 110, duration: 30.244s, episode steps: 456, steps per second:  15, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.008121, mae: 0.023132, mean_q: 0.015689, mean_eps: 0.711010\n",
            "  76930/500000: episode: 111, duration: 43.383s, episode steps: 653, steps per second:  15, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.006827, mae: 0.019763, mean_q: 0.009198, mean_eps: 0.708905\n",
            "  78310/500000: episode: 112, duration: 92.510s, episode steps: 1380, steps per second:  15, episode reward: 21.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.006714, mae: 0.019902, mean_q: 0.019409, mean_eps: 0.705044\n",
            "  79892/500000: episode: 113, duration: 104.097s, episode steps: 1582, steps per second:  15, episode reward: 26.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.007144, mae: 0.020382, mean_q: 0.018296, mean_eps: 0.699420\n",
            "  80687/500000: episode: 114, duration: 53.156s, episode steps: 795, steps per second:  15, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.006291, mae: 0.018422, mean_q: 0.016746, mean_eps: 0.694906\n",
            "  81317/500000: episode: 115, duration: 41.852s, episode steps: 630, steps per second:  15, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.086 [0.000, 5.000],  loss: 0.007474, mae: 0.019329, mean_q: 0.019852, mean_eps: 0.692192\n",
            "  81987/500000: episode: 116, duration: 44.721s, episode steps: 670, steps per second:  15, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.007005, mae: 0.020858, mean_q: 0.007005, mean_eps: 0.689722\n",
            "  82765/500000: episode: 117, duration: 51.694s, episode steps: 778, steps per second:  15, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.006999, mae: 0.019480, mean_q: 0.017624, mean_eps: 0.686971\n",
            "  83162/500000: episode: 118, duration: 26.543s, episode steps: 397, steps per second:  15, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.005571, mae: 0.020395, mean_q: 0.009395, mean_eps: 0.684737\n",
            "  83861/500000: episode: 119, duration: 47.078s, episode steps: 699, steps per second:  15, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.006732, mae: 0.017867, mean_q: 0.013970, mean_eps: 0.682654\n",
            "  84778/500000: episode: 120, duration: 61.187s, episode steps: 917, steps per second:  15, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.006144, mae: 0.022532, mean_q: 0.010871, mean_eps: 0.679584\n",
            "  85394/500000: episode: 121, duration: 41.036s, episode steps: 616, steps per second:  15, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.930 [0.000, 5.000],  loss: 0.006410, mae: 0.017807, mean_q: 0.012327, mean_eps: 0.676673\n",
            "  86104/500000: episode: 122, duration: 46.723s, episode steps: 710, steps per second:  15, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.007160, mae: 0.019705, mean_q: 0.022247, mean_eps: 0.674158\n",
            "  86545/500000: episode: 123, duration: 30.027s, episode steps: 441, steps per second:  15, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.006011, mae: 0.015215, mean_q: 0.012197, mean_eps: 0.671969\n",
            "  86937/500000: episode: 124, duration: 25.403s, episode steps: 392, steps per second:  15, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: 0.006280, mae: 0.021450, mean_q: 0.020482, mean_eps: 0.670380\n",
            "  87625/500000: episode: 125, duration: 46.845s, episode steps: 688, steps per second:  15, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.006785, mae: 0.024127, mean_q: 0.014153, mean_eps: 0.668328\n",
            "  88148/500000: episode: 126, duration: 34.028s, episode steps: 523, steps per second:  15, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.008747, mae: 0.025119, mean_q: 0.017164, mean_eps: 0.666033\n",
            "  88785/500000: episode: 127, duration: 42.487s, episode steps: 637, steps per second:  15, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.786 [0.000, 5.000],  loss: 0.006464, mae: 0.020921, mean_q: 0.017076, mean_eps: 0.663829\n",
            "  89190/500000: episode: 128, duration: 27.012s, episode steps: 405, steps per second:  15, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.007043, mae: 0.023308, mean_q: 0.011536, mean_eps: 0.661846\n",
            "  90032/500000: episode: 129, duration: 55.832s, episode steps: 842, steps per second:  15, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.007621, mae: 0.021855, mean_q: 0.024011, mean_eps: 0.659482\n",
            "  90828/500000: episode: 130, duration: 53.437s, episode steps: 796, steps per second:  15, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.721 [0.000, 5.000],  loss: 0.007023, mae: 0.022906, mean_q: 0.018504, mean_eps: 0.656374\n",
            "  91443/500000: episode: 131, duration: 41.086s, episode steps: 615, steps per second:  15, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.745 [0.000, 5.000],  loss: 0.006534, mae: 0.022676, mean_q: 0.017103, mean_eps: 0.653691\n",
            "  91780/500000: episode: 132, duration: 23.136s, episode steps: 337, steps per second:  15, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.005721, mae: 0.021991, mean_q: 0.012053, mean_eps: 0.651882\n",
            "  92605/500000: episode: 133, duration: 54.984s, episode steps: 825, steps per second:  15, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.005875, mae: 0.020959, mean_q: 0.011452, mean_eps: 0.649670\n",
            "  92999/500000: episode: 134, duration: 26.182s, episode steps: 394, steps per second:  15, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.008204, mae: 0.021576, mean_q: 0.023089, mean_eps: 0.647352\n",
            "  93440/500000: episode: 135, duration: 29.223s, episode steps: 441, steps per second:  15, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.007848, mae: 0.022705, mean_q: 0.021143, mean_eps: 0.645772\n",
            "  94095/500000: episode: 136, duration: 43.286s, episode steps: 655, steps per second:  15, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.006251, mae: 0.021153, mean_q: 0.018583, mean_eps: 0.643689\n",
            "  94582/500000: episode: 137, duration: 31.175s, episode steps: 487, steps per second:  16, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.006340, mae: 0.021213, mean_q: 0.019961, mean_eps: 0.641516\n",
            "  95392/500000: episode: 138, duration: 52.923s, episode steps: 810, steps per second:  15, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.006858, mae: 0.020218, mean_q: 0.015810, mean_eps: 0.639053\n",
            "  96305/500000: episode: 139, duration: 59.153s, episode steps: 913, steps per second:  15, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.007474, mae: 0.023244, mean_q: 0.021176, mean_eps: 0.635778\n",
            "  96799/500000: episode: 140, duration: 33.254s, episode steps: 494, steps per second:  15, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.005659, mae: 0.020277, mean_q: 0.019807, mean_eps: 0.633102\n",
            "  97613/500000: episode: 141, duration: 52.878s, episode steps: 814, steps per second:  15, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.005815, mae: 0.021201, mean_q: 0.024172, mean_eps: 0.630617\n",
            "  98382/500000: episode: 142, duration: 50.075s, episode steps: 769, steps per second:  15, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.758 [0.000, 5.000],  loss: 0.005992, mae: 0.020593, mean_q: 0.018324, mean_eps: 0.627608\n",
            "  98837/500000: episode: 143, duration: 29.703s, episode steps: 455, steps per second:  15, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.007400, mae: 0.022791, mean_q: 0.016403, mean_eps: 0.625282\n",
            " 100044/500000: episode: 144, duration: 80.784s, episode steps: 1207, steps per second:  15, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.822 [0.000, 5.000],  loss: 0.006986, mae: 0.022387, mean_q: 0.017875, mean_eps: 0.622128\n",
            " 100422/500000: episode: 145, duration: 25.795s, episode steps: 378, steps per second:  15, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.958 [0.000, 5.000],  loss: 0.007290, mae: 0.038094, mean_q: 0.048672, mean_eps: 0.619118\n",
            " 101052/500000: episode: 146, duration: 42.297s, episode steps: 630, steps per second:  15, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.007296, mae: 0.040328, mean_q: 0.046647, mean_eps: 0.617203\n",
            " 101671/500000: episode: 147, duration: 41.499s, episode steps: 619, steps per second:  15, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.005366, mae: 0.038555, mean_q: 0.044737, mean_eps: 0.614832\n",
            " 102292/500000: episode: 148, duration: 41.631s, episode steps: 621, steps per second:  15, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.006194, mae: 0.037406, mean_q: 0.042300, mean_eps: 0.612476\n",
            " 103462/500000: episode: 149, duration: 78.869s, episode steps: 1170, steps per second:  15, episode reward: 11.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.006731, mae: 0.038698, mean_q: 0.043686, mean_eps: 0.609071\n",
            " 104400/500000: episode: 150, duration: 61.749s, episode steps: 938, steps per second:  15, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.007467, mae: 0.041314, mean_q: 0.045375, mean_eps: 0.605066\n",
            " 104973/500000: episode: 151, duration: 38.823s, episode steps: 573, steps per second:  15, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.004537, mae: 0.032282, mean_q: 0.037275, mean_eps: 0.602193\n",
            " 105625/500000: episode: 152, duration: 43.252s, episode steps: 652, steps per second:  15, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.722 [0.000, 5.000],  loss: 0.006511, mae: 0.037808, mean_q: 0.041377, mean_eps: 0.599860\n",
            " 106854/500000: episode: 153, duration: 81.892s, episode steps: 1229, steps per second:  15, episode reward: 28.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.006986, mae: 0.039935, mean_q: 0.043266, mean_eps: 0.596288\n",
            " 107616/500000: episode: 154, duration: 51.525s, episode steps: 762, steps per second:  15, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.006943, mae: 0.038290, mean_q: 0.040921, mean_eps: 0.592511\n",
            " 108518/500000: episode: 155, duration: 59.927s, episode steps: 902, steps per second:  15, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006095, mae: 0.036221, mean_q: 0.039464, mean_eps: 0.589349\n",
            " 109252/500000: episode: 156, duration: 49.382s, episode steps: 734, steps per second:  15, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.006591, mae: 0.037089, mean_q: 0.040127, mean_eps: 0.586241\n",
            " 109892/500000: episode: 157, duration: 42.655s, episode steps: 640, steps per second:  15, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.839 [0.000, 5.000],  loss: 0.005603, mae: 0.033607, mean_q: 0.034897, mean_eps: 0.583634\n",
            " 110651/500000: episode: 158, duration: 50.812s, episode steps: 759, steps per second:  15, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.005806, mae: 0.036764, mean_q: 0.040467, mean_eps: 0.580974\n",
            " 111276/500000: episode: 159, duration: 42.484s, episode steps: 625, steps per second:  15, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.064 [0.000, 5.000],  loss: 0.007155, mae: 0.037334, mean_q: 0.039086, mean_eps: 0.578344\n",
            " 111893/500000: episode: 160, duration: 41.532s, episode steps: 617, steps per second:  15, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.006999, mae: 0.038566, mean_q: 0.044251, mean_eps: 0.575981\n",
            " 113020/500000: episode: 161, duration: 74.693s, episode steps: 1127, steps per second:  15, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.006541, mae: 0.037760, mean_q: 0.041317, mean_eps: 0.572667\n",
            " 113757/500000: episode: 162, duration: 50.412s, episode steps: 737, steps per second:  15, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.007190, mae: 0.039223, mean_q: 0.044019, mean_eps: 0.569126\n",
            " 114341/500000: episode: 163, duration: 38.581s, episode steps: 584, steps per second:  15, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.036 [0.000, 5.000],  loss: 0.006279, mae: 0.035117, mean_q: 0.040339, mean_eps: 0.566610\n",
            " 114953/500000: episode: 164, duration: 41.022s, episode steps: 612, steps per second:  15, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.006338, mae: 0.037540, mean_q: 0.044443, mean_eps: 0.564338\n",
            " 115447/500000: episode: 165, duration: 33.429s, episode steps: 494, steps per second:  15, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.005141, mae: 0.033482, mean_q: 0.035875, mean_eps: 0.562240\n",
            " 115889/500000: episode: 166, duration: 30.028s, episode steps: 442, steps per second:  15, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.005558, mae: 0.035585, mean_q: 0.038626, mean_eps: 0.560462\n",
            " 116322/500000: episode: 167, duration: 29.184s, episode steps: 433, steps per second:  15, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.790 [0.000, 5.000],  loss: 0.006219, mae: 0.036909, mean_q: 0.040745, mean_eps: 0.558797\n",
            " 117229/500000: episode: 168, duration: 62.409s, episode steps: 907, steps per second:  15, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.006401, mae: 0.035306, mean_q: 0.041703, mean_eps: 0.556251\n",
            " 117738/500000: episode: 169, duration: 33.455s, episode steps: 509, steps per second:  15, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.006280, mae: 0.037997, mean_q: 0.046187, mean_eps: 0.553561\n",
            " 118117/500000: episode: 170, duration: 25.379s, episode steps: 379, steps per second:  15, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.006463, mae: 0.037632, mean_q: 0.043867, mean_eps: 0.551874\n",
            " 118704/500000: episode: 171, duration: 39.426s, episode steps: 587, steps per second:  15, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006423, mae: 0.038500, mean_q: 0.045430, mean_eps: 0.550042\n",
            " 120359/500000: episode: 172, duration: 109.767s, episode steps: 1655, steps per second:  15, episode reward: 35.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.006593, mae: 0.038318, mean_q: 0.044448, mean_eps: 0.545786\n",
            " 120808/500000: episode: 173, duration: 30.003s, episode steps: 449, steps per second:  15, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.006260, mae: 0.038979, mean_q: 0.044004, mean_eps: 0.541788\n",
            " 121386/500000: episode: 174, duration: 39.363s, episode steps: 578, steps per second:  15, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.006177, mae: 0.035770, mean_q: 0.041842, mean_eps: 0.539835\n",
            " 122026/500000: episode: 175, duration: 42.753s, episode steps: 640, steps per second:  15, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.006930, mae: 0.041339, mean_q: 0.047963, mean_eps: 0.537517\n",
            " 123007/500000: episode: 176, duration: 66.299s, episode steps: 981, steps per second:  15, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.006270, mae: 0.037759, mean_q: 0.042281, mean_eps: 0.534439\n",
            " 123975/500000: episode: 177, duration: 64.773s, episode steps: 968, steps per second:  15, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.006636, mae: 0.037586, mean_q: 0.040750, mean_eps: 0.530738\n",
            " 124503/500000: episode: 178, duration: 35.831s, episode steps: 528, steps per second:  15, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.006096, mae: 0.037363, mean_q: 0.041976, mean_eps: 0.527896\n",
            " 125046/500000: episode: 179, duration: 37.031s, episode steps: 543, steps per second:  15, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.810 [0.000, 5.000],  loss: 0.006241, mae: 0.036126, mean_q: 0.041538, mean_eps: 0.525859\n",
            " 125641/500000: episode: 180, duration: 40.077s, episode steps: 595, steps per second:  15, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006531, mae: 0.038919, mean_q: 0.042438, mean_eps: 0.523693\n",
            " 126167/500000: episode: 181, duration: 33.550s, episode steps: 526, steps per second:  16, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.005693, mae: 0.036181, mean_q: 0.041307, mean_eps: 0.521565\n",
            " 126859/500000: episode: 182, duration: 45.875s, episode steps: 692, steps per second:  15, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.171 [0.000, 5.000],  loss: 0.005998, mae: 0.034934, mean_q: 0.037159, mean_eps: 0.519254\n",
            " 127691/500000: episode: 183, duration: 55.651s, episode steps: 832, steps per second:  15, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.006372, mae: 0.036665, mean_q: 0.042359, mean_eps: 0.516359\n",
            " 128329/500000: episode: 184, duration: 43.408s, episode steps: 638, steps per second:  15, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.007785, mae: 0.040438, mean_q: 0.048841, mean_eps: 0.513562\n",
            " 129050/500000: episode: 185, duration: 47.446s, episode steps: 721, steps per second:  15, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.005593, mae: 0.037612, mean_q: 0.043968, mean_eps: 0.510978\n",
            " 129699/500000: episode: 186, duration: 42.079s, episode steps: 649, steps per second:  15, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.903 [0.000, 5.000],  loss: 0.007452, mae: 0.041082, mean_q: 0.048860, mean_eps: 0.508379\n",
            " 130201/500000: episode: 187, duration: 33.237s, episode steps: 502, steps per second:  15, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.005615, mae: 0.034533, mean_q: 0.038277, mean_eps: 0.506190\n",
            " 131208/500000: episode: 188, duration: 64.900s, episode steps: 1007, steps per second:  16, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.883 [0.000, 5.000],  loss: 0.006612, mae: 0.039491, mean_q: 0.044295, mean_eps: 0.503325\n",
            " 131941/500000: episode: 189, duration: 48.734s, episode steps: 733, steps per second:  15, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.006437, mae: 0.037862, mean_q: 0.043563, mean_eps: 0.500019\n",
            " 133407/500000: episode: 190, duration: 95.895s, episode steps: 1466, steps per second:  15, episode reward: 21.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.306 [0.000, 5.000],  loss: 0.006208, mae: 0.036262, mean_q: 0.041588, mean_eps: 0.495839\n",
            " 133983/500000: episode: 191, duration: 36.841s, episode steps: 576, steps per second:  16, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: 0.007647, mae: 0.038539, mean_q: 0.045785, mean_eps: 0.491963\n",
            " 134881/500000: episode: 192, duration: 59.577s, episode steps: 898, steps per second:  15, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.287 [0.000, 5.000],  loss: 0.006020, mae: 0.037227, mean_q: 0.041086, mean_eps: 0.489158\n",
            " 135259/500000: episode: 193, duration: 23.989s, episode steps: 378, steps per second:  16, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.004884, mae: 0.035881, mean_q: 0.042253, mean_eps: 0.486734\n",
            " 136151/500000: episode: 194, duration: 59.109s, episode steps: 892, steps per second:  15, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.005806, mae: 0.037007, mean_q: 0.043252, mean_eps: 0.484325\n",
            " 137145/500000: episode: 195, duration: 65.358s, episode steps: 994, steps per second:  15, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.006553, mae: 0.039717, mean_q: 0.046020, mean_eps: 0.480738\n",
            " 137547/500000: episode: 196, duration: 25.761s, episode steps: 402, steps per second:  16, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.102 [0.000, 5.000],  loss: 0.005378, mae: 0.035358, mean_q: 0.038774, mean_eps: 0.478085\n",
            " 138180/500000: episode: 197, duration: 42.720s, episode steps: 633, steps per second:  15, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.005991, mae: 0.036627, mean_q: 0.044840, mean_eps: 0.476124\n",
            " 138692/500000: episode: 198, duration: 34.095s, episode steps: 512, steps per second:  15, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.006149, mae: 0.034917, mean_q: 0.037951, mean_eps: 0.473951\n",
            " 139073/500000: episode: 199, duration: 25.249s, episode steps: 381, steps per second:  15, episode reward:  1.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 3.050 [0.000, 5.000],  loss: 0.007213, mae: 0.040909, mean_q: 0.047068, mean_eps: 0.472248\n",
            " 139753/500000: episode: 200, duration: 44.437s, episode steps: 680, steps per second:  15, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.006577, mae: 0.037754, mean_q: 0.042467, mean_eps: 0.470227\n",
            " 140443/500000: episode: 201, duration: 45.131s, episode steps: 690, steps per second:  15, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.007009, mae: 0.039578, mean_q: 0.044990, mean_eps: 0.467628\n",
            " 140945/500000: episode: 202, duration: 34.457s, episode steps: 502, steps per second:  15, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: 0.006360, mae: 0.038591, mean_q: 0.040266, mean_eps: 0.465363\n",
            " 142147/500000: episode: 203, duration: 80.146s, episode steps: 1202, steps per second:  15, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.877 [0.000, 5.000],  loss: 0.006555, mae: 0.037670, mean_q: 0.042135, mean_eps: 0.462125\n",
            " 142840/500000: episode: 204, duration: 45.769s, episode steps: 693, steps per second:  15, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.841 [0.000, 5.000],  loss: 0.006883, mae: 0.037211, mean_q: 0.042673, mean_eps: 0.458530\n",
            " 143255/500000: episode: 205, duration: 31.523s, episode steps: 415, steps per second:  13, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.004957, mae: 0.035609, mean_q: 0.039239, mean_eps: 0.456425\n",
            " 143904/500000: episode: 206, duration: 50.692s, episode steps: 649, steps per second:  13, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.006953, mae: 0.037136, mean_q: 0.041668, mean_eps: 0.454404\n",
            " 144263/500000: episode: 207, duration: 27.386s, episode steps: 359, steps per second:  13, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.005358, mae: 0.032066, mean_q: 0.034475, mean_eps: 0.452488\n",
            " 144981/500000: episode: 208, duration: 52.387s, episode steps: 718, steps per second:  14, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.006015, mae: 0.036042, mean_q: 0.042937, mean_eps: 0.450436\n",
            " 145608/500000: episode: 209, duration: 44.415s, episode steps: 627, steps per second:  14, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.006201, mae: 0.037010, mean_q: 0.044151, mean_eps: 0.447883\n",
            " 146863/500000: episode: 210, duration: 84.339s, episode steps: 1255, steps per second:  15, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.005377, mae: 0.035878, mean_q: 0.037413, mean_eps: 0.444311\n",
            " 147820/500000: episode: 211, duration: 64.120s, episode steps: 957, steps per second:  15, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.005650, mae: 0.035434, mean_q: 0.038400, mean_eps: 0.440108\n",
            " 148395/500000: episode: 212, duration: 38.097s, episode steps: 575, steps per second:  15, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.005676, mae: 0.035610, mean_q: 0.036918, mean_eps: 0.437197\n",
            " 149451/500000: episode: 213, duration: 71.290s, episode steps: 1056, steps per second:  15, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.005993, mae: 0.036778, mean_q: 0.039819, mean_eps: 0.434096\n",
            " 149858/500000: episode: 214, duration: 27.302s, episode steps: 407, steps per second:  15, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.007131, mae: 0.037700, mean_q: 0.043188, mean_eps: 0.431315\n",
            " 150605/500000: episode: 215, duration: 50.735s, episode steps: 747, steps per second:  15, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.008747, mae: 0.057070, mean_q: 0.072559, mean_eps: 0.429118\n",
            " 151223/500000: episode: 216, duration: 41.512s, episode steps: 618, steps per second:  15, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.007011, mae: 0.055944, mean_q: 0.070132, mean_eps: 0.426527\n",
            " 151949/500000: episode: 217, duration: 49.456s, episode steps: 726, steps per second:  15, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.781 [0.000, 5.000],  loss: 0.007508, mae: 0.057544, mean_q: 0.068849, mean_eps: 0.423973\n",
            " 152618/500000: episode: 218, duration: 44.540s, episode steps: 669, steps per second:  15, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006643, mae: 0.054963, mean_q: 0.065423, mean_eps: 0.421321\n",
            " 153033/500000: episode: 219, duration: 27.941s, episode steps: 415, steps per second:  15, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.006002, mae: 0.057787, mean_q: 0.066538, mean_eps: 0.419261\n",
            " 153697/500000: episode: 220, duration: 44.407s, episode steps: 664, steps per second:  15, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.006909, mae: 0.054539, mean_q: 0.062953, mean_eps: 0.417209\n",
            " 154468/500000: episode: 221, duration: 52.654s, episode steps: 771, steps per second:  15, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.007780, mae: 0.058072, mean_q: 0.067407, mean_eps: 0.414488\n",
            " 154930/500000: episode: 222, duration: 30.960s, episode steps: 462, steps per second:  15, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.006176, mae: 0.056042, mean_q: 0.063781, mean_eps: 0.412148\n",
            " 156099/500000: episode: 223, duration: 79.668s, episode steps: 1169, steps per second:  15, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.006092, mae: 0.055660, mean_q: 0.063236, mean_eps: 0.409047\n",
            " 157071/500000: episode: 224, duration: 66.092s, episode steps: 972, steps per second:  15, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.007154, mae: 0.055227, mean_q: 0.062634, mean_eps: 0.404981\n",
            " 158112/500000: episode: 225, duration: 69.832s, episode steps: 1041, steps per second:  15, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.764 [0.000, 5.000],  loss: 0.006512, mae: 0.056778, mean_q: 0.065176, mean_eps: 0.401158\n",
            " 158926/500000: episode: 226, duration: 54.814s, episode steps: 814, steps per second:  15, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.100 [0.000, 5.000],  loss: 0.006753, mae: 0.056379, mean_q: 0.066762, mean_eps: 0.397632\n",
            " 160255/500000: episode: 227, duration: 88.023s, episode steps: 1329, steps per second:  15, episode reward: 18.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.006828, mae: 0.055965, mean_q: 0.064251, mean_eps: 0.393558\n",
            " 160933/500000: episode: 228, duration: 46.718s, episode steps: 678, steps per second:  15, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.006061, mae: 0.054950, mean_q: 0.061690, mean_eps: 0.389743\n",
            " 161722/500000: episode: 229, duration: 52.331s, episode steps: 789, steps per second:  15, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.005701, mae: 0.053215, mean_q: 0.060839, mean_eps: 0.386954\n",
            " 162811/500000: episode: 230, duration: 74.530s, episode steps: 1089, steps per second:  15, episode reward: 28.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.006551, mae: 0.054591, mean_q: 0.061988, mean_eps: 0.383389\n",
            " 163172/500000: episode: 231, duration: 24.289s, episode steps: 361, steps per second:  15, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.004958, mae: 0.051760, mean_q: 0.059682, mean_eps: 0.380638\n",
            " 164150/500000: episode: 232, duration: 65.034s, episode steps: 978, steps per second:  15, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.006840, mae: 0.054135, mean_q: 0.061389, mean_eps: 0.378092\n",
            " 164540/500000: episode: 233, duration: 26.471s, episode steps: 390, steps per second:  15, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.005486, mae: 0.053835, mean_q: 0.061343, mean_eps: 0.375493\n",
            " 164943/500000: episode: 234, duration: 27.406s, episode steps: 403, steps per second:  15, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.006099, mae: 0.051981, mean_q: 0.057447, mean_eps: 0.373988\n",
            " 166447/500000: episode: 235, duration: 102.137s, episode steps: 1504, steps per second:  15, episode reward: 18.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.753 [0.000, 5.000],  loss: 0.005661, mae: 0.054720, mean_q: 0.062933, mean_eps: 0.370363\n",
            " 167081/500000: episode: 236, duration: 43.219s, episode steps: 634, steps per second:  15, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.180 [0.000, 5.000],  loss: 0.006258, mae: 0.052668, mean_q: 0.059038, mean_eps: 0.366297\n",
            " 168021/500000: episode: 237, duration: 62.396s, episode steps: 940, steps per second:  15, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.006747, mae: 0.056308, mean_q: 0.063337, mean_eps: 0.363302\n",
            " 168835/500000: episode: 238, duration: 55.130s, episode steps: 814, steps per second:  15, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.005886, mae: 0.051815, mean_q: 0.060054, mean_eps: 0.359974\n",
            " 169775/500000: episode: 239, duration: 64.621s, episode steps: 940, steps per second:  15, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: 0.006560, mae: 0.056219, mean_q: 0.064844, mean_eps: 0.356645\n",
            " 170429/500000: episode: 240, duration: 44.052s, episode steps: 654, steps per second:  15, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: 0.006563, mae: 0.054195, mean_q: 0.062277, mean_eps: 0.353612\n",
            " 171147/500000: episode: 241, duration: 49.543s, episode steps: 718, steps per second:  14, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.776 [0.000, 5.000],  loss: 0.006245, mae: 0.055092, mean_q: 0.063416, mean_eps: 0.351006\n",
            " 171786/500000: episode: 242, duration: 42.822s, episode steps: 639, steps per second:  15, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.006518, mae: 0.055802, mean_q: 0.065278, mean_eps: 0.348429\n",
            " 172200/500000: episode: 243, duration: 27.240s, episode steps: 414, steps per second:  15, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.006217, mae: 0.056124, mean_q: 0.064552, mean_eps: 0.346430\n",
            " 172695/500000: episode: 244, duration: 31.904s, episode steps: 495, steps per second:  16, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.743 [0.000, 5.000],  loss: 0.006468, mae: 0.055616, mean_q: 0.065087, mean_eps: 0.344705\n",
            " 173741/500000: episode: 245, duration: 68.727s, episode steps: 1046, steps per second:  15, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.165 [0.000, 5.000],  loss: 0.006060, mae: 0.053305, mean_q: 0.061109, mean_eps: 0.341772\n",
            " 174348/500000: episode: 246, duration: 39.978s, episode steps: 607, steps per second:  15, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.152 [0.000, 5.000],  loss: 0.006067, mae: 0.055839, mean_q: 0.064236, mean_eps: 0.338633\n",
            " 174753/500000: episode: 247, duration: 26.981s, episode steps: 405, steps per second:  15, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.842 [0.000, 5.000],  loss: 0.005223, mae: 0.050920, mean_q: 0.057839, mean_eps: 0.336710\n",
            " 175290/500000: episode: 248, duration: 35.043s, episode steps: 537, steps per second:  15, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.006419, mae: 0.054147, mean_q: 0.062571, mean_eps: 0.334916\n",
            " 176052/500000: episode: 249, duration: 50.363s, episode steps: 762, steps per second:  15, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.713 [0.000, 5.000],  loss: 0.008169, mae: 0.058633, mean_q: 0.065962, mean_eps: 0.332454\n",
            " 176820/500000: episode: 250, duration: 51.463s, episode steps: 768, steps per second:  15, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.007052, mae: 0.056573, mean_q: 0.065720, mean_eps: 0.329551\n",
            " 177614/500000: episode: 251, duration: 53.731s, episode steps: 794, steps per second:  15, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.961 [0.000, 5.000],  loss: 0.005077, mae: 0.052031, mean_q: 0.057935, mean_eps: 0.326579\n",
            " 178564/500000: episode: 252, duration: 63.378s, episode steps: 950, steps per second:  15, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.005488, mae: 0.051084, mean_q: 0.057429, mean_eps: 0.323266\n",
            " 179383/500000: episode: 253, duration: 55.717s, episode steps: 819, steps per second:  15, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.006351, mae: 0.052666, mean_q: 0.058479, mean_eps: 0.319906\n",
            " 179903/500000: episode: 254, duration: 35.912s, episode steps: 520, steps per second:  14, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.006746, mae: 0.053992, mean_q: 0.060645, mean_eps: 0.317360\n",
            " 180777/500000: episode: 255, duration: 59.112s, episode steps: 874, steps per second:  15, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.005657, mae: 0.051451, mean_q: 0.059128, mean_eps: 0.314708\n",
            " 181485/500000: episode: 256, duration: 48.510s, episode steps: 708, steps per second:  15, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.102 [0.000, 5.000],  loss: 0.006750, mae: 0.058184, mean_q: 0.065896, mean_eps: 0.311698\n",
            " 182598/500000: episode: 257, duration: 74.578s, episode steps: 1113, steps per second:  15, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.004754, mae: 0.051951, mean_q: 0.060295, mean_eps: 0.308240\n",
            " 183550/500000: episode: 258, duration: 64.703s, episode steps: 952, steps per second:  15, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: 0.005869, mae: 0.051925, mean_q: 0.059247, mean_eps: 0.304319\n",
            " 184309/500000: episode: 259, duration: 51.924s, episode steps: 759, steps per second:  15, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.006183, mae: 0.053403, mean_q: 0.060642, mean_eps: 0.301066\n",
            " 184961/500000: episode: 260, duration: 44.166s, episode steps: 652, steps per second:  15, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.005579, mae: 0.051736, mean_q: 0.059410, mean_eps: 0.298383\n",
            " 185695/500000: episode: 261, duration: 49.997s, episode steps: 734, steps per second:  15, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.005945, mae: 0.055054, mean_q: 0.062796, mean_eps: 0.295754\n",
            " 186683/500000: episode: 262, duration: 66.345s, episode steps: 988, steps per second:  15, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: 0.006076, mae: 0.052072, mean_q: 0.059258, mean_eps: 0.292486\n",
            " 187300/500000: episode: 263, duration: 42.862s, episode steps: 617, steps per second:  14, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.005653, mae: 0.051188, mean_q: 0.057207, mean_eps: 0.289438\n",
            " 188363/500000: episode: 264, duration: 73.430s, episode steps: 1063, steps per second:  14, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.006325, mae: 0.052182, mean_q: 0.058600, mean_eps: 0.286246\n",
            " 189305/500000: episode: 265, duration: 63.091s, episode steps: 942, steps per second:  15, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.005948, mae: 0.054055, mean_q: 0.062570, mean_eps: 0.282431\n",
            " 190093/500000: episode: 266, duration: 53.647s, episode steps: 788, steps per second:  15, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.052 [0.000, 5.000],  loss: 0.006034, mae: 0.052581, mean_q: 0.061839, mean_eps: 0.279140\n",
            " 191161/500000: episode: 267, duration: 72.723s, episode steps: 1068, steps per second:  15, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.016 [0.000, 5.000],  loss: 0.006793, mae: 0.055715, mean_q: 0.064443, mean_eps: 0.275614\n",
            " 192507/500000: episode: 268, duration: 90.652s, episode steps: 1346, steps per second:  15, episode reward: 28.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.007121, mae: 0.056262, mean_q: 0.065279, mean_eps: 0.271031\n",
            " 193736/500000: episode: 269, duration: 83.756s, episode steps: 1229, steps per second:  15, episode reward: 19.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.006221, mae: 0.052145, mean_q: 0.057999, mean_eps: 0.266144\n",
            " 194705/500000: episode: 270, duration: 66.481s, episode steps: 969, steps per second:  15, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.906 [0.000, 5.000],  loss: 0.005160, mae: 0.051102, mean_q: 0.056029, mean_eps: 0.261964\n",
            " 195488/500000: episode: 271, duration: 52.976s, episode steps: 783, steps per second:  15, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.860 [0.000, 5.000],  loss: 0.007324, mae: 0.054763, mean_q: 0.062968, mean_eps: 0.258635\n",
            " 196580/500000: episode: 272, duration: 73.853s, episode steps: 1092, steps per second:  15, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.299 [0.000, 5.000],  loss: 0.007616, mae: 0.057380, mean_q: 0.067863, mean_eps: 0.255078\n",
            " 197209/500000: episode: 273, duration: 43.255s, episode steps: 629, steps per second:  15, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.007053, mae: 0.051850, mean_q: 0.060646, mean_eps: 0.251803\n",
            " 198045/500000: episode: 274, duration: 58.064s, episode steps: 836, steps per second:  14, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.999 [0.000, 5.000],  loss: 0.006685, mae: 0.054308, mean_q: 0.065184, mean_eps: 0.249014\n",
            " 198549/500000: episode: 275, duration: 33.520s, episode steps: 504, steps per second:  15, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.005523, mae: 0.052313, mean_q: 0.059260, mean_eps: 0.246468\n",
            " 199348/500000: episode: 276, duration: 54.436s, episode steps: 799, steps per second:  15, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.939 [0.000, 5.000],  loss: 0.006127, mae: 0.051407, mean_q: 0.057730, mean_eps: 0.243998\n",
            " 200046/500000: episode: 277, duration: 47.189s, episode steps: 698, steps per second:  15, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.006531, mae: 0.052614, mean_q: 0.060902, mean_eps: 0.241155\n",
            " 200494/500000: episode: 278, duration: 31.243s, episode steps: 448, steps per second:  14, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.127 [0.000, 5.000],  loss: 0.006711, mae: 0.074407, mean_q: 0.090563, mean_eps: 0.238974\n",
            " 200895/500000: episode: 279, duration: 27.117s, episode steps: 401, steps per second:  15, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.006404, mae: 0.075767, mean_q: 0.087614, mean_eps: 0.237363\n",
            " 202382/500000: episode: 280, duration: 99.814s, episode steps: 1487, steps per second:  15, episode reward: 30.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.784 [0.000, 5.000],  loss: 0.008301, mae: 0.078823, mean_q: 0.091943, mean_eps: 0.233776\n",
            " 202826/500000: episode: 281, duration: 29.833s, episode steps: 444, steps per second:  15, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.849 [0.000, 5.000],  loss: 0.005616, mae: 0.073085, mean_q: 0.085779, mean_eps: 0.230105\n",
            " 204007/500000: episode: 282, duration: 80.233s, episode steps: 1181, steps per second:  15, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.099 [0.000, 5.000],  loss: 0.007765, mae: 0.081198, mean_q: 0.095494, mean_eps: 0.227019\n",
            " 204862/500000: episode: 283, duration: 57.766s, episode steps: 855, steps per second:  15, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.926 [0.000, 5.000],  loss: 0.006919, mae: 0.077274, mean_q: 0.089573, mean_eps: 0.223151\n",
            " 205671/500000: episode: 284, duration: 54.390s, episode steps: 809, steps per second:  15, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.169 [0.000, 5.000],  loss: 0.007526, mae: 0.078150, mean_q: 0.089473, mean_eps: 0.219989\n",
            " 206111/500000: episode: 285, duration: 29.396s, episode steps: 440, steps per second:  15, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.966 [0.000, 5.000],  loss: 0.006329, mae: 0.076005, mean_q: 0.084891, mean_eps: 0.217618\n",
            " 206662/500000: episode: 286, duration: 37.558s, episode steps: 551, steps per second:  15, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.813 [0.000, 5.000],  loss: 0.006540, mae: 0.077364, mean_q: 0.090725, mean_eps: 0.215733\n",
            " 207188/500000: episode: 287, duration: 35.265s, episode steps: 526, steps per second:  15, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.007020, mae: 0.076653, mean_q: 0.088979, mean_eps: 0.213689\n",
            " 207862/500000: episode: 288, duration: 46.226s, episode steps: 674, steps per second:  15, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.884 [0.000, 5.000],  loss: 0.007118, mae: 0.077617, mean_q: 0.088913, mean_eps: 0.211409\n",
            " 208599/500000: episode: 289, duration: 48.920s, episode steps: 737, steps per second:  15, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.006619, mae: 0.075400, mean_q: 0.086307, mean_eps: 0.208726\n",
            " 209740/500000: episode: 290, duration: 78.141s, episode steps: 1141, steps per second:  15, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006334, mae: 0.074864, mean_q: 0.084569, mean_eps: 0.205162\n",
            " 210669/500000: episode: 291, duration: 64.130s, episode steps: 929, steps per second:  14, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.006410, mae: 0.074825, mean_q: 0.084720, mean_eps: 0.201225\n",
            " 211296/500000: episode: 292, duration: 42.635s, episode steps: 627, steps per second:  15, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.915 [0.000, 5.000],  loss: 0.006831, mae: 0.074630, mean_q: 0.084882, mean_eps: 0.198268\n",
            " 212324/500000: episode: 293, duration: 70.077s, episode steps: 1028, steps per second:  15, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.007334, mae: 0.078382, mean_q: 0.088295, mean_eps: 0.195130\n",
            " 212870/500000: episode: 294, duration: 37.638s, episode steps: 546, steps per second:  15, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.936 [0.000, 5.000],  loss: 0.006578, mae: 0.074229, mean_q: 0.084388, mean_eps: 0.192135\n",
            " 213651/500000: episode: 295, duration: 51.650s, episode steps: 781, steps per second:  15, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.088 [0.000, 5.000],  loss: 0.007054, mae: 0.076998, mean_q: 0.090867, mean_eps: 0.189612\n",
            " 214388/500000: episode: 296, duration: 50.372s, episode steps: 737, steps per second:  15, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.681 [0.000, 5.000],  loss: 0.007976, mae: 0.079483, mean_q: 0.092137, mean_eps: 0.186732\n",
            " 214956/500000: episode: 297, duration: 39.168s, episode steps: 568, steps per second:  15, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.986 [0.000, 5.000],  loss: 0.005505, mae: 0.071079, mean_q: 0.081491, mean_eps: 0.184254\n",
            " 215938/500000: episode: 298, duration: 66.929s, episode steps: 982, steps per second:  15, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.006950, mae: 0.076131, mean_q: 0.086357, mean_eps: 0.181305\n",
            " 216503/500000: episode: 299, duration: 37.935s, episode steps: 565, steps per second:  15, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.917 [0.000, 5.000],  loss: 0.006103, mae: 0.075565, mean_q: 0.087105, mean_eps: 0.178364\n",
            " 217412/500000: episode: 300, duration: 61.498s, episode steps: 909, steps per second:  15, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.006459, mae: 0.076045, mean_q: 0.087972, mean_eps: 0.175567\n",
            " 218213/500000: episode: 301, duration: 54.619s, episode steps: 801, steps per second:  15, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.881 [0.000, 5.000],  loss: 0.005772, mae: 0.073835, mean_q: 0.083754, mean_eps: 0.172314\n",
            " 219205/500000: episode: 302, duration: 67.603s, episode steps: 992, steps per second:  15, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.006003, mae: 0.070794, mean_q: 0.079891, mean_eps: 0.168902\n",
            " 220013/500000: episode: 303, duration: 55.043s, episode steps: 808, steps per second:  15, episode reward:  6.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.788 [0.000, 5.000],  loss: 0.006826, mae: 0.075299, mean_q: 0.084802, mean_eps: 0.165482\n",
            " 220635/500000: episode: 304, duration: 41.786s, episode steps: 622, steps per second:  15, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.844 [0.000, 5.000],  loss: 0.006424, mae: 0.076673, mean_q: 0.088754, mean_eps: 0.162769\n",
            " 221155/500000: episode: 305, duration: 34.868s, episode steps: 520, steps per second:  15, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.005366, mae: 0.072017, mean_q: 0.081192, mean_eps: 0.160603\n",
            " 221526/500000: episode: 306, duration: 24.443s, episode steps: 371, steps per second:  15, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.447 [0.000, 5.000],  loss: 0.005838, mae: 0.074739, mean_q: 0.085773, mean_eps: 0.158908\n",
            " 222011/500000: episode: 307, duration: 33.750s, episode steps: 485, steps per second:  14, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 3.161 [0.000, 5.000],  loss: 0.006201, mae: 0.071889, mean_q: 0.082079, mean_eps: 0.157282\n",
            " 222683/500000: episode: 308, duration: 44.910s, episode steps: 672, steps per second:  15, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.155 [0.000, 5.000],  loss: 0.006413, mae: 0.073197, mean_q: 0.082261, mean_eps: 0.155085\n",
            " 223225/500000: episode: 309, duration: 37.444s, episode steps: 542, steps per second:  14, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.125 [0.000, 5.000],  loss: 0.007501, mae: 0.078512, mean_q: 0.089346, mean_eps: 0.152775\n",
            " 223863/500000: episode: 310, duration: 42.689s, episode steps: 638, steps per second:  15, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.006404, mae: 0.076472, mean_q: 0.085549, mean_eps: 0.150533\n",
            " 224966/500000: episode: 311, duration: 74.047s, episode steps: 1103, steps per second:  15, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.006056, mae: 0.076455, mean_q: 0.087522, mean_eps: 0.147227\n",
            " 225514/500000: episode: 312, duration: 37.703s, episode steps: 548, steps per second:  15, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.808 [0.000, 5.000],  loss: 0.006959, mae: 0.073871, mean_q: 0.086811, mean_eps: 0.144088\n",
            " 226745/500000: episode: 313, duration: 83.549s, episode steps: 1231, steps per second:  15, episode reward: 19.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.006499, mae: 0.073840, mean_q: 0.084405, mean_eps: 0.140706\n",
            " 227419/500000: episode: 314, duration: 45.223s, episode steps: 674, steps per second:  15, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.988 [0.000, 5.000],  loss: 0.006147, mae: 0.073874, mean_q: 0.084771, mean_eps: 0.137088\n",
            " 228481/500000: episode: 315, duration: 73.835s, episode steps: 1062, steps per second:  14, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.106 [0.000, 5.000],  loss: 0.006909, mae: 0.077853, mean_q: 0.090307, mean_eps: 0.133790\n",
            " 229309/500000: episode: 316, duration: 56.339s, episode steps: 828, steps per second:  15, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.087 [0.000, 5.000],  loss: 0.005748, mae: 0.075654, mean_q: 0.087482, mean_eps: 0.130195\n",
            " 230534/500000: episode: 317, duration: 83.059s, episode steps: 1225, steps per second:  15, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.005917, mae: 0.073465, mean_q: 0.083647, mean_eps: 0.126296\n",
            " 231202/500000: episode: 318, duration: 45.330s, episode steps: 668, steps per second:  15, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.006351, mae: 0.074223, mean_q: 0.087195, mean_eps: 0.122702\n",
            " 232019/500000: episode: 319, duration: 55.499s, episode steps: 817, steps per second:  15, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: 0.006489, mae: 0.075360, mean_q: 0.086282, mean_eps: 0.119882\n",
            " 232870/500000: episode: 320, duration: 57.792s, episode steps: 851, steps per second:  15, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.902 [0.000, 5.000],  loss: 0.005209, mae: 0.071677, mean_q: 0.080879, mean_eps: 0.116713\n",
            " 233423/500000: episode: 321, duration: 38.366s, episode steps: 553, steps per second:  14, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.145 [0.000, 5.000],  loss: 0.006367, mae: 0.073288, mean_q: 0.084497, mean_eps: 0.114045\n",
            " 233816/500000: episode: 322, duration: 27.126s, episode steps: 393, steps per second:  14, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.664 [0.000, 5.000],  loss: 0.005235, mae: 0.072917, mean_q: 0.083390, mean_eps: 0.112252\n",
            " 234207/500000: episode: 323, duration: 26.958s, episode steps: 391, steps per second:  15, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.006188, mae: 0.075866, mean_q: 0.085976, mean_eps: 0.110762\n",
            " 234662/500000: episode: 324, duration: 30.684s, episode steps: 455, steps per second:  15, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.782 [0.000, 5.000],  loss: 0.006338, mae: 0.076652, mean_q: 0.088107, mean_eps: 0.109151\n",
            " 235072/500000: episode: 325, duration: 28.083s, episode steps: 410, steps per second:  15, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.006875, mae: 0.077800, mean_q: 0.089909, mean_eps: 0.107509\n",
            " 235821/500000: episode: 326, duration: 51.793s, episode steps: 749, steps per second:  14, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.805 [0.000, 5.000],  loss: 0.005618, mae: 0.073056, mean_q: 0.085011, mean_eps: 0.105305\n",
            " 236456/500000: episode: 327, duration: 43.257s, episode steps: 635, steps per second:  15, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.006137, mae: 0.077650, mean_q: 0.089714, mean_eps: 0.102676\n",
            " 236832/500000: episode: 328, duration: 26.206s, episode steps: 376, steps per second:  14, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 3.277 [0.000, 5.000],  loss: 0.006780, mae: 0.078079, mean_q: 0.087316, mean_eps: 0.100760\n",
            " 237555/500000: episode: 329, duration: 50.193s, episode steps: 723, steps per second:  14, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.006403, mae: 0.074170, mean_q: 0.085364, mean_eps: 0.098670\n",
            " 238222/500000: episode: 330, duration: 45.031s, episode steps: 667, steps per second:  15, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.005950, mae: 0.070422, mean_q: 0.076937, mean_eps: 0.096026\n",
            " 239035/500000: episode: 331, duration: 55.409s, episode steps: 813, steps per second:  15, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.809 [0.000, 5.000],  loss: 0.005422, mae: 0.073671, mean_q: 0.082827, mean_eps: 0.093214\n",
            " 239734/500000: episode: 332, duration: 48.616s, episode steps: 699, steps per second:  14, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.177 [0.000, 5.000],  loss: 0.005249, mae: 0.071603, mean_q: 0.081592, mean_eps: 0.090341\n",
            " 240921/500000: episode: 333, duration: 80.463s, episode steps: 1187, steps per second:  15, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.005746, mae: 0.072182, mean_q: 0.081816, mean_eps: 0.086754\n",
            " 241313/500000: episode: 334, duration: 26.569s, episode steps: 392, steps per second:  15, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 3.000 [0.000, 5.000],  loss: 0.005427, mae: 0.074176, mean_q: 0.084088, mean_eps: 0.083752\n",
            " 241991/500000: episode: 335, duration: 46.677s, episode steps: 678, steps per second:  15, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.006697, mae: 0.079168, mean_q: 0.090833, mean_eps: 0.081722\n",
            " 243553/500000: episode: 336, duration: 107.222s, episode steps: 1562, steps per second:  15, episode reward: 18.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.772 [0.000, 5.000],  loss: 0.006922, mae: 0.074093, mean_q: 0.086784, mean_eps: 0.077466\n",
            " 244538/500000: episode: 337, duration: 66.818s, episode steps: 985, steps per second:  15, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.717 [0.000, 5.000],  loss: 0.006127, mae: 0.075414, mean_q: 0.084090, mean_eps: 0.072625\n",
            " 245152/500000: episode: 338, duration: 42.292s, episode steps: 614, steps per second:  15, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.007277, mae: 0.074258, mean_q: 0.085476, mean_eps: 0.069593\n",
            " 246092/500000: episode: 339, duration: 63.311s, episode steps: 940, steps per second:  15, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.169 [0.000, 5.000],  loss: 0.005476, mae: 0.074845, mean_q: 0.085722, mean_eps: 0.066644\n",
            " 246750/500000: episode: 340, duration: 46.352s, episode steps: 658, steps per second:  14, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.005345, mae: 0.071797, mean_q: 0.081882, mean_eps: 0.063604\n",
            " 247321/500000: episode: 341, duration: 38.025s, episode steps: 571, steps per second:  15, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.006063, mae: 0.070373, mean_q: 0.079586, mean_eps: 0.061263\n",
            " 247831/500000: episode: 342, duration: 35.178s, episode steps: 510, steps per second:  14, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.006975, mae: 0.074343, mean_q: 0.083830, mean_eps: 0.059211\n",
            " 248369/500000: episode: 343, duration: 37.365s, episode steps: 538, steps per second:  14, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.758 [0.000, 5.000],  loss: 0.006837, mae: 0.074557, mean_q: 0.083518, mean_eps: 0.057220\n",
            " 249004/500000: episode: 344, duration: 43.079s, episode steps: 635, steps per second:  15, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.835 [0.000, 5.000],  loss: 0.006641, mae: 0.075874, mean_q: 0.088018, mean_eps: 0.054993\n",
            " 250142/500000: episode: 345, duration: 77.868s, episode steps: 1138, steps per second:  15, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.710 [0.000, 5.000],  loss: 0.006720, mae: 0.077586, mean_q: 0.090426, mean_eps: 0.051660\n",
            " 250803/500000: episode: 346, duration: 45.460s, episode steps: 661, steps per second:  15, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.006475, mae: 0.095508, mean_q: 0.118243, mean_eps: 0.050000\n",
            " 251273/500000: episode: 347, duration: 31.984s, episode steps: 470, steps per second:  15, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.006977, mae: 0.091579, mean_q: 0.111661, mean_eps: 0.050000\n",
            " 252192/500000: episode: 348, duration: 63.418s, episode steps: 919, steps per second:  14, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.006057, mae: 0.092366, mean_q: 0.109694, mean_eps: 0.050000\n",
            " 253193/500000: episode: 349, duration: 68.120s, episode steps: 1001, steps per second:  15, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.006171, mae: 0.093798, mean_q: 0.109714, mean_eps: 0.050000\n",
            " 253737/500000: episode: 350, duration: 36.024s, episode steps: 544, steps per second:  15, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.006573, mae: 0.093952, mean_q: 0.110270, mean_eps: 0.050000\n",
            " 254535/500000: episode: 351, duration: 53.902s, episode steps: 798, steps per second:  15, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.791 [0.000, 5.000],  loss: 0.005912, mae: 0.091063, mean_q: 0.105759, mean_eps: 0.050000\n",
            " 255908/500000: episode: 352, duration: 94.077s, episode steps: 1373, steps per second:  15, episode reward: 15.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: 0.006789, mae: 0.094888, mean_q: 0.111120, mean_eps: 0.050000\n",
            " 256919/500000: episode: 353, duration: 69.223s, episode steps: 1011, steps per second:  15, episode reward:  9.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.128 [0.000, 5.000],  loss: 0.005664, mae: 0.089347, mean_q: 0.102794, mean_eps: 0.050000\n",
            " 257996/500000: episode: 354, duration: 75.162s, episode steps: 1077, steps per second:  14, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.006492, mae: 0.093603, mean_q: 0.109361, mean_eps: 0.050000\n",
            " 258644/500000: episode: 355, duration: 44.084s, episode steps: 648, steps per second:  15, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.134 [0.000, 5.000],  loss: 0.007341, mae: 0.094066, mean_q: 0.111370, mean_eps: 0.050000\n",
            " 259438/500000: episode: 356, duration: 54.462s, episode steps: 794, steps per second:  15, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.873 [0.000, 5.000],  loss: 0.005873, mae: 0.091930, mean_q: 0.107628, mean_eps: 0.050000\n",
            " 260383/500000: episode: 357, duration: 64.263s, episode steps: 945, steps per second:  15, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.005879, mae: 0.089001, mean_q: 0.103721, mean_eps: 0.050000\n",
            " 261283/500000: episode: 358, duration: 63.769s, episode steps: 900, steps per second:  14, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.872 [0.000, 5.000],  loss: 0.005605, mae: 0.091095, mean_q: 0.105154, mean_eps: 0.050000\n",
            " 262265/500000: episode: 359, duration: 67.285s, episode steps: 982, steps per second:  15, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.174 [0.000, 5.000],  loss: 0.006713, mae: 0.093115, mean_q: 0.108571, mean_eps: 0.050000\n",
            " 262953/500000: episode: 360, duration: 46.477s, episode steps: 688, steps per second:  15, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.005867, mae: 0.092138, mean_q: 0.106888, mean_eps: 0.050000\n",
            " 264530/500000: episode: 361, duration: 108.230s, episode steps: 1577, steps per second:  15, episode reward: 35.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.006557, mae: 0.093551, mean_q: 0.109822, mean_eps: 0.050000\n",
            " 265370/500000: episode: 362, duration: 57.736s, episode steps: 840, steps per second:  15, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.006662, mae: 0.094108, mean_q: 0.110174, mean_eps: 0.050000\n",
            " 266066/500000: episode: 363, duration: 48.797s, episode steps: 696, steps per second:  14, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.151 [0.000, 5.000],  loss: 0.006658, mae: 0.091422, mean_q: 0.106753, mean_eps: 0.050000\n",
            " 266964/500000: episode: 364, duration: 61.466s, episode steps: 898, steps per second:  15, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.993 [0.000, 5.000],  loss: 0.007199, mae: 0.095089, mean_q: 0.112376, mean_eps: 0.050000\n",
            " 268002/500000: episode: 365, duration: 72.016s, episode steps: 1038, steps per second:  14, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.006244, mae: 0.092410, mean_q: 0.107677, mean_eps: 0.050000\n",
            " 268698/500000: episode: 366, duration: 46.251s, episode steps: 696, steps per second:  15, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.754 [0.000, 5.000],  loss: 0.006518, mae: 0.091115, mean_q: 0.106663, mean_eps: 0.050000\n",
            " 269430/500000: episode: 367, duration: 50.268s, episode steps: 732, steps per second:  15, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.006355, mae: 0.090671, mean_q: 0.106956, mean_eps: 0.050000\n",
            " 270607/500000: episode: 368, duration: 80.677s, episode steps: 1177, steps per second:  15, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.006721, mae: 0.094007, mean_q: 0.111912, mean_eps: 0.050000\n",
            " 271122/500000: episode: 369, duration: 34.731s, episode steps: 515, steps per second:  15, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.006378, mae: 0.093641, mean_q: 0.112515, mean_eps: 0.050000\n",
            " 271827/500000: episode: 370, duration: 49.504s, episode steps: 705, steps per second:  14, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.070 [0.000, 5.000],  loss: 0.006564, mae: 0.092839, mean_q: 0.107623, mean_eps: 0.050000\n",
            " 272543/500000: episode: 371, duration: 48.679s, episode steps: 716, steps per second:  15, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 3.123 [0.000, 5.000],  loss: 0.007131, mae: 0.094573, mean_q: 0.110589, mean_eps: 0.050000\n",
            " 272905/500000: episode: 372, duration: 25.377s, episode steps: 362, steps per second:  14, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.746 [0.000, 5.000],  loss: 0.008249, mae: 0.095582, mean_q: 0.112705, mean_eps: 0.050000\n",
            " 273694/500000: episode: 373, duration: 54.513s, episode steps: 789, steps per second:  14, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.899 [0.000, 5.000],  loss: 0.006231, mae: 0.093741, mean_q: 0.112011, mean_eps: 0.050000\n",
            " 274747/500000: episode: 374, duration: 71.741s, episode steps: 1053, steps per second:  15, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.005966, mae: 0.092953, mean_q: 0.109570, mean_eps: 0.050000\n",
            " 275373/500000: episode: 375, duration: 44.342s, episode steps: 626, steps per second:  14, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.157 [0.000, 5.000],  loss: 0.005834, mae: 0.091949, mean_q: 0.108106, mean_eps: 0.050000\n",
            " 276018/500000: episode: 376, duration: 44.500s, episode steps: 645, steps per second:  14, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.721 [0.000, 5.000],  loss: 0.006723, mae: 0.094307, mean_q: 0.110526, mean_eps: 0.050000\n",
            " 276641/500000: episode: 377, duration: 42.756s, episode steps: 623, steps per second:  15, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.807 [0.000, 5.000],  loss: 0.007253, mae: 0.096731, mean_q: 0.114917, mean_eps: 0.050000\n",
            " 277586/500000: episode: 378, duration: 65.472s, episode steps: 945, steps per second:  14, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.006695, mae: 0.093323, mean_q: 0.111586, mean_eps: 0.050000\n",
            " 278162/500000: episode: 379, duration: 39.379s, episode steps: 576, steps per second:  15, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.006971, mae: 0.094446, mean_q: 0.111450, mean_eps: 0.050000\n",
            " 279260/500000: episode: 380, duration: 75.816s, episode steps: 1098, steps per second:  14, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.006152, mae: 0.092563, mean_q: 0.109027, mean_eps: 0.050000\n",
            " 279812/500000: episode: 381, duration: 38.880s, episode steps: 552, steps per second:  14, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.006500, mae: 0.091110, mean_q: 0.108069, mean_eps: 0.050000\n",
            " 280443/500000: episode: 382, duration: 43.359s, episode steps: 631, steps per second:  15, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.006250, mae: 0.093011, mean_q: 0.108751, mean_eps: 0.050000\n",
            " 281091/500000: episode: 383, duration: 44.336s, episode steps: 648, steps per second:  15, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.007396, mae: 0.095151, mean_q: 0.113597, mean_eps: 0.050000\n",
            " 281708/500000: episode: 384, duration: 43.288s, episode steps: 617, steps per second:  14, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.794 [0.000, 5.000],  loss: 0.005812, mae: 0.091555, mean_q: 0.109917, mean_eps: 0.050000\n",
            " 282333/500000: episode: 385, duration: 44.125s, episode steps: 625, steps per second:  14, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.005927, mae: 0.091127, mean_q: 0.106964, mean_eps: 0.050000\n",
            " 283199/500000: episode: 386, duration: 58.855s, episode steps: 866, steps per second:  15, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.005 [0.000, 5.000],  loss: 0.006699, mae: 0.094792, mean_q: 0.113031, mean_eps: 0.050000\n",
            " 283894/500000: episode: 387, duration: 47.935s, episode steps: 695, steps per second:  14, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.006011, mae: 0.090564, mean_q: 0.104418, mean_eps: 0.050000\n",
            " 285110/500000: episode: 388, duration: 84.459s, episode steps: 1216, steps per second:  14, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.006711, mae: 0.092893, mean_q: 0.109240, mean_eps: 0.050000\n",
            " 286121/500000: episode: 389, duration: 70.154s, episode steps: 1011, steps per second:  14, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.907 [0.000, 5.000],  loss: 0.005702, mae: 0.092126, mean_q: 0.109867, mean_eps: 0.050000\n",
            " 287046/500000: episode: 390, duration: 63.175s, episode steps: 925, steps per second:  15, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.286 [0.000, 5.000],  loss: 0.005946, mae: 0.089940, mean_q: 0.109314, mean_eps: 0.050000\n",
            " 288184/500000: episode: 391, duration: 79.055s, episode steps: 1138, steps per second:  14, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.929 [0.000, 5.000],  loss: 0.006436, mae: 0.093445, mean_q: 0.110715, mean_eps: 0.050000\n",
            " 288586/500000: episode: 392, duration: 28.063s, episode steps: 402, steps per second:  14, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.025 [0.000, 5.000],  loss: 0.006068, mae: 0.094322, mean_q: 0.113303, mean_eps: 0.050000\n",
            " 289088/500000: episode: 393, duration: 35.679s, episode steps: 502, steps per second:  14, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.558 [0.000, 5.000],  loss: 0.006029, mae: 0.091347, mean_q: 0.109843, mean_eps: 0.050000\n",
            " 289451/500000: episode: 394, duration: 25.443s, episode steps: 363, steps per second:  14, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.113 [0.000, 5.000],  loss: 0.005877, mae: 0.093586, mean_q: 0.109519, mean_eps: 0.050000\n",
            " 290262/500000: episode: 395, duration: 56.062s, episode steps: 811, steps per second:  14, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.006850, mae: 0.092873, mean_q: 0.109964, mean_eps: 0.050000\n",
            " 290883/500000: episode: 396, duration: 42.922s, episode steps: 621, steps per second:  14, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.881 [0.000, 5.000],  loss: 0.005668, mae: 0.091941, mean_q: 0.107509, mean_eps: 0.050000\n",
            " 291450/500000: episode: 397, duration: 39.798s, episode steps: 567, steps per second:  14, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.945 [0.000, 5.000],  loss: 0.005730, mae: 0.090612, mean_q: 0.107004, mean_eps: 0.050000\n",
            " 292146/500000: episode: 398, duration: 47.490s, episode steps: 696, steps per second:  15, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.062 [0.000, 5.000],  loss: 0.005215, mae: 0.088837, mean_q: 0.104276, mean_eps: 0.050000\n",
            " 293442/500000: episode: 399, duration: 90.484s, episode steps: 1296, steps per second:  14, episode reward: 27.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.866 [0.000, 5.000],  loss: 0.005385, mae: 0.089690, mean_q: 0.104103, mean_eps: 0.050000\n",
            " 293941/500000: episode: 400, duration: 33.956s, episode steps: 499, steps per second:  15, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.005728, mae: 0.091503, mean_q: 0.106195, mean_eps: 0.050000\n",
            " 294602/500000: episode: 401, duration: 47.113s, episode steps: 661, steps per second:  14, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.038 [0.000, 5.000],  loss: 0.005952, mae: 0.089300, mean_q: 0.105405, mean_eps: 0.050000\n",
            " 295257/500000: episode: 402, duration: 45.156s, episode steps: 655, steps per second:  15, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.948 [0.000, 5.000],  loss: 0.006758, mae: 0.092611, mean_q: 0.107683, mean_eps: 0.050000\n",
            " 295880/500000: episode: 403, duration: 43.128s, episode steps: 623, steps per second:  14, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.093 [0.000, 5.000],  loss: 0.005774, mae: 0.091250, mean_q: 0.106414, mean_eps: 0.050000\n",
            " 296376/500000: episode: 404, duration: 35.593s, episode steps: 496, steps per second:  14, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.800 [0.000, 5.000],  loss: 0.007651, mae: 0.093400, mean_q: 0.109363, mean_eps: 0.050000\n",
            " 297596/500000: episode: 405, duration: 85.456s, episode steps: 1220, steps per second:  14, episode reward: 21.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.006644, mae: 0.095915, mean_q: 0.114386, mean_eps: 0.050000\n",
            " 298449/500000: episode: 406, duration: 60.265s, episode steps: 853, steps per second:  14, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.979 [0.000, 5.000],  loss: 0.006794, mae: 0.094764, mean_q: 0.113818, mean_eps: 0.050000\n",
            " 298989/500000: episode: 407, duration: 38.309s, episode steps: 540, steps per second:  14, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.005926, mae: 0.086366, mean_q: 0.102861, mean_eps: 0.050000\n",
            " 299854/500000: episode: 408, duration: 62.044s, episode steps: 865, steps per second:  14, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006873, mae: 0.092509, mean_q: 0.109459, mean_eps: 0.050000\n",
            " 300442/500000: episode: 409, duration: 41.214s, episode steps: 588, steps per second:  14, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.879 [0.000, 5.000],  loss: 0.005899, mae: 0.106672, mean_q: 0.132029, mean_eps: 0.050000\n",
            " 301097/500000: episode: 410, duration: 45.320s, episode steps: 655, steps per second:  14, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 3.260 [0.000, 5.000],  loss: 0.006697, mae: 0.114363, mean_q: 0.141229, mean_eps: 0.050000\n",
            " 302115/500000: episode: 411, duration: 70.121s, episode steps: 1018, steps per second:  15, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.006761, mae: 0.114622, mean_q: 0.140847, mean_eps: 0.050000\n",
            " 302920/500000: episode: 412, duration: 56.044s, episode steps: 805, steps per second:  14, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.169 [0.000, 5.000],  loss: 0.006670, mae: 0.112572, mean_q: 0.136957, mean_eps: 0.050000\n",
            " 303431/500000: episode: 413, duration: 36.315s, episode steps: 511, steps per second:  14, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.033 [0.000, 5.000],  loss: 0.006627, mae: 0.111662, mean_q: 0.134692, mean_eps: 0.050000\n",
            " 304251/500000: episode: 414, duration: 56.973s, episode steps: 820, steps per second:  14, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.007657, mae: 0.111291, mean_q: 0.135133, mean_eps: 0.050000\n",
            " 304635/500000: episode: 415, duration: 26.809s, episode steps: 384, steps per second:  14, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.656 [0.000, 5.000],  loss: 0.005528, mae: 0.112639, mean_q: 0.137337, mean_eps: 0.050000\n",
            " 306005/500000: episode: 416, duration: 95.526s, episode steps: 1370, steps per second:  14, episode reward: 23.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.173 [0.000, 5.000],  loss: 0.007071, mae: 0.115160, mean_q: 0.139644, mean_eps: 0.050000\n",
            " 306660/500000: episode: 417, duration: 45.349s, episode steps: 655, steps per second:  14, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.841 [0.000, 5.000],  loss: 0.006474, mae: 0.113457, mean_q: 0.137953, mean_eps: 0.050000\n",
            " 307348/500000: episode: 418, duration: 50.561s, episode steps: 688, steps per second:  14, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.006710, mae: 0.113526, mean_q: 0.137684, mean_eps: 0.050000\n",
            " 307903/500000: episode: 419, duration: 40.622s, episode steps: 555, steps per second:  14, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.007365, mae: 0.114513, mean_q: 0.137468, mean_eps: 0.050000\n",
            " 308557/500000: episode: 420, duration: 46.021s, episode steps: 654, steps per second:  14, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.005520, mae: 0.110613, mean_q: 0.131774, mean_eps: 0.050000\n",
            " 309657/500000: episode: 421, duration: 78.413s, episode steps: 1100, steps per second:  14, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.071 [0.000, 5.000],  loss: 0.006780, mae: 0.114736, mean_q: 0.138275, mean_eps: 0.050000\n",
            " 310558/500000: episode: 422, duration: 65.193s, episode steps: 901, steps per second:  14, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.007157, mae: 0.114321, mean_q: 0.137942, mean_eps: 0.050000\n",
            " 311568/500000: episode: 423, duration: 72.795s, episode steps: 1010, steps per second:  14, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.883 [0.000, 5.000],  loss: 0.007180, mae: 0.112919, mean_q: 0.136511, mean_eps: 0.050000\n",
            " 312300/500000: episode: 424, duration: 53.450s, episode steps: 732, steps per second:  14, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: 0.006396, mae: 0.111968, mean_q: 0.134265, mean_eps: 0.050000\n",
            " 313011/500000: episode: 425, duration: 51.220s, episode steps: 711, steps per second:  14, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.923 [0.000, 5.000],  loss: 0.006095, mae: 0.107787, mean_q: 0.128194, mean_eps: 0.050000\n",
            " 313540/500000: episode: 426, duration: 36.247s, episode steps: 529, steps per second:  15, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.006131, mae: 0.114002, mean_q: 0.137852, mean_eps: 0.050000\n",
            " 314213/500000: episode: 427, duration: 48.840s, episode steps: 673, steps per second:  14, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.006443, mae: 0.113497, mean_q: 0.136298, mean_eps: 0.050000\n",
            " 314726/500000: episode: 428, duration: 36.686s, episode steps: 513, steps per second:  14, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.005648, mae: 0.111635, mean_q: 0.134487, mean_eps: 0.050000\n",
            " 315398/500000: episode: 429, duration: 48.053s, episode steps: 672, steps per second:  14, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.007173, mae: 0.112479, mean_q: 0.136550, mean_eps: 0.050000\n",
            " 316073/500000: episode: 430, duration: 49.485s, episode steps: 675, steps per second:  14, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.006778, mae: 0.112389, mean_q: 0.134199, mean_eps: 0.050000\n",
            " 316470/500000: episode: 431, duration: 28.281s, episode steps: 397, steps per second:  14, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.006043, mae: 0.112299, mean_q: 0.134540, mean_eps: 0.050000\n",
            " 317478/500000: episode: 432, duration: 70.610s, episode steps: 1008, steps per second:  14, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.007780, mae: 0.117784, mean_q: 0.142269, mean_eps: 0.050000\n",
            " 318147/500000: episode: 433, duration: 47.204s, episode steps: 669, steps per second:  14, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.061 [0.000, 5.000],  loss: 0.006264, mae: 0.109176, mean_q: 0.128923, mean_eps: 0.050000\n",
            " 318680/500000: episode: 434, duration: 39.027s, episode steps: 533, steps per second:  14, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.071 [0.000, 5.000],  loss: 0.007616, mae: 0.116119, mean_q: 0.138101, mean_eps: 0.050000\n",
            " 319494/500000: episode: 435, duration: 58.065s, episode steps: 814, steps per second:  14, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.435 [0.000, 5.000],  loss: 0.006204, mae: 0.113804, mean_q: 0.136589, mean_eps: 0.050000\n",
            " 320147/500000: episode: 436, duration: 47.678s, episode steps: 653, steps per second:  14, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.006555, mae: 0.112438, mean_q: 0.136328, mean_eps: 0.050000\n",
            " 320834/500000: episode: 437, duration: 48.399s, episode steps: 687, steps per second:  14, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.319 [0.000, 5.000],  loss: 0.006723, mae: 0.114561, mean_q: 0.140957, mean_eps: 0.050000\n",
            " 321650/500000: episode: 438, duration: 60.053s, episode steps: 816, steps per second:  14, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: 0.006345, mae: 0.112470, mean_q: 0.137853, mean_eps: 0.050000\n",
            " 322565/500000: episode: 439, duration: 65.618s, episode steps: 915, steps per second:  14, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.007327, mae: 0.113690, mean_q: 0.138185, mean_eps: 0.050000\n",
            " 323629/500000: episode: 440, duration: 76.726s, episode steps: 1064, steps per second:  14, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.851 [0.000, 5.000],  loss: 0.006365, mae: 0.113932, mean_q: 0.139689, mean_eps: 0.050000\n",
            " 324277/500000: episode: 441, duration: 46.738s, episode steps: 648, steps per second:  14, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.991 [0.000, 5.000],  loss: 0.006921, mae: 0.111167, mean_q: 0.134403, mean_eps: 0.050000\n",
            " 325139/500000: episode: 442, duration: 61.306s, episode steps: 862, steps per second:  14, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.007219, mae: 0.114947, mean_q: 0.138221, mean_eps: 0.050000\n",
            " 325967/500000: episode: 443, duration: 58.990s, episode steps: 828, steps per second:  14, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.048 [0.000, 5.000],  loss: 0.006104, mae: 0.111322, mean_q: 0.133349, mean_eps: 0.050000\n",
            " 326351/500000: episode: 444, duration: 27.572s, episode steps: 384, steps per second:  14, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.729 [0.000, 5.000],  loss: 0.006689, mae: 0.111989, mean_q: 0.136441, mean_eps: 0.050000\n",
            " 326832/500000: episode: 445, duration: 35.029s, episode steps: 481, steps per second:  14, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: 0.006720, mae: 0.110836, mean_q: 0.134854, mean_eps: 0.050000\n",
            " 327773/500000: episode: 446, duration: 67.999s, episode steps: 941, steps per second:  14, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.392 [0.000, 5.000],  loss: 0.007055, mae: 0.113269, mean_q: 0.137612, mean_eps: 0.050000\n",
            " 328719/500000: episode: 447, duration: 68.799s, episode steps: 946, steps per second:  14, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 3.196 [0.000, 5.000],  loss: 0.006846, mae: 0.111782, mean_q: 0.137011, mean_eps: 0.050000\n",
            " 329475/500000: episode: 448, duration: 53.799s, episode steps: 756, steps per second:  14, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.005575, mae: 0.109031, mean_q: 0.131381, mean_eps: 0.050000\n",
            " 330011/500000: episode: 449, duration: 39.429s, episode steps: 536, steps per second:  14, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.005621, mae: 0.111706, mean_q: 0.134780, mean_eps: 0.050000\n",
            " 330607/500000: episode: 450, duration: 42.592s, episode steps: 596, steps per second:  14, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.005816, mae: 0.109896, mean_q: 0.132041, mean_eps: 0.050000\n",
            " 331563/500000: episode: 451, duration: 70.218s, episode steps: 956, steps per second:  14, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.164 [0.000, 5.000],  loss: 0.006691, mae: 0.111686, mean_q: 0.134803, mean_eps: 0.050000\n",
            " 332554/500000: episode: 452, duration: 70.910s, episode steps: 991, steps per second:  14, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.005615, mae: 0.111351, mean_q: 0.133445, mean_eps: 0.050000\n",
            " 333182/500000: episode: 453, duration: 44.578s, episode steps: 628, steps per second:  14, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.196 [0.000, 5.000],  loss: 0.006988, mae: 0.115940, mean_q: 0.139036, mean_eps: 0.050000\n",
            " 333725/500000: episode: 454, duration: 39.294s, episode steps: 543, steps per second:  14, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.006430, mae: 0.111247, mean_q: 0.133223, mean_eps: 0.050000\n",
            " 334369/500000: episode: 455, duration: 45.096s, episode steps: 644, steps per second:  14, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.006166, mae: 0.110733, mean_q: 0.134233, mean_eps: 0.050000\n",
            " 335671/500000: episode: 456, duration: 91.513s, episode steps: 1302, steps per second:  14, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.083 [0.000, 5.000],  loss: 0.005287, mae: 0.108766, mean_q: 0.129907, mean_eps: 0.050000\n",
            " 336266/500000: episode: 457, duration: 41.469s, episode steps: 595, steps per second:  14, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.007583, mae: 0.117784, mean_q: 0.143247, mean_eps: 0.050000\n",
            " 336858/500000: episode: 458, duration: 41.638s, episode steps: 592, steps per second:  14, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.005047, mae: 0.110978, mean_q: 0.134574, mean_eps: 0.050000\n",
            " 338320/500000: episode: 459, duration: 104.480s, episode steps: 1462, steps per second:  14, episode reward: 28.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.006294, mae: 0.110703, mean_q: 0.135092, mean_eps: 0.050000\n",
            " 339260/500000: episode: 460, duration: 66.967s, episode steps: 940, steps per second:  14, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: 0.006190, mae: 0.108695, mean_q: 0.131874, mean_eps: 0.050000\n",
            " 339839/500000: episode: 461, duration: 40.909s, episode steps: 579, steps per second:  14, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.095 [0.000, 5.000],  loss: 0.006034, mae: 0.110541, mean_q: 0.133483, mean_eps: 0.050000\n",
            " 340381/500000: episode: 462, duration: 37.207s, episode steps: 542, steps per second:  15, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.005111, mae: 0.104058, mean_q: 0.124359, mean_eps: 0.050000\n",
            " 341356/500000: episode: 463, duration: 69.708s, episode steps: 975, steps per second:  14, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.812 [0.000, 5.000],  loss: 0.006352, mae: 0.113595, mean_q: 0.136620, mean_eps: 0.050000\n",
            " 341909/500000: episode: 464, duration: 39.108s, episode steps: 553, steps per second:  14, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.779 [0.000, 5.000],  loss: 0.005542, mae: 0.112887, mean_q: 0.136734, mean_eps: 0.050000\n",
            " 342656/500000: episode: 465, duration: 53.150s, episode steps: 747, steps per second:  14, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.005971, mae: 0.111181, mean_q: 0.134456, mean_eps: 0.050000\n",
            " 343641/500000: episode: 466, duration: 69.834s, episode steps: 985, steps per second:  14, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.007066, mae: 0.109704, mean_q: 0.130971, mean_eps: 0.050000\n",
            " 344500/500000: episode: 467, duration: 61.898s, episode steps: 859, steps per second:  14, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 3.307 [0.000, 5.000],  loss: 0.006504, mae: 0.111867, mean_q: 0.137230, mean_eps: 0.050000\n",
            " 345336/500000: episode: 468, duration: 58.938s, episode steps: 836, steps per second:  14, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.006179, mae: 0.113531, mean_q: 0.140614, mean_eps: 0.050000\n",
            " 346080/500000: episode: 469, duration: 52.866s, episode steps: 744, steps per second:  14, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.953 [0.000, 5.000],  loss: 0.006753, mae: 0.112185, mean_q: 0.136958, mean_eps: 0.050000\n",
            " 346976/500000: episode: 470, duration: 64.239s, episode steps: 896, steps per second:  14, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.006577, mae: 0.112474, mean_q: 0.136253, mean_eps: 0.050000\n",
            " 347596/500000: episode: 471, duration: 44.027s, episode steps: 620, steps per second:  14, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.977 [0.000, 5.000],  loss: 0.006285, mae: 0.112189, mean_q: 0.135942, mean_eps: 0.050000\n",
            " 348133/500000: episode: 472, duration: 38.833s, episode steps: 537, steps per second:  14, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.842 [0.000, 5.000],  loss: 0.005442, mae: 0.110114, mean_q: 0.133345, mean_eps: 0.050000\n",
            " 348734/500000: episode: 473, duration: 42.345s, episode steps: 601, steps per second:  14, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.007503, mae: 0.113374, mean_q: 0.137844, mean_eps: 0.050000\n",
            " 349399/500000: episode: 474, duration: 46.239s, episode steps: 665, steps per second:  14, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.872 [0.000, 5.000],  loss: 0.006865, mae: 0.114313, mean_q: 0.138304, mean_eps: 0.050000\n",
            " 350094/500000: episode: 475, duration: 49.809s, episode steps: 695, steps per second:  14, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.853 [0.000, 5.000],  loss: 0.005205, mae: 0.110819, mean_q: 0.136079, mean_eps: 0.050000\n",
            " 350846/500000: episode: 476, duration: 53.452s, episode steps: 752, steps per second:  14, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.006490, mae: 0.133568, mean_q: 0.167511, mean_eps: 0.050000\n",
            " 351728/500000: episode: 477, duration: 61.862s, episode steps: 882, steps per second:  14, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.287 [0.000, 5.000],  loss: 0.006908, mae: 0.133377, mean_q: 0.164456, mean_eps: 0.050000\n",
            " 352090/500000: episode: 478, duration: 26.191s, episode steps: 362, steps per second:  14, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.146 [0.000, 5.000],  loss: 0.006730, mae: 0.137410, mean_q: 0.172278, mean_eps: 0.050000\n",
            " 353009/500000: episode: 479, duration: 65.653s, episode steps: 919, steps per second:  14, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: 0.007518, mae: 0.135736, mean_q: 0.167559, mean_eps: 0.050000\n",
            " 353849/500000: episode: 480, duration: 59.215s, episode steps: 840, steps per second:  14, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.695 [0.000, 5.000],  loss: 0.006900, mae: 0.134792, mean_q: 0.166635, mean_eps: 0.050000\n",
            " 354558/500000: episode: 481, duration: 50.827s, episode steps: 709, steps per second:  14, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.005993, mae: 0.136417, mean_q: 0.168231, mean_eps: 0.050000\n",
            " 355628/500000: episode: 482, duration: 75.681s, episode steps: 1070, steps per second:  14, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.006642, mae: 0.136237, mean_q: 0.166689, mean_eps: 0.050000\n",
            " 356346/500000: episode: 483, duration: 51.096s, episode steps: 718, steps per second:  14, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.006376, mae: 0.133880, mean_q: 0.162383, mean_eps: 0.050000\n",
            " 357025/500000: episode: 484, duration: 49.205s, episode steps: 679, steps per second:  14, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.007347, mae: 0.142200, mean_q: 0.174348, mean_eps: 0.050000\n",
            " 357501/500000: episode: 485, duration: 33.526s, episode steps: 476, steps per second:  14, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.007373, mae: 0.138191, mean_q: 0.168855, mean_eps: 0.050000\n",
            " 358476/500000: episode: 486, duration: 69.691s, episode steps: 975, steps per second:  14, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.007303, mae: 0.136123, mean_q: 0.166524, mean_eps: 0.050000\n",
            " 359273/500000: episode: 487, duration: 57.348s, episode steps: 797, steps per second:  14, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.768 [0.000, 5.000],  loss: 0.006464, mae: 0.134953, mean_q: 0.164724, mean_eps: 0.050000\n",
            " 359835/500000: episode: 488, duration: 39.665s, episode steps: 562, steps per second:  14, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.006750, mae: 0.137466, mean_q: 0.167902, mean_eps: 0.050000\n",
            " 360350/500000: episode: 489, duration: 37.691s, episode steps: 515, steps per second:  14, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.009080, mae: 0.135353, mean_q: 0.165106, mean_eps: 0.050000\n",
            " 361025/500000: episode: 490, duration: 49.752s, episode steps: 675, steps per second:  14, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.007590, mae: 0.136920, mean_q: 0.167333, mean_eps: 0.050000\n",
            " 361528/500000: episode: 491, duration: 35.046s, episode steps: 503, steps per second:  14, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.007228, mae: 0.132673, mean_q: 0.162547, mean_eps: 0.050000\n",
            " 362121/500000: episode: 492, duration: 42.637s, episode steps: 593, steps per second:  14, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.007392, mae: 0.135725, mean_q: 0.168038, mean_eps: 0.050000\n",
            " 362516/500000: episode: 493, duration: 28.147s, episode steps: 395, steps per second:  14, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.901 [0.000, 5.000],  loss: 0.007350, mae: 0.135501, mean_q: 0.165299, mean_eps: 0.050000\n",
            " 363026/500000: episode: 494, duration: 36.372s, episode steps: 510, steps per second:  14, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.786 [0.000, 5.000],  loss: 0.006621, mae: 0.131514, mean_q: 0.159983, mean_eps: 0.050000\n",
            " 364276/500000: episode: 495, duration: 90.166s, episode steps: 1250, steps per second:  14, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.006844, mae: 0.133676, mean_q: 0.163508, mean_eps: 0.050000\n",
            " 365061/500000: episode: 496, duration: 56.318s, episode steps: 785, steps per second:  14, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007862, mae: 0.135125, mean_q: 0.164307, mean_eps: 0.050000\n",
            " 365890/500000: episode: 497, duration: 58.375s, episode steps: 829, steps per second:  14, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.110 [0.000, 5.000],  loss: 0.006931, mae: 0.134848, mean_q: 0.164325, mean_eps: 0.050000\n",
            " 366863/500000: episode: 498, duration: 69.657s, episode steps: 973, steps per second:  14, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.007078, mae: 0.132732, mean_q: 0.160375, mean_eps: 0.050000\n",
            " 367901/500000: episode: 499, duration: 74.299s, episode steps: 1038, steps per second:  14, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.006041, mae: 0.131994, mean_q: 0.161538, mean_eps: 0.050000\n",
            " 368517/500000: episode: 500, duration: 42.667s, episode steps: 616, steps per second:  14, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.081 [0.000, 5.000],  loss: 0.006800, mae: 0.135074, mean_q: 0.165437, mean_eps: 0.050000\n",
            " 369424/500000: episode: 501, duration: 62.175s, episode steps: 907, steps per second:  15, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.007078, mae: 0.135249, mean_q: 0.166078, mean_eps: 0.050000\n",
            " 370452/500000: episode: 502, duration: 72.780s, episode steps: 1028, steps per second:  14, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.007180, mae: 0.133445, mean_q: 0.164055, mean_eps: 0.050000\n",
            " 371189/500000: episode: 503, duration: 51.039s, episode steps: 737, steps per second:  14, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.803 [0.000, 5.000],  loss: 0.006350, mae: 0.131550, mean_q: 0.161336, mean_eps: 0.050000\n",
            " 372492/500000: episode: 504, duration: 92.317s, episode steps: 1303, steps per second:  14, episode reward: 31.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.858 [0.000, 5.000],  loss: 0.006502, mae: 0.133247, mean_q: 0.164643, mean_eps: 0.050000\n",
            " 373142/500000: episode: 505, duration: 45.873s, episode steps: 650, steps per second:  14, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006396, mae: 0.129784, mean_q: 0.159092, mean_eps: 0.050000\n",
            " 373656/500000: episode: 506, duration: 37.073s, episode steps: 514, steps per second:  14, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.007849, mae: 0.137190, mean_q: 0.168105, mean_eps: 0.050000\n",
            " 374654/500000: episode: 507, duration: 71.037s, episode steps: 998, steps per second:  14, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.007815, mae: 0.141738, mean_q: 0.176624, mean_eps: 0.050000\n",
            " 375284/500000: episode: 508, duration: 46.440s, episode steps: 630, steps per second:  14, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.006009, mae: 0.130445, mean_q: 0.161305, mean_eps: 0.050000\n",
            " 376214/500000: episode: 509, duration: 66.695s, episode steps: 930, steps per second:  14, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.006971, mae: 0.132361, mean_q: 0.162833, mean_eps: 0.050000\n",
            " 376881/500000: episode: 510, duration: 47.639s, episode steps: 667, steps per second:  14, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.315 [0.000, 5.000],  loss: 0.006910, mae: 0.137637, mean_q: 0.170383, mean_eps: 0.050000\n",
            " 377259/500000: episode: 511, duration: 26.884s, episode steps: 378, steps per second:  14, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.807 [0.000, 5.000],  loss: 0.006480, mae: 0.131916, mean_q: 0.163710, mean_eps: 0.050000\n",
            " 377600/500000: episode: 512, duration: 24.975s, episode steps: 341, steps per second:  14, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.006379, mae: 0.131628, mean_q: 0.162005, mean_eps: 0.050000\n",
            " 378566/500000: episode: 513, duration: 69.032s, episode steps: 966, steps per second:  14, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.007562, mae: 0.136312, mean_q: 0.165567, mean_eps: 0.050000\n",
            " 379866/500000: episode: 514, duration: 92.449s, episode steps: 1300, steps per second:  14, episode reward: 28.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.006764, mae: 0.133633, mean_q: 0.164100, mean_eps: 0.050000\n",
            " 380378/500000: episode: 515, duration: 35.154s, episode steps: 512, steps per second:  15, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.809 [0.000, 5.000],  loss: 0.007337, mae: 0.134910, mean_q: 0.167048, mean_eps: 0.050000\n",
            " 381031/500000: episode: 516, duration: 46.346s, episode steps: 653, steps per second:  14, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.006114, mae: 0.136604, mean_q: 0.169573, mean_eps: 0.050000\n",
            " 381890/500000: episode: 517, duration: 60.431s, episode steps: 859, steps per second:  14, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.010 [0.000, 5.000],  loss: 0.005856, mae: 0.135822, mean_q: 0.166627, mean_eps: 0.050000\n",
            " 382475/500000: episode: 518, duration: 41.398s, episode steps: 585, steps per second:  14, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.006708, mae: 0.130133, mean_q: 0.160212, mean_eps: 0.050000\n",
            " 383416/500000: episode: 519, duration: 67.918s, episode steps: 941, steps per second:  14, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.004 [0.000, 5.000],  loss: 0.007033, mae: 0.133019, mean_q: 0.163030, mean_eps: 0.050000\n",
            " 384062/500000: episode: 520, duration: 46.142s, episode steps: 646, steps per second:  14, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.986 [0.000, 5.000],  loss: 0.005879, mae: 0.131132, mean_q: 0.160340, mean_eps: 0.050000\n",
            " 384739/500000: episode: 521, duration: 49.680s, episode steps: 677, steps per second:  14, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.006983, mae: 0.132394, mean_q: 0.163462, mean_eps: 0.050000\n",
            " 385377/500000: episode: 522, duration: 45.950s, episode steps: 638, steps per second:  14, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.139 [0.000, 5.000],  loss: 0.007177, mae: 0.135608, mean_q: 0.166859, mean_eps: 0.050000\n",
            " 386334/500000: episode: 523, duration: 68.644s, episode steps: 957, steps per second:  14, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.134 [0.000, 5.000],  loss: 0.006483, mae: 0.132208, mean_q: 0.163572, mean_eps: 0.050000\n",
            " 387308/500000: episode: 524, duration: 70.820s, episode steps: 974, steps per second:  14, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.006543, mae: 0.131889, mean_q: 0.162904, mean_eps: 0.050000\n",
            " 387821/500000: episode: 525, duration: 37.131s, episode steps: 513, steps per second:  14, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.006811, mae: 0.135807, mean_q: 0.168633, mean_eps: 0.050000\n",
            " 388464/500000: episode: 526, duration: 46.933s, episode steps: 643, steps per second:  14, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.019 [0.000, 5.000],  loss: 0.007664, mae: 0.132692, mean_q: 0.163095, mean_eps: 0.050000\n",
            " 389401/500000: episode: 527, duration: 67.285s, episode steps: 937, steps per second:  14, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.063 [0.000, 5.000],  loss: 0.007880, mae: 0.140363, mean_q: 0.173277, mean_eps: 0.050000\n",
            " 390739/500000: episode: 528, duration: 97.540s, episode steps: 1338, steps per second:  14, episode reward: 25.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.801 [0.000, 5.000],  loss: 0.007440, mae: 0.133136, mean_q: 0.162552, mean_eps: 0.050000\n",
            " 391810/500000: episode: 529, duration: 76.050s, episode steps: 1071, steps per second:  14, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.709 [0.000, 5.000],  loss: 0.006404, mae: 0.133909, mean_q: 0.165762, mean_eps: 0.050000\n",
            " 392622/500000: episode: 530, duration: 59.377s, episode steps: 812, steps per second:  14, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.006863, mae: 0.135796, mean_q: 0.167867, mean_eps: 0.050000\n",
            " 393466/500000: episode: 531, duration: 60.302s, episode steps: 844, steps per second:  14, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.813 [0.000, 5.000],  loss: 0.006637, mae: 0.133363, mean_q: 0.165208, mean_eps: 0.050000\n",
            " 394747/500000: episode: 532, duration: 92.349s, episode steps: 1281, steps per second:  14, episode reward: 26.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.006487, mae: 0.131355, mean_q: 0.162496, mean_eps: 0.050000\n",
            " 395424/500000: episode: 533, duration: 48.524s, episode steps: 677, steps per second:  14, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.006015, mae: 0.130281, mean_q: 0.160790, mean_eps: 0.050000\n",
            " 396411/500000: episode: 534, duration: 73.202s, episode steps: 987, steps per second:  13, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.007220, mae: 0.132396, mean_q: 0.162465, mean_eps: 0.050000\n",
            " 397102/500000: episode: 535, duration: 50.490s, episode steps: 691, steps per second:  14, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.007109, mae: 0.138444, mean_q: 0.169064, mean_eps: 0.050000\n",
            " 397619/500000: episode: 536, duration: 38.235s, episode steps: 517, steps per second:  14, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.133 [0.000, 5.000],  loss: 0.006227, mae: 0.137357, mean_q: 0.167584, mean_eps: 0.050000\n",
            " 398303/500000: episode: 537, duration: 50.519s, episode steps: 684, steps per second:  14, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.111 [0.000, 5.000],  loss: 0.006325, mae: 0.130854, mean_q: 0.159770, mean_eps: 0.050000\n",
            " 399095/500000: episode: 538, duration: 57.409s, episode steps: 792, steps per second:  14, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.006111, mae: 0.132292, mean_q: 0.162242, mean_eps: 0.050000\n",
            " 399677/500000: episode: 539, duration: 42.313s, episode steps: 582, steps per second:  14, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.253 [0.000, 5.000],  loss: 0.007335, mae: 0.138439, mean_q: 0.170232, mean_eps: 0.050000\n",
            " 400473/500000: episode: 540, duration: 58.110s, episode steps: 796, steps per second:  14, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.803 [0.000, 5.000],  loss: 0.007341, mae: 0.152298, mean_q: 0.192473, mean_eps: 0.050000\n",
            " 401520/500000: episode: 541, duration: 77.042s, episode steps: 1047, steps per second:  14, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.818 [0.000, 5.000],  loss: 0.008070, mae: 0.164628, mean_q: 0.208260, mean_eps: 0.050000\n",
            " 402033/500000: episode: 542, duration: 37.919s, episode steps: 513, steps per second:  14, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 3.111 [0.000, 5.000],  loss: 0.008230, mae: 0.171364, mean_q: 0.216677, mean_eps: 0.050000\n",
            " 402682/500000: episode: 543, duration: 46.654s, episode steps: 649, steps per second:  14, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.169 [0.000, 5.000],  loss: 0.008315, mae: 0.167279, mean_q: 0.209377, mean_eps: 0.050000\n",
            " 403063/500000: episode: 544, duration: 27.713s, episode steps: 381, steps per second:  14, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.007131, mae: 0.171376, mean_q: 0.216561, mean_eps: 0.050000\n",
            " 404016/500000: episode: 545, duration: 69.753s, episode steps: 953, steps per second:  14, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.121 [0.000, 5.000],  loss: 0.006843, mae: 0.160117, mean_q: 0.200351, mean_eps: 0.050000\n",
            " 405129/500000: episode: 546, duration: 82.045s, episode steps: 1113, steps per second:  14, episode reward: 35.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.007177, mae: 0.162726, mean_q: 0.204204, mean_eps: 0.050000\n",
            " 405672/500000: episode: 547, duration: 39.858s, episode steps: 543, steps per second:  14, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.893 [0.000, 5.000],  loss: 0.007910, mae: 0.167805, mean_q: 0.210530, mean_eps: 0.050000\n",
            " 406659/500000: episode: 548, duration: 70.428s, episode steps: 987, steps per second:  14, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.008 [0.000, 5.000],  loss: 0.007187, mae: 0.165496, mean_q: 0.208351, mean_eps: 0.050000\n",
            " 407223/500000: episode: 549, duration: 40.352s, episode steps: 564, steps per second:  14, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.778 [0.000, 5.000],  loss: 0.006507, mae: 0.163773, mean_q: 0.207256, mean_eps: 0.050000\n",
            " 408124/500000: episode: 550, duration: 64.866s, episode steps: 901, steps per second:  14, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.121 [0.000, 5.000],  loss: 0.007055, mae: 0.160528, mean_q: 0.199159, mean_eps: 0.050000\n",
            " 409061/500000: episode: 551, duration: 68.016s, episode steps: 937, steps per second:  14, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.171 [0.000, 5.000],  loss: 0.006616, mae: 0.163469, mean_q: 0.203931, mean_eps: 0.050000\n",
            " 409977/500000: episode: 552, duration: 67.108s, episode steps: 916, steps per second:  14, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.038 [0.000, 5.000],  loss: 0.009043, mae: 0.165726, mean_q: 0.205542, mean_eps: 0.050000\n",
            " 411078/500000: episode: 553, duration: 81.161s, episode steps: 1101, steps per second:  14, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.895 [0.000, 5.000],  loss: 0.007207, mae: 0.162724, mean_q: 0.204037, mean_eps: 0.050000\n",
            " 411756/500000: episode: 554, duration: 49.330s, episode steps: 678, steps per second:  14, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.960 [0.000, 5.000],  loss: 0.007576, mae: 0.156560, mean_q: 0.196743, mean_eps: 0.050000\n",
            " 412332/500000: episode: 555, duration: 43.294s, episode steps: 576, steps per second:  13, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.908 [0.000, 5.000],  loss: 0.007393, mae: 0.162095, mean_q: 0.202564, mean_eps: 0.050000\n",
            " 413807/500000: episode: 556, duration: 107.062s, episode steps: 1475, steps per second:  14, episode reward: 14.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.008331, mae: 0.162473, mean_q: 0.204232, mean_eps: 0.050000\n",
            " 414424/500000: episode: 557, duration: 45.825s, episode steps: 617, steps per second:  13, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.007583, mae: 0.160397, mean_q: 0.202246, mean_eps: 0.050000\n",
            " 415138/500000: episode: 558, duration: 52.676s, episode steps: 714, steps per second:  14, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.986 [0.000, 5.000],  loss: 0.006486, mae: 0.158787, mean_q: 0.199975, mean_eps: 0.050000\n",
            " 416020/500000: episode: 559, duration: 62.953s, episode steps: 882, steps per second:  14, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.007541, mae: 0.164565, mean_q: 0.206791, mean_eps: 0.050000\n",
            " 416565/500000: episode: 560, duration: 40.188s, episode steps: 545, steps per second:  14, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.006617, mae: 0.159935, mean_q: 0.199871, mean_eps: 0.050000\n",
            " 417385/500000: episode: 561, duration: 60.921s, episode steps: 820, steps per second:  13, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.091 [0.000, 5.000],  loss: 0.007766, mae: 0.165709, mean_q: 0.208062, mean_eps: 0.050000\n",
            " 418269/500000: episode: 562, duration: 63.516s, episode steps: 884, steps per second:  14, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.007942, mae: 0.164888, mean_q: 0.206747, mean_eps: 0.050000\n",
            " 418826/500000: episode: 563, duration: 40.754s, episode steps: 557, steps per second:  14, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.006201, mae: 0.157106, mean_q: 0.197477, mean_eps: 0.050000\n",
            " 419700/500000: episode: 564, duration: 64.412s, episode steps: 874, steps per second:  14, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.006618, mae: 0.160421, mean_q: 0.200238, mean_eps: 0.050000\n",
            " 420061/500000: episode: 565, duration: 26.752s, episode steps: 361, steps per second:  13, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 3.114 [0.000, 5.000],  loss: 0.007493, mae: 0.159413, mean_q: 0.199697, mean_eps: 0.050000\n",
            " 421214/500000: episode: 566, duration: 84.263s, episode steps: 1153, steps per second:  14, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.071 [0.000, 5.000],  loss: 0.006958, mae: 0.164375, mean_q: 0.205882, mean_eps: 0.050000\n",
            " 421851/500000: episode: 567, duration: 47.553s, episode steps: 637, steps per second:  13, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.841 [0.000, 5.000],  loss: 0.007156, mae: 0.157277, mean_q: 0.195969, mean_eps: 0.050000\n",
            " 422770/500000: episode: 568, duration: 65.263s, episode steps: 919, steps per second:  14, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.886 [0.000, 5.000],  loss: 0.006280, mae: 0.156014, mean_q: 0.195612, mean_eps: 0.050000\n",
            " 423802/500000: episode: 569, duration: 74.709s, episode steps: 1032, steps per second:  14, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.007351, mae: 0.160573, mean_q: 0.201166, mean_eps: 0.050000\n",
            " 424502/500000: episode: 570, duration: 50.624s, episode steps: 700, steps per second:  14, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.817 [0.000, 5.000],  loss: 0.007424, mae: 0.163610, mean_q: 0.205424, mean_eps: 0.050000\n",
            " 425136/500000: episode: 571, duration: 46.071s, episode steps: 634, steps per second:  14, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.005965, mae: 0.158479, mean_q: 0.199808, mean_eps: 0.050000\n",
            " 425965/500000: episode: 572, duration: 60.304s, episode steps: 829, steps per second:  14, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.843 [0.000, 5.000],  loss: 0.007254, mae: 0.159580, mean_q: 0.200563, mean_eps: 0.050000\n",
            " 427029/500000: episode: 573, duration: 78.690s, episode steps: 1064, steps per second:  14, episode reward: 25.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.089 [0.000, 5.000],  loss: 0.007775, mae: 0.162740, mean_q: 0.203503, mean_eps: 0.050000\n",
            " 427766/500000: episode: 574, duration: 54.081s, episode steps: 737, steps per second:  14, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.095 [0.000, 5.000],  loss: 0.007528, mae: 0.167484, mean_q: 0.209551, mean_eps: 0.050000\n",
            " 428898/500000: episode: 575, duration: 82.843s, episode steps: 1132, steps per second:  14, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: 0.007850, mae: 0.162179, mean_q: 0.201235, mean_eps: 0.050000\n",
            " 429769/500000: episode: 576, duration: 64.157s, episode steps: 871, steps per second:  14, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.007144, mae: 0.161739, mean_q: 0.204010, mean_eps: 0.050000\n",
            " 430326/500000: episode: 577, duration: 40.917s, episode steps: 557, steps per second:  14, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.007177, mae: 0.160450, mean_q: 0.203752, mean_eps: 0.050000\n",
            " 431239/500000: episode: 578, duration: 67.107s, episode steps: 913, steps per second:  14, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.007219, mae: 0.165682, mean_q: 0.209104, mean_eps: 0.050000\n",
            " 432110/500000: episode: 579, duration: 63.576s, episode steps: 871, steps per second:  14, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.980 [0.000, 5.000],  loss: 0.006188, mae: 0.162748, mean_q: 0.204967, mean_eps: 0.050000\n",
            " 432975/500000: episode: 580, duration: 63.671s, episode steps: 865, steps per second:  14, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.207 [0.000, 5.000],  loss: 0.006828, mae: 0.156818, mean_q: 0.197301, mean_eps: 0.050000\n",
            " 433820/500000: episode: 581, duration: 62.659s, episode steps: 845, steps per second:  13, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.135 [0.000, 5.000],  loss: 0.006630, mae: 0.157122, mean_q: 0.197372, mean_eps: 0.050000\n",
            " 434776/500000: episode: 582, duration: 69.679s, episode steps: 956, steps per second:  14, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.006844, mae: 0.163503, mean_q: 0.206281, mean_eps: 0.050000\n",
            " 435733/500000: episode: 583, duration: 69.549s, episode steps: 957, steps per second:  14, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.007154, mae: 0.162062, mean_q: 0.203842, mean_eps: 0.050000\n",
            " 436130/500000: episode: 584, duration: 28.552s, episode steps: 397, steps per second:  14, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.196 [0.000, 5.000],  loss: 0.006901, mae: 0.157084, mean_q: 0.196413, mean_eps: 0.050000\n",
            " 437158/500000: episode: 585, duration: 75.248s, episode steps: 1028, steps per second:  14, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.006831, mae: 0.157529, mean_q: 0.198372, mean_eps: 0.050000\n",
            " 438072/500000: episode: 586, duration: 67.072s, episode steps: 914, steps per second:  14, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.006161, mae: 0.156956, mean_q: 0.197360, mean_eps: 0.050000\n",
            " 438819/500000: episode: 587, duration: 54.201s, episode steps: 747, steps per second:  14, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.006959, mae: 0.160623, mean_q: 0.200271, mean_eps: 0.050000\n",
            " 439684/500000: episode: 588, duration: 63.450s, episode steps: 865, steps per second:  14, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.007430, mae: 0.161945, mean_q: 0.203544, mean_eps: 0.050000\n",
            " 440713/500000: episode: 589, duration: 76.672s, episode steps: 1029, steps per second:  13, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.684 [0.000, 5.000],  loss: 0.006847, mae: 0.160889, mean_q: 0.200902, mean_eps: 0.050000\n",
            " 441385/500000: episode: 590, duration: 48.829s, episode steps: 672, steps per second:  14, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.936 [0.000, 5.000],  loss: 0.007065, mae: 0.158249, mean_q: 0.197404, mean_eps: 0.050000\n",
            " 442258/500000: episode: 591, duration: 65.181s, episode steps: 873, steps per second:  13, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.299 [0.000, 5.000],  loss: 0.007234, mae: 0.163925, mean_q: 0.206085, mean_eps: 0.050000\n",
            " 442720/500000: episode: 592, duration: 35.332s, episode steps: 462, steps per second:  13, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.844 [0.000, 5.000],  loss: 0.007126, mae: 0.159312, mean_q: 0.200500, mean_eps: 0.050000\n",
            " 443480/500000: episode: 593, duration: 56.625s, episode steps: 760, steps per second:  13, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.964 [0.000, 5.000],  loss: 0.007229, mae: 0.156049, mean_q: 0.195156, mean_eps: 0.050000\n",
            " 444404/500000: episode: 594, duration: 68.951s, episode steps: 924, steps per second:  13, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.287 [0.000, 5.000],  loss: 0.007598, mae: 0.163542, mean_q: 0.205774, mean_eps: 0.050000\n",
            " 445376/500000: episode: 595, duration: 72.184s, episode steps: 972, steps per second:  13, episode reward: 10.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.006904, mae: 0.160248, mean_q: 0.200655, mean_eps: 0.050000\n",
            " 445915/500000: episode: 596, duration: 40.408s, episode steps: 539, steps per second:  13, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.007591, mae: 0.164673, mean_q: 0.208583, mean_eps: 0.050000\n",
            " 446988/500000: episode: 597, duration: 79.744s, episode steps: 1073, steps per second:  13, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.207 [0.000, 5.000],  loss: 0.007051, mae: 0.160810, mean_q: 0.201873, mean_eps: 0.050000\n",
            " 447646/500000: episode: 598, duration: 47.683s, episode steps: 658, steps per second:  14, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.006552, mae: 0.158106, mean_q: 0.197067, mean_eps: 0.050000\n",
            " 448210/500000: episode: 599, duration: 40.952s, episode steps: 564, steps per second:  14, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.007159, mae: 0.159695, mean_q: 0.201058, mean_eps: 0.050000\n",
            " 448783/500000: episode: 600, duration: 41.875s, episode steps: 573, steps per second:  14, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.243 [0.000, 5.000],  loss: 0.007485, mae: 0.157760, mean_q: 0.199392, mean_eps: 0.050000\n",
            " 449329/500000: episode: 601, duration: 39.607s, episode steps: 546, steps per second:  14, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.007252, mae: 0.163974, mean_q: 0.207774, mean_eps: 0.050000\n",
            " 450339/500000: episode: 602, duration: 74.715s, episode steps: 1010, steps per second:  14, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.003 [0.000, 5.000],  loss: 0.007466, mae: 0.176417, mean_q: 0.223429, mean_eps: 0.050000\n",
            " 451130/500000: episode: 603, duration: 58.431s, episode steps: 791, steps per second:  14, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.697 [0.000, 5.000],  loss: 0.007271, mae: 0.193027, mean_q: 0.242898, mean_eps: 0.050000\n",
            " 452279/500000: episode: 604, duration: 84.684s, episode steps: 1149, steps per second:  14, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.111 [0.000, 5.000],  loss: 0.007626, mae: 0.190174, mean_q: 0.239177, mean_eps: 0.050000\n",
            " 453091/500000: episode: 605, duration: 60.986s, episode steps: 812, steps per second:  13, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.007063, mae: 0.186678, mean_q: 0.233672, mean_eps: 0.050000\n",
            " 454036/500000: episode: 606, duration: 70.444s, episode steps: 945, steps per second:  13, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.008342, mae: 0.187570, mean_q: 0.234745, mean_eps: 0.050000\n",
            " 454519/500000: episode: 607, duration: 36.526s, episode steps: 483, steps per second:  13, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 3.176 [0.000, 5.000],  loss: 0.007729, mae: 0.185797, mean_q: 0.228285, mean_eps: 0.050000\n",
            " 455220/500000: episode: 608, duration: 51.731s, episode steps: 701, steps per second:  14, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.007468, mae: 0.184910, mean_q: 0.228637, mean_eps: 0.050000\n",
            " 455718/500000: episode: 609, duration: 36.957s, episode steps: 498, steps per second:  13, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.918 [0.000, 5.000],  loss: 0.007046, mae: 0.186011, mean_q: 0.229589, mean_eps: 0.050000\n",
            " 456644/500000: episode: 610, duration: 68.581s, episode steps: 926, steps per second:  14, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.008020, mae: 0.186750, mean_q: 0.230720, mean_eps: 0.050000\n",
            " 457356/500000: episode: 611, duration: 53.100s, episode steps: 712, steps per second:  13, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.927 [0.000, 5.000],  loss: 0.008589, mae: 0.184923, mean_q: 0.227403, mean_eps: 0.050000\n",
            " 457854/500000: episode: 612, duration: 37.716s, episode steps: 498, steps per second:  13, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.007814, mae: 0.188911, mean_q: 0.231934, mean_eps: 0.050000\n",
            " 458555/500000: episode: 613, duration: 52.268s, episode steps: 701, steps per second:  13, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.873 [0.000, 5.000],  loss: 0.006732, mae: 0.189675, mean_q: 0.233142, mean_eps: 0.050000\n",
            " 459755/500000: episode: 614, duration: 88.550s, episode steps: 1200, steps per second:  14, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.965 [0.000, 5.000],  loss: 0.007214, mae: 0.184614, mean_q: 0.227683, mean_eps: 0.050000\n",
            " 460968/500000: episode: 615, duration: 90.343s, episode steps: 1213, steps per second:  13, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.006934, mae: 0.183024, mean_q: 0.225649, mean_eps: 0.050000\n",
            " 461858/500000: episode: 616, duration: 66.212s, episode steps: 890, steps per second:  13, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.216 [0.000, 5.000],  loss: 0.007382, mae: 0.186367, mean_q: 0.232214, mean_eps: 0.050000\n",
            " 462541/500000: episode: 617, duration: 49.630s, episode steps: 683, steps per second:  14, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.007 [0.000, 5.000],  loss: 0.008390, mae: 0.192868, mean_q: 0.239180, mean_eps: 0.050000\n",
            " 463612/500000: episode: 618, duration: 79.955s, episode steps: 1071, steps per second:  13, episode reward: 27.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.008010, mae: 0.185653, mean_q: 0.229979, mean_eps: 0.050000\n",
            " 464154/500000: episode: 619, duration: 40.611s, episode steps: 542, steps per second:  13, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.007555, mae: 0.181310, mean_q: 0.221339, mean_eps: 0.050000\n",
            " 464841/500000: episode: 620, duration: 51.466s, episode steps: 687, steps per second:  13, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.007434, mae: 0.192382, mean_q: 0.238156, mean_eps: 0.050000\n",
            " 465744/500000: episode: 621, duration: 67.813s, episode steps: 903, steps per second:  13, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.122 [0.000, 5.000],  loss: 0.007020, mae: 0.184006, mean_q: 0.228820, mean_eps: 0.050000\n",
            " 466888/500000: episode: 622, duration: 85.589s, episode steps: 1144, steps per second:  13, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007449, mae: 0.188726, mean_q: 0.235310, mean_eps: 0.050000\n",
            " 467452/500000: episode: 623, duration: 42.244s, episode steps: 564, steps per second:  13, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.025 [0.000, 5.000],  loss: 0.007030, mae: 0.178145, mean_q: 0.218571, mean_eps: 0.050000\n",
            " 468027/500000: episode: 624, duration: 43.101s, episode steps: 575, steps per second:  13, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.006741, mae: 0.180587, mean_q: 0.221780, mean_eps: 0.050000\n",
            " 469000/500000: episode: 625, duration: 73.074s, episode steps: 973, steps per second:  13, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.007494, mae: 0.184623, mean_q: 0.227455, mean_eps: 0.050000\n",
            " 469953/500000: episode: 626, duration: 70.884s, episode steps: 953, steps per second:  13, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.008091, mae: 0.188776, mean_q: 0.233649, mean_eps: 0.050000\n",
            " 470479/500000: episode: 627, duration: 39.305s, episode steps: 526, steps per second:  13, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.173 [0.000, 5.000],  loss: 0.006502, mae: 0.182506, mean_q: 0.226268, mean_eps: 0.050000\n",
            " 471431/500000: episode: 628, duration: 70.933s, episode steps: 952, steps per second:  13, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.915 [0.000, 5.000],  loss: 0.007042, mae: 0.185389, mean_q: 0.228671, mean_eps: 0.050000\n",
            " 472473/500000: episode: 629, duration: 78.348s, episode steps: 1042, steps per second:  13, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.007607, mae: 0.187669, mean_q: 0.230894, mean_eps: 0.050000\n",
            " 473178/500000: episode: 630, duration: 52.959s, episode steps: 705, steps per second:  13, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.102 [0.000, 5.000],  loss: 0.008222, mae: 0.194511, mean_q: 0.241034, mean_eps: 0.050000\n",
            " 474147/500000: episode: 631, duration: 71.840s, episode steps: 969, steps per second:  13, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007085, mae: 0.183199, mean_q: 0.225868, mean_eps: 0.050000\n",
            " 474662/500000: episode: 632, duration: 39.246s, episode steps: 515, steps per second:  13, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.008238, mae: 0.189028, mean_q: 0.234122, mean_eps: 0.050000\n",
            " 475634/500000: episode: 633, duration: 72.246s, episode steps: 972, steps per second:  13, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007228, mae: 0.185352, mean_q: 0.228615, mean_eps: 0.050000\n",
            " 476006/500000: episode: 634, duration: 27.841s, episode steps: 372, steps per second:  13, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.161 [0.000, 5.000],  loss: 0.006821, mae: 0.179757, mean_q: 0.222735, mean_eps: 0.050000\n",
            " 476974/500000: episode: 635, duration: 73.425s, episode steps: 968, steps per second:  13, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.122 [0.000, 5.000],  loss: 0.007920, mae: 0.189977, mean_q: 0.234732, mean_eps: 0.050000\n",
            " 477782/500000: episode: 636, duration: 59.805s, episode steps: 808, steps per second:  14, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.007439, mae: 0.184569, mean_q: 0.228545, mean_eps: 0.050000\n",
            " 478164/500000: episode: 637, duration: 28.719s, episode steps: 382, steps per second:  13, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.024 [0.000, 5.000],  loss: 0.006958, mae: 0.183372, mean_q: 0.229028, mean_eps: 0.050000\n",
            " 478796/500000: episode: 638, duration: 48.913s, episode steps: 632, steps per second:  13, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.945 [0.000, 5.000],  loss: 0.007441, mae: 0.184796, mean_q: 0.228179, mean_eps: 0.050000\n",
            " 479485/500000: episode: 639, duration: 51.429s, episode steps: 689, steps per second:  13, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.006872, mae: 0.183613, mean_q: 0.227253, mean_eps: 0.050000\n",
            " 480384/500000: episode: 640, duration: 67.463s, episode steps: 899, steps per second:  13, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.007523, mae: 0.180961, mean_q: 0.223789, mean_eps: 0.050000\n",
            " 481033/500000: episode: 641, duration: 49.640s, episode steps: 649, steps per second:  13, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.328 [0.000, 5.000],  loss: 0.007204, mae: 0.183135, mean_q: 0.226829, mean_eps: 0.050000\n",
            " 481887/500000: episode: 642, duration: 64.795s, episode steps: 854, steps per second:  13, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.007297, mae: 0.184565, mean_q: 0.228203, mean_eps: 0.050000\n",
            " 482267/500000: episode: 643, duration: 28.600s, episode steps: 380, steps per second:  13, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.006562, mae: 0.174671, mean_q: 0.214487, mean_eps: 0.050000\n",
            " 483250/500000: episode: 644, duration: 73.471s, episode steps: 983, steps per second:  13, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.007623, mae: 0.188010, mean_q: 0.233344, mean_eps: 0.050000\n",
            " 483889/500000: episode: 645, duration: 48.884s, episode steps: 639, steps per second:  13, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.169 [0.000, 5.000],  loss: 0.007926, mae: 0.179648, mean_q: 0.222090, mean_eps: 0.050000\n",
            " 484767/500000: episode: 646, duration: 66.514s, episode steps: 878, steps per second:  13, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.007068, mae: 0.184685, mean_q: 0.227882, mean_eps: 0.050000\n",
            " 485422/500000: episode: 647, duration: 48.671s, episode steps: 655, steps per second:  13, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.007640, mae: 0.187061, mean_q: 0.228831, mean_eps: 0.050000\n",
            " 485927/500000: episode: 648, duration: 38.402s, episode steps: 505, steps per second:  13, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.198 [0.000, 5.000],  loss: 0.007015, mae: 0.178842, mean_q: 0.221351, mean_eps: 0.050000\n",
            " 486568/500000: episode: 649, duration: 49.274s, episode steps: 641, steps per second:  13, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.007656, mae: 0.184204, mean_q: 0.225916, mean_eps: 0.050000\n",
            " 487073/500000: episode: 650, duration: 37.778s, episode steps: 505, steps per second:  13, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.006523, mae: 0.182870, mean_q: 0.227188, mean_eps: 0.050000\n",
            " 487713/500000: episode: 651, duration: 48.730s, episode steps: 640, steps per second:  13, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.991 [0.000, 5.000],  loss: 0.008063, mae: 0.184729, mean_q: 0.228518, mean_eps: 0.050000\n",
            " 488504/500000: episode: 652, duration: 58.608s, episode steps: 791, steps per second:  13, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.007619, mae: 0.185380, mean_q: 0.230890, mean_eps: 0.050000\n",
            " 488990/500000: episode: 653, duration: 36.962s, episode steps: 486, steps per second:  13, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.924 [0.000, 5.000],  loss: 0.006616, mae: 0.179568, mean_q: 0.223552, mean_eps: 0.050000\n",
            " 490162/500000: episode: 654, duration: 86.485s, episode steps: 1172, steps per second:  14, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.007931, mae: 0.189624, mean_q: 0.235447, mean_eps: 0.050000\n",
            " 491011/500000: episode: 655, duration: 63.241s, episode steps: 849, steps per second:  13, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: 0.006822, mae: 0.175179, mean_q: 0.217442, mean_eps: 0.050000\n",
            " 491740/500000: episode: 656, duration: 54.672s, episode steps: 729, steps per second:  13, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006984, mae: 0.185580, mean_q: 0.230251, mean_eps: 0.050000\n",
            " 492391/500000: episode: 657, duration: 49.108s, episode steps: 651, steps per second:  13, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.138 [0.000, 5.000],  loss: 0.008011, mae: 0.182793, mean_q: 0.227081, mean_eps: 0.050000\n",
            " 493031/500000: episode: 658, duration: 47.694s, episode steps: 640, steps per second:  13, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.006910, mae: 0.182111, mean_q: 0.226629, mean_eps: 0.050000\n",
            " 493882/500000: episode: 659, duration: 64.925s, episode steps: 851, steps per second:  13, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.055 [0.000, 5.000],  loss: 0.007679, mae: 0.182670, mean_q: 0.226504, mean_eps: 0.050000\n",
            " 494574/500000: episode: 660, duration: 52.707s, episode steps: 692, steps per second:  13, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.808 [0.000, 5.000],  loss: 0.006840, mae: 0.179713, mean_q: 0.223628, mean_eps: 0.050000\n",
            " 495212/500000: episode: 661, duration: 47.442s, episode steps: 638, steps per second:  13, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.007964, mae: 0.184358, mean_q: 0.229954, mean_eps: 0.050000\n",
            " 495888/500000: episode: 662, duration: 51.573s, episode steps: 676, steps per second:  13, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.112 [0.000, 5.000],  loss: 0.006884, mae: 0.186432, mean_q: 0.232460, mean_eps: 0.050000\n",
            " 496602/500000: episode: 663, duration: 54.044s, episode steps: 714, steps per second:  13, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.706 [0.000, 5.000],  loss: 0.007897, mae: 0.182871, mean_q: 0.226100, mean_eps: 0.050000\n",
            " 497465/500000: episode: 664, duration: 64.759s, episode steps: 863, steps per second:  13, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.283 [0.000, 5.000],  loss: 0.007710, mae: 0.186838, mean_q: 0.231957, mean_eps: 0.050000\n",
            " 498113/500000: episode: 665, duration: 47.194s, episode steps: 648, steps per second:  14, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.006837, mae: 0.184485, mean_q: 0.231883, mean_eps: 0.050000\n",
            " 499146/500000: episode: 666, duration: 77.441s, episode steps: 1033, steps per second:  13, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.008170, mae: 0.187823, mean_q: 0.232946, mean_eps: 0.050000\n",
            "done, took 31800.907 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 13.000, steps: 891\n",
            "Episode 2: reward: 12.000, steps: 712\n",
            "Episode 3: reward: 21.000, steps: 1080\n",
            "Episode 4: reward: 10.000, steps: 613\n",
            "Episode 5: reward: 11.000, steps: 737\n",
            "Episode 6: reward: 19.000, steps: 1077\n",
            "Episode 7: reward: 19.000, steps: 856\n",
            "Episode 8: reward: 8.000, steps: 514\n",
            "Episode 9: reward: 14.000, steps: 687\n",
            "Episode 10: reward: 15.000, steps: 1053\n",
            "Episode 11: reward: 16.000, steps: 747\n",
            "Episode 12: reward: 8.000, steps: 458\n",
            "Episode 13: reward: 10.000, steps: 558\n",
            "Episode 14: reward: 29.000, steps: 1393\n",
            "Episode 15: reward: 15.000, steps: 915\n",
            "Episode 16: reward: 17.000, steps: 878\n",
            "Episode 17: reward: 21.000, steps: 1038\n",
            "Episode 18: reward: 17.000, steps: 816\n",
            "Episode 19: reward: 20.000, steps: 1048\n",
            "Episode 20: reward: 17.000, steps: 944\n",
            "\n",
            "🎯 Recompensa promedio tras refinamiento: 15.60\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Lambda, Add, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# ==== Constantes ====\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "\n",
        "# ==== Procesador de observaciones ====\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        img = Image.fromarray(observation).resize(INPUT_SHAPE).convert('L')\n",
        "        return np.array(img).astype('uint8')\n",
        "    def process_state_batch(self, batch):\n",
        "        return batch.astype('float32') / 255.\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "# ==== Modelo Dueling CNN ====\n",
        "def build_dueling_model(nb_actions, input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Permute((2, 3, 1))(inputs)\n",
        "    x = Conv2D(32, 8, strides=4, activation='relu')(x)\n",
        "    x = Conv2D(64, 4, strides=2, activation='relu')(x)\n",
        "    x = Conv2D(64, 3, strides=1, activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Dueling streams\n",
        "    value = Dense(512, activation='relu')(x)\n",
        "    value = Dense(1)(value)\n",
        "\n",
        "    advantage = Dense(512, activation='relu')(x)\n",
        "    advantage = Dense(nb_actions)(advantage)\n",
        "\n",
        "    # Combine streams\n",
        "    advantage_mean = Lambda(lambda a: a - K.mean(a, axis=1, keepdims=True))(advantage)\n",
        "    q_values = Add()([value, advantage_mean])\n",
        "\n",
        "    return Model(inputs=inputs, outputs=q_values)\n",
        "\n",
        "# ==== Preparar entorno ====\n",
        "env = gym.make(ENV_NAME)\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "# ==== Modelo y Memoria ====\n",
        "model = build_dueling_model(nb_actions, input_shape)\n",
        "memory = SequentialMemory(limit=2000000, window_length=WINDOW_LENGTH)\n",
        "\n",
        "# ==== Política refinada ====\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=1.0, value_min=0.05, value_test=0.01,\n",
        "                              nb_steps=250000)\n",
        "\n",
        "# ==== Agente DQN con hiperparámetros ajustados ====\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               memory=memory,\n",
        "               processor=AtariProcessor(),\n",
        "               nb_steps_warmup=50000,\n",
        "               enable_double_dqn=True,\n",
        "               target_model_update=50000,\n",
        "               policy=policy,\n",
        "               train_interval=4,\n",
        "               gamma=0.995)\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.0001), metrics=['mae'])\n",
        "\n",
        "# ==== Callbacks (opcional para guardar logs y pesos) ====\n",
        "checkpoint_weights_filename = f'dqn_{ENV_NAME}_refined_weights_{{step}}.h5f'\n",
        "log_filename = f'dqn_{ENV_NAME}_refined_log.json'\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_weights_filename, interval=100000),\n",
        "    FileLogger(log_filename, interval=100)\n",
        "]\n",
        "\n",
        "# ==== ENTRENAMIENTO REFINADO (500k pasos) ====\n",
        "dqn.fit(env,\n",
        "        nb_steps=500000,\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "# ==== Guardar pesos finales ====\n",
        "dqn.save_weights(f'dqn_{ENV_NAME}_dueling_double_refined.h5f', overwrite=True)\n",
        "\n",
        "# ==== Evaluación (20 episodios) ====\n",
        "history = dqn.test(env, nb_episodes=20, visualize=False)\n",
        "rewards = history.history['episode_reward']\n",
        "mean_reward = np.mean(rewards)\n",
        "print(f\"\\n🎯 Recompensa promedio tras refinamiento: {mean_reward:.2f}\")\n",
        "\n",
        "# ==== GRAFICAR REWARDS (usando log si existe) ====\n",
        "try:\n",
        "    with open(log_filename) as f:\n",
        "        log_data = json.load(f)\n",
        "\n",
        "    episode_rewards = log_data['episode_reward']\n",
        "    episodes = list(range(1, len(episode_rewards) + 1))\n",
        "\n",
        "    def moving_average(data, window_size=10):\n",
        "        return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "    smoothed_rewards = moving_average(episode_rewards)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(episodes, episode_rewards, alpha=0.3, label='Reward por episodio')\n",
        "    plt.plot(episodes[:len(smoothed_rewards)], smoothed_rewards, color='red', label='Media móvil (10)')\n",
        "    plt.xlabel('Episodio')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.title('Evolución del reward durante el entrenamiento refinado')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"No se pudo generar la gráfica. ¿Ejecutaste con `FileLogger` activado?\")\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0bohJ3Y4cXD",
        "outputId": "8b8729d9-2905-421f-dcec-764cf288e50d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 250000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    420/250000: episode: 1, duration: 1.903s, episode steps: 420, steps per second: 221, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "    980/250000: episode: 2, duration: 2.387s, episode steps: 560, steps per second: 235, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1378/250000: episode: 3, duration: 1.677s, episode steps: 398, steps per second: 237, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2082/250000: episode: 4, duration: 2.871s, episode steps: 704, steps per second: 245, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2919/250000: episode: 5, duration: 3.521s, episode steps: 837, steps per second: 238, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3440/250000: episode: 6, duration: 2.253s, episode steps: 521, steps per second: 231, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3991/250000: episode: 7, duration: 2.296s, episode steps: 551, steps per second: 240, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4804/250000: episode: 8, duration: 3.365s, episode steps: 813, steps per second: 242, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5691/250000: episode: 9, duration: 3.602s, episode steps: 887, steps per second: 246, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6568/250000: episode: 10, duration: 3.698s, episode steps: 877, steps per second: 237, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7080/250000: episode: 11, duration: 2.130s, episode steps: 512, steps per second: 240, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7456/250000: episode: 12, duration: 1.577s, episode steps: 376, steps per second: 238, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8271/250000: episode: 13, duration: 3.345s, episode steps: 815, steps per second: 244, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9025/250000: episode: 14, duration: 3.158s, episode steps: 754, steps per second: 239, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9681/250000: episode: 15, duration: 2.776s, episode steps: 656, steps per second: 236, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10368/250000: episode: 16, duration: 2.871s, episode steps: 687, steps per second: 239, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11019/250000: episode: 17, duration: 2.710s, episode steps: 651, steps per second: 240, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11519/250000: episode: 18, duration: 2.040s, episode steps: 500, steps per second: 245, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12213/250000: episode: 19, duration: 2.933s, episode steps: 694, steps per second: 237, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12808/250000: episode: 20, duration: 2.449s, episode steps: 595, steps per second: 243, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13313/250000: episode: 21, duration: 2.144s, episode steps: 505, steps per second: 236, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13915/250000: episode: 22, duration: 2.443s, episode steps: 602, steps per second: 246, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14701/250000: episode: 23, duration: 3.271s, episode steps: 786, steps per second: 240, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15822/250000: episode: 24, duration: 4.773s, episode steps: 1121, steps per second: 235, episode reward: 10.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16395/250000: episode: 25, duration: 2.369s, episode steps: 573, steps per second: 242, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16987/250000: episode: 26, duration: 2.420s, episode steps: 592, steps per second: 245, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17623/250000: episode: 27, duration: 2.609s, episode steps: 636, steps per second: 244, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18117/250000: episode: 28, duration: 2.143s, episode steps: 494, steps per second: 230, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18797/250000: episode: 29, duration: 2.861s, episode steps: 680, steps per second: 238, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19799/250000: episode: 30, duration: 4.003s, episode steps: 1002, steps per second: 250, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20660/250000: episode: 31, duration: 3.585s, episode steps: 861, steps per second: 240, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21165/250000: episode: 32, duration: 2.094s, episode steps: 505, steps per second: 241, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21854/250000: episode: 33, duration: 2.861s, episode steps: 689, steps per second: 241, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22455/250000: episode: 34, duration: 2.505s, episode steps: 601, steps per second: 240, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22892/250000: episode: 35, duration: 1.810s, episode steps: 437, steps per second: 241, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23644/250000: episode: 36, duration: 3.060s, episode steps: 752, steps per second: 246, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24361/250000: episode: 37, duration: 3.027s, episode steps: 717, steps per second: 237, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24797/250000: episode: 38, duration: 1.837s, episode steps: 436, steps per second: 237, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25515/250000: episode: 39, duration: 2.932s, episode steps: 718, steps per second: 245, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26108/250000: episode: 40, duration: 2.442s, episode steps: 593, steps per second: 243, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26933/250000: episode: 41, duration: 3.437s, episode steps: 825, steps per second: 240, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27331/250000: episode: 42, duration: 1.689s, episode steps: 398, steps per second: 236, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27903/250000: episode: 43, duration: 2.412s, episode steps: 572, steps per second: 237, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28494/250000: episode: 44, duration: 2.411s, episode steps: 591, steps per second: 245, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28968/250000: episode: 45, duration: 1.984s, episode steps: 474, steps per second: 239, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29704/250000: episode: 46, duration: 3.109s, episode steps: 736, steps per second: 237, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30427/250000: episode: 47, duration: 3.036s, episode steps: 723, steps per second: 238, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31204/250000: episode: 48, duration: 3.250s, episode steps: 777, steps per second: 239, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31601/250000: episode: 49, duration: 1.633s, episode steps: 397, steps per second: 243, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32014/250000: episode: 50, duration: 1.671s, episode steps: 413, steps per second: 247, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32474/250000: episode: 51, duration: 1.952s, episode steps: 460, steps per second: 236, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32963/250000: episode: 52, duration: 2.031s, episode steps: 489, steps per second: 241, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33631/250000: episode: 53, duration: 2.731s, episode steps: 668, steps per second: 245, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34469/250000: episode: 54, duration: 3.450s, episode steps: 838, steps per second: 243, episode reward:  6.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34985/250000: episode: 55, duration: 2.163s, episode steps: 516, steps per second: 239, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35633/250000: episode: 56, duration: 2.654s, episode steps: 648, steps per second: 244, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36590/250000: episode: 57, duration: 3.937s, episode steps: 957, steps per second: 243, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37660/250000: episode: 58, duration: 4.429s, episode steps: 1070, steps per second: 242, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38963/250000: episode: 59, duration: 5.518s, episode steps: 1303, steps per second: 236, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39672/250000: episode: 60, duration: 2.925s, episode steps: 709, steps per second: 242, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40269/250000: episode: 61, duration: 2.484s, episode steps: 597, steps per second: 240, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41039/250000: episode: 62, duration: 3.237s, episode steps: 770, steps per second: 238, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42008/250000: episode: 63, duration: 4.089s, episode steps: 969, steps per second: 237, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42738/250000: episode: 64, duration: 3.062s, episode steps: 730, steps per second: 238, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43981/250000: episode: 65, duration: 5.040s, episode steps: 1243, steps per second: 247, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44763/250000: episode: 66, duration: 3.268s, episode steps: 782, steps per second: 239, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45305/250000: episode: 67, duration: 2.225s, episode steps: 542, steps per second: 244, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46201/250000: episode: 68, duration: 3.730s, episode steps: 896, steps per second: 240, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47126/250000: episode: 69, duration: 3.734s, episode steps: 925, steps per second: 248, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47598/250000: episode: 70, duration: 2.067s, episode steps: 472, steps per second: 228, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48291/250000: episode: 71, duration: 2.876s, episode steps: 693, steps per second: 241, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48689/250000: episode: 72, duration: 1.672s, episode steps: 398, steps per second: 238, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49262/250000: episode: 73, duration: 2.373s, episode steps: 573, steps per second: 241, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49652/250000: episode: 74, duration: 1.599s, episode steps: 390, steps per second: 244, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.328 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  50636/250000: episode: 75, duration: 20.992s, episode steps: 984, steps per second:  47, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.006419, mae: 0.023217, mean_q: 0.041597, mean_eps: 0.808792\n",
            "  51319/250000: episode: 76, duration: 20.582s, episode steps: 683, steps per second:  33, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.006452, mae: 0.023202, mean_q: 0.036921, mean_eps: 0.806291\n",
            "  51672/250000: episode: 77, duration: 10.659s, episode steps: 353, steps per second:  33, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.007224, mae: 0.026601, mean_q: 0.036748, mean_eps: 0.804323\n",
            "  52075/250000: episode: 78, duration: 12.132s, episode steps: 403, steps per second:  33, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.005617, mae: 0.021662, mean_q: 0.033422, mean_eps: 0.802886\n",
            "  52872/250000: episode: 79, duration: 23.922s, episode steps: 797, steps per second:  33, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.006123, mae: 0.023906, mean_q: 0.035509, mean_eps: 0.800606\n",
            "  53417/250000: episode: 80, duration: 16.727s, episode steps: 545, steps per second:  33, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.007032, mae: 0.026924, mean_q: 0.040176, mean_eps: 0.798053\n",
            "  54147/250000: episode: 81, duration: 21.859s, episode steps: 730, steps per second:  33, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.005846, mae: 0.022705, mean_q: 0.033354, mean_eps: 0.795628\n",
            "  55215/250000: episode: 82, duration: 31.800s, episode steps: 1068, steps per second:  34, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.005536, mae: 0.022266, mean_q: 0.032572, mean_eps: 0.792216\n",
            "  55642/250000: episode: 83, duration: 12.847s, episode steps: 427, steps per second:  33, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.006464, mae: 0.025312, mean_q: 0.037153, mean_eps: 0.789374\n",
            "  56441/250000: episode: 84, duration: 23.997s, episode steps: 799, steps per second:  33, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.006449, mae: 0.024304, mean_q: 0.034452, mean_eps: 0.787040\n",
            "  57065/250000: episode: 85, duration: 18.788s, episode steps: 624, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.841 [0.000, 5.000],  loss: 0.005305, mae: 0.023421, mean_q: 0.034590, mean_eps: 0.784335\n",
            "  57569/250000: episode: 86, duration: 15.173s, episode steps: 504, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.008129, mae: 0.027401, mean_q: 0.037802, mean_eps: 0.782192\n",
            "  58554/250000: episode: 87, duration: 29.472s, episode steps: 985, steps per second:  33, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.006291, mae: 0.024616, mean_q: 0.036142, mean_eps: 0.779364\n",
            "  59698/250000: episode: 88, duration: 34.417s, episode steps: 1144, steps per second:  33, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.006364, mae: 0.024247, mean_q: 0.035244, mean_eps: 0.775321\n",
            "  60284/250000: episode: 89, duration: 17.664s, episode steps: 586, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.005469, mae: 0.023071, mean_q: 0.033730, mean_eps: 0.772038\n",
            "  60808/250000: episode: 90, duration: 15.762s, episode steps: 524, steps per second:  33, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.742 [0.000, 5.000],  loss: 0.006949, mae: 0.025724, mean_q: 0.036349, mean_eps: 0.769933\n",
            "  61199/250000: episode: 91, duration: 11.747s, episode steps: 391, steps per second:  33, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.005023, mae: 0.021609, mean_q: 0.034069, mean_eps: 0.768192\n",
            "  61545/250000: episode: 92, duration: 10.413s, episode steps: 346, steps per second:  33, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.005637, mae: 0.023206, mean_q: 0.034430, mean_eps: 0.766786\n",
            "  62363/250000: episode: 93, duration: 24.416s, episode steps: 818, steps per second:  34, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.005422, mae: 0.022248, mean_q: 0.032123, mean_eps: 0.764575\n",
            "  63286/250000: episode: 94, duration: 27.704s, episode steps: 923, steps per second:  33, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.006538, mae: 0.025224, mean_q: 0.035734, mean_eps: 0.761269\n",
            "  63680/250000: episode: 95, duration: 12.070s, episode steps: 394, steps per second:  33, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.746 [0.000, 5.000],  loss: 0.007845, mae: 0.027640, mean_q: 0.042355, mean_eps: 0.758768\n",
            "  64580/250000: episode: 96, duration: 27.498s, episode steps: 900, steps per second:  33, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.005329, mae: 0.023385, mean_q: 0.034207, mean_eps: 0.756314\n",
            "  64926/250000: episode: 97, duration: 10.510s, episode steps: 346, steps per second:  33, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.004743, mae: 0.021069, mean_q: 0.032065, mean_eps: 0.753942\n",
            "  65688/250000: episode: 98, duration: 23.251s, episode steps: 762, steps per second:  33, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.006159, mae: 0.024326, mean_q: 0.036212, mean_eps: 0.751837\n",
            "  66215/250000: episode: 99, duration: 15.837s, episode steps: 527, steps per second:  33, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.005661, mae: 0.023375, mean_q: 0.035969, mean_eps: 0.749390\n",
            "  67092/250000: episode: 100, duration: 26.364s, episode steps: 877, steps per second:  33, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.006509, mae: 0.024887, mean_q: 0.039982, mean_eps: 0.746722\n",
            "  67744/250000: episode: 101, duration: 19.782s, episode steps: 652, steps per second:  33, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.005261, mae: 0.022919, mean_q: 0.035839, mean_eps: 0.743819\n",
            "  68245/250000: episode: 102, duration: 15.150s, episode steps: 501, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.006742, mae: 0.025327, mean_q: 0.036137, mean_eps: 0.741623\n",
            "  69024/250000: episode: 103, duration: 23.417s, episode steps: 779, steps per second:  33, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.007955, mae: 0.027922, mean_q: 0.042162, mean_eps: 0.739191\n",
            "  69847/250000: episode: 104, duration: 24.626s, episode steps: 823, steps per second:  33, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.005946, mae: 0.024589, mean_q: 0.034909, mean_eps: 0.736151\n",
            "  70415/250000: episode: 105, duration: 16.891s, episode steps: 568, steps per second:  34, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.005929, mae: 0.024637, mean_q: 0.034968, mean_eps: 0.733506\n",
            "  70825/250000: episode: 106, duration: 12.238s, episode steps: 410, steps per second:  34, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.006390, mae: 0.023847, mean_q: 0.034142, mean_eps: 0.731644\n",
            "  71280/250000: episode: 107, duration: 13.665s, episode steps: 455, steps per second:  33, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006881, mae: 0.026400, mean_q: 0.035770, mean_eps: 0.730002\n",
            "  71695/250000: episode: 108, duration: 12.504s, episode steps: 415, steps per second:  33, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.007276, mae: 0.027368, mean_q: 0.040176, mean_eps: 0.728353\n",
            "  72191/250000: episode: 109, duration: 14.862s, episode steps: 496, steps per second:  33, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.007152, mae: 0.025820, mean_q: 0.035930, mean_eps: 0.726620\n",
            "  72901/250000: episode: 110, duration: 21.555s, episode steps: 710, steps per second:  33, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.007328, mae: 0.026214, mean_q: 0.038454, mean_eps: 0.724325\n",
            "  73453/250000: episode: 111, duration: 16.623s, episode steps: 552, steps per second:  33, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.006307, mae: 0.025882, mean_q: 0.039061, mean_eps: 0.721924\n",
            "  74011/250000: episode: 112, duration: 16.936s, episode steps: 558, steps per second:  33, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.006897, mae: 0.026643, mean_q: 0.038303, mean_eps: 0.719818\n",
            "  74802/250000: episode: 113, duration: 23.830s, episode steps: 791, steps per second:  33, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.006070, mae: 0.024085, mean_q: 0.036931, mean_eps: 0.717257\n",
            "  75881/250000: episode: 114, duration: 32.608s, episode steps: 1079, steps per second:  33, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.006251, mae: 0.025277, mean_q: 0.037731, mean_eps: 0.713700\n",
            "  76899/250000: episode: 115, duration: 30.602s, episode steps: 1018, steps per second:  33, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.005626, mae: 0.023275, mean_q: 0.034360, mean_eps: 0.709718\n",
            "  77792/250000: episode: 116, duration: 27.443s, episode steps: 893, steps per second:  33, episode reward: 25.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.006392, mae: 0.025643, mean_q: 0.039261, mean_eps: 0.706093\n",
            "  78444/250000: episode: 117, duration: 19.693s, episode steps: 652, steps per second:  33, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.776 [0.000, 5.000],  loss: 0.007284, mae: 0.025908, mean_q: 0.039577, mean_eps: 0.703159\n",
            "  79768/250000: episode: 118, duration: 40.882s, episode steps: 1324, steps per second:  32, episode reward: 17.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.006570, mae: 0.025663, mean_q: 0.039410, mean_eps: 0.699405\n",
            "  80599/250000: episode: 119, duration: 25.996s, episode steps: 831, steps per second:  32, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.005620, mae: 0.023735, mean_q: 0.036485, mean_eps: 0.695308\n",
            "  81186/250000: episode: 120, duration: 18.238s, episode steps: 587, steps per second:  32, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.006416, mae: 0.024450, mean_q: 0.036498, mean_eps: 0.692610\n",
            "  82520/250000: episode: 121, duration: 41.169s, episode steps: 1334, steps per second:  32, episode reward: 26.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.007433, mae: 0.026905, mean_q: 0.044796, mean_eps: 0.688962\n",
            "  83190/250000: episode: 122, duration: 20.475s, episode steps: 670, steps per second:  33, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.005554, mae: 0.024367, mean_q: 0.037317, mean_eps: 0.685155\n",
            "  83658/250000: episode: 123, duration: 14.206s, episode steps: 468, steps per second:  33, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: 0.006115, mae: 0.024644, mean_q: 0.037954, mean_eps: 0.682989\n",
            "  84274/250000: episode: 124, duration: 19.039s, episode steps: 616, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.005950, mae: 0.023904, mean_q: 0.036865, mean_eps: 0.680929\n",
            "  84762/250000: episode: 125, duration: 14.889s, episode steps: 488, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.762 [0.000, 5.000],  loss: 0.007927, mae: 0.028509, mean_q: 0.043315, mean_eps: 0.678832\n",
            "  85219/250000: episode: 126, duration: 13.872s, episode steps: 457, steps per second:  33, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.008564, mae: 0.028775, mean_q: 0.041952, mean_eps: 0.677038\n",
            "  86425/250000: episode: 127, duration: 36.904s, episode steps: 1206, steps per second:  33, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.006491, mae: 0.026182, mean_q: 0.041089, mean_eps: 0.673876\n",
            "  87457/250000: episode: 128, duration: 31.685s, episode steps: 1032, steps per second:  33, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.827 [0.000, 5.000],  loss: 0.006705, mae: 0.026482, mean_q: 0.040564, mean_eps: 0.669620\n",
            "  87930/250000: episode: 129, duration: 14.478s, episode steps: 473, steps per second:  33, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.007620, mae: 0.027760, mean_q: 0.041236, mean_eps: 0.666763\n",
            "  88700/250000: episode: 130, duration: 23.639s, episode steps: 770, steps per second:  33, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.008084, mae: 0.029103, mean_q: 0.044391, mean_eps: 0.664407\n",
            "  89426/250000: episode: 131, duration: 22.571s, episode steps: 726, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.005850, mae: 0.024232, mean_q: 0.037172, mean_eps: 0.661564\n",
            "  90060/250000: episode: 132, duration: 19.660s, episode steps: 634, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.005214, mae: 0.022643, mean_q: 0.035745, mean_eps: 0.658980\n",
            "  91039/250000: episode: 133, duration: 30.106s, episode steps: 979, steps per second:  33, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.006485, mae: 0.025516, mean_q: 0.039620, mean_eps: 0.655918\n",
            "  91847/250000: episode: 134, duration: 24.837s, episode steps: 808, steps per second:  33, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.006535, mae: 0.025283, mean_q: 0.041884, mean_eps: 0.652520\n",
            "  92893/250000: episode: 135, duration: 32.237s, episode steps: 1046, steps per second:  32, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.007381, mae: 0.027930, mean_q: 0.044957, mean_eps: 0.648994\n",
            "  93396/250000: episode: 136, duration: 15.551s, episode steps: 503, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.829 [0.000, 5.000],  loss: 0.007008, mae: 0.026061, mean_q: 0.041914, mean_eps: 0.646053\n",
            "  94171/250000: episode: 137, duration: 23.933s, episode steps: 775, steps per second:  32, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.006009, mae: 0.024224, mean_q: 0.040238, mean_eps: 0.643628\n",
            "  94648/250000: episode: 138, duration: 14.796s, episode steps: 477, steps per second:  32, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.007850, mae: 0.028936, mean_q: 0.045101, mean_eps: 0.641250\n",
            "  95250/250000: episode: 139, duration: 18.545s, episode steps: 602, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.005947, mae: 0.024260, mean_q: 0.038521, mean_eps: 0.639198\n",
            "  95839/250000: episode: 140, duration: 18.129s, episode steps: 589, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.006782, mae: 0.024932, mean_q: 0.039390, mean_eps: 0.636933\n",
            "  96490/250000: episode: 141, duration: 20.019s, episode steps: 651, steps per second:  33, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.006761, mae: 0.026670, mean_q: 0.041382, mean_eps: 0.634577\n",
            "  96988/250000: episode: 142, duration: 15.395s, episode steps: 498, steps per second:  32, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.775 [0.000, 5.000],  loss: 0.004603, mae: 0.022314, mean_q: 0.036509, mean_eps: 0.632396\n",
            "  97760/250000: episode: 143, duration: 23.995s, episode steps: 772, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.863 [0.000, 5.000],  loss: 0.005224, mae: 0.022270, mean_q: 0.037130, mean_eps: 0.629986\n",
            "  98614/250000: episode: 144, duration: 26.277s, episode steps: 854, steps per second:  32, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.726 [0.000, 5.000],  loss: 0.007131, mae: 0.026393, mean_q: 0.040149, mean_eps: 0.626893\n",
            "  99159/250000: episode: 145, duration: 16.631s, episode steps: 545, steps per second:  33, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.007717, mae: 0.028369, mean_q: 0.043300, mean_eps: 0.624233\n",
            "  99738/250000: episode: 146, duration: 17.949s, episode steps: 579, steps per second:  32, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.005596, mae: 0.024561, mean_q: 0.040229, mean_eps: 0.622098\n",
            " 100237/250000: episode: 147, duration: 15.463s, episode steps: 499, steps per second:  32, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.009168, mae: 0.044389, mean_q: 0.069073, mean_eps: 0.620046\n",
            " 100742/250000: episode: 148, duration: 15.525s, episode steps: 505, steps per second:  33, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.007404, mae: 0.059948, mean_q: 0.087250, mean_eps: 0.618138\n",
            " 101272/250000: episode: 149, duration: 16.443s, episode steps: 530, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.005395, mae: 0.057436, mean_q: 0.086283, mean_eps: 0.616177\n",
            " 102004/250000: episode: 150, duration: 22.437s, episode steps: 732, steps per second:  33, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.009142, mae: 0.066867, mean_q: 0.094436, mean_eps: 0.613783\n",
            " 102381/250000: episode: 151, duration: 11.653s, episode steps: 377, steps per second:  32, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.007252, mae: 0.059084, mean_q: 0.084005, mean_eps: 0.611670\n",
            " 103006/250000: episode: 152, duration: 19.461s, episode steps: 625, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.790 [0.000, 5.000],  loss: 0.006406, mae: 0.060309, mean_q: 0.086624, mean_eps: 0.609763\n",
            " 103532/250000: episode: 153, duration: 16.422s, episode steps: 526, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.007233, mae: 0.061615, mean_q: 0.088594, mean_eps: 0.607582\n",
            " 104537/250000: episode: 154, duration: 31.259s, episode steps: 1005, steps per second:  32, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006653, mae: 0.061073, mean_q: 0.088203, mean_eps: 0.604671\n",
            " 105406/250000: episode: 155, duration: 26.571s, episode steps: 869, steps per second:  33, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.283 [0.000, 5.000],  loss: 0.007105, mae: 0.061622, mean_q: 0.086870, mean_eps: 0.601106\n",
            " 106236/250000: episode: 156, duration: 25.460s, episode steps: 830, steps per second:  33, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.005982, mae: 0.058753, mean_q: 0.083850, mean_eps: 0.597884\n",
            " 106588/250000: episode: 157, duration: 10.960s, episode steps: 352, steps per second:  32, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.006391, mae: 0.059303, mean_q: 0.082810, mean_eps: 0.595642\n",
            " 107325/250000: episode: 158, duration: 22.762s, episode steps: 737, steps per second:  32, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.008033, mae: 0.063251, mean_q: 0.089275, mean_eps: 0.593567\n",
            " 107910/250000: episode: 159, duration: 17.889s, episode steps: 585, steps per second:  33, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: 0.005943, mae: 0.059229, mean_q: 0.085190, mean_eps: 0.591052\n",
            " 108408/250000: episode: 160, duration: 15.558s, episode steps: 498, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.004022, mae: 0.056304, mean_q: 0.079112, mean_eps: 0.589000\n",
            " 108793/250000: episode: 161, duration: 12.023s, episode steps: 385, steps per second:  32, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.821 [0.000, 5.000],  loss: 0.006009, mae: 0.058157, mean_q: 0.081709, mean_eps: 0.587320\n",
            " 109500/250000: episode: 162, duration: 22.135s, episode steps: 707, steps per second:  32, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.952 [0.000, 5.000],  loss: 0.006694, mae: 0.061637, mean_q: 0.086624, mean_eps: 0.585245\n",
            " 110113/250000: episode: 163, duration: 19.340s, episode steps: 613, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.008915, mae: 0.065800, mean_q: 0.093208, mean_eps: 0.582737\n",
            " 111222/250000: episode: 164, duration: 34.198s, episode steps: 1109, steps per second:  32, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.808 [0.000, 5.000],  loss: 0.007894, mae: 0.063456, mean_q: 0.092340, mean_eps: 0.579462\n",
            " 111631/250000: episode: 165, duration: 12.703s, episode steps: 409, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.005893, mae: 0.059896, mean_q: 0.090483, mean_eps: 0.576581\n",
            " 111956/250000: episode: 166, duration: 10.000s, episode steps: 325, steps per second:  33, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.797 [0.000, 5.000],  loss: 0.005097, mae: 0.057121, mean_q: 0.084850, mean_eps: 0.575190\n",
            " 112333/250000: episode: 167, duration: 11.782s, episode steps: 377, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.005964, mae: 0.059876, mean_q: 0.086147, mean_eps: 0.573853\n",
            " 112757/250000: episode: 168, duration: 13.078s, episode steps: 424, steps per second:  32, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.005530, mae: 0.058301, mean_q: 0.082764, mean_eps: 0.572325\n",
            " 113783/250000: episode: 169, duration: 31.323s, episode steps: 1026, steps per second:  33, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.842 [0.000, 5.000],  loss: 0.006310, mae: 0.060051, mean_q: 0.085372, mean_eps: 0.569574\n",
            " 114462/250000: episode: 170, duration: 21.054s, episode steps: 679, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.717 [0.000, 5.000],  loss: 0.007507, mae: 0.061868, mean_q: 0.086476, mean_eps: 0.566336\n",
            " 115087/250000: episode: 171, duration: 19.492s, episode steps: 625, steps per second:  32, episode reward: 15.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.005797, mae: 0.060070, mean_q: 0.085310, mean_eps: 0.563859\n",
            " 116076/250000: episode: 172, duration: 31.250s, episode steps: 989, steps per second:  32, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.006890, mae: 0.062694, mean_q: 0.089899, mean_eps: 0.560796\n",
            " 117039/250000: episode: 173, duration: 29.705s, episode steps: 963, steps per second:  32, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.006954, mae: 0.060991, mean_q: 0.086091, mean_eps: 0.557087\n",
            " 117662/250000: episode: 174, duration: 19.191s, episode steps: 623, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.875 [0.000, 5.000],  loss: 0.005321, mae: 0.058317, mean_q: 0.081090, mean_eps: 0.554070\n",
            " 118028/250000: episode: 175, duration: 11.336s, episode steps: 366, steps per second:  32, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.005586, mae: 0.060088, mean_q: 0.082385, mean_eps: 0.552193\n",
            " 118377/250000: episode: 176, duration: 10.857s, episode steps: 349, steps per second:  32, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.006431, mae: 0.059681, mean_q: 0.083059, mean_eps: 0.550832\n",
            " 118899/250000: episode: 177, duration: 15.944s, episode steps: 522, steps per second:  33, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.787 [0.000, 5.000],  loss: 0.005880, mae: 0.060974, mean_q: 0.087028, mean_eps: 0.549176\n",
            " 119852/250000: episode: 178, duration: 29.575s, episode steps: 953, steps per second:  32, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.006869, mae: 0.061848, mean_q: 0.087937, mean_eps: 0.546379\n",
            " 120399/250000: episode: 179, duration: 17.163s, episode steps: 547, steps per second:  32, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.005752, mae: 0.058641, mean_q: 0.082262, mean_eps: 0.543529\n",
            " 121210/250000: episode: 180, duration: 25.287s, episode steps: 811, steps per second:  32, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.855 [0.000, 5.000],  loss: 0.005456, mae: 0.059316, mean_q: 0.083824, mean_eps: 0.540945\n",
            " 121856/250000: episode: 181, duration: 20.006s, episode steps: 646, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.947 [0.000, 5.000],  loss: 0.005845, mae: 0.059788, mean_q: 0.085725, mean_eps: 0.538178\n",
            " 122832/250000: episode: 182, duration: 30.381s, episode steps: 976, steps per second:  32, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.736 [0.000, 5.000],  loss: 0.006879, mae: 0.062640, mean_q: 0.088521, mean_eps: 0.535100\n",
            " 123456/250000: episode: 183, duration: 19.334s, episode steps: 624, steps per second:  32, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.007588, mae: 0.064506, mean_q: 0.091276, mean_eps: 0.532060\n",
            " 124023/250000: episode: 184, duration: 17.969s, episode steps: 567, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.007222, mae: 0.062688, mean_q: 0.089068, mean_eps: 0.529796\n",
            " 125260/250000: episode: 185, duration: 38.567s, episode steps: 1237, steps per second:  32, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006265, mae: 0.060960, mean_q: 0.085468, mean_eps: 0.526368\n",
            " 125609/250000: episode: 186, duration: 11.159s, episode steps: 349, steps per second:  31, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.007194, mae: 0.064989, mean_q: 0.091095, mean_eps: 0.523351\n",
            " 126261/250000: episode: 187, duration: 20.652s, episode steps: 652, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.005842, mae: 0.059547, mean_q: 0.086066, mean_eps: 0.521443\n",
            " 126990/250000: episode: 188, duration: 22.959s, episode steps: 729, steps per second:  32, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.702 [0.000, 5.000],  loss: 0.007156, mae: 0.063396, mean_q: 0.088628, mean_eps: 0.518821\n",
            " 127898/250000: episode: 189, duration: 28.061s, episode steps: 908, steps per second:  32, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.007366, mae: 0.063798, mean_q: 0.091730, mean_eps: 0.515713\n",
            " 128893/250000: episode: 190, duration: 30.848s, episode steps: 995, steps per second:  32, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: 0.005497, mae: 0.059387, mean_q: 0.085913, mean_eps: 0.512095\n",
            " 129615/250000: episode: 191, duration: 22.848s, episode steps: 722, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.007066, mae: 0.062813, mean_q: 0.089324, mean_eps: 0.508835\n",
            " 130703/250000: episode: 192, duration: 33.930s, episode steps: 1088, steps per second:  32, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.006832, mae: 0.062075, mean_q: 0.088405, mean_eps: 0.505400\n",
            " 131349/250000: episode: 193, duration: 19.955s, episode steps: 646, steps per second:  32, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.006177, mae: 0.061567, mean_q: 0.088924, mean_eps: 0.502101\n",
            " 131736/250000: episode: 194, duration: 12.109s, episode steps: 387, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: 0.007396, mae: 0.064711, mean_q: 0.092097, mean_eps: 0.500140\n",
            " 133037/250000: episode: 195, duration: 41.005s, episode steps: 1301, steps per second:  32, episode reward: 21.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: 0.006863, mae: 0.061923, mean_q: 0.087171, mean_eps: 0.496933\n",
            " 133723/250000: episode: 196, duration: 21.343s, episode steps: 686, steps per second:  32, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.006808, mae: 0.061508, mean_q: 0.086744, mean_eps: 0.493156\n",
            " 134105/250000: episode: 197, duration: 11.950s, episode steps: 382, steps per second:  32, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.139 [0.000, 5.000],  loss: 0.007173, mae: 0.062938, mean_q: 0.089833, mean_eps: 0.491127\n",
            " 135235/250000: episode: 198, duration: 35.153s, episode steps: 1130, steps per second:  32, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.006418, mae: 0.062423, mean_q: 0.089926, mean_eps: 0.488254\n",
            " 136030/250000: episode: 199, duration: 25.316s, episode steps: 795, steps per second:  31, episode reward: 20.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.006487, mae: 0.062633, mean_q: 0.089080, mean_eps: 0.484598\n",
            " 136896/250000: episode: 200, duration: 27.669s, episode steps: 866, steps per second:  31, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.007029, mae: 0.063282, mean_q: 0.090215, mean_eps: 0.481444\n",
            " 137697/250000: episode: 201, duration: 25.064s, episode steps: 801, steps per second:  32, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.006439, mae: 0.061501, mean_q: 0.088563, mean_eps: 0.478275\n",
            " 138481/250000: episode: 202, duration: 24.241s, episode steps: 784, steps per second:  32, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.006034, mae: 0.061281, mean_q: 0.087560, mean_eps: 0.475258\n",
            " 139883/250000: episode: 203, duration: 43.839s, episode steps: 1402, steps per second:  32, episode reward: 27.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.754 [0.000, 5.000],  loss: 0.007170, mae: 0.063142, mean_q: 0.091665, mean_eps: 0.471108\n",
            " 141025/250000: episode: 204, duration: 35.246s, episode steps: 1142, steps per second:  32, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.006558, mae: 0.062716, mean_q: 0.090128, mean_eps: 0.466275\n",
            " 141852/250000: episode: 205, duration: 25.546s, episode steps: 827, steps per second:  32, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.006523, mae: 0.061688, mean_q: 0.090153, mean_eps: 0.462536\n",
            " 142439/250000: episode: 206, duration: 18.163s, episode steps: 587, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.007006, mae: 0.063189, mean_q: 0.093035, mean_eps: 0.459853\n",
            " 143769/250000: episode: 207, duration: 40.870s, episode steps: 1330, steps per second:  33, episode reward: 18.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.926 [0.000, 5.000],  loss: 0.006851, mae: 0.063315, mean_q: 0.091944, mean_eps: 0.456205\n",
            " 144612/250000: episode: 208, duration: 26.298s, episode steps: 843, steps per second:  32, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.692 [0.000, 5.000],  loss: 0.005536, mae: 0.059247, mean_q: 0.085377, mean_eps: 0.452078\n",
            " 145571/250000: episode: 209, duration: 30.246s, episode steps: 959, steps per second:  32, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.007014, mae: 0.063354, mean_q: 0.089707, mean_eps: 0.448658\n",
            " 146399/250000: episode: 210, duration: 26.020s, episode steps: 828, steps per second:  32, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.007422, mae: 0.063747, mean_q: 0.092525, mean_eps: 0.445261\n",
            " 147036/250000: episode: 211, duration: 20.062s, episode steps: 637, steps per second:  32, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.005629, mae: 0.061210, mean_q: 0.089488, mean_eps: 0.442479\n",
            " 147408/250000: episode: 212, duration: 11.715s, episode steps: 372, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007043, mae: 0.063318, mean_q: 0.090593, mean_eps: 0.440564\n",
            " 148374/250000: episode: 213, duration: 30.462s, episode steps: 966, steps per second:  32, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.006380, mae: 0.062125, mean_q: 0.089551, mean_eps: 0.438018\n",
            " 148723/250000: episode: 214, duration: 10.969s, episode steps: 349, steps per second:  32, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.748 [0.000, 5.000],  loss: 0.005389, mae: 0.058468, mean_q: 0.084304, mean_eps: 0.435518\n",
            " 149273/250000: episode: 215, duration: 17.188s, episode steps: 550, steps per second:  32, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.005841, mae: 0.061756, mean_q: 0.089037, mean_eps: 0.433808\n",
            " 149912/250000: episode: 216, duration: 20.155s, episode steps: 639, steps per second:  32, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.761 [0.000, 5.000],  loss: 0.008334, mae: 0.066457, mean_q: 0.095607, mean_eps: 0.431550\n",
            " 151190/250000: episode: 217, duration: 39.781s, episode steps: 1278, steps per second:  32, episode reward: 24.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.007902, mae: 0.104862, mean_q: 0.146825, mean_eps: 0.427910\n",
            " 151976/250000: episode: 218, duration: 24.757s, episode steps: 786, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.800 [0.000, 5.000],  loss: 0.006644, mae: 0.107231, mean_q: 0.151457, mean_eps: 0.423988\n",
            " 152736/250000: episode: 219, duration: 23.912s, episode steps: 760, steps per second:  32, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.006795, mae: 0.107948, mean_q: 0.151626, mean_eps: 0.421055\n",
            " 153629/250000: episode: 220, duration: 28.069s, episode steps: 893, steps per second:  32, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.007425, mae: 0.109030, mean_q: 0.149435, mean_eps: 0.417908\n",
            " 154511/250000: episode: 221, duration: 27.743s, episode steps: 882, steps per second:  32, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.009399, mae: 0.115318, mean_q: 0.157761, mean_eps: 0.414534\n",
            " 155202/250000: episode: 222, duration: 21.807s, episode steps: 691, steps per second:  32, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: 0.006603, mae: 0.107744, mean_q: 0.149071, mean_eps: 0.411547\n",
            " 156179/250000: episode: 223, duration: 30.763s, episode steps: 977, steps per second:  32, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.007938, mae: 0.110312, mean_q: 0.151460, mean_eps: 0.408378\n",
            " 157303/250000: episode: 224, duration: 35.222s, episode steps: 1124, steps per second:  32, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.006953, mae: 0.109207, mean_q: 0.150845, mean_eps: 0.404388\n",
            " 157797/250000: episode: 225, duration: 15.564s, episode steps: 494, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.006969, mae: 0.108313, mean_q: 0.148559, mean_eps: 0.401310\n",
            " 158861/250000: episode: 226, duration: 33.251s, episode steps: 1064, steps per second:  32, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.007035, mae: 0.108610, mean_q: 0.149216, mean_eps: 0.398346\n",
            " 159262/250000: episode: 227, duration: 12.540s, episode steps: 401, steps per second:  32, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: 0.008199, mae: 0.110575, mean_q: 0.151651, mean_eps: 0.395564\n",
            " 160063/250000: episode: 228, duration: 24.930s, episode steps: 801, steps per second:  32, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.006778, mae: 0.107703, mean_q: 0.147897, mean_eps: 0.393284\n",
            " 161118/250000: episode: 229, duration: 33.133s, episode steps: 1055, steps per second:  32, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.006618, mae: 0.108849, mean_q: 0.147684, mean_eps: 0.389758\n",
            " 162193/250000: episode: 230, duration: 33.864s, episode steps: 1075, steps per second:  32, episode reward: 24.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.006537, mae: 0.106193, mean_q: 0.144839, mean_eps: 0.385707\n",
            " 163019/250000: episode: 231, duration: 25.841s, episode steps: 826, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.007584, mae: 0.109236, mean_q: 0.150063, mean_eps: 0.382097\n",
            " 164086/250000: episode: 232, duration: 34.160s, episode steps: 1067, steps per second:  31, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.007947, mae: 0.110269, mean_q: 0.150726, mean_eps: 0.378502\n",
            " 164719/250000: episode: 233, duration: 20.048s, episode steps: 633, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.703 [0.000, 5.000],  loss: 0.008250, mae: 0.111513, mean_q: 0.153099, mean_eps: 0.375272\n",
            " 165613/250000: episode: 234, duration: 27.944s, episode steps: 894, steps per second:  32, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007448, mae: 0.110725, mean_q: 0.152946, mean_eps: 0.372369\n",
            " 166003/250000: episode: 235, duration: 12.249s, episode steps: 390, steps per second:  32, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.007363, mae: 0.109456, mean_q: 0.151560, mean_eps: 0.369930\n",
            " 167337/250000: episode: 236, duration: 41.671s, episode steps: 1334, steps per second:  32, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.007517, mae: 0.110523, mean_q: 0.152013, mean_eps: 0.366654\n",
            " 167977/250000: episode: 237, duration: 20.210s, episode steps: 640, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.007214, mae: 0.111086, mean_q: 0.152986, mean_eps: 0.362900\n",
            " 168596/250000: episode: 238, duration: 19.646s, episode steps: 619, steps per second:  32, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.006403, mae: 0.105741, mean_q: 0.144516, mean_eps: 0.360513\n",
            " 169455/250000: episode: 239, duration: 27.016s, episode steps: 859, steps per second:  32, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.882 [0.000, 5.000],  loss: 0.007118, mae: 0.108402, mean_q: 0.149352, mean_eps: 0.357709\n",
            " 170463/250000: episode: 240, duration: 32.075s, episode steps: 1008, steps per second:  31, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.006680, mae: 0.107607, mean_q: 0.147423, mean_eps: 0.354160\n",
            " 171655/250000: episode: 241, duration: 37.601s, episode steps: 1192, steps per second:  32, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.006802, mae: 0.108536, mean_q: 0.146883, mean_eps: 0.349980\n",
            " 172352/250000: episode: 242, duration: 21.960s, episode steps: 697, steps per second:  32, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.215 [0.000, 5.000],  loss: 0.006124, mae: 0.107880, mean_q: 0.148553, mean_eps: 0.346392\n",
            " 172706/250000: episode: 243, duration: 11.103s, episode steps: 354, steps per second:  32, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.008815, mae: 0.112997, mean_q: 0.151972, mean_eps: 0.344394\n",
            " 173080/250000: episode: 244, duration: 11.750s, episode steps: 374, steps per second:  32, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.006540, mae: 0.110199, mean_q: 0.150010, mean_eps: 0.343010\n",
            " 173647/250000: episode: 245, duration: 18.105s, episode steps: 567, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007038, mae: 0.110188, mean_q: 0.150262, mean_eps: 0.341224\n",
            " 174299/250000: episode: 246, duration: 20.784s, episode steps: 652, steps per second:  31, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.006780, mae: 0.107051, mean_q: 0.145537, mean_eps: 0.338906\n",
            " 174691/250000: episode: 247, duration: 12.494s, episode steps: 392, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006915, mae: 0.109796, mean_q: 0.149489, mean_eps: 0.336923\n",
            " 175264/250000: episode: 248, duration: 18.337s, episode steps: 573, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.939 [0.000, 5.000],  loss: 0.007608, mae: 0.112467, mean_q: 0.152720, mean_eps: 0.335091\n",
            " 175633/250000: episode: 249, duration: 11.804s, episode steps: 369, steps per second:  31, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.184 [0.000, 5.000],  loss: 0.005753, mae: 0.104802, mean_q: 0.144789, mean_eps: 0.333298\n",
            " 176224/250000: episode: 250, duration: 18.782s, episode steps: 591, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.919 [0.000, 5.000],  loss: 0.007201, mae: 0.106240, mean_q: 0.145338, mean_eps: 0.331474\n",
            " 176601/250000: episode: 251, duration: 11.977s, episode steps: 377, steps per second:  31, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.117 [0.000, 5.000],  loss: 0.006624, mae: 0.109253, mean_q: 0.148586, mean_eps: 0.329634\n",
            " 177450/250000: episode: 252, duration: 26.673s, episode steps: 849, steps per second:  32, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.005995, mae: 0.107830, mean_q: 0.146340, mean_eps: 0.327301\n",
            " 178257/250000: episode: 253, duration: 25.647s, episode steps: 807, steps per second:  31, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.005267, mae: 0.105052, mean_q: 0.141915, mean_eps: 0.324155\n",
            " 179517/250000: episode: 254, duration: 39.920s, episode steps: 1260, steps per second:  32, episode reward: 18.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.006574, mae: 0.108190, mean_q: 0.145688, mean_eps: 0.320226\n",
            " 180436/250000: episode: 255, duration: 29.642s, episode steps: 919, steps per second:  31, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.283 [0.000, 5.000],  loss: 0.006803, mae: 0.109944, mean_q: 0.149720, mean_eps: 0.316091\n",
            " 181182/250000: episode: 256, duration: 23.831s, episode steps: 746, steps per second:  31, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.704 [0.000, 5.000],  loss: 0.007572, mae: 0.108971, mean_q: 0.149871, mean_eps: 0.312930\n",
            " 181883/250000: episode: 257, duration: 22.616s, episode steps: 701, steps per second:  31, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.006412, mae: 0.109241, mean_q: 0.149148, mean_eps: 0.310178\n",
            " 182581/250000: episode: 258, duration: 22.252s, episode steps: 698, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.005738, mae: 0.107219, mean_q: 0.146181, mean_eps: 0.307518\n",
            " 183242/250000: episode: 259, duration: 20.776s, episode steps: 661, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.006733, mae: 0.110564, mean_q: 0.149625, mean_eps: 0.304934\n",
            " 183886/250000: episode: 260, duration: 20.640s, episode steps: 644, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.759 [0.000, 5.000],  loss: 0.007236, mae: 0.110533, mean_q: 0.150821, mean_eps: 0.302457\n",
            " 184687/250000: episode: 261, duration: 25.217s, episode steps: 801, steps per second:  32, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.008024, mae: 0.112256, mean_q: 0.151937, mean_eps: 0.299713\n",
            " 185321/250000: episode: 262, duration: 20.106s, episode steps: 634, steps per second:  32, episode reward: 17.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.744 [0.000, 5.000],  loss: 0.006768, mae: 0.107893, mean_q: 0.148171, mean_eps: 0.296985\n",
            " 186150/250000: episode: 263, duration: 26.191s, episode steps: 829, steps per second:  32, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.071 [0.000, 5.000],  loss: 0.007020, mae: 0.108973, mean_q: 0.147866, mean_eps: 0.294203\n",
            " 187104/250000: episode: 264, duration: 30.744s, episode steps: 954, steps per second:  31, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.838 [0.000, 5.000],  loss: 0.007706, mae: 0.111145, mean_q: 0.152248, mean_eps: 0.290821\n",
            " 187915/250000: episode: 265, duration: 25.936s, episode steps: 811, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.005594, mae: 0.105857, mean_q: 0.146281, mean_eps: 0.287470\n",
            " 188876/250000: episode: 266, duration: 31.011s, episode steps: 961, steps per second:  31, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.006448, mae: 0.107332, mean_q: 0.146164, mean_eps: 0.284103\n",
            " 189379/250000: episode: 267, duration: 16.138s, episode steps: 503, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.795 [0.000, 5.000],  loss: 0.007454, mae: 0.109803, mean_q: 0.150813, mean_eps: 0.281321\n",
            " 189761/250000: episode: 268, duration: 12.255s, episode steps: 382, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.005479, mae: 0.108087, mean_q: 0.149689, mean_eps: 0.279634\n",
            " 190163/250000: episode: 269, duration: 12.780s, episode steps: 402, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.905 [0.000, 5.000],  loss: 0.006698, mae: 0.108283, mean_q: 0.148554, mean_eps: 0.278144\n",
            " 190961/250000: episode: 270, duration: 25.176s, episode steps: 798, steps per second:  32, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.006561, mae: 0.108692, mean_q: 0.149280, mean_eps: 0.275864\n",
            " 191519/250000: episode: 271, duration: 17.793s, episode steps: 558, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.892 [0.000, 5.000],  loss: 0.007063, mae: 0.106916, mean_q: 0.146169, mean_eps: 0.273288\n",
            " 191941/250000: episode: 272, duration: 13.364s, episode steps: 422, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006166, mae: 0.106261, mean_q: 0.146691, mean_eps: 0.271426\n",
            " 192500/250000: episode: 273, duration: 17.414s, episode steps: 559, steps per second:  32, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.007005, mae: 0.108695, mean_q: 0.148826, mean_eps: 0.269564\n",
            " 193033/250000: episode: 274, duration: 16.796s, episode steps: 533, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: 0.007860, mae: 0.112734, mean_q: 0.154246, mean_eps: 0.267489\n",
            " 193661/250000: episode: 275, duration: 20.087s, episode steps: 628, steps per second:  31, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.006590, mae: 0.106951, mean_q: 0.145960, mean_eps: 0.265278\n",
            " 194054/250000: episode: 276, duration: 12.505s, episode steps: 393, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.669 [0.000, 5.000],  loss: 0.005085, mae: 0.106050, mean_q: 0.145804, mean_eps: 0.263340\n",
            " 194607/250000: episode: 277, duration: 17.273s, episode steps: 553, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.212 [0.000, 5.000],  loss: 0.007306, mae: 0.108680, mean_q: 0.149113, mean_eps: 0.261546\n",
            " 195238/250000: episode: 278, duration: 19.824s, episode steps: 631, steps per second:  32, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.786 [0.000, 5.000],  loss: 0.007712, mae: 0.113075, mean_q: 0.155026, mean_eps: 0.259296\n",
            " 195823/250000: episode: 279, duration: 18.523s, episode steps: 585, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.005039, mae: 0.107107, mean_q: 0.147439, mean_eps: 0.256986\n",
            " 196697/250000: episode: 280, duration: 27.638s, episode steps: 874, steps per second:  32, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006297, mae: 0.107617, mean_q: 0.146785, mean_eps: 0.254212\n",
            " 197800/250000: episode: 281, duration: 34.715s, episode steps: 1103, steps per second:  32, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.785 [0.000, 5.000],  loss: 0.006835, mae: 0.110473, mean_q: 0.150863, mean_eps: 0.250458\n",
            " 198468/250000: episode: 282, duration: 21.261s, episode steps: 668, steps per second:  31, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.006803, mae: 0.108971, mean_q: 0.146893, mean_eps: 0.247098\n",
            " 199257/250000: episode: 283, duration: 24.976s, episode steps: 789, steps per second:  32, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.943 [0.000, 5.000],  loss: 0.005748, mae: 0.106578, mean_q: 0.145152, mean_eps: 0.244324\n",
            " 200039/250000: episode: 284, duration: 24.404s, episode steps: 782, steps per second:  32, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.006516, mae: 0.108213, mean_q: 0.147474, mean_eps: 0.241338\n",
            " 200692/250000: episode: 285, duration: 20.635s, episode steps: 653, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.007993, mae: 0.149440, mean_q: 0.201981, mean_eps: 0.238617\n",
            " 201317/250000: episode: 286, duration: 19.907s, episode steps: 625, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.006431, mae: 0.144568, mean_q: 0.193869, mean_eps: 0.236185\n",
            " 202198/250000: episode: 287, duration: 27.741s, episode steps: 881, steps per second:  32, episode reward:  5.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.007019, mae: 0.147653, mean_q: 0.196327, mean_eps: 0.233320\n",
            " 202681/250000: episode: 288, duration: 15.295s, episode steps: 483, steps per second:  32, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.006997, mae: 0.148074, mean_q: 0.197022, mean_eps: 0.230728\n",
            " 203270/250000: episode: 289, duration: 18.607s, episode steps: 589, steps per second:  32, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.008542, mae: 0.151118, mean_q: 0.201686, mean_eps: 0.228691\n",
            " 204090/250000: episode: 290, duration: 26.186s, episode steps: 820, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.807 [0.000, 5.000],  loss: 0.008056, mae: 0.149963, mean_q: 0.198911, mean_eps: 0.226016\n",
            " 205034/250000: episode: 291, duration: 30.177s, episode steps: 944, steps per second:  31, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.007181, mae: 0.147612, mean_q: 0.198097, mean_eps: 0.222664\n",
            " 205788/250000: episode: 292, duration: 24.060s, episode steps: 754, steps per second:  31, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.006656, mae: 0.145276, mean_q: 0.194932, mean_eps: 0.219442\n",
            " 206522/250000: episode: 293, duration: 23.322s, episode steps: 734, steps per second:  31, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.007278, mae: 0.150261, mean_q: 0.200135, mean_eps: 0.216615\n",
            " 207974/250000: episode: 294, duration: 45.988s, episode steps: 1452, steps per second:  32, episode reward: 26.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.008008, mae: 0.150691, mean_q: 0.202265, mean_eps: 0.212458\n",
            " 208344/250000: episode: 295, duration: 11.765s, episode steps: 370, steps per second:  31, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.124 [0.000, 5.000],  loss: 0.007459, mae: 0.149578, mean_q: 0.201994, mean_eps: 0.209000\n",
            " 209346/250000: episode: 296, duration: 31.849s, episode steps: 1002, steps per second:  31, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.168 [0.000, 5.000],  loss: 0.006144, mae: 0.145321, mean_q: 0.194264, mean_eps: 0.206393\n",
            " 210311/250000: episode: 297, duration: 30.472s, episode steps: 965, steps per second:  32, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.007434, mae: 0.150449, mean_q: 0.200668, mean_eps: 0.202654\n",
            " 211521/250000: episode: 298, duration: 38.561s, episode steps: 1210, steps per second:  31, episode reward: 27.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.941 [0.000, 5.000],  loss: 0.007257, mae: 0.148531, mean_q: 0.197954, mean_eps: 0.198519\n",
            " 212194/250000: episode: 299, duration: 21.446s, episode steps: 673, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.143 [0.000, 5.000],  loss: 0.005949, mae: 0.145739, mean_q: 0.195373, mean_eps: 0.194940\n",
            " 212592/250000: episode: 300, duration: 12.815s, episode steps: 398, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.006626, mae: 0.144652, mean_q: 0.191814, mean_eps: 0.192910\n",
            " 212981/250000: episode: 301, duration: 12.694s, episode steps: 389, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.118 [0.000, 5.000],  loss: 0.006757, mae: 0.146647, mean_q: 0.194811, mean_eps: 0.191413\n",
            " 213474/250000: episode: 302, duration: 15.708s, episode steps: 493, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.089 [0.000, 5.000],  loss: 0.007079, mae: 0.147771, mean_q: 0.197702, mean_eps: 0.189734\n",
            " 214096/250000: episode: 303, duration: 20.027s, episode steps: 622, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.207 [0.000, 5.000],  loss: 0.005969, mae: 0.145474, mean_q: 0.193563, mean_eps: 0.187621\n",
            " 214796/250000: episode: 304, duration: 22.571s, episode steps: 700, steps per second:  31, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.007096, mae: 0.149122, mean_q: 0.199184, mean_eps: 0.185113\n",
            " 215491/250000: episode: 305, duration: 22.344s, episode steps: 695, steps per second:  31, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.006210, mae: 0.143497, mean_q: 0.192356, mean_eps: 0.182460\n",
            " 216401/250000: episode: 306, duration: 29.041s, episode steps: 910, steps per second:  31, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.006624, mae: 0.147664, mean_q: 0.197806, mean_eps: 0.179405\n",
            " 216925/250000: episode: 307, duration: 16.677s, episode steps: 524, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006159, mae: 0.144761, mean_q: 0.193738, mean_eps: 0.176677\n",
            " 218026/250000: episode: 308, duration: 34.923s, episode steps: 1101, steps per second:  32, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.202 [0.000, 5.000],  loss: 0.006498, mae: 0.145725, mean_q: 0.194358, mean_eps: 0.173591\n",
            " 218995/250000: episode: 309, duration: 30.803s, episode steps: 969, steps per second:  31, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.007349, mae: 0.147793, mean_q: 0.196557, mean_eps: 0.169662\n",
            " 219771/250000: episode: 310, duration: 24.685s, episode steps: 776, steps per second:  31, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.006163, mae: 0.145680, mean_q: 0.195421, mean_eps: 0.166348\n",
            " 220733/250000: episode: 311, duration: 30.569s, episode steps: 962, steps per second:  31, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.006143, mae: 0.146352, mean_q: 0.195124, mean_eps: 0.163042\n",
            " 221759/250000: episode: 312, duration: 32.734s, episode steps: 1026, steps per second:  31, episode reward: 24.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.007157, mae: 0.150584, mean_q: 0.201155, mean_eps: 0.159265\n",
            " 222707/250000: episode: 313, duration: 30.181s, episode steps: 948, steps per second:  31, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.007521, mae: 0.149905, mean_q: 0.200245, mean_eps: 0.155518\n",
            " 223480/250000: episode: 314, duration: 24.670s, episode steps: 773, steps per second:  31, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 3.048 [0.000, 5.000],  loss: 0.007918, mae: 0.150444, mean_q: 0.199319, mean_eps: 0.152250\n",
            " 223998/250000: episode: 315, duration: 16.592s, episode steps: 518, steps per second:  31, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.007786, mae: 0.153947, mean_q: 0.204883, mean_eps: 0.149796\n",
            " 224540/250000: episode: 316, duration: 17.311s, episode steps: 542, steps per second:  31, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006345, mae: 0.146971, mean_q: 0.196752, mean_eps: 0.147782\n",
            " 224905/250000: episode: 317, duration: 11.710s, episode steps: 365, steps per second:  31, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.047 [0.000, 5.000],  loss: 0.006367, mae: 0.144507, mean_q: 0.193700, mean_eps: 0.146056\n",
            " 225910/250000: episode: 318, duration: 32.085s, episode steps: 1005, steps per second:  31, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.006522, mae: 0.146215, mean_q: 0.195548, mean_eps: 0.143450\n",
            " 226423/250000: episode: 319, duration: 16.192s, episode steps: 513, steps per second:  32, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.006369, mae: 0.145796, mean_q: 0.196940, mean_eps: 0.140569\n",
            " 227166/250000: episode: 320, duration: 23.474s, episode steps: 743, steps per second:  32, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 3.179 [0.000, 5.000],  loss: 0.006677, mae: 0.147438, mean_q: 0.197315, mean_eps: 0.138183\n",
            " 228477/250000: episode: 321, duration: 41.383s, episode steps: 1311, steps per second:  32, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.054 [0.000, 5.000],  loss: 0.006981, mae: 0.146956, mean_q: 0.196911, mean_eps: 0.134276\n",
            " 228901/250000: episode: 322, duration: 13.485s, episode steps: 424, steps per second:  31, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.006600, mae: 0.146328, mean_q: 0.195356, mean_eps: 0.130978\n",
            " 229886/250000: episode: 323, duration: 30.919s, episode steps: 985, steps per second:  32, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.006697, mae: 0.148279, mean_q: 0.196819, mean_eps: 0.128303\n",
            " 230452/250000: episode: 324, duration: 18.087s, episode steps: 566, steps per second:  31, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.159 [0.000, 5.000],  loss: 0.006559, mae: 0.149969, mean_q: 0.200986, mean_eps: 0.125362\n",
            " 230948/250000: episode: 325, duration: 15.984s, episode steps: 496, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.946 [0.000, 5.000],  loss: 0.007169, mae: 0.150208, mean_q: 0.201023, mean_eps: 0.123348\n",
            " 231599/250000: episode: 326, duration: 20.716s, episode steps: 651, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.876 [0.000, 5.000],  loss: 0.007979, mae: 0.152375, mean_q: 0.205488, mean_eps: 0.121166\n",
            " 232271/250000: episode: 327, duration: 21.474s, episode steps: 672, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.006732, mae: 0.144854, mean_q: 0.196180, mean_eps: 0.118651\n",
            " 233085/250000: episode: 328, duration: 26.278s, episode steps: 814, steps per second:  31, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.891 [0.000, 5.000],  loss: 0.006485, mae: 0.150670, mean_q: 0.203185, mean_eps: 0.115824\n",
            " 233996/250000: episode: 329, duration: 29.255s, episode steps: 911, steps per second:  31, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.007161, mae: 0.147512, mean_q: 0.196660, mean_eps: 0.112548\n",
            " 234403/250000: episode: 330, duration: 13.046s, episode steps: 407, steps per second:  31, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.865 [0.000, 5.000],  loss: 0.005633, mae: 0.146225, mean_q: 0.195728, mean_eps: 0.110048\n",
            " 234937/250000: episode: 331, duration: 16.980s, episode steps: 534, steps per second:  31, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.007181, mae: 0.150027, mean_q: 0.201180, mean_eps: 0.108254\n",
            " 235769/250000: episode: 332, duration: 26.337s, episode steps: 832, steps per second:  32, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.007998, mae: 0.153130, mean_q: 0.202565, mean_eps: 0.105655\n",
            " 236518/250000: episode: 333, duration: 23.723s, episode steps: 749, steps per second:  32, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.006429, mae: 0.145606, mean_q: 0.194607, mean_eps: 0.102653\n",
            " 236897/250000: episode: 334, duration: 12.075s, episode steps: 379, steps per second:  31, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.739 [0.000, 5.000],  loss: 0.007133, mae: 0.148452, mean_q: 0.198451, mean_eps: 0.100510\n",
            " 237963/250000: episode: 335, duration: 33.876s, episode steps: 1066, steps per second:  31, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.031 [0.000, 5.000],  loss: 0.006842, mae: 0.149920, mean_q: 0.200836, mean_eps: 0.097766\n",
            " 238630/250000: episode: 336, duration: 21.164s, episode steps: 667, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.005598, mae: 0.145387, mean_q: 0.195228, mean_eps: 0.094475\n",
            " 239099/250000: episode: 337, duration: 14.821s, episode steps: 469, steps per second:  32, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.007623, mae: 0.155390, mean_q: 0.207307, mean_eps: 0.092317\n",
            " 239736/250000: episode: 338, duration: 20.227s, episode steps: 637, steps per second:  31, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.138 [0.000, 5.000],  loss: 0.005062, mae: 0.145288, mean_q: 0.196249, mean_eps: 0.090219\n",
            " 240912/250000: episode: 339, duration: 37.541s, episode steps: 1176, steps per second:  31, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.005956, mae: 0.147893, mean_q: 0.199350, mean_eps: 0.086776\n",
            " 241767/250000: episode: 340, duration: 27.314s, episode steps: 855, steps per second:  31, episode reward: 21.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.795 [0.000, 5.000],  loss: 0.005819, mae: 0.148438, mean_q: 0.199553, mean_eps: 0.082916\n",
            " 242686/250000: episode: 341, duration: 29.425s, episode steps: 919, steps per second:  31, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.006521, mae: 0.148930, mean_q: 0.200002, mean_eps: 0.079541\n",
            " 243152/250000: episode: 342, duration: 15.000s, episode steps: 466, steps per second:  31, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.006792, mae: 0.147484, mean_q: 0.198005, mean_eps: 0.076912\n",
            " 243839/250000: episode: 343, duration: 21.873s, episode steps: 687, steps per second:  31, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.008327, mae: 0.152953, mean_q: 0.203686, mean_eps: 0.074723\n",
            " 245154/250000: episode: 344, duration: 42.108s, episode steps: 1315, steps per second:  31, episode reward: 22.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.006419, mae: 0.149369, mean_q: 0.199497, mean_eps: 0.070915\n",
            " 246538/250000: episode: 345, duration: 44.323s, episode steps: 1384, steps per second:  31, episode reward: 22.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.007305, mae: 0.151568, mean_q: 0.202389, mean_eps: 0.065785\n",
            " 247736/250000: episode: 346, duration: 39.436s, episode steps: 1198, steps per second:  30, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.006651, mae: 0.149253, mean_q: 0.199474, mean_eps: 0.060883\n",
            " 248676/250000: episode: 347, duration: 30.607s, episode steps: 940, steps per second:  31, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.007225, mae: 0.151789, mean_q: 0.203148, mean_eps: 0.056825\n",
            " 249246/250000: episode: 348, duration: 18.460s, episode steps: 570, steps per second:  31, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.005538, mae: 0.148887, mean_q: 0.199488, mean_eps: 0.053952\n",
            "done, took 6463.749 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 14.000, steps: 706\n",
            "Episode 2: reward: 3.000, steps: 509\n",
            "Episode 3: reward: 4.000, steps: 435\n",
            "Episode 4: reward: 11.000, steps: 938\n",
            "Episode 5: reward: 13.000, steps: 804\n",
            "Episode 6: reward: 16.000, steps: 853\n",
            "Episode 7: reward: 20.000, steps: 895\n",
            "Episode 8: reward: 9.000, steps: 701\n",
            "Episode 9: reward: 14.000, steps: 636\n",
            "Episode 10: reward: 8.000, steps: 599\n",
            "Episode 11: reward: 4.000, steps: 670\n",
            "Episode 12: reward: 21.000, steps: 1041\n",
            "Episode 13: reward: 8.000, steps: 537\n",
            "Episode 14: reward: 3.000, steps: 462\n",
            "Episode 15: reward: 17.000, steps: 911\n",
            "Episode 16: reward: 5.000, steps: 582\n",
            "Episode 17: reward: 16.000, steps: 911\n",
            "Episode 18: reward: 11.000, steps: 563\n",
            "Episode 19: reward: 8.000, steps: 516\n",
            "Episode 20: reward: 21.000, steps: 942\n",
            "BASELINE --> Reward promedio: 11.30\n",
            "Training for 250000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    397/250000: episode: 1, duration: 1.982s, episode steps: 397, steps per second: 200, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   1165/250000: episode: 2, duration: 3.597s, episode steps: 768, steps per second: 213, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   1904/250000: episode: 3, duration: 3.424s, episode steps: 739, steps per second: 216, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   2681/250000: episode: 4, duration: 3.654s, episode steps: 777, steps per second: 213, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   4230/250000: episode: 5, duration: 7.158s, episode steps: 1549, steps per second: 216, episode reward: 25.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   4782/250000: episode: 6, duration: 2.653s, episode steps: 552, steps per second: 208, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   5305/250000: episode: 7, duration: 2.498s, episode steps: 523, steps per second: 209, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   6007/250000: episode: 8, duration: 3.297s, episode steps: 702, steps per second: 213, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   6596/250000: episode: 9, duration: 2.715s, episode steps: 589, steps per second: 217, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   7188/250000: episode: 10, duration: 2.951s, episode steps: 592, steps per second: 201, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   8156/250000: episode: 11, duration: 4.513s, episode steps: 968, steps per second: 214, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   8668/250000: episode: 12, duration: 2.412s, episode steps: 512, steps per second: 212, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   9284/250000: episode: 13, duration: 2.824s, episode steps: 616, steps per second: 218, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "   9701/250000: episode: 14, duration: 1.894s, episode steps: 417, steps per second: 220, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  10334/250000: episode: 15, duration: 2.968s, episode steps: 633, steps per second: 213, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  11567/250000: episode: 16, duration: 5.658s, episode steps: 1233, steps per second: 218, episode reward: 11.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  12047/250000: episode: 17, duration: 2.302s, episode steps: 480, steps per second: 209, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  12430/250000: episode: 18, duration: 1.753s, episode steps: 383, steps per second: 219, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  13350/250000: episode: 19, duration: 4.285s, episode steps: 920, steps per second: 215, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  13998/250000: episode: 20, duration: 3.015s, episode steps: 648, steps per second: 215, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  14779/250000: episode: 21, duration: 3.555s, episode steps: 781, steps per second: 220, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  15464/250000: episode: 22, duration: 3.163s, episode steps: 685, steps per second: 217, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  16060/250000: episode: 23, duration: 2.714s, episode steps: 596, steps per second: 220, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  16768/250000: episode: 24, duration: 3.258s, episode steps: 708, steps per second: 217, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  17771/250000: episode: 25, duration: 4.588s, episode steps: 1003, steps per second: 219, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  18490/250000: episode: 26, duration: 3.383s, episode steps: 719, steps per second: 213, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  18877/250000: episode: 27, duration: 1.744s, episode steps: 387, steps per second: 222, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  19553/250000: episode: 28, duration: 3.130s, episode steps: 676, steps per second: 216, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  20374/250000: episode: 29, duration: 3.700s, episode steps: 821, steps per second: 222, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  21022/250000: episode: 30, duration: 3.016s, episode steps: 648, steps per second: 215, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  21582/250000: episode: 31, duration: 2.538s, episode steps: 560, steps per second: 221, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  21969/250000: episode: 32, duration: 1.719s, episode steps: 387, steps per second: 225, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  22452/250000: episode: 33, duration: 2.227s, episode steps: 483, steps per second: 217, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  23022/250000: episode: 34, duration: 2.667s, episode steps: 570, steps per second: 214, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  23647/250000: episode: 35, duration: 2.918s, episode steps: 625, steps per second: 214, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  24267/250000: episode: 36, duration: 2.785s, episode steps: 620, steps per second: 223, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  25785/250000: episode: 37, duration: 6.952s, episode steps: 1518, steps per second: 218, episode reward: 28.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  27244/250000: episode: 38, duration: 6.708s, episode steps: 1459, steps per second: 217, episode reward: 16.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  27981/250000: episode: 39, duration: 3.396s, episode steps: 737, steps per second: 217, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  28832/250000: episode: 40, duration: 4.000s, episode steps: 851, steps per second: 213, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  29531/250000: episode: 41, duration: 3.228s, episode steps: 699, steps per second: 217, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  30144/250000: episode: 42, duration: 2.827s, episode steps: 613, steps per second: 217, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  30905/250000: episode: 43, duration: 3.514s, episode steps: 761, steps per second: 217, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  31547/250000: episode: 44, duration: 3.149s, episode steps: 642, steps per second: 204, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  32182/250000: episode: 45, duration: 3.012s, episode steps: 635, steps per second: 211, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  32850/250000: episode: 46, duration: 3.048s, episode steps: 668, steps per second: 219, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  33780/250000: episode: 47, duration: 4.202s, episode steps: 930, steps per second: 221, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  34430/250000: episode: 48, duration: 3.025s, episode steps: 650, steps per second: 215, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  35935/250000: episode: 49, duration: 6.824s, episode steps: 1505, steps per second: 221, episode reward: 16.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  36627/250000: episode: 50, duration: 3.201s, episode steps: 692, steps per second: 216, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  37134/250000: episode: 51, duration: 2.401s, episode steps: 507, steps per second: 211, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  37671/250000: episode: 52, duration: 2.440s, episode steps: 537, steps per second: 220, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  38409/250000: episode: 53, duration: 3.321s, episode steps: 738, steps per second: 222, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  39644/250000: episode: 54, duration: 5.582s, episode steps: 1235, steps per second: 221, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  40366/250000: episode: 55, duration: 3.270s, episode steps: 722, steps per second: 221, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  40858/250000: episode: 56, duration: 2.273s, episode steps: 492, steps per second: 216, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  41513/250000: episode: 57, duration: 3.081s, episode steps: 655, steps per second: 213, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  42651/250000: episode: 58, duration: 5.225s, episode steps: 1138, steps per second: 218, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  43082/250000: episode: 59, duration: 1.974s, episode steps: 431, steps per second: 218, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  43814/250000: episode: 60, duration: 3.350s, episode steps: 732, steps per second: 219, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  44618/250000: episode: 61, duration: 3.702s, episode steps: 804, steps per second: 217, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  45256/250000: episode: 62, duration: 2.932s, episode steps: 638, steps per second: 218, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  45657/250000: episode: 63, duration: 1.776s, episode steps: 401, steps per second: 226, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  46558/250000: episode: 64, duration: 4.031s, episode steps: 901, steps per second: 224, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  47325/250000: episode: 65, duration: 3.524s, episode steps: 767, steps per second: 218, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  47734/250000: episode: 66, duration: 1.984s, episode steps: 409, steps per second: 206, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  48867/250000: episode: 67, duration: 5.072s, episode steps: 1133, steps per second: 223, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n",
            "  49677/250000: episode: 68, duration: 3.729s, episode steps: 810, steps per second: 217, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: --, mae: --, mean_q: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  51020/250000: episode: 69, duration: 33.828s, episode steps: 1343, steps per second:  40, episode reward: 19.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.006500, mae: 0.045772, mean_q: 0.071469\n",
            "  51660/250000: episode: 70, duration: 19.810s, episode steps: 640, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.005837, mae: 0.045433, mean_q: 0.063795\n",
            "  52729/250000: episode: 71, duration: 33.073s, episode steps: 1069, steps per second:  32, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006764, mae: 0.046869, mean_q: 0.065199\n",
            "  53915/250000: episode: 72, duration: 36.452s, episode steps: 1186, steps per second:  33, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.006890, mae: 0.047224, mean_q: 0.065581\n",
            "  54403/250000: episode: 73, duration: 14.982s, episode steps: 488, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.005564, mae: 0.044547, mean_q: 0.058912\n",
            "  55036/250000: episode: 74, duration: 19.466s, episode steps: 633, steps per second:  33, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.007511, mae: 0.049436, mean_q: 0.064506\n",
            "  55457/250000: episode: 75, duration: 13.042s, episode steps: 421, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.005248, mae: 0.044690, mean_q: 0.061616\n",
            "  56015/250000: episode: 76, duration: 17.231s, episode steps: 558, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006425, mae: 0.045715, mean_q: 0.060024\n",
            "  57135/250000: episode: 77, duration: 34.467s, episode steps: 1120, steps per second:  32, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006399, mae: 0.046519, mean_q: 0.061843\n",
            "  58387/250000: episode: 78, duration: 38.398s, episode steps: 1252, steps per second:  33, episode reward: 14.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.006289, mae: 0.046476, mean_q: 0.059358\n",
            "  58891/250000: episode: 79, duration: 15.336s, episode steps: 504, steps per second:  33, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.006975, mae: 0.049009, mean_q: 0.064661\n",
            "  59433/250000: episode: 80, duration: 16.632s, episode steps: 542, steps per second:  33, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.006634, mae: 0.047080, mean_q: 0.063552\n",
            "  60021/250000: episode: 81, duration: 18.025s, episode steps: 588, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.006819, mae: 0.046101, mean_q: 0.061198\n",
            "  60404/250000: episode: 82, duration: 11.789s, episode steps: 383, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.006560, mae: 0.049189, mean_q: 0.065808\n",
            "  60908/250000: episode: 83, duration: 15.749s, episode steps: 504, steps per second:  32, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.006552, mae: 0.047866, mean_q: 0.065409\n",
            "  61962/250000: episode: 84, duration: 32.785s, episode steps: 1054, steps per second:  32, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.007292, mae: 0.047999, mean_q: 0.064960\n",
            "  62882/250000: episode: 85, duration: 28.892s, episode steps: 920, steps per second:  32, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.006608, mae: 0.047955, mean_q: 0.062995\n",
            "  63295/250000: episode: 86, duration: 12.935s, episode steps: 413, steps per second:  32, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.007396, mae: 0.049982, mean_q: 0.065648\n",
            "  64102/250000: episode: 87, duration: 25.156s, episode steps: 807, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.006284, mae: 0.047137, mean_q: 0.064627\n",
            "  64737/250000: episode: 88, duration: 20.223s, episode steps: 635, steps per second:  31, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.006098, mae: 0.046017, mean_q: 0.060699\n",
            "  65284/250000: episode: 89, duration: 17.068s, episode steps: 547, steps per second:  32, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.006278, mae: 0.047035, mean_q: 0.063903\n",
            "  65906/250000: episode: 90, duration: 19.293s, episode steps: 622, steps per second:  32, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.006959, mae: 0.048121, mean_q: 0.063207\n",
            "  66540/250000: episode: 91, duration: 19.581s, episode steps: 634, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.006664, mae: 0.048072, mean_q: 0.062754\n",
            "  67350/250000: episode: 92, duration: 25.189s, episode steps: 810, steps per second:  32, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.007128, mae: 0.049283, mean_q: 0.066518\n",
            "  67965/250000: episode: 93, duration: 18.999s, episode steps: 615, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.006053, mae: 0.046877, mean_q: 0.067037\n",
            "  68490/250000: episode: 94, duration: 16.096s, episode steps: 525, steps per second:  33, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007221, mae: 0.049068, mean_q: 0.065306\n",
            "  69107/250000: episode: 95, duration: 19.056s, episode steps: 617, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.007571, mae: 0.050896, mean_q: 0.069513\n",
            "  70190/250000: episode: 96, duration: 33.134s, episode steps: 1083, steps per second:  33, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.006559, mae: 0.048155, mean_q: 0.065458\n",
            "  70991/250000: episode: 97, duration: 24.593s, episode steps: 801, steps per second:  33, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.005719, mae: 0.045951, mean_q: 0.061645\n",
            "  71543/250000: episode: 98, duration: 17.239s, episode steps: 552, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007031, mae: 0.048763, mean_q: 0.066334\n",
            "  72131/250000: episode: 99, duration: 18.272s, episode steps: 588, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.007863, mae: 0.050776, mean_q: 0.070789\n",
            "  72962/250000: episode: 100, duration: 25.780s, episode steps: 831, steps per second:  32, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.007938, mae: 0.050225, mean_q: 0.069070\n",
            "  73650/250000: episode: 101, duration: 21.104s, episode steps: 688, steps per second:  33, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.006534, mae: 0.048033, mean_q: 0.065640\n",
            "  74195/250000: episode: 102, duration: 16.974s, episode steps: 545, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.006883, mae: 0.050511, mean_q: 0.074310\n",
            "  75242/250000: episode: 103, duration: 32.444s, episode steps: 1047, steps per second:  32, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.006380, mae: 0.047368, mean_q: 0.064593\n",
            "  75878/250000: episode: 104, duration: 19.743s, episode steps: 636, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006859, mae: 0.048928, mean_q: 0.067462\n",
            "  76498/250000: episode: 105, duration: 19.213s, episode steps: 620, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.007236, mae: 0.049238, mean_q: 0.066303\n",
            "  77440/250000: episode: 106, duration: 29.474s, episode steps: 942, steps per second:  32, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.006871, mae: 0.048624, mean_q: 0.067501\n",
            "  77841/250000: episode: 107, duration: 12.585s, episode steps: 401, steps per second:  32, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.004941, mae: 0.045340, mean_q: 0.065450\n",
            "  78346/250000: episode: 108, duration: 15.608s, episode steps: 505, steps per second:  32, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.006678, mae: 0.048430, mean_q: 0.069303\n",
            "  78950/250000: episode: 109, duration: 18.617s, episode steps: 604, steps per second:  32, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.008060, mae: 0.052268, mean_q: 0.074458\n",
            "  79425/250000: episode: 110, duration: 14.851s, episode steps: 475, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.007891, mae: 0.050315, mean_q: 0.070134\n",
            "  80507/250000: episode: 111, duration: 33.317s, episode steps: 1082, steps per second:  32, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.005633, mae: 0.046191, mean_q: 0.064982\n",
            "  81123/250000: episode: 112, duration: 19.011s, episode steps: 616, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.006479, mae: 0.048121, mean_q: 0.065152\n",
            "  81759/250000: episode: 113, duration: 19.560s, episode steps: 636, steps per second:  33, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.007423, mae: 0.049754, mean_q: 0.067288\n",
            "  82448/250000: episode: 114, duration: 21.620s, episode steps: 689, steps per second:  32, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006923, mae: 0.048870, mean_q: 0.067395\n",
            "  83078/250000: episode: 115, duration: 20.002s, episode steps: 630, steps per second:  31, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.006205, mae: 0.047720, mean_q: 0.064764\n",
            "  83565/250000: episode: 116, duration: 15.023s, episode steps: 487, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006932, mae: 0.048821, mean_q: 0.066912\n",
            "  84469/250000: episode: 117, duration: 28.211s, episode steps: 904, steps per second:  32, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.006882, mae: 0.048783, mean_q: 0.067890\n",
            "  85127/250000: episode: 118, duration: 20.302s, episode steps: 658, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.006275, mae: 0.047548, mean_q: 0.066268\n",
            "  85654/250000: episode: 119, duration: 16.365s, episode steps: 527, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007382, mae: 0.049642, mean_q: 0.069660\n",
            "  86554/250000: episode: 120, duration: 28.075s, episode steps: 900, steps per second:  32, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.005585, mae: 0.046408, mean_q: 0.065063\n",
            "  87257/250000: episode: 121, duration: 21.815s, episode steps: 703, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.005736, mae: 0.046628, mean_q: 0.066703\n",
            "  87886/250000: episode: 122, duration: 19.701s, episode steps: 629, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.005783, mae: 0.046921, mean_q: 0.064538\n",
            "  88594/250000: episode: 123, duration: 22.225s, episode steps: 708, steps per second:  32, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.005609, mae: 0.045558, mean_q: 0.064619\n",
            "  89185/250000: episode: 124, duration: 18.248s, episode steps: 591, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.006903, mae: 0.048481, mean_q: 0.067233\n",
            "  89799/250000: episode: 125, duration: 18.948s, episode steps: 614, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.006546, mae: 0.049264, mean_q: 0.070073\n",
            "  90654/250000: episode: 126, duration: 26.604s, episode steps: 855, steps per second:  32, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007799, mae: 0.051029, mean_q: 0.068853\n",
            "  91266/250000: episode: 127, duration: 18.974s, episode steps: 612, steps per second:  32, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.007248, mae: 0.050090, mean_q: 0.069496\n",
            "  91794/250000: episode: 128, duration: 16.343s, episode steps: 528, steps per second:  32, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.005985, mae: 0.047829, mean_q: 0.066286\n",
            "  92784/250000: episode: 129, duration: 30.678s, episode steps: 990, steps per second:  32, episode reward: 26.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.005945, mae: 0.046492, mean_q: 0.063702\n",
            "  93301/250000: episode: 130, duration: 16.132s, episode steps: 517, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.006310, mae: 0.047679, mean_q: 0.065475\n",
            "  94150/250000: episode: 131, duration: 26.416s, episode steps: 849, steps per second:  32, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.006385, mae: 0.048088, mean_q: 0.065929\n",
            "  94778/250000: episode: 132, duration: 19.497s, episode steps: 628, steps per second:  32, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.005468, mae: 0.045770, mean_q: 0.063197\n",
            "  95928/250000: episode: 133, duration: 35.610s, episode steps: 1150, steps per second:  32, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.006408, mae: 0.048243, mean_q: 0.066957\n",
            "  96590/250000: episode: 134, duration: 20.664s, episode steps: 662, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.006677, mae: 0.048706, mean_q: 0.067631\n",
            "  97233/250000: episode: 135, duration: 20.196s, episode steps: 643, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.006740, mae: 0.048415, mean_q: 0.068282\n",
            "  97618/250000: episode: 136, duration: 12.041s, episode steps: 385, steps per second:  32, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.006984, mae: 0.050631, mean_q: 0.072034\n",
            "  97990/250000: episode: 137, duration: 11.471s, episode steps: 372, steps per second:  32, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.005645, mae: 0.046098, mean_q: 0.066077\n",
            "  98789/250000: episode: 138, duration: 24.805s, episode steps: 799, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.005788, mae: 0.047170, mean_q: 0.066522\n",
            "  99763/250000: episode: 139, duration: 30.364s, episode steps: 974, steps per second:  32, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.007093, mae: 0.049076, mean_q: 0.069611\n",
            " 100528/250000: episode: 140, duration: 23.884s, episode steps: 765, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.005982, mae: 0.066623, mean_q: 0.091804\n",
            " 101205/250000: episode: 141, duration: 21.098s, episode steps: 677, steps per second:  32, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.007653, mae: 0.080838, mean_q: 0.113050\n",
            " 101605/250000: episode: 142, duration: 12.410s, episode steps: 400, steps per second:  32, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.006381, mae: 0.078819, mean_q: 0.108916\n",
            " 102058/250000: episode: 143, duration: 13.987s, episode steps: 453, steps per second:  32, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.007136, mae: 0.079121, mean_q: 0.110212\n",
            " 103069/250000: episode: 144, duration: 31.571s, episode steps: 1011, steps per second:  32, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.007135, mae: 0.080770, mean_q: 0.112567\n",
            " 104213/250000: episode: 145, duration: 35.294s, episode steps: 1144, steps per second:  32, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.006460, mae: 0.078915, mean_q: 0.108600\n",
            " 104784/250000: episode: 146, duration: 17.722s, episode steps: 571, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006656, mae: 0.079553, mean_q: 0.107613\n",
            " 105254/250000: episode: 147, duration: 14.643s, episode steps: 470, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006943, mae: 0.079013, mean_q: 0.108801\n",
            " 105894/250000: episode: 148, duration: 19.795s, episode steps: 640, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.005529, mae: 0.077702, mean_q: 0.107123\n",
            " 106522/250000: episode: 149, duration: 19.283s, episode steps: 628, steps per second:  33, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.006257, mae: 0.078716, mean_q: 0.109112\n",
            " 107309/250000: episode: 150, duration: 24.430s, episode steps: 787, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.005478, mae: 0.077615, mean_q: 0.106976\n",
            " 107908/250000: episode: 151, duration: 18.648s, episode steps: 599, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.006834, mae: 0.079727, mean_q: 0.106311\n",
            " 108651/250000: episode: 152, duration: 22.999s, episode steps: 743, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.006274, mae: 0.079956, mean_q: 0.109122\n",
            " 109181/250000: episode: 153, duration: 16.367s, episode steps: 530, steps per second:  32, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006721, mae: 0.077746, mean_q: 0.103423\n",
            " 109587/250000: episode: 154, duration: 12.559s, episode steps: 406, steps per second:  32, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.004221, mae: 0.076959, mean_q: 0.102730\n",
            " 110570/250000: episode: 155, duration: 30.352s, episode steps: 983, steps per second:  32, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.006655, mae: 0.078620, mean_q: 0.105292\n",
            " 111323/250000: episode: 156, duration: 23.595s, episode steps: 753, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.006306, mae: 0.079045, mean_q: 0.106470\n",
            " 112208/250000: episode: 157, duration: 28.158s, episode steps: 885, steps per second:  31, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.006429, mae: 0.079585, mean_q: 0.109383\n",
            " 112982/250000: episode: 158, duration: 24.323s, episode steps: 774, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.005364, mae: 0.077309, mean_q: 0.105980\n",
            " 113600/250000: episode: 159, duration: 19.247s, episode steps: 618, steps per second:  32, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006568, mae: 0.078706, mean_q: 0.107113\n",
            " 114005/250000: episode: 160, duration: 12.753s, episode steps: 405, steps per second:  32, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.004427, mae: 0.074980, mean_q: 0.103903\n",
            " 114395/250000: episode: 161, duration: 12.372s, episode steps: 390, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.005923, mae: 0.077823, mean_q: 0.104617\n",
            " 114836/250000: episode: 162, duration: 14.047s, episode steps: 441, steps per second:  31, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006633, mae: 0.079466, mean_q: 0.108074\n",
            " 115809/250000: episode: 163, duration: 30.404s, episode steps: 973, steps per second:  32, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.006494, mae: 0.080672, mean_q: 0.109811\n",
            " 116919/250000: episode: 164, duration: 34.383s, episode steps: 1110, steps per second:  32, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006966, mae: 0.080606, mean_q: 0.108713\n",
            " 117967/250000: episode: 165, duration: 32.502s, episode steps: 1048, steps per second:  32, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.007201, mae: 0.082480, mean_q: 0.113677\n",
            " 118692/250000: episode: 166, duration: 22.626s, episode steps: 725, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006384, mae: 0.080717, mean_q: 0.110331\n",
            " 119648/250000: episode: 167, duration: 29.803s, episode steps: 956, steps per second:  32, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.006930, mae: 0.080573, mean_q: 0.109909\n",
            " 120885/250000: episode: 168, duration: 38.852s, episode steps: 1237, steps per second:  32, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.006587, mae: 0.081100, mean_q: 0.110511\n",
            " 121396/250000: episode: 169, duration: 15.852s, episode steps: 511, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.006626, mae: 0.080525, mean_q: 0.109159\n",
            " 122248/250000: episode: 170, duration: 26.792s, episode steps: 852, steps per second:  32, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006212, mae: 0.079661, mean_q: 0.108372\n",
            " 122833/250000: episode: 171, duration: 18.667s, episode steps: 585, steps per second:  31, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.005890, mae: 0.078763, mean_q: 0.106791\n",
            " 123573/250000: episode: 172, duration: 23.006s, episode steps: 740, steps per second:  32, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006620, mae: 0.080961, mean_q: 0.109248\n",
            " 124199/250000: episode: 173, duration: 19.578s, episode steps: 626, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006343, mae: 0.078576, mean_q: 0.106687\n",
            " 124695/250000: episode: 174, duration: 15.614s, episode steps: 496, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.006932, mae: 0.081987, mean_q: 0.111115\n",
            " 125455/250000: episode: 175, duration: 24.017s, episode steps: 760, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.005555, mae: 0.077264, mean_q: 0.104477\n",
            " 125957/250000: episode: 176, duration: 15.869s, episode steps: 502, steps per second:  32, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006073, mae: 0.077442, mean_q: 0.104157\n",
            " 126830/250000: episode: 177, duration: 27.233s, episode steps: 873, steps per second:  32, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.006867, mae: 0.081762, mean_q: 0.112038\n",
            " 127771/250000: episode: 178, duration: 29.349s, episode steps: 941, steps per second:  32, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.006656, mae: 0.080859, mean_q: 0.113309\n",
            " 128279/250000: episode: 179, duration: 15.827s, episode steps: 508, steps per second:  32, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.008273, mae: 0.083908, mean_q: 0.113050\n",
            " 128838/250000: episode: 180, duration: 17.208s, episode steps: 559, steps per second:  32, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.006840, mae: 0.082206, mean_q: 0.112789\n",
            " 129592/250000: episode: 181, duration: 23.024s, episode steps: 754, steps per second:  33, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.006011, mae: 0.078436, mean_q: 0.109164\n",
            " 130127/250000: episode: 182, duration: 16.263s, episode steps: 535, steps per second:  33, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.006652, mae: 0.081032, mean_q: 0.109806\n",
            " 131038/250000: episode: 183, duration: 27.916s, episode steps: 911, steps per second:  33, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.006053, mae: 0.078847, mean_q: 0.107755\n",
            " 131671/250000: episode: 184, duration: 19.236s, episode steps: 633, steps per second:  33, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.006223, mae: 0.079747, mean_q: 0.108264\n",
            " 132496/250000: episode: 185, duration: 25.277s, episode steps: 825, steps per second:  33, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.005954, mae: 0.079366, mean_q: 0.109668\n",
            " 133049/250000: episode: 186, duration: 16.829s, episode steps: 553, steps per second:  33, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.007228, mae: 0.081332, mean_q: 0.110564\n",
            " 133437/250000: episode: 187, duration: 11.718s, episode steps: 388, steps per second:  33, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.004478, mae: 0.074353, mean_q: 0.100569\n",
            " 133937/250000: episode: 188, duration: 15.380s, episode steps: 500, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.005416, mae: 0.078015, mean_q: 0.105593\n",
            " 134387/250000: episode: 189, duration: 13.716s, episode steps: 450, steps per second:  33, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.005178, mae: 0.078698, mean_q: 0.107570\n",
            " 135086/250000: episode: 190, duration: 21.256s, episode steps: 699, steps per second:  33, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.007605, mae: 0.082639, mean_q: 0.111695\n",
            " 135890/250000: episode: 191, duration: 24.484s, episode steps: 804, steps per second:  33, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.006037, mae: 0.079547, mean_q: 0.108712\n",
            " 136780/250000: episode: 192, duration: 27.022s, episode steps: 890, steps per second:  33, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.007320, mae: 0.082230, mean_q: 0.112519\n",
            " 137699/250000: episode: 193, duration: 27.777s, episode steps: 919, steps per second:  33, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006034, mae: 0.078707, mean_q: 0.108604\n",
            " 138401/250000: episode: 194, duration: 21.338s, episode steps: 702, steps per second:  33, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.005990, mae: 0.079358, mean_q: 0.108560\n",
            " 138985/250000: episode: 195, duration: 17.740s, episode steps: 584, steps per second:  33, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.007493, mae: 0.082881, mean_q: 0.112553\n",
            " 139697/250000: episode: 196, duration: 21.612s, episode steps: 712, steps per second:  33, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.006814, mae: 0.080878, mean_q: 0.110419\n",
            " 140226/250000: episode: 197, duration: 16.172s, episode steps: 529, steps per second:  33, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.005258, mae: 0.079165, mean_q: 0.110630\n",
            " 140823/250000: episode: 198, duration: 18.209s, episode steps: 597, steps per second:  33, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.006253, mae: 0.080106, mean_q: 0.109993\n",
            " 141499/250000: episode: 199, duration: 20.439s, episode steps: 676, steps per second:  33, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.004726, mae: 0.075623, mean_q: 0.102684\n",
            " 141923/250000: episode: 200, duration: 13.033s, episode steps: 424, steps per second:  33, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.006482, mae: 0.079842, mean_q: 0.106875\n",
            " 142566/250000: episode: 201, duration: 19.689s, episode steps: 643, steps per second:  33, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.004435, mae: 0.075411, mean_q: 0.102402\n",
            " 143679/250000: episode: 202, duration: 33.964s, episode steps: 1113, steps per second:  33, episode reward: 23.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.006586, mae: 0.080912, mean_q: 0.110100\n",
            " 144544/250000: episode: 203, duration: 26.598s, episode steps: 865, steps per second:  33, episode reward: 20.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.006205, mae: 0.079924, mean_q: 0.110581\n",
            " 145310/250000: episode: 204, duration: 23.529s, episode steps: 766, steps per second:  33, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.006118, mae: 0.080900, mean_q: 0.112013\n",
            " 146332/250000: episode: 205, duration: 31.667s, episode steps: 1022, steps per second:  32, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.005335, mae: 0.077305, mean_q: 0.106446\n",
            " 146743/250000: episode: 206, duration: 12.746s, episode steps: 411, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.006243, mae: 0.079692, mean_q: 0.109592\n",
            " 147283/250000: episode: 207, duration: 16.695s, episode steps: 540, steps per second:  32, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.005420, mae: 0.078929, mean_q: 0.107330\n",
            " 147890/250000: episode: 208, duration: 18.616s, episode steps: 607, steps per second:  33, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.006078, mae: 0.079441, mean_q: 0.110650\n",
            " 148290/250000: episode: 209, duration: 12.069s, episode steps: 400, steps per second:  33, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.008034, mae: 0.083916, mean_q: 0.116119\n",
            " 149038/250000: episode: 210, duration: 22.702s, episode steps: 748, steps per second:  33, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.006765, mae: 0.081800, mean_q: 0.113789\n",
            " 149609/250000: episode: 211, duration: 17.596s, episode steps: 571, steps per second:  32, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.006427, mae: 0.081615, mean_q: 0.113864\n",
            " 150296/250000: episode: 212, duration: 21.199s, episode steps: 687, steps per second:  32, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007700, mae: 0.096876, mean_q: 0.133458\n",
            " 150708/250000: episode: 213, duration: 12.736s, episode steps: 412, steps per second:  32, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.006200, mae: 0.114399, mean_q: 0.156561\n",
            " 151354/250000: episode: 214, duration: 19.593s, episode steps: 646, steps per second:  33, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.006624, mae: 0.114210, mean_q: 0.156856\n",
            " 151859/250000: episode: 215, duration: 15.566s, episode steps: 505, steps per second:  32, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.006327, mae: 0.116135, mean_q: 0.156777\n",
            " 152501/250000: episode: 216, duration: 19.929s, episode steps: 642, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.005204, mae: 0.111055, mean_q: 0.151610\n",
            " 153128/250000: episode: 217, duration: 19.503s, episode steps: 627, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.006905, mae: 0.115525, mean_q: 0.156955\n",
            " 153526/250000: episode: 218, duration: 12.290s, episode steps: 398, steps per second:  32, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.006946, mae: 0.115388, mean_q: 0.158133\n",
            " 154212/250000: episode: 219, duration: 20.996s, episode steps: 686, steps per second:  33, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.006911, mae: 0.117123, mean_q: 0.159237\n",
            " 155016/250000: episode: 220, duration: 24.806s, episode steps: 804, steps per second:  32, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.005869, mae: 0.113371, mean_q: 0.153294\n",
            " 155548/250000: episode: 221, duration: 16.481s, episode steps: 532, steps per second:  32, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006408, mae: 0.113227, mean_q: 0.155397\n",
            " 156376/250000: episode: 222, duration: 25.891s, episode steps: 828, steps per second:  32, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.005832, mae: 0.113625, mean_q: 0.152781\n",
            " 156863/250000: episode: 223, duration: 14.919s, episode steps: 487, steps per second:  33, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.006572, mae: 0.115626, mean_q: 0.154938\n",
            " 157367/250000: episode: 224, duration: 15.614s, episode steps: 504, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.005400, mae: 0.114147, mean_q: 0.154397\n",
            " 157916/250000: episode: 225, duration: 17.114s, episode steps: 549, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.005431, mae: 0.112733, mean_q: 0.153402\n",
            " 158488/250000: episode: 226, duration: 17.505s, episode steps: 572, steps per second:  33, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.004702, mae: 0.111486, mean_q: 0.150671\n",
            " 159157/250000: episode: 227, duration: 20.676s, episode steps: 669, steps per second:  32, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.005698, mae: 0.114445, mean_q: 0.153514\n",
            " 159903/250000: episode: 228, duration: 23.202s, episode steps: 746, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.005672, mae: 0.113044, mean_q: 0.153341\n",
            " 160831/250000: episode: 229, duration: 28.997s, episode steps: 928, steps per second:  32, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.005711, mae: 0.114439, mean_q: 0.153681\n",
            " 161466/250000: episode: 230, duration: 19.803s, episode steps: 635, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.006363, mae: 0.114824, mean_q: 0.152060\n",
            " 161840/250000: episode: 231, duration: 11.725s, episode steps: 374, steps per second:  32, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.005477, mae: 0.113664, mean_q: 0.151217\n",
            " 162284/250000: episode: 232, duration: 13.858s, episode steps: 444, steps per second:  32, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.006994, mae: 0.113624, mean_q: 0.151491\n",
            " 162949/250000: episode: 233, duration: 21.032s, episode steps: 665, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.005575, mae: 0.114757, mean_q: 0.155719\n",
            " 163491/250000: episode: 234, duration: 16.709s, episode steps: 542, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.005548, mae: 0.112954, mean_q: 0.152036\n",
            " 164118/250000: episode: 235, duration: 19.523s, episode steps: 627, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.006493, mae: 0.115924, mean_q: 0.155362\n",
            " 164914/250000: episode: 236, duration: 24.731s, episode steps: 796, steps per second:  32, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.005831, mae: 0.114603, mean_q: 0.153566\n",
            " 165736/250000: episode: 237, duration: 25.685s, episode steps: 822, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.006694, mae: 0.115684, mean_q: 0.155302\n",
            " 166318/250000: episode: 238, duration: 18.070s, episode steps: 582, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.007500, mae: 0.116944, mean_q: 0.152867\n",
            " 167044/250000: episode: 239, duration: 22.757s, episode steps: 726, steps per second:  32, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.006088, mae: 0.113787, mean_q: 0.150981\n",
            " 167671/250000: episode: 240, duration: 19.125s, episode steps: 627, steps per second:  33, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.005029, mae: 0.112295, mean_q: 0.151801\n",
            " 168696/250000: episode: 241, duration: 31.771s, episode steps: 1025, steps per second:  32, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.006730, mae: 0.116110, mean_q: 0.157833\n",
            " 169311/250000: episode: 242, duration: 19.334s, episode steps: 615, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.005596, mae: 0.113730, mean_q: 0.154819\n",
            " 170033/250000: episode: 243, duration: 22.400s, episode steps: 722, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.005556, mae: 0.114525, mean_q: 0.154444\n",
            " 171019/250000: episode: 244, duration: 30.501s, episode steps: 986, steps per second:  32, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.005911, mae: 0.114704, mean_q: 0.155381\n",
            " 171617/250000: episode: 245, duration: 18.678s, episode steps: 598, steps per second:  32, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.005575, mae: 0.114347, mean_q: 0.153624\n",
            " 172585/250000: episode: 246, duration: 29.918s, episode steps: 968, steps per second:  32, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.006257, mae: 0.115797, mean_q: 0.154967\n",
            " 173311/250000: episode: 247, duration: 22.670s, episode steps: 726, steps per second:  32, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.005865, mae: 0.112814, mean_q: 0.150817\n",
            " 173692/250000: episode: 248, duration: 11.932s, episode steps: 381, steps per second:  32, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.004966, mae: 0.111203, mean_q: 0.148606\n",
            " 174031/250000: episode: 249, duration: 10.541s, episode steps: 339, steps per second:  32, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.005770, mae: 0.114568, mean_q: 0.152874\n",
            " 175162/250000: episode: 250, duration: 35.053s, episode steps: 1131, steps per second:  32, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.005967, mae: 0.114971, mean_q: 0.153879\n",
            " 175782/250000: episode: 251, duration: 19.163s, episode steps: 620, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.007268, mae: 0.115652, mean_q: 0.156192\n",
            " 176769/250000: episode: 252, duration: 30.644s, episode steps: 987, steps per second:  32, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.005501, mae: 0.113155, mean_q: 0.151314\n",
            " 177469/250000: episode: 253, duration: 21.515s, episode steps: 700, steps per second:  33, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.006785, mae: 0.118262, mean_q: 0.159961\n",
            " 178214/250000: episode: 254, duration: 23.019s, episode steps: 745, steps per second:  32, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.005807, mae: 0.112585, mean_q: 0.152616\n",
            " 179011/250000: episode: 255, duration: 24.599s, episode steps: 797, steps per second:  32, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.005485, mae: 0.113500, mean_q: 0.152820\n",
            " 179488/250000: episode: 256, duration: 14.957s, episode steps: 477, steps per second:  32, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.005400, mae: 0.110992, mean_q: 0.148145\n",
            " 179873/250000: episode: 257, duration: 12.019s, episode steps: 385, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.005793, mae: 0.114384, mean_q: 0.151881\n",
            " 180262/250000: episode: 258, duration: 12.091s, episode steps: 389, steps per second:  32, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.004131, mae: 0.110638, mean_q: 0.147580\n",
            " 180813/250000: episode: 259, duration: 17.245s, episode steps: 551, steps per second:  32, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.006900, mae: 0.117556, mean_q: 0.156830\n",
            " 181209/250000: episode: 260, duration: 12.467s, episode steps: 396, steps per second:  32, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.006258, mae: 0.114017, mean_q: 0.154312\n",
            " 181861/250000: episode: 261, duration: 20.405s, episode steps: 652, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.005655, mae: 0.113739, mean_q: 0.152765\n",
            " 182588/250000: episode: 262, duration: 22.821s, episode steps: 727, steps per second:  32, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.005657, mae: 0.114539, mean_q: 0.154237\n",
            " 183223/250000: episode: 263, duration: 20.163s, episode steps: 635, steps per second:  31, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.006023, mae: 0.117017, mean_q: 0.157481\n",
            " 184194/250000: episode: 264, duration: 30.554s, episode steps: 971, steps per second:  32, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.005694, mae: 0.114507, mean_q: 0.153137\n",
            " 185162/250000: episode: 265, duration: 30.396s, episode steps: 968, steps per second:  32, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.005492, mae: 0.114988, mean_q: 0.153452\n",
            " 186095/250000: episode: 266, duration: 29.623s, episode steps: 933, steps per second:  31, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.005178, mae: 0.111675, mean_q: 0.149064\n",
            " 186920/250000: episode: 267, duration: 26.056s, episode steps: 825, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.005707, mae: 0.114818, mean_q: 0.153800\n",
            " 187722/250000: episode: 268, duration: 25.425s, episode steps: 802, steps per second:  32, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.005652, mae: 0.112186, mean_q: 0.149823\n",
            " 188367/250000: episode: 269, duration: 20.389s, episode steps: 645, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.005518, mae: 0.112416, mean_q: 0.150140\n",
            " 189170/250000: episode: 270, duration: 25.223s, episode steps: 803, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.007149, mae: 0.118128, mean_q: 0.156855\n",
            " 189790/250000: episode: 271, duration: 19.575s, episode steps: 620, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.005384, mae: 0.115025, mean_q: 0.153388\n",
            " 191299/250000: episode: 272, duration: 47.561s, episode steps: 1509, steps per second:  32, episode reward: 13.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.006429, mae: 0.116866, mean_q: 0.156175\n",
            " 192261/250000: episode: 273, duration: 30.307s, episode steps: 962, steps per second:  32, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.005705, mae: 0.115537, mean_q: 0.155435\n",
            " 192908/250000: episode: 274, duration: 20.472s, episode steps: 647, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.005897, mae: 0.115745, mean_q: 0.153778\n",
            " 193407/250000: episode: 275, duration: 15.515s, episode steps: 499, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.006204, mae: 0.114882, mean_q: 0.155079\n",
            " 194815/250000: episode: 276, duration: 44.094s, episode steps: 1408, steps per second:  32, episode reward: 13.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.005565, mae: 0.112794, mean_q: 0.152547\n",
            " 195728/250000: episode: 277, duration: 28.798s, episode steps: 913, steps per second:  32, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.005702, mae: 0.114690, mean_q: 0.154845\n",
            " 196289/250000: episode: 278, duration: 17.737s, episode steps: 561, steps per second:  32, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006528, mae: 0.116839, mean_q: 0.156374\n",
            " 196914/250000: episode: 279, duration: 19.336s, episode steps: 625, steps per second:  32, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.006029, mae: 0.111396, mean_q: 0.148032\n",
            " 197516/250000: episode: 280, duration: 18.982s, episode steps: 602, steps per second:  32, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.006011, mae: 0.114538, mean_q: 0.152305\n",
            " 198143/250000: episode: 281, duration: 19.563s, episode steps: 627, steps per second:  32, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.005727, mae: 0.114170, mean_q: 0.153041\n",
            " 198676/250000: episode: 282, duration: 16.796s, episode steps: 533, steps per second:  32, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.005902, mae: 0.115461, mean_q: 0.154428\n",
            " 200094/250000: episode: 283, duration: 44.166s, episode steps: 1418, steps per second:  32, episode reward: 17.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.005695, mae: 0.116181, mean_q: 0.157022\n",
            " 200665/250000: episode: 284, duration: 17.933s, episode steps: 571, steps per second:  32, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.006347, mae: 0.140747, mean_q: 0.185863\n",
            " 201034/250000: episode: 285, duration: 11.521s, episode steps: 369, steps per second:  32, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007689, mae: 0.145602, mean_q: 0.193247\n",
            " 201974/250000: episode: 286, duration: 29.447s, episode steps: 940, steps per second:  32, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.005485, mae: 0.141080, mean_q: 0.187262\n",
            " 202703/250000: episode: 287, duration: 23.053s, episode steps: 729, steps per second:  32, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.006410, mae: 0.144010, mean_q: 0.189634\n",
            " 203418/250000: episode: 288, duration: 22.525s, episode steps: 715, steps per second:  32, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.005946, mae: 0.140612, mean_q: 0.188831\n",
            " 204055/250000: episode: 289, duration: 20.055s, episode steps: 637, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.006202, mae: 0.142186, mean_q: 0.188037\n",
            " 205213/250000: episode: 290, duration: 35.983s, episode steps: 1158, steps per second:  32, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.007340, mae: 0.144943, mean_q: 0.192208\n",
            " 205912/250000: episode: 291, duration: 21.865s, episode steps: 699, steps per second:  32, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006336, mae: 0.141018, mean_q: 0.189736\n",
            " 206361/250000: episode: 292, duration: 14.129s, episode steps: 449, steps per second:  32, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.007826, mae: 0.146004, mean_q: 0.193019\n",
            " 207010/250000: episode: 293, duration: 20.274s, episode steps: 649, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.006195, mae: 0.144700, mean_q: 0.193941\n",
            " 207466/250000: episode: 294, duration: 14.124s, episode steps: 456, steps per second:  32, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.005828, mae: 0.141072, mean_q: 0.190773\n",
            " 208201/250000: episode: 295, duration: 22.977s, episode steps: 735, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.005427, mae: 0.141058, mean_q: 0.187668\n",
            " 208961/250000: episode: 296, duration: 23.561s, episode steps: 760, steps per second:  32, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.005859, mae: 0.141737, mean_q: 0.186759\n",
            " 209495/250000: episode: 297, duration: 16.541s, episode steps: 534, steps per second:  32, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.005983, mae: 0.142708, mean_q: 0.191230\n",
            " 210009/250000: episode: 298, duration: 16.303s, episode steps: 514, steps per second:  32, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.005614, mae: 0.138848, mean_q: 0.184900\n",
            " 210458/250000: episode: 299, duration: 14.089s, episode steps: 449, steps per second:  32, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.005545, mae: 0.141762, mean_q: 0.188936\n",
            " 210856/250000: episode: 300, duration: 12.490s, episode steps: 398, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.005964, mae: 0.138978, mean_q: 0.187653\n",
            " 211398/250000: episode: 301, duration: 16.936s, episode steps: 542, steps per second:  32, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.006492, mae: 0.141144, mean_q: 0.186642\n",
            " 211950/250000: episode: 302, duration: 17.412s, episode steps: 552, steps per second:  32, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.006265, mae: 0.142939, mean_q: 0.189359\n",
            " 212890/250000: episode: 303, duration: 29.603s, episode steps: 940, steps per second:  32, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.006584, mae: 0.141761, mean_q: 0.187829\n",
            " 213592/250000: episode: 304, duration: 22.163s, episode steps: 702, steps per second:  32, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.005823, mae: 0.143318, mean_q: 0.189690\n",
            " 214089/250000: episode: 305, duration: 15.614s, episode steps: 497, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.006578, mae: 0.141764, mean_q: 0.187868\n",
            " 214640/250000: episode: 306, duration: 17.363s, episode steps: 551, steps per second:  32, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.006202, mae: 0.144378, mean_q: 0.192206\n",
            " 215233/250000: episode: 307, duration: 18.711s, episode steps: 593, steps per second:  32, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.004854, mae: 0.140964, mean_q: 0.186545\n",
            " 216094/250000: episode: 308, duration: 27.091s, episode steps: 861, steps per second:  32, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.005991, mae: 0.141489, mean_q: 0.185662\n",
            " 216863/250000: episode: 309, duration: 24.369s, episode steps: 769, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006885, mae: 0.142431, mean_q: 0.187525\n",
            " 217643/250000: episode: 310, duration: 24.422s, episode steps: 780, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.006259, mae: 0.142771, mean_q: 0.190617\n",
            " 218091/250000: episode: 311, duration: 14.115s, episode steps: 448, steps per second:  32, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.005472, mae: 0.141899, mean_q: 0.188659\n",
            " 218489/250000: episode: 312, duration: 12.522s, episode steps: 398, steps per second:  32, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.006374, mae: 0.143482, mean_q: 0.191428\n",
            " 219697/250000: episode: 313, duration: 37.841s, episode steps: 1208, steps per second:  32, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.005643, mae: 0.142132, mean_q: 0.189671\n",
            " 220377/250000: episode: 314, duration: 21.164s, episode steps: 680, steps per second:  32, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.004923, mae: 0.138707, mean_q: 0.184715\n",
            " 221092/250000: episode: 315, duration: 22.627s, episode steps: 715, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.005486, mae: 0.140031, mean_q: 0.184820\n",
            " 221675/250000: episode: 316, duration: 18.388s, episode steps: 583, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.005258, mae: 0.139480, mean_q: 0.185019\n",
            " 222451/250000: episode: 317, duration: 24.609s, episode steps: 776, steps per second:  32, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006073, mae: 0.142468, mean_q: 0.189340\n",
            " 222917/250000: episode: 318, duration: 14.746s, episode steps: 466, steps per second:  32, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.005652, mae: 0.140607, mean_q: 0.185021\n",
            " 223638/250000: episode: 319, duration: 22.708s, episode steps: 721, steps per second:  32, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.004351, mae: 0.138768, mean_q: 0.182928\n",
            " 224228/250000: episode: 320, duration: 18.606s, episode steps: 590, steps per second:  32, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.005903, mae: 0.141196, mean_q: 0.186950\n",
            " 224961/250000: episode: 321, duration: 23.181s, episode steps: 733, steps per second:  32, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.005368, mae: 0.139197, mean_q: 0.184572\n",
            " 225589/250000: episode: 322, duration: 19.921s, episode steps: 628, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.005132, mae: 0.140703, mean_q: 0.187634\n",
            " 226162/250000: episode: 323, duration: 18.098s, episode steps: 573, steps per second:  32, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.005538, mae: 0.140560, mean_q: 0.186255\n",
            " 227266/250000: episode: 324, duration: 34.872s, episode steps: 1104, steps per second:  32, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.006124, mae: 0.143745, mean_q: 0.189925\n",
            " 227879/250000: episode: 325, duration: 19.221s, episode steps: 613, steps per second:  32, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.005051, mae: 0.140836, mean_q: 0.187405\n",
            " 228447/250000: episode: 326, duration: 17.655s, episode steps: 568, steps per second:  32, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.005092, mae: 0.137931, mean_q: 0.183068\n",
            " 229340/250000: episode: 327, duration: 28.007s, episode steps: 893, steps per second:  32, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.005819, mae: 0.144626, mean_q: 0.192345\n",
            " 229828/250000: episode: 328, duration: 15.642s, episode steps: 488, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.006668, mae: 0.142827, mean_q: 0.187428\n",
            " 231036/250000: episode: 329, duration: 38.113s, episode steps: 1208, steps per second:  32, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.005948, mae: 0.141596, mean_q: 0.186311\n",
            " 232002/250000: episode: 330, duration: 30.639s, episode steps: 966, steps per second:  32, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.005054, mae: 0.141149, mean_q: 0.186381\n",
            " 232392/250000: episode: 331, duration: 12.691s, episode steps: 390, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.006501, mae: 0.143495, mean_q: 0.191432\n",
            " 233116/250000: episode: 332, duration: 23.499s, episode steps: 724, steps per second:  31, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.005327, mae: 0.138880, mean_q: 0.184670\n",
            " 233783/250000: episode: 333, duration: 21.663s, episode steps: 667, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.007665, mae: 0.146400, mean_q: 0.192588\n",
            " 234290/250000: episode: 334, duration: 16.487s, episode steps: 507, steps per second:  31, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.005909, mae: 0.143081, mean_q: 0.191103\n",
            " 234707/250000: episode: 335, duration: 13.332s, episode steps: 417, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006443, mae: 0.143861, mean_q: 0.190827\n",
            " 235302/250000: episode: 336, duration: 19.092s, episode steps: 595, steps per second:  31, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.006303, mae: 0.143331, mean_q: 0.189151\n",
            " 235790/250000: episode: 337, duration: 15.568s, episode steps: 488, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006636, mae: 0.140959, mean_q: 0.186054\n",
            " 236407/250000: episode: 338, duration: 19.740s, episode steps: 617, steps per second:  31, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.004646, mae: 0.139297, mean_q: 0.185161\n",
            " 237444/250000: episode: 339, duration: 33.048s, episode steps: 1037, steps per second:  31, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.005243, mae: 0.138437, mean_q: 0.184493\n",
            " 238229/250000: episode: 340, duration: 25.073s, episode steps: 785, steps per second:  31, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.005101, mae: 0.140530, mean_q: 0.188713\n",
            " 239147/250000: episode: 341, duration: 29.382s, episode steps: 918, steps per second:  31, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: 0.005420, mae: 0.139724, mean_q: 0.187334\n",
            " 239654/250000: episode: 342, duration: 16.218s, episode steps: 507, steps per second:  31, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.006316, mae: 0.142797, mean_q: 0.188488\n",
            " 240191/250000: episode: 343, duration: 17.100s, episode steps: 537, steps per second:  31, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006397, mae: 0.142703, mean_q: 0.188757\n",
            " 240880/250000: episode: 344, duration: 21.880s, episode steps: 689, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.005306, mae: 0.140093, mean_q: 0.185781\n",
            " 241559/250000: episode: 345, duration: 21.621s, episode steps: 679, steps per second:  31, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.005218, mae: 0.139799, mean_q: 0.185468\n",
            " 242105/250000: episode: 346, duration: 17.648s, episode steps: 546, steps per second:  31, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.005731, mae: 0.139124, mean_q: 0.183826\n",
            " 242622/250000: episode: 347, duration: 16.334s, episode steps: 517, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.004783, mae: 0.141540, mean_q: 0.186569\n",
            " 243327/250000: episode: 348, duration: 22.365s, episode steps: 705, steps per second:  32, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.005373, mae: 0.140415, mean_q: 0.185236\n",
            " 244629/250000: episode: 349, duration: 41.163s, episode steps: 1302, steps per second:  32, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.005628, mae: 0.140622, mean_q: 0.185440\n",
            " 245458/250000: episode: 350, duration: 26.135s, episode steps: 829, steps per second:  32, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.004927, mae: 0.139950, mean_q: 0.184141\n",
            " 246277/250000: episode: 351, duration: 26.025s, episode steps: 819, steps per second:  31, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.006077, mae: 0.142039, mean_q: 0.187946\n",
            " 246656/250000: episode: 352, duration: 12.056s, episode steps: 379, steps per second:  31, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.004730, mae: 0.141269, mean_q: 0.189117\n",
            " 247306/250000: episode: 353, duration: 20.704s, episode steps: 650, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.006006, mae: 0.140023, mean_q: 0.185961\n",
            " 247830/250000: episode: 354, duration: 16.823s, episode steps: 524, steps per second:  31, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.004613, mae: 0.139203, mean_q: 0.185646\n",
            " 248224/250000: episode: 355, duration: 12.703s, episode steps: 394, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.005780, mae: 0.140179, mean_q: 0.185966\n",
            " 249219/250000: episode: 356, duration: 31.544s, episode steps: 995, steps per second:  32, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.005127, mae: 0.140592, mean_q: 0.185238\n",
            " 249788/250000: episode: 357, duration: 18.207s, episode steps: 569, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.005636, mae: 0.142125, mean_q: 0.186425\n",
            "done, took 6469.170 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 12.000, steps: 839\n",
            "Episode 2: reward: 23.000, steps: 1267\n",
            "Episode 3: reward: 11.000, steps: 812\n",
            "Episode 4: reward: 16.000, steps: 950\n",
            "Episode 5: reward: 12.000, steps: 820\n",
            "Episode 6: reward: 12.000, steps: 834\n",
            "Episode 7: reward: 22.000, steps: 1217\n",
            "Episode 8: reward: 12.000, steps: 803\n",
            "Episode 9: reward: 8.000, steps: 780\n",
            "Episode 10: reward: 15.000, steps: 1002\n",
            "Episode 11: reward: 7.000, steps: 692\n",
            "Episode 12: reward: 17.000, steps: 906\n",
            "Episode 13: reward: 11.000, steps: 1052\n",
            "Episode 14: reward: 12.000, steps: 935\n",
            "Episode 15: reward: 5.000, steps: 680\n",
            "Episode 16: reward: 14.000, steps: 827\n",
            "Episode 17: reward: 10.000, steps: 784\n",
            "Episode 18: reward: 7.000, steps: 720\n",
            "Episode 19: reward: 13.000, steps: 940\n",
            "Episode 20: reward: 15.000, steps: 966\n",
            "BOLTZMANN --> Reward promedio: 12.70\n",
            "Training for 250000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    420/250000: episode: 1, duration: 1.916s, episode steps: 420, steps per second: 219, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "    980/250000: episode: 2, duration: 2.489s, episode steps: 560, steps per second: 225, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1378/250000: episode: 3, duration: 1.659s, episode steps: 398, steps per second: 240, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2082/250000: episode: 4, duration: 2.942s, episode steps: 704, steps per second: 239, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2977/250000: episode: 5, duration: 3.772s, episode steps: 895, steps per second: 237, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4176/250000: episode: 6, duration: 4.908s, episode steps: 1199, steps per second: 244, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4694/250000: episode: 7, duration: 2.114s, episode steps: 518, steps per second: 245, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5372/250000: episode: 8, duration: 2.792s, episode steps: 678, steps per second: 243, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6053/250000: episode: 9, duration: 2.836s, episode steps: 681, steps per second: 240, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6744/250000: episode: 10, duration: 3.045s, episode steps: 691, steps per second: 227, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7669/250000: episode: 11, duration: 3.926s, episode steps: 925, steps per second: 236, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8643/250000: episode: 12, duration: 4.218s, episode steps: 974, steps per second: 231, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9581/250000: episode: 13, duration: 3.953s, episode steps: 938, steps per second: 237, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10310/250000: episode: 14, duration: 3.060s, episode steps: 729, steps per second: 238, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11373/250000: episode: 15, duration: 4.408s, episode steps: 1063, steps per second: 241, episode reward: 25.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11748/250000: episode: 16, duration: 1.586s, episode steps: 375, steps per second: 236, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12553/250000: episode: 17, duration: 3.448s, episode steps: 805, steps per second: 233, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13271/250000: episode: 18, duration: 3.010s, episode steps: 718, steps per second: 239, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13908/250000: episode: 19, duration: 2.644s, episode steps: 637, steps per second: 241, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.694 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14416/250000: episode: 20, duration: 2.153s, episode steps: 508, steps per second: 236, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15281/250000: episode: 21, duration: 3.649s, episode steps: 865, steps per second: 237, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15663/250000: episode: 22, duration: 1.636s, episode steps: 382, steps per second: 233, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16589/250000: episode: 23, duration: 3.863s, episode steps: 926, steps per second: 240, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17649/250000: episode: 24, duration: 4.453s, episode steps: 1060, steps per second: 238, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18280/250000: episode: 25, duration: 2.700s, episode steps: 631, steps per second: 234, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19010/250000: episode: 26, duration: 3.066s, episode steps: 730, steps per second: 238, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19507/250000: episode: 27, duration: 2.060s, episode steps: 497, steps per second: 241, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19988/250000: episode: 28, duration: 2.027s, episode steps: 481, steps per second: 237, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20800/250000: episode: 29, duration: 3.380s, episode steps: 812, steps per second: 240, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21293/250000: episode: 30, duration: 2.174s, episode steps: 493, steps per second: 227, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21851/250000: episode: 31, duration: 2.365s, episode steps: 558, steps per second: 236, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22481/250000: episode: 32, duration: 2.598s, episode steps: 630, steps per second: 243, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23064/250000: episode: 33, duration: 2.404s, episode steps: 583, steps per second: 242, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23464/250000: episode: 34, duration: 1.644s, episode steps: 400, steps per second: 243, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24141/250000: episode: 35, duration: 2.893s, episode steps: 677, steps per second: 234, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25000/250000: episode: 36, duration: 3.647s, episode steps: 859, steps per second: 236, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25949/250000: episode: 37, duration: 3.990s, episode steps: 949, steps per second: 238, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26496/250000: episode: 38, duration: 2.246s, episode steps: 547, steps per second: 244, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27405/250000: episode: 39, duration: 3.843s, episode steps: 909, steps per second: 237, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28191/250000: episode: 40, duration: 3.210s, episode steps: 786, steps per second: 245, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28933/250000: episode: 41, duration: 3.051s, episode steps: 742, steps per second: 243, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29778/250000: episode: 42, duration: 3.509s, episode steps: 845, steps per second: 241, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30488/250000: episode: 43, duration: 2.987s, episode steps: 710, steps per second: 238, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.692 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31246/250000: episode: 44, duration: 3.112s, episode steps: 758, steps per second: 244, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31854/250000: episode: 45, duration: 2.500s, episode steps: 608, steps per second: 243, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32395/250000: episode: 46, duration: 2.249s, episode steps: 541, steps per second: 241, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33451/250000: episode: 47, duration: 4.544s, episode steps: 1056, steps per second: 232, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34516/250000: episode: 48, duration: 4.401s, episode steps: 1065, steps per second: 242, episode reward: 28.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35238/250000: episode: 49, duration: 3.015s, episode steps: 722, steps per second: 239, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36402/250000: episode: 50, duration: 4.752s, episode steps: 1164, steps per second: 245, episode reward: 26.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37169/250000: episode: 51, duration: 3.143s, episode steps: 767, steps per second: 244, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37853/250000: episode: 52, duration: 2.793s, episode steps: 684, steps per second: 245, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38544/250000: episode: 53, duration: 2.836s, episode steps: 691, steps per second: 244, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38968/250000: episode: 54, duration: 1.826s, episode steps: 424, steps per second: 232, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.750 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39388/250000: episode: 55, duration: 1.774s, episode steps: 420, steps per second: 237, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39901/250000: episode: 56, duration: 2.127s, episode steps: 513, steps per second: 241, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40412/250000: episode: 57, duration: 2.124s, episode steps: 511, steps per second: 241, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41037/250000: episode: 58, duration: 2.549s, episode steps: 625, steps per second: 245, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.722 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41866/250000: episode: 59, duration: 3.439s, episode steps: 829, steps per second: 241, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42593/250000: episode: 60, duration: 2.938s, episode steps: 727, steps per second: 247, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43090/250000: episode: 61, duration: 2.016s, episode steps: 497, steps per second: 246, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43454/250000: episode: 62, duration: 1.470s, episode steps: 364, steps per second: 248, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43988/250000: episode: 63, duration: 2.129s, episode steps: 534, steps per second: 251, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.772 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44383/250000: episode: 64, duration: 1.593s, episode steps: 395, steps per second: 248, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44786/250000: episode: 65, duration: 1.675s, episode steps: 403, steps per second: 241, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45441/250000: episode: 66, duration: 2.755s, episode steps: 655, steps per second: 238, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.782 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46170/250000: episode: 67, duration: 2.986s, episode steps: 729, steps per second: 244, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46706/250000: episode: 68, duration: 2.155s, episode steps: 536, steps per second: 249, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.694 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47126/250000: episode: 69, duration: 1.692s, episode steps: 420, steps per second: 248, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.771 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48057/250000: episode: 70, duration: 3.761s, episode steps: 931, steps per second: 248, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48436/250000: episode: 71, duration: 1.566s, episode steps: 379, steps per second: 242, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49333/250000: episode: 72, duration: 3.722s, episode steps: 897, steps per second: 241, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49991/250000: episode: 73, duration: 2.650s, episode steps: 658, steps per second: 248, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.824 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  50812/250000: episode: 74, duration: 26.049s, episode steps: 821, steps per second:  32, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.008291, mae: 0.034142, mean_q: 0.056889, mean_eps: 0.808457\n",
            "  51328/250000: episode: 75, duration: 16.173s, episode steps: 516, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.009399, mae: 0.041528, mean_q: 0.060406, mean_eps: 0.805942\n",
            "  51710/250000: episode: 76, duration: 11.840s, episode steps: 382, steps per second:  32, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.008878, mae: 0.040473, mean_q: 0.057225, mean_eps: 0.804232\n",
            "  52901/250000: episode: 77, duration: 37.116s, episode steps: 1191, steps per second:  32, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.007661, mae: 0.034456, mean_q: 0.049520, mean_eps: 0.801237\n",
            "  53359/250000: episode: 78, duration: 14.259s, episode steps: 458, steps per second:  32, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.009539, mae: 0.043946, mean_q: 0.063176, mean_eps: 0.798106\n",
            "  53889/250000: episode: 79, duration: 16.500s, episode steps: 530, steps per second:  32, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.864 [0.000, 5.000],  loss: 0.008949, mae: 0.046446, mean_q: 0.063613, mean_eps: 0.796229\n",
            "  54556/250000: episode: 80, duration: 20.688s, episode steps: 667, steps per second:  32, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.008650, mae: 0.037314, mean_q: 0.052242, mean_eps: 0.793956\n",
            "  55156/250000: episode: 81, duration: 18.565s, episode steps: 600, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.007324, mae: 0.034549, mean_q: 0.047242, mean_eps: 0.791555\n",
            "  55541/250000: episode: 82, duration: 12.150s, episode steps: 385, steps per second:  32, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.008076, mae: 0.036746, mean_q: 0.048146, mean_eps: 0.789678\n",
            "  55931/250000: episode: 83, duration: 12.192s, episode steps: 390, steps per second:  32, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.005865, mae: 0.029760, mean_q: 0.040932, mean_eps: 0.788203\n",
            "  56872/250000: episode: 84, duration: 29.750s, episode steps: 941, steps per second:  32, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.007354, mae: 0.037482, mean_q: 0.051238, mean_eps: 0.785680\n",
            "  57544/250000: episode: 85, duration: 20.956s, episode steps: 672, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.008284, mae: 0.038923, mean_q: 0.053120, mean_eps: 0.782617\n",
            "  58178/250000: episode: 86, duration: 19.661s, episode steps: 634, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.008492, mae: 0.036374, mean_q: 0.052388, mean_eps: 0.780132\n",
            "  59386/250000: episode: 87, duration: 37.538s, episode steps: 1208, steps per second:  32, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.008211, mae: 0.035017, mean_q: 0.045967, mean_eps: 0.776628\n",
            "  60162/250000: episode: 88, duration: 24.039s, episode steps: 776, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.007697, mae: 0.038454, mean_q: 0.054403, mean_eps: 0.772859\n",
            "  61221/250000: episode: 89, duration: 32.726s, episode steps: 1059, steps per second:  32, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.008601, mae: 0.036854, mean_q: 0.051911, mean_eps: 0.769370\n",
            "  61888/250000: episode: 90, duration: 20.819s, episode steps: 667, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.006917, mae: 0.032495, mean_q: 0.045316, mean_eps: 0.766095\n",
            "  62997/250000: episode: 91, duration: 34.766s, episode steps: 1109, steps per second:  32, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.008082, mae: 0.037859, mean_q: 0.050990, mean_eps: 0.762720\n",
            "  63510/250000: episode: 92, duration: 16.148s, episode steps: 513, steps per second:  32, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.008597, mae: 0.033722, mean_q: 0.049394, mean_eps: 0.759635\n",
            "  64555/250000: episode: 93, duration: 32.454s, episode steps: 1045, steps per second:  32, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.005816, mae: 0.029752, mean_q: 0.041382, mean_eps: 0.756678\n",
            "  65107/250000: episode: 94, duration: 17.181s, episode steps: 552, steps per second:  32, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.007601, mae: 0.037191, mean_q: 0.049015, mean_eps: 0.753646\n",
            "  65976/250000: episode: 95, duration: 27.229s, episode steps: 869, steps per second:  32, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.287 [0.000, 5.000],  loss: 0.007802, mae: 0.034242, mean_q: 0.048691, mean_eps: 0.750948\n",
            "  66530/250000: episode: 96, duration: 17.397s, episode steps: 554, steps per second:  32, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.006481, mae: 0.036504, mean_q: 0.052198, mean_eps: 0.748242\n",
            "  67157/250000: episode: 97, duration: 19.563s, episode steps: 627, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006212, mae: 0.034119, mean_q: 0.046885, mean_eps: 0.745993\n",
            "  67809/250000: episode: 98, duration: 20.348s, episode steps: 652, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.007240, mae: 0.034452, mean_q: 0.047867, mean_eps: 0.743561\n",
            "  68869/250000: episode: 99, duration: 33.013s, episode steps: 1060, steps per second:  32, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.007980, mae: 0.036597, mean_q: 0.052086, mean_eps: 0.740308\n",
            "  69571/250000: episode: 100, duration: 22.057s, episode steps: 702, steps per second:  32, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.007845, mae: 0.033615, mean_q: 0.048235, mean_eps: 0.736964\n",
            "  69999/250000: episode: 101, duration: 13.434s, episode steps: 428, steps per second:  32, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.007810, mae: 0.035582, mean_q: 0.050735, mean_eps: 0.734821\n",
            "  70708/250000: episode: 102, duration: 22.071s, episode steps: 709, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.007809, mae: 0.037753, mean_q: 0.055414, mean_eps: 0.732662\n",
            "  71685/250000: episode: 103, duration: 30.538s, episode steps: 977, steps per second:  32, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.682 [0.000, 5.000],  loss: 0.007317, mae: 0.033091, mean_q: 0.047551, mean_eps: 0.729455\n",
            "  72400/250000: episode: 104, duration: 22.665s, episode steps: 715, steps per second:  32, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.007860, mae: 0.038305, mean_q: 0.054689, mean_eps: 0.726240\n",
            "  73141/250000: episode: 105, duration: 23.413s, episode steps: 741, steps per second:  32, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.007194, mae: 0.034191, mean_q: 0.051077, mean_eps: 0.723474\n",
            "  74286/250000: episode: 106, duration: 35.548s, episode steps: 1145, steps per second:  32, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.007421, mae: 0.032879, mean_q: 0.048651, mean_eps: 0.719887\n",
            "  74687/250000: episode: 107, duration: 12.579s, episode steps: 401, steps per second:  32, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: 0.006908, mae: 0.037415, mean_q: 0.054264, mean_eps: 0.716953\n",
            "  75442/250000: episode: 108, duration: 23.556s, episode steps: 755, steps per second:  32, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006830, mae: 0.035761, mean_q: 0.053643, mean_eps: 0.714757\n",
            "  76103/250000: episode: 109, duration: 20.691s, episode steps: 661, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.007570, mae: 0.039649, mean_q: 0.057872, mean_eps: 0.712066\n",
            "  76561/250000: episode: 110, duration: 14.427s, episode steps: 458, steps per second:  32, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.007457, mae: 0.033215, mean_q: 0.049637, mean_eps: 0.709938\n",
            "  77727/250000: episode: 111, duration: 36.329s, episode steps: 1166, steps per second:  32, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.006652, mae: 0.035855, mean_q: 0.052624, mean_eps: 0.706853\n",
            "  78515/250000: episode: 112, duration: 24.655s, episode steps: 788, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.744 [0.000, 5.000],  loss: 0.006649, mae: 0.030920, mean_q: 0.047500, mean_eps: 0.703144\n",
            "  79223/250000: episode: 113, duration: 22.211s, episode steps: 708, steps per second:  32, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.007153, mae: 0.033342, mean_q: 0.049723, mean_eps: 0.700302\n",
            "  80103/250000: episode: 114, duration: 27.487s, episode steps: 880, steps per second:  32, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.006647, mae: 0.035492, mean_q: 0.053791, mean_eps: 0.697284\n",
            "  80853/250000: episode: 115, duration: 23.404s, episode steps: 750, steps per second:  32, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: 0.008446, mae: 0.034688, mean_q: 0.054391, mean_eps: 0.694184\n",
            "  81636/250000: episode: 116, duration: 24.664s, episode steps: 783, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.007373, mae: 0.035973, mean_q: 0.055057, mean_eps: 0.691273\n",
            "  82568/250000: episode: 117, duration: 29.327s, episode steps: 932, steps per second:  32, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.007783, mae: 0.034625, mean_q: 0.054744, mean_eps: 0.688020\n",
            "  83572/250000: episode: 118, duration: 31.692s, episode steps: 1004, steps per second:  32, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.007168, mae: 0.034628, mean_q: 0.053508, mean_eps: 0.684342\n",
            "  84186/250000: episode: 119, duration: 19.325s, episode steps: 614, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.881 [0.000, 5.000],  loss: 0.006228, mae: 0.028917, mean_q: 0.046015, mean_eps: 0.681264\n",
            "  85154/250000: episode: 120, duration: 30.453s, episode steps: 968, steps per second:  32, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.006013, mae: 0.030837, mean_q: 0.049567, mean_eps: 0.678254\n",
            "  85953/250000: episode: 121, duration: 25.052s, episode steps: 799, steps per second:  32, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.224 [0.000, 5.000],  loss: 0.007365, mae: 0.033481, mean_q: 0.051334, mean_eps: 0.674895\n",
            "  86884/250000: episode: 122, duration: 28.974s, episode steps: 931, steps per second:  32, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.007280, mae: 0.031992, mean_q: 0.050262, mean_eps: 0.671612\n",
            "  87407/250000: episode: 123, duration: 16.571s, episode steps: 523, steps per second:  32, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.007493, mae: 0.035723, mean_q: 0.056689, mean_eps: 0.668853\n",
            "  88198/250000: episode: 124, duration: 24.875s, episode steps: 791, steps per second:  32, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.007312, mae: 0.035136, mean_q: 0.055160, mean_eps: 0.666352\n",
            "  88774/250000: episode: 125, duration: 18.185s, episode steps: 576, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.006174, mae: 0.032194, mean_q: 0.053124, mean_eps: 0.663753\n",
            "  89569/250000: episode: 126, duration: 24.867s, episode steps: 795, steps per second:  32, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.255 [0.000, 5.000],  loss: 0.006578, mae: 0.033128, mean_q: 0.056144, mean_eps: 0.661146\n",
            "  90412/250000: episode: 127, duration: 26.074s, episode steps: 843, steps per second:  32, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007419, mae: 0.034088, mean_q: 0.054624, mean_eps: 0.658038\n",
            "  91189/250000: episode: 128, duration: 24.353s, episode steps: 777, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.007111, mae: 0.032600, mean_q: 0.052430, mean_eps: 0.654960\n",
            "  91920/250000: episode: 129, duration: 23.057s, episode steps: 731, steps per second:  32, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.007366, mae: 0.033504, mean_q: 0.054128, mean_eps: 0.652095\n",
            "  92671/250000: episode: 130, duration: 23.729s, episode steps: 751, steps per second:  32, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.006677, mae: 0.033424, mean_q: 0.055190, mean_eps: 0.649283\n",
            "  93358/250000: episode: 131, duration: 21.517s, episode steps: 687, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.008619, mae: 0.033074, mean_q: 0.051549, mean_eps: 0.646547\n",
            "  94309/250000: episode: 132, duration: 29.674s, episode steps: 951, steps per second:  32, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.797 [0.000, 5.000],  loss: 0.007615, mae: 0.037469, mean_q: 0.057694, mean_eps: 0.643431\n",
            "  94986/250000: episode: 133, duration: 21.158s, episode steps: 677, steps per second:  32, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.008029, mae: 0.037846, mean_q: 0.061082, mean_eps: 0.640338\n",
            "  95844/250000: episode: 134, duration: 26.789s, episode steps: 858, steps per second:  32, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.007516, mae: 0.034614, mean_q: 0.056689, mean_eps: 0.637427\n",
            "  96349/250000: episode: 135, duration: 15.976s, episode steps: 505, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.007056, mae: 0.035340, mean_q: 0.058427, mean_eps: 0.634835\n",
            "  97289/250000: episode: 136, duration: 29.748s, episode steps: 940, steps per second:  32, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.006900, mae: 0.033291, mean_q: 0.052648, mean_eps: 0.632084\n",
            "  97757/250000: episode: 137, duration: 14.810s, episode steps: 468, steps per second:  32, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.005891, mae: 0.030913, mean_q: 0.053047, mean_eps: 0.629409\n",
            "  98548/250000: episode: 138, duration: 24.911s, episode steps: 791, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.283 [0.000, 5.000],  loss: 0.006285, mae: 0.031290, mean_q: 0.050605, mean_eps: 0.627022\n",
            "  99160/250000: episode: 139, duration: 19.452s, episode steps: 612, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.007755, mae: 0.034106, mean_q: 0.057573, mean_eps: 0.624362\n",
            "  99792/250000: episode: 140, duration: 19.811s, episode steps: 632, steps per second:  32, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.007950, mae: 0.034796, mean_q: 0.056785, mean_eps: 0.621999\n",
            " 100657/250000: episode: 141, duration: 27.304s, episode steps: 865, steps per second:  32, episode reward: 22.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.006696, mae: 0.055181, mean_q: 0.085608, mean_eps: 0.619149\n",
            " 101446/250000: episode: 142, duration: 24.796s, episode steps: 789, steps per second:  32, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.006752, mae: 0.060313, mean_q: 0.089775, mean_eps: 0.616002\n",
            " 101967/250000: episode: 143, duration: 16.350s, episode steps: 521, steps per second:  32, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.203 [0.000, 5.000],  loss: 0.006749, mae: 0.059381, mean_q: 0.087266, mean_eps: 0.613517\n",
            " 102454/250000: episode: 144, duration: 15.384s, episode steps: 487, steps per second:  32, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.729 [0.000, 5.000],  loss: 0.008198, mae: 0.059822, mean_q: 0.089062, mean_eps: 0.611602\n",
            " 103611/250000: episode: 145, duration: 36.183s, episode steps: 1157, steps per second:  32, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.007949, mae: 0.061604, mean_q: 0.094231, mean_eps: 0.608478\n",
            " 104225/250000: episode: 146, duration: 19.624s, episode steps: 614, steps per second:  31, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 3.029 [0.000, 5.000],  loss: 0.007345, mae: 0.059069, mean_q: 0.089519, mean_eps: 0.605112\n",
            " 105380/250000: episode: 147, duration: 36.232s, episode steps: 1155, steps per second:  32, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.144 [0.000, 5.000],  loss: 0.006993, mae: 0.060342, mean_q: 0.090926, mean_eps: 0.601752\n",
            " 106643/250000: episode: 148, duration: 39.744s, episode steps: 1263, steps per second:  32, episode reward: 11.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.007322, mae: 0.059116, mean_q: 0.089737, mean_eps: 0.597162\n",
            " 107304/250000: episode: 149, duration: 21.035s, episode steps: 661, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.006903, mae: 0.059112, mean_q: 0.088820, mean_eps: 0.593506\n",
            " 108201/250000: episode: 150, duration: 28.429s, episode steps: 897, steps per second:  32, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: 0.007362, mae: 0.060053, mean_q: 0.088278, mean_eps: 0.590542\n",
            " 108779/250000: episode: 151, duration: 18.166s, episode steps: 578, steps per second:  32, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.007119, mae: 0.059512, mean_q: 0.088669, mean_eps: 0.587738\n",
            " 109280/250000: episode: 152, duration: 15.884s, episode steps: 501, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.005732, mae: 0.056324, mean_q: 0.085240, mean_eps: 0.585694\n",
            " 109786/250000: episode: 153, duration: 15.940s, episode steps: 506, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.007027, mae: 0.057738, mean_q: 0.087635, mean_eps: 0.583778\n",
            " 110628/250000: episode: 154, duration: 26.675s, episode steps: 842, steps per second:  32, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.007473, mae: 0.060522, mean_q: 0.092302, mean_eps: 0.581217\n",
            " 111008/250000: episode: 155, duration: 12.182s, episode steps: 380, steps per second:  31, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.005820, mae: 0.053898, mean_q: 0.082446, mean_eps: 0.578899\n",
            " 111575/250000: episode: 156, duration: 18.055s, episode steps: 567, steps per second:  31, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.005709, mae: 0.056426, mean_q: 0.083225, mean_eps: 0.577098\n",
            " 112221/250000: episode: 157, duration: 20.607s, episode steps: 646, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.008018, mae: 0.060864, mean_q: 0.092661, mean_eps: 0.574788\n",
            " 112998/250000: episode: 158, duration: 24.575s, episode steps: 777, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.006095, mae: 0.055948, mean_q: 0.086433, mean_eps: 0.572082\n",
            " 113468/250000: episode: 159, duration: 15.044s, episode steps: 470, steps per second:  31, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.005458, mae: 0.057499, mean_q: 0.084712, mean_eps: 0.569718\n",
            " 114101/250000: episode: 160, duration: 20.284s, episode steps: 633, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.771 [0.000, 5.000],  loss: 0.006333, mae: 0.055230, mean_q: 0.082998, mean_eps: 0.567621\n",
            " 114728/250000: episode: 161, duration: 19.993s, episode steps: 627, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.006694, mae: 0.056764, mean_q: 0.084084, mean_eps: 0.565227\n",
            " 115530/250000: episode: 162, duration: 25.448s, episode steps: 802, steps per second:  32, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.007306, mae: 0.057821, mean_q: 0.085773, mean_eps: 0.562514\n",
            " 116116/250000: episode: 163, duration: 18.543s, episode steps: 586, steps per second:  32, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.007134, mae: 0.056788, mean_q: 0.083415, mean_eps: 0.559876\n",
            " 116974/250000: episode: 164, duration: 27.250s, episode steps: 858, steps per second:  31, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.006171, mae: 0.054912, mean_q: 0.082801, mean_eps: 0.557133\n",
            " 117678/250000: episode: 165, duration: 22.399s, episode steps: 704, steps per second:  31, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.793 [0.000, 5.000],  loss: 0.007545, mae: 0.058371, mean_q: 0.088077, mean_eps: 0.554161\n",
            " 119100/250000: episode: 166, duration: 45.363s, episode steps: 1422, steps per second:  31, episode reward: 14.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.006741, mae: 0.057268, mean_q: 0.085036, mean_eps: 0.550126\n",
            " 119899/250000: episode: 167, duration: 25.377s, episode steps: 799, steps per second:  31, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.006217, mae: 0.055555, mean_q: 0.083650, mean_eps: 0.545908\n",
            " 120540/250000: episode: 168, duration: 20.414s, episode steps: 641, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006441, mae: 0.055904, mean_q: 0.085376, mean_eps: 0.543172\n",
            " 120924/250000: episode: 169, duration: 12.306s, episode steps: 384, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.006361, mae: 0.057433, mean_q: 0.085003, mean_eps: 0.541226\n",
            " 121498/250000: episode: 170, duration: 18.096s, episode steps: 574, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: 0.007723, mae: 0.060137, mean_q: 0.086143, mean_eps: 0.539402\n",
            " 121889/250000: episode: 171, duration: 12.602s, episode steps: 391, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.726 [0.000, 5.000],  loss: 0.008604, mae: 0.060002, mean_q: 0.087336, mean_eps: 0.537563\n",
            " 122517/250000: episode: 172, duration: 20.003s, episode steps: 628, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.755 [0.000, 5.000],  loss: 0.006833, mae: 0.054582, mean_q: 0.080143, mean_eps: 0.535625\n",
            " 123381/250000: episode: 173, duration: 27.411s, episode steps: 864, steps per second:  32, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.007932, mae: 0.058768, mean_q: 0.085679, mean_eps: 0.532790\n",
            " 123760/250000: episode: 174, duration: 12.010s, episode steps: 379, steps per second:  32, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.007731, mae: 0.057765, mean_q: 0.085611, mean_eps: 0.530434\n",
            " 124796/250000: episode: 175, duration: 32.868s, episode steps: 1036, steps per second:  32, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.009 [0.000, 5.000],  loss: 0.007118, mae: 0.056164, mean_q: 0.085560, mean_eps: 0.527751\n",
            " 125303/250000: episode: 176, duration: 15.890s, episode steps: 507, steps per second:  32, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.830 [0.000, 5.000],  loss: 0.008191, mae: 0.058958, mean_q: 0.088105, mean_eps: 0.524818\n",
            " 125938/250000: episode: 177, duration: 20.090s, episode steps: 635, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.883 [0.000, 5.000],  loss: 0.006512, mae: 0.056317, mean_q: 0.084234, mean_eps: 0.522644\n",
            " 126443/250000: episode: 178, duration: 15.857s, episode steps: 505, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.006804, mae: 0.057547, mean_q: 0.083905, mean_eps: 0.520478\n",
            " 127066/250000: episode: 179, duration: 19.492s, episode steps: 623, steps per second:  32, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.006838, mae: 0.057786, mean_q: 0.087447, mean_eps: 0.518335\n",
            " 128325/250000: episode: 180, duration: 39.477s, episode steps: 1259, steps per second:  32, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.006802, mae: 0.056970, mean_q: 0.086037, mean_eps: 0.514755\n",
            " 129006/250000: episode: 181, duration: 21.522s, episode steps: 681, steps per second:  32, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.006416, mae: 0.056699, mean_q: 0.086150, mean_eps: 0.511069\n",
            " 129572/250000: episode: 182, duration: 17.871s, episode steps: 566, steps per second:  32, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.006019, mae: 0.053905, mean_q: 0.079391, mean_eps: 0.508706\n",
            " 129953/250000: episode: 183, duration: 12.054s, episode steps: 381, steps per second:  32, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.131 [0.000, 5.000],  loss: 0.006989, mae: 0.056703, mean_q: 0.084256, mean_eps: 0.506904\n",
            " 131163/250000: episode: 184, duration: 38.107s, episode steps: 1210, steps per second:  32, episode reward: 21.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.890 [0.000, 5.000],  loss: 0.006679, mae: 0.056223, mean_q: 0.082923, mean_eps: 0.503880\n",
            " 131826/250000: episode: 185, duration: 21.193s, episode steps: 663, steps per second:  31, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.007636, mae: 0.058096, mean_q: 0.085535, mean_eps: 0.500323\n",
            " 132447/250000: episode: 186, duration: 19.531s, episode steps: 621, steps per second:  32, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.721 [0.000, 5.000],  loss: 0.007741, mae: 0.062099, mean_q: 0.095584, mean_eps: 0.497883\n",
            " 133110/250000: episode: 187, duration: 21.033s, episode steps: 663, steps per second:  32, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.006802, mae: 0.055263, mean_q: 0.085066, mean_eps: 0.495444\n",
            " 133629/250000: episode: 188, duration: 16.430s, episode steps: 519, steps per second:  32, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: 0.007323, mae: 0.057991, mean_q: 0.088020, mean_eps: 0.493194\n",
            " 134505/250000: episode: 189, duration: 27.726s, episode steps: 876, steps per second:  32, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.007176, mae: 0.057072, mean_q: 0.084684, mean_eps: 0.490542\n",
            " 135078/250000: episode: 190, duration: 17.971s, episode steps: 573, steps per second:  32, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.709 [0.000, 5.000],  loss: 0.006441, mae: 0.055792, mean_q: 0.086146, mean_eps: 0.487790\n",
            " 135724/250000: episode: 191, duration: 20.260s, episode steps: 646, steps per second:  32, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.006902, mae: 0.055806, mean_q: 0.086806, mean_eps: 0.485480\n",
            " 136401/250000: episode: 192, duration: 21.213s, episode steps: 677, steps per second:  32, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.005807, mae: 0.054433, mean_q: 0.084159, mean_eps: 0.482964\n",
            " 137037/250000: episode: 193, duration: 19.854s, episode steps: 636, steps per second:  32, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.007059, mae: 0.055177, mean_q: 0.082859, mean_eps: 0.480464\n",
            " 138077/250000: episode: 194, duration: 32.797s, episode steps: 1040, steps per second:  32, episode reward: 27.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006224, mae: 0.054158, mean_q: 0.083146, mean_eps: 0.477280\n",
            " 138773/250000: episode: 195, duration: 22.116s, episode steps: 696, steps per second:  31, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.007009, mae: 0.058171, mean_q: 0.088516, mean_eps: 0.473981\n",
            " 139583/250000: episode: 196, duration: 25.319s, episode steps: 810, steps per second:  32, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007456, mae: 0.056656, mean_q: 0.083864, mean_eps: 0.471124\n",
            " 140741/250000: episode: 197, duration: 36.588s, episode steps: 1158, steps per second:  32, episode reward: 11.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.007853, mae: 0.058380, mean_q: 0.087864, mean_eps: 0.467384\n",
            " 141378/250000: episode: 198, duration: 20.051s, episode steps: 637, steps per second:  32, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.007171, mae: 0.055100, mean_q: 0.084708, mean_eps: 0.463972\n",
            " 142043/250000: episode: 199, duration: 21.009s, episode steps: 665, steps per second:  32, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.006702, mae: 0.055603, mean_q: 0.083799, mean_eps: 0.461502\n",
            " 142684/250000: episode: 200, duration: 20.206s, episode steps: 641, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.005844, mae: 0.054775, mean_q: 0.082579, mean_eps: 0.459024\n",
            " 143827/250000: episode: 201, duration: 35.935s, episode steps: 1143, steps per second:  32, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.006959, mae: 0.055938, mean_q: 0.083158, mean_eps: 0.455635\n",
            " 144856/250000: episode: 202, duration: 32.301s, episode steps: 1029, steps per second:  32, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.006535, mae: 0.055566, mean_q: 0.084461, mean_eps: 0.451508\n",
            " 145697/250000: episode: 203, duration: 26.367s, episode steps: 841, steps per second:  32, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.006501, mae: 0.055823, mean_q: 0.084284, mean_eps: 0.447951\n",
            " 146121/250000: episode: 204, duration: 13.482s, episode steps: 424, steps per second:  31, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.800 [0.000, 5.000],  loss: 0.006749, mae: 0.057515, mean_q: 0.087299, mean_eps: 0.445542\n",
            " 146614/250000: episode: 205, duration: 15.526s, episode steps: 493, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.164 [0.000, 5.000],  loss: 0.006683, mae: 0.056961, mean_q: 0.087045, mean_eps: 0.443802\n",
            " 147281/250000: episode: 206, duration: 21.117s, episode steps: 667, steps per second:  32, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.006593, mae: 0.053991, mean_q: 0.082341, mean_eps: 0.441598\n",
            " 147949/250000: episode: 207, duration: 21.061s, episode steps: 668, steps per second:  32, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: 0.008100, mae: 0.055185, mean_q: 0.082743, mean_eps: 0.439059\n",
            " 148936/250000: episode: 208, duration: 31.011s, episode steps: 987, steps per second:  32, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.927 [0.000, 5.000],  loss: 0.007132, mae: 0.054360, mean_q: 0.083790, mean_eps: 0.435920\n",
            " 149742/250000: episode: 209, duration: 25.398s, episode steps: 806, steps per second:  32, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.006388, mae: 0.055243, mean_q: 0.085951, mean_eps: 0.432516\n",
            " 150252/250000: episode: 210, duration: 16.027s, episode steps: 510, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 3.067 [0.000, 5.000],  loss: 0.007836, mae: 0.074732, mean_q: 0.110289, mean_eps: 0.430015\n",
            " 151237/250000: episode: 211, duration: 31.201s, episode steps: 985, steps per second:  32, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.007644, mae: 0.090997, mean_q: 0.133360, mean_eps: 0.427173\n",
            " 151743/250000: episode: 212, duration: 16.036s, episode steps: 506, steps per second:  32, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.842 [0.000, 5.000],  loss: 0.005829, mae: 0.086844, mean_q: 0.126898, mean_eps: 0.424338\n",
            " 152680/250000: episode: 213, duration: 29.557s, episode steps: 937, steps per second:  32, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.007949, mae: 0.089441, mean_q: 0.127841, mean_eps: 0.421602\n",
            " 153383/250000: episode: 214, duration: 22.066s, episode steps: 703, steps per second:  32, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: 0.007878, mae: 0.090689, mean_q: 0.131898, mean_eps: 0.418486\n",
            " 154395/250000: episode: 215, duration: 32.303s, episode steps: 1012, steps per second:  31, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.006438, mae: 0.088244, mean_q: 0.127333, mean_eps: 0.415226\n",
            " 154798/250000: episode: 216, duration: 12.725s, episode steps: 403, steps per second:  32, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.707 [0.000, 5.000],  loss: 0.007849, mae: 0.089109, mean_q: 0.128380, mean_eps: 0.412535\n",
            " 155801/250000: episode: 217, duration: 31.768s, episode steps: 1003, steps per second:  32, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.006364, mae: 0.087276, mean_q: 0.125908, mean_eps: 0.409860\n",
            " 156714/250000: episode: 218, duration: 29.376s, episode steps: 913, steps per second:  31, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.767 [0.000, 5.000],  loss: 0.007490, mae: 0.088068, mean_q: 0.126511, mean_eps: 0.406220\n",
            " 157433/250000: episode: 219, duration: 23.576s, episode steps: 719, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.006671, mae: 0.084375, mean_q: 0.120889, mean_eps: 0.403119\n",
            " 158073/250000: episode: 220, duration: 20.182s, episode steps: 640, steps per second:  32, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.375 [0.000, 5.000],  loss: 0.005786, mae: 0.086107, mean_q: 0.123499, mean_eps: 0.400535\n",
            " 159325/250000: episode: 221, duration: 39.385s, episode steps: 1252, steps per second:  32, episode reward: 28.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.083 [0.000, 5.000],  loss: 0.006801, mae: 0.086992, mean_q: 0.125920, mean_eps: 0.396940\n",
            " 159775/250000: episode: 222, duration: 14.087s, episode steps: 450, steps per second:  32, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.006151, mae: 0.087315, mean_q: 0.127655, mean_eps: 0.393710\n",
            " 160734/250000: episode: 223, duration: 30.147s, episode steps: 959, steps per second:  32, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.750 [0.000, 5.000],  loss: 0.006906, mae: 0.087959, mean_q: 0.128744, mean_eps: 0.391035\n",
            " 161489/250000: episode: 224, duration: 24.315s, episode steps: 755, steps per second:  31, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.007655, mae: 0.088785, mean_q: 0.126634, mean_eps: 0.387774\n",
            " 162460/250000: episode: 225, duration: 31.390s, episode steps: 971, steps per second:  31, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007329, mae: 0.087347, mean_q: 0.124914, mean_eps: 0.384499\n",
            " 163044/250000: episode: 226, duration: 18.970s, episode steps: 584, steps per second:  31, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.006103, mae: 0.085137, mean_q: 0.120639, mean_eps: 0.381550\n",
            " 163819/250000: episode: 227, duration: 24.975s, episode steps: 775, steps per second:  31, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.006783, mae: 0.085842, mean_q: 0.123169, mean_eps: 0.378966\n",
            " 165025/250000: episode: 228, duration: 38.588s, episode steps: 1206, steps per second:  31, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007916, mae: 0.088360, mean_q: 0.126817, mean_eps: 0.375196\n",
            " 166459/250000: episode: 229, duration: 45.848s, episode steps: 1434, steps per second:  31, episode reward: 31.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.007304, mae: 0.086460, mean_q: 0.125778, mean_eps: 0.370180\n",
            " 167218/250000: episode: 230, duration: 24.317s, episode steps: 759, steps per second:  31, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.843 [0.000, 5.000],  loss: 0.006964, mae: 0.087235, mean_q: 0.126198, mean_eps: 0.366016\n",
            " 168019/250000: episode: 231, duration: 25.591s, episode steps: 801, steps per second:  31, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.007012, mae: 0.087646, mean_q: 0.128338, mean_eps: 0.363052\n",
            " 168669/250000: episode: 232, duration: 21.045s, episode steps: 650, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: 0.006479, mae: 0.085378, mean_q: 0.122637, mean_eps: 0.360293\n",
            " 169715/250000: episode: 233, duration: 34.123s, episode steps: 1046, steps per second:  31, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.262 [0.000, 5.000],  loss: 0.006893, mae: 0.086177, mean_q: 0.122899, mean_eps: 0.357070\n",
            " 170377/250000: episode: 234, duration: 21.573s, episode steps: 662, steps per second:  31, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.989 [0.000, 5.000],  loss: 0.007292, mae: 0.086860, mean_q: 0.123426, mean_eps: 0.353825\n",
            " 170780/250000: episode: 235, duration: 13.199s, episode steps: 403, steps per second:  31, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.774 [0.000, 5.000],  loss: 0.006746, mae: 0.087855, mean_q: 0.127000, mean_eps: 0.351804\n",
            " 171445/250000: episode: 236, duration: 21.605s, episode steps: 665, steps per second:  31, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.883 [0.000, 5.000],  loss: 0.007407, mae: 0.085387, mean_q: 0.123201, mean_eps: 0.349774\n",
            " 173077/250000: episode: 237, duration: 51.929s, episode steps: 1632, steps per second:  31, episode reward: 23.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: 0.006540, mae: 0.084751, mean_q: 0.121987, mean_eps: 0.345404\n",
            " 173571/250000: episode: 238, duration: 15.553s, episode steps: 494, steps per second:  32, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.939 [0.000, 5.000],  loss: 0.007622, mae: 0.086628, mean_q: 0.124933, mean_eps: 0.341369\n",
            " 174068/250000: episode: 239, duration: 15.814s, episode steps: 497, steps per second:  31, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.207 [0.000, 5.000],  loss: 0.007027, mae: 0.086338, mean_q: 0.123576, mean_eps: 0.339492\n",
            " 174425/250000: episode: 240, duration: 11.425s, episode steps: 357, steps per second:  31, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: 0.007936, mae: 0.090982, mean_q: 0.130973, mean_eps: 0.337865\n",
            " 174914/250000: episode: 241, duration: 15.469s, episode steps: 489, steps per second:  32, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.006866, mae: 0.084152, mean_q: 0.122407, mean_eps: 0.336254\n",
            " 175813/250000: episode: 242, duration: 28.755s, episode steps: 899, steps per second:  31, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.006731, mae: 0.084951, mean_q: 0.123101, mean_eps: 0.333617\n",
            " 176487/250000: episode: 243, duration: 21.487s, episode steps: 674, steps per second:  31, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.006410, mae: 0.084713, mean_q: 0.123421, mean_eps: 0.330630\n",
            " 177147/250000: episode: 244, duration: 20.998s, episode steps: 660, steps per second:  31, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: 0.007463, mae: 0.085118, mean_q: 0.122649, mean_eps: 0.328099\n",
            " 177648/250000: episode: 245, duration: 16.240s, episode steps: 501, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.006871, mae: 0.085907, mean_q: 0.122727, mean_eps: 0.325895\n",
            " 178362/250000: episode: 246, duration: 22.933s, episode steps: 714, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.005100, mae: 0.081465, mean_q: 0.116993, mean_eps: 0.323585\n",
            " 179455/250000: episode: 247, duration: 35.008s, episode steps: 1093, steps per second:  31, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.006691, mae: 0.087404, mean_q: 0.125522, mean_eps: 0.320150\n",
            " 180439/250000: episode: 248, duration: 31.523s, episode steps: 984, steps per second:  31, episode reward: 25.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.006785, mae: 0.084523, mean_q: 0.122284, mean_eps: 0.316205\n",
            " 181543/250000: episode: 249, duration: 35.368s, episode steps: 1104, steps per second:  31, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.005888, mae: 0.083376, mean_q: 0.119708, mean_eps: 0.312238\n",
            " 182614/250000: episode: 250, duration: 34.395s, episode steps: 1071, steps per second:  31, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.007649, mae: 0.087616, mean_q: 0.125059, mean_eps: 0.308104\n",
            " 183218/250000: episode: 251, duration: 19.362s, episode steps: 604, steps per second:  31, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.848 [0.000, 5.000],  loss: 0.006267, mae: 0.082178, mean_q: 0.117128, mean_eps: 0.304919\n",
            " 183770/250000: episode: 252, duration: 17.769s, episode steps: 552, steps per second:  31, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.006462, mae: 0.083718, mean_q: 0.119546, mean_eps: 0.302723\n",
            " 185162/250000: episode: 253, duration: 44.657s, episode steps: 1392, steps per second:  31, episode reward: 17.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.006273, mae: 0.084230, mean_q: 0.121326, mean_eps: 0.299029\n",
            " 185811/250000: episode: 254, duration: 21.085s, episode steps: 649, steps per second:  31, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.005671, mae: 0.084386, mean_q: 0.122483, mean_eps: 0.295153\n",
            " 186916/250000: episode: 255, duration: 35.767s, episode steps: 1105, steps per second:  31, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.006360, mae: 0.084421, mean_q: 0.121321, mean_eps: 0.291824\n",
            " 187718/250000: episode: 256, duration: 25.665s, episode steps: 802, steps per second:  31, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.005464, mae: 0.080522, mean_q: 0.115724, mean_eps: 0.288199\n",
            " 188990/250000: episode: 257, duration: 40.857s, episode steps: 1272, steps per second:  31, episode reward: 21.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: 0.006104, mae: 0.083495, mean_q: 0.119988, mean_eps: 0.284255\n",
            " 189655/250000: episode: 258, duration: 21.502s, episode steps: 665, steps per second:  31, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.007512, mae: 0.087548, mean_q: 0.125270, mean_eps: 0.280576\n",
            " 190216/250000: episode: 259, duration: 18.301s, episode steps: 561, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.006878, mae: 0.084698, mean_q: 0.120043, mean_eps: 0.278251\n",
            " 191173/250000: episode: 260, duration: 30.833s, episode steps: 957, steps per second:  31, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.007618, mae: 0.087683, mean_q: 0.126187, mean_eps: 0.275363\n",
            " 192120/250000: episode: 261, duration: 30.492s, episode steps: 947, steps per second:  31, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.005953, mae: 0.082986, mean_q: 0.120112, mean_eps: 0.271745\n",
            " 192799/250000: episode: 262, duration: 21.844s, episode steps: 679, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.006120, mae: 0.085010, mean_q: 0.121572, mean_eps: 0.268660\n",
            " 193446/250000: episode: 263, duration: 20.842s, episode steps: 647, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.007791, mae: 0.086770, mean_q: 0.124194, mean_eps: 0.266136\n",
            " 194242/250000: episode: 264, duration: 25.609s, episode steps: 796, steps per second:  31, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.006993, mae: 0.083746, mean_q: 0.120535, mean_eps: 0.263393\n",
            " 194871/250000: episode: 265, duration: 20.353s, episode steps: 629, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006826, mae: 0.085207, mean_q: 0.123920, mean_eps: 0.260687\n",
            " 195530/250000: episode: 266, duration: 21.521s, episode steps: 659, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.006933, mae: 0.083534, mean_q: 0.121265, mean_eps: 0.258240\n",
            " 195892/250000: episode: 267, duration: 11.888s, episode steps: 362, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.006913, mae: 0.087095, mean_q: 0.126000, mean_eps: 0.256302\n",
            " 196381/250000: episode: 268, duration: 15.970s, episode steps: 489, steps per second:  31, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.125 [0.000, 5.000],  loss: 0.006636, mae: 0.083716, mean_q: 0.120659, mean_eps: 0.254683\n",
            " 197244/250000: episode: 269, duration: 27.744s, episode steps: 863, steps per second:  31, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.811 [0.000, 5.000],  loss: 0.007160, mae: 0.085145, mean_q: 0.120841, mean_eps: 0.252114\n",
            " 198209/250000: episode: 270, duration: 31.333s, episode steps: 965, steps per second:  31, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.006020, mae: 0.083276, mean_q: 0.118219, mean_eps: 0.248641\n",
            " 198857/250000: episode: 271, duration: 20.810s, episode steps: 648, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.008090, mae: 0.087931, mean_q: 0.124297, mean_eps: 0.245571\n",
            " 199674/250000: episode: 272, duration: 26.562s, episode steps: 817, steps per second:  31, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.006339, mae: 0.082912, mean_q: 0.118601, mean_eps: 0.242789\n",
            " 200773/250000: episode: 273, duration: 35.231s, episode steps: 1099, steps per second:  31, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.007787, mae: 0.106858, mean_q: 0.151009, mean_eps: 0.239149\n",
            " 201133/250000: episode: 274, duration: 11.562s, episode steps: 360, steps per second:  31, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 3.206 [0.000, 5.000],  loss: 0.008711, mae: 0.112242, mean_q: 0.158331, mean_eps: 0.236375\n",
            " 202215/250000: episode: 275, duration: 34.954s, episode steps: 1082, steps per second:  31, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.684 [0.000, 5.000],  loss: 0.006948, mae: 0.111452, mean_q: 0.157344, mean_eps: 0.233639\n",
            " 202777/250000: episode: 276, duration: 18.172s, episode steps: 562, steps per second:  31, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.173 [0.000, 5.000],  loss: 0.006507, mae: 0.110250, mean_q: 0.154315, mean_eps: 0.230515\n",
            " 203629/250000: episode: 277, duration: 27.582s, episode steps: 852, steps per second:  31, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.007036, mae: 0.111150, mean_q: 0.156055, mean_eps: 0.227825\n",
            " 204635/250000: episode: 278, duration: 32.465s, episode steps: 1006, steps per second:  31, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.790 [0.000, 5.000],  loss: 0.007007, mae: 0.113320, mean_q: 0.158721, mean_eps: 0.224298\n",
            " 205244/250000: episode: 279, duration: 19.715s, episode steps: 609, steps per second:  31, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.008 [0.000, 5.000],  loss: 0.007541, mae: 0.112074, mean_q: 0.159266, mean_eps: 0.221236\n",
            " 206235/250000: episode: 280, duration: 32.020s, episode steps: 991, steps per second:  31, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.006948, mae: 0.112207, mean_q: 0.157908, mean_eps: 0.218196\n",
            " 206804/250000: episode: 281, duration: 18.566s, episode steps: 569, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.819 [0.000, 5.000],  loss: 0.007316, mae: 0.111199, mean_q: 0.155830, mean_eps: 0.215232\n",
            " 207377/250000: episode: 282, duration: 18.579s, episode steps: 573, steps per second:  31, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.183 [0.000, 5.000],  loss: 0.007466, mae: 0.111228, mean_q: 0.156128, mean_eps: 0.213058\n",
            " 208378/250000: episode: 283, duration: 32.105s, episode steps: 1001, steps per second:  31, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.832 [0.000, 5.000],  loss: 0.007157, mae: 0.110552, mean_q: 0.154694, mean_eps: 0.210064\n",
            " 209308/250000: episode: 284, duration: 30.036s, episode steps: 930, steps per second:  31, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.242 [0.000, 5.000],  loss: 0.006309, mae: 0.108092, mean_q: 0.151026, mean_eps: 0.206400\n",
            " 209962/250000: episode: 285, duration: 21.256s, episode steps: 654, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.007137, mae: 0.107016, mean_q: 0.147259, mean_eps: 0.203391\n",
            " 210572/250000: episode: 286, duration: 19.956s, episode steps: 610, steps per second:  31, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.966 [0.000, 5.000],  loss: 0.006891, mae: 0.108419, mean_q: 0.150647, mean_eps: 0.200989\n",
            " 211626/250000: episode: 287, duration: 34.652s, episode steps: 1054, steps per second:  30, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.852 [0.000, 5.000],  loss: 0.008168, mae: 0.112042, mean_q: 0.157550, mean_eps: 0.197828\n",
            " 212444/250000: episode: 288, duration: 26.622s, episode steps: 818, steps per second:  31, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.006300, mae: 0.105374, mean_q: 0.148508, mean_eps: 0.194271\n",
            " 212882/250000: episode: 289, duration: 14.449s, episode steps: 438, steps per second:  30, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.705 [0.000, 5.000],  loss: 0.006054, mae: 0.104789, mean_q: 0.145963, mean_eps: 0.191884\n",
            " 213238/250000: episode: 290, duration: 11.675s, episode steps: 356, steps per second:  30, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.242 [0.000, 5.000],  loss: 0.007821, mae: 0.113208, mean_q: 0.156259, mean_eps: 0.190372\n",
            " 214557/250000: episode: 291, duration: 43.273s, episode steps: 1319, steps per second:  30, episode reward: 13.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.007136, mae: 0.110470, mean_q: 0.154521, mean_eps: 0.187188\n",
            " 214871/250000: episode: 292, duration: 10.234s, episode steps: 314, steps per second:  31, episode reward:  4.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.697 [0.000, 5.000],  loss: 0.008048, mae: 0.108814, mean_q: 0.151496, mean_eps: 0.184087\n",
            " 215513/250000: episode: 293, duration: 21.138s, episode steps: 642, steps per second:  30, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.006988, mae: 0.110412, mean_q: 0.153657, mean_eps: 0.182270\n",
            " 216900/250000: episode: 294, duration: 45.305s, episode steps: 1387, steps per second:  31, episode reward: 15.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.900 [0.000, 5.000],  loss: 0.006894, mae: 0.110106, mean_q: 0.153698, mean_eps: 0.178417\n",
            " 217543/250000: episode: 295, duration: 20.907s, episode steps: 643, steps per second:  31, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.821 [0.000, 5.000],  loss: 0.007147, mae: 0.108588, mean_q: 0.154057, mean_eps: 0.174564\n",
            " 218565/250000: episode: 296, duration: 33.540s, episode steps: 1022, steps per second:  30, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.007009, mae: 0.110689, mean_q: 0.156630, mean_eps: 0.171395\n",
            " 218954/250000: episode: 297, duration: 12.748s, episode steps: 389, steps per second:  31, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 3.306 [0.000, 5.000],  loss: 0.007192, mae: 0.110660, mean_q: 0.157656, mean_eps: 0.168712\n",
            " 220278/250000: episode: 298, duration: 42.907s, episode steps: 1324, steps per second:  31, episode reward: 17.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.006339, mae: 0.107410, mean_q: 0.152482, mean_eps: 0.165459\n",
            " 220949/250000: episode: 299, duration: 21.969s, episode steps: 671, steps per second:  31, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: 0.007739, mae: 0.111852, mean_q: 0.156178, mean_eps: 0.161667\n",
            " 221687/250000: episode: 300, duration: 23.991s, episode steps: 738, steps per second:  31, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.006835, mae: 0.108170, mean_q: 0.153239, mean_eps: 0.158992\n",
            " 222706/250000: episode: 301, duration: 33.018s, episode steps: 1019, steps per second:  31, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.811 [0.000, 5.000],  loss: 0.006106, mae: 0.107444, mean_q: 0.150924, mean_eps: 0.155655\n",
            " 223779/250000: episode: 302, duration: 34.846s, episode steps: 1073, steps per second:  31, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.006754, mae: 0.109868, mean_q: 0.153449, mean_eps: 0.151680\n",
            " 224456/250000: episode: 303, duration: 21.911s, episode steps: 677, steps per second:  31, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.756 [0.000, 5.000],  loss: 0.008205, mae: 0.111246, mean_q: 0.155946, mean_eps: 0.148359\n",
            " 225093/250000: episode: 304, duration: 20.776s, episode steps: 637, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.007080, mae: 0.108637, mean_q: 0.151919, mean_eps: 0.145859\n",
            " 226224/250000: episode: 305, duration: 36.831s, episode steps: 1131, steps per second:  31, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.006474, mae: 0.107159, mean_q: 0.149994, mean_eps: 0.142500\n",
            " 226783/250000: episode: 306, duration: 18.509s, episode steps: 559, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.007530, mae: 0.109443, mean_q: 0.152110, mean_eps: 0.139292\n",
            " 227468/250000: episode: 307, duration: 22.527s, episode steps: 685, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.061 [0.000, 5.000],  loss: 0.006464, mae: 0.104820, mean_q: 0.147474, mean_eps: 0.136929\n",
            " 228795/250000: episode: 308, duration: 43.664s, episode steps: 1327, steps per second:  30, episode reward: 14.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.772 [0.000, 5.000],  loss: 0.006192, mae: 0.106458, mean_q: 0.150086, mean_eps: 0.133106\n",
            " 229244/250000: episode: 309, duration: 14.770s, episode steps: 449, steps per second:  30, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.833 [0.000, 5.000],  loss: 0.006651, mae: 0.108153, mean_q: 0.151127, mean_eps: 0.129732\n",
            " 230036/250000: episode: 310, duration: 25.813s, episode steps: 792, steps per second:  31, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.007342, mae: 0.108682, mean_q: 0.152199, mean_eps: 0.127376\n",
            " 230680/250000: episode: 311, duration: 21.183s, episode steps: 644, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.866 [0.000, 5.000],  loss: 0.007200, mae: 0.110526, mean_q: 0.155820, mean_eps: 0.124647\n",
            " 231468/250000: episode: 312, duration: 26.120s, episode steps: 788, steps per second:  30, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.108 [0.000, 5.000],  loss: 0.006993, mae: 0.108933, mean_q: 0.154677, mean_eps: 0.121926\n",
            " 231829/250000: episode: 313, duration: 11.927s, episode steps: 361, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.008017, mae: 0.111562, mean_q: 0.156050, mean_eps: 0.119738\n",
            " 233052/250000: episode: 314, duration: 39.952s, episode steps: 1223, steps per second:  31, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.007402, mae: 0.110743, mean_q: 0.156464, mean_eps: 0.116728\n",
            " 233906/250000: episode: 315, duration: 27.919s, episode steps: 854, steps per second:  31, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.007037, mae: 0.107067, mean_q: 0.150935, mean_eps: 0.112784\n",
            " 234668/250000: episode: 316, duration: 24.896s, episode steps: 762, steps per second:  31, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 3.046 [0.000, 5.000],  loss: 0.006604, mae: 0.107595, mean_q: 0.151003, mean_eps: 0.109713\n",
            " 235337/250000: episode: 317, duration: 21.930s, episode steps: 669, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.005714, mae: 0.106077, mean_q: 0.148910, mean_eps: 0.106992\n",
            " 236500/250000: episode: 318, duration: 37.531s, episode steps: 1163, steps per second:  31, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.155 [0.000, 5.000],  loss: 0.005894, mae: 0.106160, mean_q: 0.148115, mean_eps: 0.103512\n",
            " 237435/250000: episode: 319, duration: 30.403s, episode steps: 935, steps per second:  31, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.006265, mae: 0.106161, mean_q: 0.148808, mean_eps: 0.099529\n",
            " 238181/250000: episode: 320, duration: 24.451s, episode steps: 746, steps per second:  31, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.006764, mae: 0.108516, mean_q: 0.152664, mean_eps: 0.096330\n",
            " 239033/250000: episode: 321, duration: 27.655s, episode steps: 852, steps per second:  31, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.006955, mae: 0.107099, mean_q: 0.151668, mean_eps: 0.093290\n",
            " 239871/250000: episode: 322, duration: 27.145s, episode steps: 838, steps per second:  31, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.005530, mae: 0.106130, mean_q: 0.147966, mean_eps: 0.090082\n",
            " 240553/250000: episode: 323, duration: 22.230s, episode steps: 682, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.826 [0.000, 5.000],  loss: 0.007054, mae: 0.105856, mean_q: 0.147145, mean_eps: 0.087194\n",
            " 240971/250000: episode: 324, duration: 13.510s, episode steps: 418, steps per second:  31, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.006917, mae: 0.107319, mean_q: 0.151975, mean_eps: 0.085104\n",
            " 241375/250000: episode: 325, duration: 13.205s, episode steps: 404, steps per second:  31, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 3.198 [0.000, 5.000],  loss: 0.006796, mae: 0.110111, mean_q: 0.155527, mean_eps: 0.083546\n",
            " 242069/250000: episode: 326, duration: 22.655s, episode steps: 694, steps per second:  31, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.876 [0.000, 5.000],  loss: 0.006948, mae: 0.108083, mean_q: 0.152258, mean_eps: 0.081456\n",
            " 242464/250000: episode: 327, duration: 13.029s, episode steps: 395, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 3.623 [0.000, 5.000],  loss: 0.008086, mae: 0.107408, mean_q: 0.151074, mean_eps: 0.079389\n",
            " 242983/250000: episode: 328, duration: 16.873s, episode steps: 519, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: 0.006430, mae: 0.105579, mean_q: 0.149013, mean_eps: 0.077656\n",
            " 243581/250000: episode: 329, duration: 19.542s, episode steps: 598, steps per second:  31, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.042 [0.000, 5.000],  loss: 0.005513, mae: 0.107238, mean_q: 0.151038, mean_eps: 0.075528\n",
            " 244693/250000: episode: 330, duration: 36.098s, episode steps: 1112, steps per second:  31, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 3.001 [0.000, 5.000],  loss: 0.006011, mae: 0.103251, mean_q: 0.145421, mean_eps: 0.072276\n",
            " 245932/250000: episode: 331, duration: 40.511s, episode steps: 1239, steps per second:  31, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.006897, mae: 0.107807, mean_q: 0.152391, mean_eps: 0.067814\n",
            " 246525/250000: episode: 332, duration: 19.655s, episode steps: 593, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.675 [0.000, 5.000],  loss: 0.006727, mae: 0.105692, mean_q: 0.151042, mean_eps: 0.064334\n",
            " 247860/250000: episode: 333, duration: 44.424s, episode steps: 1335, steps per second:  30, episode reward: 24.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.007272, mae: 0.108293, mean_q: 0.153415, mean_eps: 0.060670\n",
            " 248762/250000: episode: 334, duration: 29.910s, episode steps: 902, steps per second:  30, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.006754, mae: 0.107117, mean_q: 0.150772, mean_eps: 0.056422\n",
            " 249795/250000: episode: 335, duration: 34.013s, episode steps: 1033, steps per second:  30, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.007186, mae: 0.107879, mean_q: 0.151678, mean_eps: 0.052744\n",
            "done, took 6589.998 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 5.000, steps: 524\n",
            "Episode 2: reward: 3.000, steps: 507\n",
            "Episode 3: reward: 8.000, steps: 656\n",
            "Episode 4: reward: 3.000, steps: 411\n",
            "Episode 5: reward: 11.000, steps: 685\n",
            "Episode 6: reward: 9.000, steps: 991\n",
            "Episode 7: reward: 9.000, steps: 804\n",
            "Episode 8: reward: 20.000, steps: 1387\n",
            "Episode 9: reward: 4.000, steps: 612\n",
            "Episode 10: reward: 9.000, steps: 712\n",
            "Episode 11: reward: 7.000, steps: 553\n",
            "Episode 12: reward: 7.000, steps: 666\n",
            "Episode 13: reward: 6.000, steps: 541\n",
            "Episode 14: reward: 8.000, steps: 525\n",
            "Episode 15: reward: 4.000, steps: 618\n",
            "Episode 16: reward: 5.000, steps: 653\n",
            "Episode 17: reward: 8.000, steps: 792\n",
            "Episode 18: reward: 9.000, steps: 992\n",
            "Episode 19: reward: 3.000, steps: 549\n",
            "Episode 20: reward: 7.000, steps: 661\n",
            "DOUBLE --> Reward promedio: 7.25\n",
            "Training for 250000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    420/250000: episode: 1, duration: 2.166s, episode steps: 420, steps per second: 194, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "    980/250000: episode: 2, duration: 2.499s, episode steps: 560, steps per second: 224, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1378/250000: episode: 3, duration: 1.774s, episode steps: 398, steps per second: 224, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2082/250000: episode: 4, duration: 3.178s, episode steps: 704, steps per second: 222, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2919/250000: episode: 5, duration: 3.762s, episode steps: 837, steps per second: 222, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3439/250000: episode: 6, duration: 2.356s, episode steps: 520, steps per second: 221, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3961/250000: episode: 7, duration: 2.311s, episode steps: 522, steps per second: 226, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4993/250000: episode: 8, duration: 4.770s, episode steps: 1032, steps per second: 216, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5640/250000: episode: 9, duration: 3.013s, episode steps: 647, steps per second: 215, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6335/250000: episode: 10, duration: 3.163s, episode steps: 695, steps per second: 220, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6974/250000: episode: 11, duration: 2.911s, episode steps: 639, steps per second: 220, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7646/250000: episode: 12, duration: 3.070s, episode steps: 672, steps per second: 219, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8328/250000: episode: 13, duration: 3.023s, episode steps: 682, steps per second: 226, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8953/250000: episode: 14, duration: 2.812s, episode steps: 625, steps per second: 222, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9429/250000: episode: 15, duration: 2.199s, episode steps: 476, steps per second: 216, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10106/250000: episode: 16, duration: 3.077s, episode steps: 677, steps per second: 220, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10818/250000: episode: 17, duration: 3.254s, episode steps: 712, steps per second: 219, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12032/250000: episode: 18, duration: 5.451s, episode steps: 1214, steps per second: 223, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13036/250000: episode: 19, duration: 4.580s, episode steps: 1004, steps per second: 219, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13798/250000: episode: 20, duration: 3.389s, episode steps: 762, steps per second: 225, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14444/250000: episode: 21, duration: 2.900s, episode steps: 646, steps per second: 223, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15276/250000: episode: 22, duration: 3.755s, episode steps: 832, steps per second: 222, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15801/250000: episode: 23, duration: 2.327s, episode steps: 525, steps per second: 226, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16655/250000: episode: 24, duration: 3.731s, episode steps: 854, steps per second: 229, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17648/250000: episode: 25, duration: 4.472s, episode steps: 993, steps per second: 222, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18242/250000: episode: 26, duration: 2.774s, episode steps: 594, steps per second: 214, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19044/250000: episode: 27, duration: 3.548s, episode steps: 802, steps per second: 226, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19996/250000: episode: 28, duration: 4.289s, episode steps: 952, steps per second: 222, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20717/250000: episode: 29, duration: 3.308s, episode steps: 721, steps per second: 218, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21351/250000: episode: 30, duration: 2.753s, episode steps: 634, steps per second: 230, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.222 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22283/250000: episode: 31, duration: 4.019s, episode steps: 932, steps per second: 232, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22670/250000: episode: 32, duration: 1.729s, episode steps: 387, steps per second: 224, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23575/250000: episode: 33, duration: 3.959s, episode steps: 905, steps per second: 229, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.234 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24137/250000: episode: 34, duration: 2.428s, episode steps: 562, steps per second: 231, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.222 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24874/250000: episode: 35, duration: 3.195s, episode steps: 737, steps per second: 231, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25810/250000: episode: 36, duration: 4.132s, episode steps: 936, steps per second: 227, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26315/250000: episode: 37, duration: 2.273s, episode steps: 505, steps per second: 222, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.200 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26844/250000: episode: 38, duration: 2.265s, episode steps: 529, steps per second: 234, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27611/250000: episode: 39, duration: 3.266s, episode steps: 767, steps per second: 235, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.226 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28191/250000: episode: 40, duration: 2.519s, episode steps: 580, steps per second: 230, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29471/250000: episode: 41, duration: 5.675s, episode steps: 1280, steps per second: 226, episode reward: 13.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30753/250000: episode: 42, duration: 5.482s, episode steps: 1282, steps per second: 234, episode reward: 14.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.241 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31453/250000: episode: 43, duration: 3.044s, episode steps: 700, steps per second: 230, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32075/250000: episode: 44, duration: 2.725s, episode steps: 622, steps per second: 228, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.111 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32704/250000: episode: 45, duration: 2.751s, episode steps: 629, steps per second: 229, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33294/250000: episode: 46, duration: 2.563s, episode steps: 590, steps per second: 230, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34129/250000: episode: 47, duration: 3.593s, episode steps: 835, steps per second: 232, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35074/250000: episode: 48, duration: 4.170s, episode steps: 945, steps per second: 227, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.093 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35903/250000: episode: 49, duration: 3.688s, episode steps: 829, steps per second: 225, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.166 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36417/250000: episode: 50, duration: 2.285s, episode steps: 514, steps per second: 225, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37195/250000: episode: 51, duration: 3.551s, episode steps: 778, steps per second: 219, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37789/250000: episode: 52, duration: 2.678s, episode steps: 594, steps per second: 222, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.052 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38695/250000: episode: 53, duration: 4.003s, episode steps: 906, steps per second: 226, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39081/250000: episode: 54, duration: 1.714s, episode steps: 386, steps per second: 225, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.269 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39782/250000: episode: 55, duration: 3.108s, episode steps: 701, steps per second: 226, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.198 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40591/250000: episode: 56, duration: 3.596s, episode steps: 809, steps per second: 225, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.192 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41447/250000: episode: 57, duration: 3.772s, episode steps: 856, steps per second: 227, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.137 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42141/250000: episode: 58, duration: 3.048s, episode steps: 694, steps per second: 228, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.190 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42636/250000: episode: 59, duration: 2.334s, episode steps: 495, steps per second: 212, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.127 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43164/250000: episode: 60, duration: 2.371s, episode steps: 528, steps per second: 223, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.110 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43873/250000: episode: 61, duration: 3.179s, episode steps: 709, steps per second: 223, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.138 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44485/250000: episode: 62, duration: 2.805s, episode steps: 612, steps per second: 218, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.137 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45024/250000: episode: 63, duration: 2.479s, episode steps: 539, steps per second: 217, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.065 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45704/250000: episode: 64, duration: 3.131s, episode steps: 680, steps per second: 217, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46311/250000: episode: 65, duration: 2.702s, episode steps: 607, steps per second: 225, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.023 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46970/250000: episode: 66, duration: 2.936s, episode steps: 659, steps per second: 224, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.012 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47464/250000: episode: 67, duration: 2.231s, episode steps: 494, steps per second: 221, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.063 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47905/250000: episode: 68, duration: 2.181s, episode steps: 441, steps per second: 202, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.973 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48534/250000: episode: 69, duration: 2.863s, episode steps: 629, steps per second: 220, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.103 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49244/250000: episode: 70, duration: 3.180s, episode steps: 710, steps per second: 223, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.094 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49917/250000: episode: 71, duration: 3.042s, episode steps: 673, steps per second: 221, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.082 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  50743/250000: episode: 72, duration: 25.646s, episode steps: 826, steps per second:  32, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.007575, mae: 0.031226, mean_q: -0.011184, mean_eps: 0.808586\n",
            "  51542/250000: episode: 73, duration: 26.107s, episode steps: 799, steps per second:  31, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.158 [0.000, 5.000],  loss: 0.007909, mae: 0.027791, mean_q: -0.012915, mean_eps: 0.805660\n",
            "  52058/250000: episode: 74, duration: 16.649s, episode steps: 516, steps per second:  31, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.007113, mae: 0.029134, mean_q: -0.021130, mean_eps: 0.803160\n",
            "  52491/250000: episode: 75, duration: 13.907s, episode steps: 433, steps per second:  31, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.007803, mae: 0.030449, mean_q: -0.017215, mean_eps: 0.801359\n",
            "  53271/250000: episode: 76, duration: 25.129s, episode steps: 780, steps per second:  31, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.005968, mae: 0.034097, mean_q: -0.026448, mean_eps: 0.799056\n",
            "  53921/250000: episode: 77, duration: 21.179s, episode steps: 650, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.751 [0.000, 5.000],  loss: 0.006787, mae: 0.033898, mean_q: -0.024863, mean_eps: 0.796335\n",
            "  54835/250000: episode: 78, duration: 29.326s, episode steps: 914, steps per second:  31, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.136 [0.000, 5.000],  loss: 0.008013, mae: 0.024963, mean_q: -0.014008, mean_eps: 0.793364\n",
            "  55463/250000: episode: 79, duration: 20.326s, episode steps: 628, steps per second:  31, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.005665, mae: 0.030667, mean_q: -0.023026, mean_eps: 0.790438\n",
            "  56233/250000: episode: 80, duration: 24.903s, episode steps: 770, steps per second:  31, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006532, mae: 0.030349, mean_q: -0.021335, mean_eps: 0.787778\n",
            "  56783/250000: episode: 81, duration: 17.959s, episode steps: 550, steps per second:  31, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.007823, mae: 0.030133, mean_q: -0.017591, mean_eps: 0.785270\n",
            "  57549/250000: episode: 82, duration: 25.065s, episode steps: 766, steps per second:  31, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.007221, mae: 0.030576, mean_q: -0.015776, mean_eps: 0.782769\n",
            "  58360/250000: episode: 83, duration: 26.503s, episode steps: 811, steps per second:  31, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.007675, mae: 0.032621, mean_q: -0.020940, mean_eps: 0.779775\n",
            "  59510/250000: episode: 84, duration: 37.597s, episode steps: 1150, steps per second:  31, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.007151, mae: 0.032844, mean_q: -0.020189, mean_eps: 0.776051\n",
            "  60507/250000: episode: 85, duration: 32.584s, episode steps: 997, steps per second:  31, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.006777, mae: 0.029233, mean_q: -0.017063, mean_eps: 0.771970\n",
            "  60872/250000: episode: 86, duration: 12.028s, episode steps: 365, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.006110, mae: 0.034174, mean_q: -0.024090, mean_eps: 0.769386\n",
            "  61424/250000: episode: 87, duration: 17.914s, episode steps: 552, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.006931, mae: 0.031338, mean_q: -0.020920, mean_eps: 0.767645\n",
            "  62181/250000: episode: 88, duration: 24.722s, episode steps: 757, steps per second:  31, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.005002, mae: 0.032348, mean_q: -0.022809, mean_eps: 0.765152\n",
            "  62985/250000: episode: 89, duration: 26.227s, episode steps: 804, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.007859, mae: 0.027937, mean_q: -0.011607, mean_eps: 0.762181\n",
            "  63624/250000: episode: 90, duration: 20.936s, episode steps: 639, steps per second:  31, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.750 [0.000, 5.000],  loss: 0.006763, mae: 0.034125, mean_q: -0.023868, mean_eps: 0.759445\n",
            "  64223/250000: episode: 91, duration: 19.657s, episode steps: 599, steps per second:  30, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.005023, mae: 0.034695, mean_q: -0.025394, mean_eps: 0.757096\n",
            "  64878/250000: episode: 92, duration: 21.471s, episode steps: 655, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.180 [0.000, 5.000],  loss: 0.007493, mae: 0.026680, mean_q: -0.012420, mean_eps: 0.754710\n",
            "  65561/250000: episode: 93, duration: 22.149s, episode steps: 683, steps per second:  31, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.007085, mae: 0.031820, mean_q: -0.019571, mean_eps: 0.752164\n",
            "  66269/250000: episode: 94, duration: 22.976s, episode steps: 708, steps per second:  31, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.006689, mae: 0.034380, mean_q: -0.025158, mean_eps: 0.749519\n",
            "  67006/250000: episode: 95, duration: 23.953s, episode steps: 737, steps per second:  31, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.006504, mae: 0.027950, mean_q: -0.016195, mean_eps: 0.746776\n",
            "  67814/250000: episode: 96, duration: 26.644s, episode steps: 808, steps per second:  30, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.006943, mae: 0.033684, mean_q: -0.023042, mean_eps: 0.743842\n",
            "  68468/250000: episode: 97, duration: 21.637s, episode steps: 654, steps per second:  30, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.167 [0.000, 5.000],  loss: 0.006434, mae: 0.028827, mean_q: -0.017751, mean_eps: 0.741068\n",
            "  69191/250000: episode: 98, duration: 23.573s, episode steps: 723, steps per second:  31, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.007036, mae: 0.030437, mean_q: -0.017192, mean_eps: 0.738454\n",
            "  70602/250000: episode: 99, duration: 45.836s, episode steps: 1411, steps per second:  31, episode reward: 20.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.007717, mae: 0.031056, mean_q: -0.016432, mean_eps: 0.734395\n",
            "  71437/250000: episode: 100, duration: 26.940s, episode steps: 835, steps per second:  31, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.006913, mae: 0.030091, mean_q: -0.018092, mean_eps: 0.730124\n",
            "  72094/250000: episode: 101, duration: 21.333s, episode steps: 657, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.007542, mae: 0.031035, mean_q: -0.016707, mean_eps: 0.727289\n",
            "  73054/250000: episode: 102, duration: 31.076s, episode steps: 960, steps per second:  31, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.008222, mae: 0.032589, mean_q: -0.015799, mean_eps: 0.724219\n",
            "  73722/250000: episode: 103, duration: 21.429s, episode steps: 668, steps per second:  31, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.005646, mae: 0.031586, mean_q: -0.019730, mean_eps: 0.721126\n",
            "  74274/250000: episode: 104, duration: 17.867s, episode steps: 552, steps per second:  31, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: 0.007400, mae: 0.030533, mean_q: -0.013826, mean_eps: 0.718808\n",
            "  74644/250000: episode: 105, duration: 11.933s, episode steps: 370, steps per second:  31, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.006010, mae: 0.033486, mean_q: -0.021510, mean_eps: 0.717060\n",
            "  75612/250000: episode: 106, duration: 30.970s, episode steps: 968, steps per second:  31, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.006460, mae: 0.028387, mean_q: -0.012131, mean_eps: 0.714521\n",
            "  76258/250000: episode: 107, duration: 20.846s, episode steps: 646, steps per second:  31, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.005421, mae: 0.033330, mean_q: -0.020854, mean_eps: 0.711451\n",
            "  77220/250000: episode: 108, duration: 31.171s, episode steps: 962, steps per second:  31, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.007252, mae: 0.030303, mean_q: -0.013547, mean_eps: 0.708396\n",
            "  78631/250000: episode: 109, duration: 45.140s, episode steps: 1411, steps per second:  31, episode reward: 29.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.752 [0.000, 5.000],  loss: 0.007788, mae: 0.033616, mean_q: -0.016168, mean_eps: 0.703889\n",
            "  79559/250000: episode: 110, duration: 30.099s, episode steps: 928, steps per second:  31, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.006246, mae: 0.034302, mean_q: -0.017791, mean_eps: 0.699443\n",
            "  80484/250000: episode: 111, duration: 30.099s, episode steps: 925, steps per second:  31, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.007155, mae: 0.031244, mean_q: -0.013569, mean_eps: 0.695924\n",
            "  81359/250000: episode: 112, duration: 28.869s, episode steps: 875, steps per second:  30, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.005205, mae: 0.032079, mean_q: -0.017967, mean_eps: 0.692504\n",
            "  82262/250000: episode: 113, duration: 29.565s, episode steps: 903, steps per second:  31, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.007356, mae: 0.030719, mean_q: -0.015057, mean_eps: 0.689122\n",
            "  83529/250000: episode: 114, duration: 41.411s, episode steps: 1267, steps per second:  31, episode reward: 25.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.006692, mae: 0.032441, mean_q: -0.016953, mean_eps: 0.684995\n",
            "  84305/250000: episode: 115, duration: 25.295s, episode steps: 776, steps per second:  31, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.006515, mae: 0.032992, mean_q: -0.014591, mean_eps: 0.681112\n",
            "  85092/250000: episode: 116, duration: 25.671s, episode steps: 787, steps per second:  31, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.006348, mae: 0.032446, mean_q: -0.016050, mean_eps: 0.678148\n",
            "  85612/250000: episode: 117, duration: 16.955s, episode steps: 520, steps per second:  31, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.007327, mae: 0.030741, mean_q: -0.008253, mean_eps: 0.675670\n",
            "  86332/250000: episode: 118, duration: 23.489s, episode steps: 720, steps per second:  31, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: 0.008463, mae: 0.032474, mean_q: -0.011624, mean_eps: 0.673314\n",
            "  87096/250000: episode: 119, duration: 24.887s, episode steps: 764, steps per second:  31, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.006285, mae: 0.034552, mean_q: -0.014852, mean_eps: 0.670494\n",
            "  87522/250000: episode: 120, duration: 13.828s, episode steps: 426, steps per second:  31, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.007649, mae: 0.035541, mean_q: -0.016404, mean_eps: 0.668230\n",
            "  88204/250000: episode: 121, duration: 22.192s, episode steps: 682, steps per second:  31, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.006567, mae: 0.033104, mean_q: -0.015048, mean_eps: 0.666124\n",
            "  88838/250000: episode: 122, duration: 20.837s, episode steps: 634, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.006845, mae: 0.034850, mean_q: -0.013999, mean_eps: 0.663624\n",
            "  89545/250000: episode: 123, duration: 23.495s, episode steps: 707, steps per second:  30, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.007186, mae: 0.031651, mean_q: -0.009093, mean_eps: 0.661070\n",
            "  90033/250000: episode: 124, duration: 16.041s, episode steps: 488, steps per second:  30, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.006582, mae: 0.034323, mean_q: -0.014303, mean_eps: 0.658798\n",
            "  90696/250000: episode: 125, duration: 21.823s, episode steps: 663, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.007959, mae: 0.032991, mean_q: -0.012496, mean_eps: 0.656617\n",
            "  91314/250000: episode: 126, duration: 20.405s, episode steps: 618, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.006672, mae: 0.032979, mean_q: -0.012303, mean_eps: 0.654185\n",
            "  91951/250000: episode: 127, duration: 20.922s, episode steps: 637, steps per second:  30, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.006611, mae: 0.035379, mean_q: -0.016641, mean_eps: 0.651798\n",
            "  93396/250000: episode: 128, duration: 47.777s, episode steps: 1445, steps per second:  30, episode reward: 28.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.007414, mae: 0.035154, mean_q: -0.012985, mean_eps: 0.647846\n",
            "  94495/250000: episode: 129, duration: 35.697s, episode steps: 1099, steps per second:  31, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.006398, mae: 0.035008, mean_q: -0.015461, mean_eps: 0.643013\n",
            "  94892/250000: episode: 130, duration: 13.009s, episode steps: 397, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.798 [0.000, 5.000],  loss: 0.005747, mae: 0.036637, mean_q: -0.018201, mean_eps: 0.640170\n",
            "  95370/250000: episode: 131, duration: 15.526s, episode steps: 478, steps per second:  31, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.006979, mae: 0.034809, mean_q: -0.012856, mean_eps: 0.638506\n",
            "  95885/250000: episode: 132, duration: 16.725s, episode steps: 515, steps per second:  31, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.728 [0.000, 5.000],  loss: 0.006798, mae: 0.036496, mean_q: -0.014946, mean_eps: 0.636614\n",
            "  96619/250000: episode: 133, duration: 23.901s, episode steps: 734, steps per second:  31, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.007538, mae: 0.032638, mean_q: -0.009173, mean_eps: 0.634242\n",
            "  98106/250000: episode: 134, duration: 47.585s, episode steps: 1487, steps per second:  31, episode reward: 28.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.006997, mae: 0.034935, mean_q: -0.015462, mean_eps: 0.630024\n",
            "  98786/250000: episode: 135, duration: 21.935s, episode steps: 680, steps per second:  31, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.005789, mae: 0.033977, mean_q: -0.014994, mean_eps: 0.625905\n",
            "  99167/250000: episode: 136, duration: 12.340s, episode steps: 381, steps per second:  31, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.908 [0.000, 5.000],  loss: 0.008272, mae: 0.032334, mean_q: -0.005815, mean_eps: 0.623891\n",
            "  99752/250000: episode: 137, duration: 19.032s, episode steps: 585, steps per second:  31, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.007305, mae: 0.032055, mean_q: -0.006678, mean_eps: 0.622060\n",
            " 100429/250000: episode: 138, duration: 22.215s, episode steps: 677, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.006809, mae: 0.029424, mean_q: 0.016626, mean_eps: 0.619658\n",
            " 101002/250000: episode: 139, duration: 18.653s, episode steps: 573, steps per second:  31, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.007851, mae: 0.032487, mean_q: 0.034024, mean_eps: 0.617279\n",
            " 101666/250000: episode: 140, duration: 21.640s, episode steps: 664, steps per second:  31, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.007048, mae: 0.033434, mean_q: 0.032732, mean_eps: 0.614931\n",
            " 102115/250000: episode: 141, duration: 14.598s, episode steps: 449, steps per second:  31, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.007739, mae: 0.032019, mean_q: 0.029031, mean_eps: 0.612818\n",
            " 102828/250000: episode: 142, duration: 23.309s, episode steps: 713, steps per second:  31, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.007448, mae: 0.034134, mean_q: 0.031624, mean_eps: 0.610614\n",
            " 103205/250000: episode: 143, duration: 12.356s, episode steps: 377, steps per second:  31, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.006673, mae: 0.031146, mean_q: 0.025857, mean_eps: 0.608539\n",
            " 104039/250000: episode: 144, duration: 27.366s, episode steps: 834, steps per second:  30, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.006444, mae: 0.031477, mean_q: 0.026739, mean_eps: 0.606236\n",
            " 104631/250000: episode: 145, duration: 19.451s, episode steps: 592, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.006427, mae: 0.032630, mean_q: 0.028354, mean_eps: 0.603531\n",
            " 105126/250000: episode: 146, duration: 16.141s, episode steps: 495, steps per second:  31, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.265 [0.000, 5.000],  loss: 0.006848, mae: 0.032799, mean_q: 0.022983, mean_eps: 0.601464\n",
            " 105772/250000: episode: 147, duration: 21.387s, episode steps: 646, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.006874, mae: 0.032353, mean_q: 0.025156, mean_eps: 0.599298\n",
            " 106526/250000: episode: 148, duration: 24.615s, episode steps: 754, steps per second:  31, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.840 [0.000, 5.000],  loss: 0.007277, mae: 0.033762, mean_q: 0.025103, mean_eps: 0.596638\n",
            " 107357/250000: episode: 149, duration: 27.258s, episode steps: 831, steps per second:  30, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.006660, mae: 0.030988, mean_q: 0.023598, mean_eps: 0.593620\n",
            " 108136/250000: episode: 150, duration: 25.478s, episode steps: 779, steps per second:  31, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.005605, mae: 0.030289, mean_q: 0.021858, mean_eps: 0.590565\n",
            " 108754/250000: episode: 151, duration: 20.281s, episode steps: 618, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.757 [0.000, 5.000],  loss: 0.007718, mae: 0.035520, mean_q: 0.031446, mean_eps: 0.587913\n",
            " 109705/250000: episode: 152, duration: 30.918s, episode steps: 951, steps per second:  31, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.006512, mae: 0.032952, mean_q: 0.024372, mean_eps: 0.584926\n",
            " 110359/250000: episode: 153, duration: 21.285s, episode steps: 654, steps per second:  31, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.007108, mae: 0.032739, mean_q: 0.022383, mean_eps: 0.581878\n",
            " 110991/250000: episode: 154, duration: 20.955s, episode steps: 632, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.301 [0.000, 5.000],  loss: 0.008405, mae: 0.035204, mean_q: 0.026524, mean_eps: 0.579439\n",
            " 112175/250000: episode: 155, duration: 39.639s, episode steps: 1184, steps per second:  30, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.818 [0.000, 5.000],  loss: 0.007191, mae: 0.031695, mean_q: 0.026246, mean_eps: 0.575988\n",
            " 113094/250000: episode: 156, duration: 31.567s, episode steps: 919, steps per second:  29, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006958, mae: 0.033521, mean_q: 0.025815, mean_eps: 0.571991\n",
            " 114040/250000: episode: 157, duration: 31.453s, episode steps: 946, steps per second:  30, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.692 [0.000, 5.000],  loss: 0.007088, mae: 0.032740, mean_q: 0.028134, mean_eps: 0.568449\n",
            " 114633/250000: episode: 158, duration: 19.977s, episode steps: 593, steps per second:  30, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.008303, mae: 0.035623, mean_q: 0.031912, mean_eps: 0.565523\n",
            " 115404/250000: episode: 159, duration: 25.561s, episode steps: 771, steps per second:  30, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.636 [0.000, 5.000],  loss: 0.006828, mae: 0.032135, mean_q: 0.028074, mean_eps: 0.562932\n",
            " 115813/250000: episode: 160, duration: 13.694s, episode steps: 409, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: 0.007379, mae: 0.032213, mean_q: 0.030641, mean_eps: 0.560690\n",
            " 116563/250000: episode: 161, duration: 24.939s, episode steps: 750, steps per second:  30, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.005547, mae: 0.030765, mean_q: 0.026050, mean_eps: 0.558486\n",
            " 117184/250000: episode: 162, duration: 20.628s, episode steps: 621, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.006029, mae: 0.030827, mean_q: 0.021867, mean_eps: 0.555886\n",
            " 118033/250000: episode: 163, duration: 28.219s, episode steps: 849, steps per second:  30, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.636 [0.000, 5.000],  loss: 0.007801, mae: 0.036184, mean_q: 0.032001, mean_eps: 0.553090\n",
            " 118726/250000: episode: 164, duration: 22.654s, episode steps: 693, steps per second:  31, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.008298, mae: 0.034720, mean_q: 0.027761, mean_eps: 0.550156\n",
            " 119202/250000: episode: 165, duration: 15.694s, episode steps: 476, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 3.069 [0.000, 5.000],  loss: 0.006705, mae: 0.035509, mean_q: 0.030847, mean_eps: 0.547937\n",
            " 119637/250000: episode: 166, duration: 14.268s, episode steps: 435, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.007304, mae: 0.033903, mean_q: 0.027523, mean_eps: 0.546204\n",
            " 120624/250000: episode: 167, duration: 32.321s, episode steps: 987, steps per second:  31, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.866 [0.000, 5.000],  loss: 0.006538, mae: 0.033982, mean_q: 0.025507, mean_eps: 0.543506\n",
            " 121258/250000: episode: 168, duration: 20.783s, episode steps: 634, steps per second:  31, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.007940, mae: 0.036337, mean_q: 0.030662, mean_eps: 0.540428\n",
            " 121925/250000: episode: 169, duration: 21.957s, episode steps: 667, steps per second:  30, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.007164, mae: 0.035494, mean_q: 0.025058, mean_eps: 0.537950\n",
            " 122511/250000: episode: 170, duration: 19.063s, episode steps: 586, steps per second:  31, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.006045, mae: 0.031627, mean_q: 0.024217, mean_eps: 0.535572\n",
            " 123256/250000: episode: 171, duration: 24.521s, episode steps: 745, steps per second:  30, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.323 [0.000, 5.000],  loss: 0.006921, mae: 0.034455, mean_q: 0.025542, mean_eps: 0.533048\n",
            " 124070/250000: episode: 172, duration: 26.788s, episode steps: 814, steps per second:  30, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: 0.006551, mae: 0.032460, mean_q: 0.027030, mean_eps: 0.530084\n",
            " 124919/250000: episode: 173, duration: 27.805s, episode steps: 849, steps per second:  31, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.005463, mae: 0.031335, mean_q: 0.022292, mean_eps: 0.526923\n",
            " 125294/250000: episode: 174, duration: 12.268s, episode steps: 375, steps per second:  31, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.803 [0.000, 5.000],  loss: 0.005938, mae: 0.031631, mean_q: 0.021696, mean_eps: 0.524597\n",
            " 125822/250000: episode: 175, duration: 17.416s, episode steps: 528, steps per second:  30, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.992 [0.000, 5.000],  loss: 0.006837, mae: 0.033863, mean_q: 0.022195, mean_eps: 0.522880\n",
            " 126748/250000: episode: 176, duration: 30.467s, episode steps: 926, steps per second:  30, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.006286, mae: 0.031427, mean_q: 0.022496, mean_eps: 0.520121\n",
            " 127686/250000: episode: 177, duration: 31.268s, episode steps: 938, steps per second:  30, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.050 [0.000, 5.000],  loss: 0.006635, mae: 0.032155, mean_q: 0.024064, mean_eps: 0.516579\n",
            " 128324/250000: episode: 178, duration: 21.096s, episode steps: 638, steps per second:  30, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.007553, mae: 0.033270, mean_q: 0.028684, mean_eps: 0.513585\n",
            " 129370/250000: episode: 179, duration: 34.846s, episode steps: 1046, steps per second:  30, episode reward: 28.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.005777, mae: 0.033754, mean_q: 0.022528, mean_eps: 0.510385\n",
            " 130219/250000: episode: 180, duration: 28.194s, episode steps: 849, steps per second:  30, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006988, mae: 0.032863, mean_q: 0.024301, mean_eps: 0.506783\n",
            " 130895/250000: episode: 181, duration: 22.168s, episode steps: 676, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.006328, mae: 0.036538, mean_q: 0.029726, mean_eps: 0.503887\n",
            " 131432/250000: episode: 182, duration: 17.853s, episode steps: 537, steps per second:  30, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.006714, mae: 0.033241, mean_q: 0.023594, mean_eps: 0.501584\n",
            " 132123/250000: episode: 183, duration: 22.798s, episode steps: 691, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.006190, mae: 0.034925, mean_q: 0.022088, mean_eps: 0.499251\n",
            " 132610/250000: episode: 184, duration: 15.997s, episode steps: 487, steps per second:  30, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.780 [0.000, 5.000],  loss: 0.007583, mae: 0.034228, mean_q: 0.027156, mean_eps: 0.497009\n",
            " 133577/250000: episode: 185, duration: 32.336s, episode steps: 967, steps per second:  30, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.811 [0.000, 5.000],  loss: 0.006573, mae: 0.031880, mean_q: 0.022886, mean_eps: 0.494243\n",
            " 134568/250000: episode: 186, duration: 32.771s, episode steps: 991, steps per second:  30, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.108 [0.000, 5.000],  loss: 0.006610, mae: 0.035303, mean_q: 0.024614, mean_eps: 0.490526\n",
            " 135435/250000: episode: 187, duration: 28.526s, episode steps: 867, steps per second:  30, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.006623, mae: 0.034361, mean_q: 0.027126, mean_eps: 0.487000\n",
            " 136257/250000: episode: 188, duration: 27.073s, episode steps: 822, steps per second:  30, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.007261, mae: 0.036649, mean_q: 0.032500, mean_eps: 0.483785\n",
            " 136897/250000: episode: 189, duration: 20.861s, episode steps: 640, steps per second:  31, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.905 [0.000, 5.000],  loss: 0.006303, mae: 0.034628, mean_q: 0.024739, mean_eps: 0.481004\n",
            " 137737/250000: episode: 190, duration: 27.261s, episode steps: 840, steps per second:  31, episode reward: 22.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.007233, mae: 0.032138, mean_q: 0.026829, mean_eps: 0.478192\n",
            " 138913/250000: episode: 191, duration: 38.489s, episode steps: 1176, steps per second:  31, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.007194, mae: 0.034445, mean_q: 0.026434, mean_eps: 0.474361\n",
            " 139542/250000: episode: 192, duration: 20.625s, episode steps: 629, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.005353, mae: 0.031967, mean_q: 0.023411, mean_eps: 0.470934\n",
            " 140362/250000: episode: 193, duration: 26.983s, episode steps: 820, steps per second:  30, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.785 [0.000, 5.000],  loss: 0.006137, mae: 0.031631, mean_q: 0.022444, mean_eps: 0.468182\n",
            " 140939/250000: episode: 194, duration: 18.957s, episode steps: 577, steps per second:  30, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.120 [0.000, 5.000],  loss: 0.006692, mae: 0.033603, mean_q: 0.024186, mean_eps: 0.465530\n",
            " 141447/250000: episode: 195, duration: 16.614s, episode steps: 508, steps per second:  31, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.295 [0.000, 5.000],  loss: 0.005996, mae: 0.033782, mean_q: 0.022998, mean_eps: 0.463470\n",
            " 142416/250000: episode: 196, duration: 31.878s, episode steps: 969, steps per second:  30, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.881 [0.000, 5.000],  loss: 0.007589, mae: 0.033539, mean_q: 0.025321, mean_eps: 0.460666\n",
            " 143055/250000: episode: 197, duration: 21.236s, episode steps: 639, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.006068, mae: 0.034478, mean_q: 0.027568, mean_eps: 0.457611\n",
            " 143838/250000: episode: 198, duration: 25.918s, episode steps: 783, steps per second:  30, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.005726, mae: 0.032262, mean_q: 0.024381, mean_eps: 0.454905\n",
            " 145324/250000: episode: 199, duration: 48.791s, episode steps: 1486, steps per second:  30, episode reward: 34.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.781 [0.000, 5.000],  loss: 0.005964, mae: 0.032569, mean_q: 0.024650, mean_eps: 0.450596\n",
            " 146061/250000: episode: 200, duration: 24.328s, episode steps: 737, steps per second:  30, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.007031, mae: 0.033582, mean_q: 0.026254, mean_eps: 0.446370\n",
            " 146495/250000: episode: 201, duration: 14.188s, episode steps: 434, steps per second:  31, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.901 [0.000, 5.000],  loss: 0.008060, mae: 0.034891, mean_q: 0.030181, mean_eps: 0.444144\n",
            " 147214/250000: episode: 202, duration: 23.461s, episode steps: 719, steps per second:  31, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.005907, mae: 0.034142, mean_q: 0.026709, mean_eps: 0.441955\n",
            " 147584/250000: episode: 203, duration: 12.294s, episode steps: 370, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.007709, mae: 0.040698, mean_q: 0.031672, mean_eps: 0.439888\n",
            " 147930/250000: episode: 204, duration: 11.468s, episode steps: 346, steps per second:  30, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.014 [0.000, 5.000],  loss: 0.006847, mae: 0.034407, mean_q: 0.028255, mean_eps: 0.438527\n",
            " 148765/250000: episode: 205, duration: 27.472s, episode steps: 835, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.006191, mae: 0.035215, mean_q: 0.025987, mean_eps: 0.436278\n",
            " 149117/250000: episode: 206, duration: 11.512s, episode steps: 352, steps per second:  31, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.007619, mae: 0.036723, mean_q: 0.028627, mean_eps: 0.434020\n",
            " 149766/250000: episode: 207, duration: 21.328s, episode steps: 649, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.006243, mae: 0.034278, mean_q: 0.024471, mean_eps: 0.432120\n",
            " 150685/250000: episode: 208, duration: 30.196s, episode steps: 919, steps per second:  30, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.008312, mae: 0.048961, mean_q: 0.051576, mean_eps: 0.429141\n",
            " 151503/250000: episode: 209, duration: 26.754s, episode steps: 818, steps per second:  31, episode reward: 19.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.006964, mae: 0.054345, mean_q: 0.054234, mean_eps: 0.425843\n",
            " 151893/250000: episode: 210, duration: 12.970s, episode steps: 390, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: 0.007246, mae: 0.056454, mean_q: 0.053989, mean_eps: 0.423548\n",
            " 152408/250000: episode: 211, duration: 17.011s, episode steps: 515, steps per second:  30, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.767 [0.000, 5.000],  loss: 0.007931, mae: 0.055855, mean_q: 0.054418, mean_eps: 0.421830\n",
            " 153042/250000: episode: 212, duration: 21.226s, episode steps: 634, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.006250, mae: 0.053517, mean_q: 0.052315, mean_eps: 0.419649\n",
            " 153582/250000: episode: 213, duration: 18.001s, episode steps: 540, steps per second:  30, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.007343, mae: 0.055068, mean_q: 0.053872, mean_eps: 0.417414\n",
            " 153981/250000: episode: 214, duration: 13.287s, episode steps: 399, steps per second:  30, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.070 [0.000, 5.000],  loss: 0.007818, mae: 0.057760, mean_q: 0.058655, mean_eps: 0.415628\n",
            " 155013/250000: episode: 215, duration: 34.134s, episode steps: 1032, steps per second:  30, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.006158, mae: 0.051866, mean_q: 0.049274, mean_eps: 0.412908\n",
            " 156173/250000: episode: 216, duration: 38.675s, episode steps: 1160, steps per second:  30, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.944 [0.000, 5.000],  loss: 0.006950, mae: 0.053335, mean_q: 0.049561, mean_eps: 0.408743\n",
            " 157292/250000: episode: 217, duration: 37.420s, episode steps: 1119, steps per second:  30, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.955 [0.000, 5.000],  loss: 0.007280, mae: 0.054289, mean_q: 0.049319, mean_eps: 0.404418\n",
            " 157937/250000: episode: 218, duration: 21.520s, episode steps: 645, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.007365, mae: 0.054751, mean_q: 0.053517, mean_eps: 0.401067\n",
            " 158321/250000: episode: 219, duration: 12.982s, episode steps: 384, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.286 [0.000, 5.000],  loss: 0.005704, mae: 0.049261, mean_q: 0.045065, mean_eps: 0.399106\n",
            " 158725/250000: episode: 220, duration: 13.634s, episode steps: 404, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.772 [0.000, 5.000],  loss: 0.007918, mae: 0.053576, mean_q: 0.051187, mean_eps: 0.397609\n",
            " 159346/250000: episode: 221, duration: 20.995s, episode steps: 621, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.006180, mae: 0.049259, mean_q: 0.043385, mean_eps: 0.395663\n",
            " 160673/250000: episode: 222, duration: 44.337s, episode steps: 1327, steps per second:  30, episode reward: 18.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.148 [0.000, 5.000],  loss: 0.006561, mae: 0.051973, mean_q: 0.048800, mean_eps: 0.391962\n",
            " 161538/250000: episode: 223, duration: 28.626s, episode steps: 865, steps per second:  30, episode reward: 23.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.003 [0.000, 5.000],  loss: 0.006653, mae: 0.053813, mean_q: 0.049451, mean_eps: 0.387797\n",
            " 162150/250000: episode: 224, duration: 20.214s, episode steps: 612, steps per second:  30, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.810 [0.000, 5.000],  loss: 0.006789, mae: 0.052499, mean_q: 0.049257, mean_eps: 0.384993\n",
            " 162841/250000: episode: 225, duration: 22.711s, episode steps: 691, steps per second:  30, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.006141, mae: 0.051158, mean_q: 0.047204, mean_eps: 0.382515\n",
            " 163508/250000: episode: 226, duration: 21.977s, episode steps: 667, steps per second:  30, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: 0.005624, mae: 0.049120, mean_q: 0.041644, mean_eps: 0.379939\n",
            " 164204/250000: episode: 227, duration: 23.029s, episode steps: 696, steps per second:  30, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: 0.007050, mae: 0.055255, mean_q: 0.050942, mean_eps: 0.377355\n",
            " 164639/250000: episode: 228, duration: 14.368s, episode steps: 435, steps per second:  30, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.006944, mae: 0.053469, mean_q: 0.048112, mean_eps: 0.375204\n",
            " 165071/250000: episode: 229, duration: 14.394s, episode steps: 432, steps per second:  30, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.006682, mae: 0.051541, mean_q: 0.047056, mean_eps: 0.373555\n",
            " 166304/250000: episode: 230, duration: 40.786s, episode steps: 1233, steps per second:  30, episode reward: 21.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.007003, mae: 0.052993, mean_q: 0.046373, mean_eps: 0.370393\n",
            " 166771/250000: episode: 231, duration: 15.669s, episode steps: 467, steps per second:  30, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.007140, mae: 0.054262, mean_q: 0.050137, mean_eps: 0.367163\n",
            " 167420/250000: episode: 232, duration: 21.437s, episode steps: 649, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.148 [0.000, 5.000],  loss: 0.006855, mae: 0.051690, mean_q: 0.045471, mean_eps: 0.365043\n",
            " 167914/250000: episode: 233, duration: 16.474s, episode steps: 494, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.846 [0.000, 5.000],  loss: 0.006396, mae: 0.052275, mean_q: 0.047926, mean_eps: 0.362869\n",
            " 168782/250000: episode: 234, duration: 28.899s, episode steps: 868, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.007441, mae: 0.054199, mean_q: 0.049392, mean_eps: 0.360278\n",
            " 169391/250000: episode: 235, duration: 20.369s, episode steps: 609, steps per second:  30, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.841 [0.000, 5.000],  loss: 0.006251, mae: 0.053230, mean_q: 0.046230, mean_eps: 0.357473\n",
            " 169818/250000: episode: 236, duration: 14.081s, episode steps: 427, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.173 [0.000, 5.000],  loss: 0.007742, mae: 0.055846, mean_q: 0.050271, mean_eps: 0.355505\n",
            " 170205/250000: episode: 237, duration: 12.783s, episode steps: 387, steps per second:  30, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.007150, mae: 0.050497, mean_q: 0.045011, mean_eps: 0.353954\n",
            " 170579/250000: episode: 238, duration: 12.231s, episode steps: 374, steps per second:  31, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.842 [0.000, 5.000],  loss: 0.007654, mae: 0.055779, mean_q: 0.052281, mean_eps: 0.352510\n",
            " 171240/250000: episode: 239, duration: 22.132s, episode steps: 661, steps per second:  30, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.113 [0.000, 5.000],  loss: 0.006760, mae: 0.053307, mean_q: 0.050415, mean_eps: 0.350550\n",
            " 171923/250000: episode: 240, duration: 22.819s, episode steps: 683, steps per second:  30, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.005043, mae: 0.050471, mean_q: 0.042081, mean_eps: 0.347996\n",
            " 172672/250000: episode: 241, duration: 24.843s, episode steps: 749, steps per second:  30, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.198 [0.000, 5.000],  loss: 0.006860, mae: 0.055598, mean_q: 0.050819, mean_eps: 0.345275\n",
            " 173047/250000: episode: 242, duration: 12.591s, episode steps: 375, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007215, mae: 0.051256, mean_q: 0.047078, mean_eps: 0.343140\n",
            " 173523/250000: episode: 243, duration: 15.691s, episode steps: 476, steps per second:  30, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.007437, mae: 0.054747, mean_q: 0.053269, mean_eps: 0.341521\n",
            " 174158/250000: episode: 244, duration: 21.057s, episode steps: 635, steps per second:  30, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.005892, mae: 0.051246, mean_q: 0.046051, mean_eps: 0.339408\n",
            " 174761/250000: episode: 245, duration: 20.224s, episode steps: 603, steps per second:  30, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.740 [0.000, 5.000],  loss: 0.005825, mae: 0.052268, mean_q: 0.049329, mean_eps: 0.337052\n",
            " 175470/250000: episode: 246, duration: 23.621s, episode steps: 709, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.006974, mae: 0.052578, mean_q: 0.046976, mean_eps: 0.334559\n",
            " 176316/250000: episode: 247, duration: 27.894s, episode steps: 846, steps per second:  30, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.739 [0.000, 5.000],  loss: 0.007423, mae: 0.056115, mean_q: 0.053870, mean_eps: 0.331610\n",
            " 177247/250000: episode: 248, duration: 30.891s, episode steps: 931, steps per second:  30, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.006366, mae: 0.052433, mean_q: 0.047742, mean_eps: 0.328236\n",
            " 177759/250000: episode: 249, duration: 17.256s, episode steps: 512, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.035 [0.000, 5.000],  loss: 0.008090, mae: 0.054498, mean_q: 0.049220, mean_eps: 0.325492\n",
            " 178572/250000: episode: 250, duration: 27.252s, episode steps: 813, steps per second:  30, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.007128, mae: 0.055683, mean_q: 0.048514, mean_eps: 0.322977\n",
            " 179087/250000: episode: 251, duration: 17.490s, episode steps: 515, steps per second:  29, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.006522, mae: 0.053957, mean_q: 0.045786, mean_eps: 0.320454\n",
            " 180201/250000: episode: 252, duration: 37.057s, episode steps: 1114, steps per second:  30, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.006516, mae: 0.051638, mean_q: 0.047983, mean_eps: 0.317353\n",
            " 180725/250000: episode: 253, duration: 17.242s, episode steps: 524, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.088 [0.000, 5.000],  loss: 0.007121, mae: 0.057174, mean_q: 0.052338, mean_eps: 0.314237\n",
            " 181596/250000: episode: 254, duration: 29.268s, episode steps: 871, steps per second:  30, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.902 [0.000, 5.000],  loss: 0.006493, mae: 0.053556, mean_q: 0.049864, mean_eps: 0.311592\n",
            " 182643/250000: episode: 255, duration: 35.304s, episode steps: 1047, steps per second:  30, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.959 [0.000, 5.000],  loss: 0.007437, mae: 0.055097, mean_q: 0.053393, mean_eps: 0.307952\n",
            " 183799/250000: episode: 256, duration: 39.122s, episode steps: 1156, steps per second:  30, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.973 [0.000, 5.000],  loss: 0.006713, mae: 0.053990, mean_q: 0.051993, mean_eps: 0.303764\n",
            " 184440/250000: episode: 257, duration: 21.402s, episode steps: 641, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.122 [0.000, 5.000],  loss: 0.007402, mae: 0.056026, mean_q: 0.056588, mean_eps: 0.300352\n",
            " 185093/250000: episode: 258, duration: 22.278s, episode steps: 653, steps per second:  29, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.202 [0.000, 5.000],  loss: 0.006128, mae: 0.049843, mean_q: 0.048182, mean_eps: 0.297889\n",
            " 186084/250000: episode: 259, duration: 33.193s, episode steps: 991, steps per second:  30, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.007449, mae: 0.053262, mean_q: 0.049709, mean_eps: 0.294766\n",
            " 187066/250000: episode: 260, duration: 32.537s, episode steps: 982, steps per second:  30, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.110 [0.000, 5.000],  loss: 0.006003, mae: 0.053027, mean_q: 0.046985, mean_eps: 0.291019\n",
            " 187872/250000: episode: 261, duration: 26.662s, episode steps: 806, steps per second:  30, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.947 [0.000, 5.000],  loss: 0.006916, mae: 0.051281, mean_q: 0.047060, mean_eps: 0.287622\n",
            " 188510/250000: episode: 262, duration: 21.281s, episode steps: 638, steps per second:  30, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.007574, mae: 0.058213, mean_q: 0.053952, mean_eps: 0.284878\n",
            " 189188/250000: episode: 263, duration: 22.563s, episode steps: 678, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.108 [0.000, 5.000],  loss: 0.006784, mae: 0.053995, mean_q: 0.049318, mean_eps: 0.282378\n",
            " 189617/250000: episode: 264, duration: 14.513s, episode steps: 429, steps per second:  30, episode reward: 10.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.902 [0.000, 5.000],  loss: 0.003831, mae: 0.048285, mean_q: 0.039407, mean_eps: 0.280272\n",
            " 190936/250000: episode: 265, duration: 44.220s, episode steps: 1319, steps per second:  30, episode reward: 29.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.006990, mae: 0.052135, mean_q: 0.047151, mean_eps: 0.276951\n",
            " 191689/250000: episode: 266, duration: 25.313s, episode steps: 753, steps per second:  30, episode reward: 18.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.121 [0.000, 5.000],  loss: 0.007384, mae: 0.056511, mean_q: 0.053976, mean_eps: 0.273014\n",
            " 192329/250000: episode: 267, duration: 21.301s, episode steps: 640, steps per second:  30, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.772 [0.000, 5.000],  loss: 0.008036, mae: 0.056906, mean_q: 0.057588, mean_eps: 0.270362\n",
            " 192864/250000: episode: 268, duration: 17.948s, episode steps: 535, steps per second:  30, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: 0.006277, mae: 0.054179, mean_q: 0.051497, mean_eps: 0.268135\n",
            " 193467/250000: episode: 269, duration: 20.147s, episode steps: 603, steps per second:  30, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.006599, mae: 0.053436, mean_q: 0.048612, mean_eps: 0.265977\n",
            " 194577/250000: episode: 270, duration: 37.074s, episode steps: 1110, steps per second:  30, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: 0.007402, mae: 0.055327, mean_q: 0.051530, mean_eps: 0.262716\n",
            " 195170/250000: episode: 271, duration: 19.673s, episode steps: 593, steps per second:  30, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.997 [0.000, 5.000],  loss: 0.007825, mae: 0.055353, mean_q: 0.049855, mean_eps: 0.259479\n",
            " 195636/250000: episode: 272, duration: 15.683s, episode steps: 466, steps per second:  30, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.005965, mae: 0.050564, mean_q: 0.047261, mean_eps: 0.257472\n",
            " 196309/250000: episode: 273, duration: 22.546s, episode steps: 673, steps per second:  30, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.006838, mae: 0.052069, mean_q: 0.048022, mean_eps: 0.255306\n",
            " 197451/250000: episode: 274, duration: 37.840s, episode steps: 1142, steps per second:  30, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.254 [0.000, 5.000],  loss: 0.006254, mae: 0.052838, mean_q: 0.048341, mean_eps: 0.251856\n",
            " 198035/250000: episode: 275, duration: 19.431s, episode steps: 584, steps per second:  30, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.003 [0.000, 5.000],  loss: 0.006229, mae: 0.052680, mean_q: 0.048266, mean_eps: 0.248580\n",
            " 198453/250000: episode: 276, duration: 13.859s, episode steps: 418, steps per second:  30, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.268 [0.000, 5.000],  loss: 0.005898, mae: 0.054108, mean_q: 0.047415, mean_eps: 0.246673\n",
            " 198919/250000: episode: 277, duration: 15.549s, episode steps: 466, steps per second:  30, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.004 [0.000, 5.000],  loss: 0.006996, mae: 0.055917, mean_q: 0.052785, mean_eps: 0.244993\n",
            " 199397/250000: episode: 278, duration: 16.333s, episode steps: 478, steps per second:  29, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.004976, mae: 0.050646, mean_q: 0.045509, mean_eps: 0.243200\n",
            " 200026/250000: episode: 279, duration: 21.195s, episode steps: 629, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.881 [0.000, 5.000],  loss: 0.006034, mae: 0.051282, mean_q: 0.046449, mean_eps: 0.241094\n",
            " 200771/250000: episode: 280, duration: 24.808s, episode steps: 745, steps per second:  30, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.008367, mae: 0.072082, mean_q: 0.087325, mean_eps: 0.238488\n",
            " 202184/250000: episode: 281, duration: 46.975s, episode steps: 1413, steps per second:  30, episode reward: 21.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.006872, mae: 0.070709, mean_q: 0.081934, mean_eps: 0.234391\n",
            " 203021/250000: episode: 282, duration: 28.146s, episode steps: 837, steps per second:  30, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.006981, mae: 0.073471, mean_q: 0.082838, mean_eps: 0.230112\n",
            " 203742/250000: episode: 283, duration: 24.104s, episode steps: 721, steps per second:  30, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.005670, mae: 0.069381, mean_q: 0.077446, mean_eps: 0.227148\n",
            " 204467/250000: episode: 284, duration: 23.913s, episode steps: 725, steps per second:  30, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.007301, mae: 0.075584, mean_q: 0.086258, mean_eps: 0.224405\n",
            " 205515/250000: episode: 285, duration: 34.779s, episode steps: 1048, steps per second:  30, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.205 [0.000, 5.000],  loss: 0.007256, mae: 0.072951, mean_q: 0.083703, mean_eps: 0.221038\n",
            " 206222/250000: episode: 286, duration: 23.423s, episode steps: 707, steps per second:  30, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.007156, mae: 0.073646, mean_q: 0.083717, mean_eps: 0.217702\n",
            " 206736/250000: episode: 287, duration: 17.234s, episode steps: 514, steps per second:  30, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.007462, mae: 0.073533, mean_q: 0.082392, mean_eps: 0.215384\n",
            " 207768/250000: episode: 288, duration: 34.871s, episode steps: 1032, steps per second:  30, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.245 [0.000, 5.000],  loss: 0.007507, mae: 0.074578, mean_q: 0.084796, mean_eps: 0.212450\n",
            " 208405/250000: episode: 289, duration: 21.279s, episode steps: 637, steps per second:  30, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006229, mae: 0.070816, mean_q: 0.082466, mean_eps: 0.209273\n",
            " 209304/250000: episode: 290, duration: 29.754s, episode steps: 899, steps per second:  30, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.007400, mae: 0.070995, mean_q: 0.080919, mean_eps: 0.206355\n",
            " 210180/250000: episode: 291, duration: 29.081s, episode steps: 876, steps per second:  30, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.168 [0.000, 5.000],  loss: 0.006605, mae: 0.071636, mean_q: 0.082789, mean_eps: 0.202988\n",
            " 210689/250000: episode: 292, duration: 16.933s, episode steps: 509, steps per second:  30, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.277 [0.000, 5.000],  loss: 0.007008, mae: 0.071142, mean_q: 0.083570, mean_eps: 0.200351\n",
            " 211400/250000: episode: 293, duration: 23.536s, episode steps: 711, steps per second:  30, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.065 [0.000, 5.000],  loss: 0.007359, mae: 0.073206, mean_q: 0.084056, mean_eps: 0.198033\n",
            " 211818/250000: episode: 294, duration: 13.972s, episode steps: 418, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 3.519 [0.000, 5.000],  loss: 0.007408, mae: 0.076681, mean_q: 0.088973, mean_eps: 0.195890\n",
            " 212442/250000: episode: 295, duration: 20.772s, episode steps: 624, steps per second:  30, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.006785, mae: 0.071228, mean_q: 0.078409, mean_eps: 0.193906\n",
            " 212947/250000: episode: 296, duration: 16.719s, episode steps: 505, steps per second:  30, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.009836, mae: 0.075134, mean_q: 0.088557, mean_eps: 0.191763\n",
            " 213541/250000: episode: 297, duration: 19.972s, episode steps: 594, steps per second:  30, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006797, mae: 0.072875, mean_q: 0.084688, mean_eps: 0.189673\n",
            " 214032/250000: episode: 298, duration: 16.429s, episode steps: 491, steps per second:  30, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.006242, mae: 0.069466, mean_q: 0.079385, mean_eps: 0.187613\n",
            " 214931/250000: episode: 299, duration: 30.314s, episode steps: 899, steps per second:  30, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.006373, mae: 0.071298, mean_q: 0.081744, mean_eps: 0.184976\n",
            " 215484/250000: episode: 300, duration: 18.496s, episode steps: 553, steps per second:  30, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.006930, mae: 0.074033, mean_q: 0.087916, mean_eps: 0.182217\n",
            " 215865/250000: episode: 301, duration: 12.913s, episode steps: 381, steps per second:  30, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 3.016 [0.000, 5.000],  loss: 0.005737, mae: 0.068938, mean_q: 0.080799, mean_eps: 0.180439\n",
            " 216200/250000: episode: 302, duration: 11.357s, episode steps: 335, steps per second:  29, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.006448, mae: 0.067534, mean_q: 0.077020, mean_eps: 0.179078\n",
            " 216598/250000: episode: 303, duration: 13.464s, episode steps: 398, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.006815, mae: 0.068186, mean_q: 0.076724, mean_eps: 0.177688\n",
            " 216981/250000: episode: 304, duration: 12.845s, episode steps: 383, steps per second:  30, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.007697, mae: 0.072589, mean_q: 0.082684, mean_eps: 0.176198\n",
            " 218498/250000: episode: 305, duration: 51.027s, episode steps: 1517, steps per second:  30, episode reward: 25.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.006719, mae: 0.071787, mean_q: 0.081943, mean_eps: 0.172588\n",
            " 218928/250000: episode: 306, duration: 14.493s, episode steps: 430, steps per second:  30, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.514 [0.000, 5.000],  loss: 0.007674, mae: 0.073836, mean_q: 0.085080, mean_eps: 0.168894\n",
            " 219306/250000: episode: 307, duration: 12.753s, episode steps: 378, steps per second:  30, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.006614, mae: 0.074884, mean_q: 0.087525, mean_eps: 0.167359\n",
            " 220245/250000: episode: 308, duration: 31.491s, episode steps: 939, steps per second:  30, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.092 [0.000, 5.000],  loss: 0.007318, mae: 0.071944, mean_q: 0.081702, mean_eps: 0.164851\n",
            " 220741/250000: episode: 309, duration: 16.559s, episode steps: 496, steps per second:  30, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.913 [0.000, 5.000],  loss: 0.004560, mae: 0.069753, mean_q: 0.079159, mean_eps: 0.162123\n",
            " 221541/250000: episode: 310, duration: 26.757s, episode steps: 800, steps per second:  30, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.871 [0.000, 5.000],  loss: 0.006730, mae: 0.070441, mean_q: 0.079281, mean_eps: 0.159660\n",
            " 221879/250000: episode: 311, duration: 11.135s, episode steps: 338, steps per second:  30, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.007233, mae: 0.070723, mean_q: 0.081720, mean_eps: 0.157502\n",
            " 222574/250000: episode: 312, duration: 23.052s, episode steps: 695, steps per second:  30, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.007178, mae: 0.072719, mean_q: 0.083678, mean_eps: 0.155541\n",
            " 223381/250000: episode: 313, duration: 26.918s, episode steps: 807, steps per second:  30, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.005988, mae: 0.069308, mean_q: 0.078463, mean_eps: 0.152684\n",
            " 224007/250000: episode: 314, duration: 21.013s, episode steps: 626, steps per second:  30, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.807 [0.000, 5.000],  loss: 0.006301, mae: 0.074790, mean_q: 0.085038, mean_eps: 0.149963\n",
            " 224887/250000: episode: 315, duration: 29.274s, episode steps: 880, steps per second:  30, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.006379, mae: 0.070508, mean_q: 0.081819, mean_eps: 0.147105\n",
            " 225307/250000: episode: 316, duration: 14.122s, episode steps: 420, steps per second:  30, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.005293, mae: 0.070848, mean_q: 0.079599, mean_eps: 0.144635\n",
            " 225984/250000: episode: 317, duration: 22.863s, episode steps: 677, steps per second:  30, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.065 [0.000, 5.000],  loss: 0.007229, mae: 0.071958, mean_q: 0.081257, mean_eps: 0.142553\n",
            " 226497/250000: episode: 318, duration: 17.321s, episode steps: 513, steps per second:  30, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.893 [0.000, 5.000],  loss: 0.006341, mae: 0.072704, mean_q: 0.081486, mean_eps: 0.140288\n",
            " 227120/250000: episode: 319, duration: 21.318s, episode steps: 623, steps per second:  29, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.945 [0.000, 5.000],  loss: 0.007180, mae: 0.071674, mean_q: 0.080362, mean_eps: 0.138130\n",
            " 227789/250000: episode: 320, duration: 22.874s, episode steps: 669, steps per second:  29, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.994 [0.000, 5.000],  loss: 0.005991, mae: 0.069999, mean_q: 0.079217, mean_eps: 0.135675\n",
            " 228628/250000: episode: 321, duration: 28.503s, episode steps: 839, steps per second:  29, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.768 [0.000, 5.000],  loss: 0.006183, mae: 0.070923, mean_q: 0.078847, mean_eps: 0.132810\n",
            " 229211/250000: episode: 322, duration: 19.578s, episode steps: 583, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.082 [0.000, 5.000],  loss: 0.006552, mae: 0.069472, mean_q: 0.079062, mean_eps: 0.130112\n",
            " 229906/250000: episode: 323, duration: 23.337s, episode steps: 695, steps per second:  30, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 3.164 [0.000, 5.000],  loss: 0.007144, mae: 0.074156, mean_q: 0.083733, mean_eps: 0.127680\n",
            " 230563/250000: episode: 324, duration: 22.081s, episode steps: 657, steps per second:  30, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.006537, mae: 0.070658, mean_q: 0.079202, mean_eps: 0.125111\n",
            " 231465/250000: episode: 325, duration: 30.567s, episode steps: 902, steps per second:  30, episode reward: 22.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.007180, mae: 0.070006, mean_q: 0.081008, mean_eps: 0.122147\n",
            " 232234/250000: episode: 326, duration: 26.363s, episode steps: 769, steps per second:  29, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.007278, mae: 0.072175, mean_q: 0.081100, mean_eps: 0.118970\n",
            " 232716/250000: episode: 327, duration: 16.710s, episode steps: 482, steps per second:  29, episode reward:  1.000, mean reward:  0.002 [ 0.000,  1.000], mean action: 1.822 [0.000, 5.000],  loss: 0.006122, mae: 0.067417, mean_q: 0.075548, mean_eps: 0.116599\n",
            " 233966/250000: episode: 328, duration: 42.572s, episode steps: 1250, steps per second:  29, episode reward: 18.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006918, mae: 0.068994, mean_q: 0.076980, mean_eps: 0.113308\n",
            " 234330/250000: episode: 329, duration: 12.359s, episode steps: 364, steps per second:  29, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.007904, mae: 0.074091, mean_q: 0.081927, mean_eps: 0.110238\n",
            " 235007/250000: episode: 330, duration: 23.073s, episode steps: 677, steps per second:  29, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.005975, mae: 0.066578, mean_q: 0.074791, mean_eps: 0.108262\n",
            " 235831/250000: episode: 331, duration: 28.285s, episode steps: 824, steps per second:  29, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.922 [0.000, 5.000],  loss: 0.006732, mae: 0.071679, mean_q: 0.079889, mean_eps: 0.105412\n",
            " 236482/250000: episode: 332, duration: 22.266s, episode steps: 651, steps per second:  29, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.922 [0.000, 5.000],  loss: 0.007437, mae: 0.072067, mean_q: 0.082238, mean_eps: 0.102607\n",
            " 237007/250000: episode: 333, duration: 17.725s, episode steps: 525, steps per second:  30, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.088 [0.000, 5.000],  loss: 0.007119, mae: 0.072489, mean_q: 0.082971, mean_eps: 0.100373\n",
            " 238167/250000: episode: 334, duration: 39.296s, episode steps: 1160, steps per second:  30, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.005724, mae: 0.067785, mean_q: 0.075953, mean_eps: 0.097173\n",
            " 238536/250000: episode: 335, duration: 12.548s, episode steps: 369, steps per second:  29, episode reward:  2.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.553 [0.000, 5.000],  loss: 0.006064, mae: 0.065991, mean_q: 0.073531, mean_eps: 0.094270\n",
            " 239351/250000: episode: 336, duration: 27.707s, episode steps: 815, steps per second:  29, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.023 [0.000, 5.000],  loss: 0.006954, mae: 0.071854, mean_q: 0.080607, mean_eps: 0.092020\n",
            " 240154/250000: episode: 337, duration: 27.111s, episode steps: 803, steps per second:  30, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.006060, mae: 0.070090, mean_q: 0.079246, mean_eps: 0.088942\n",
            " 241988/250000: episode: 338, duration: 61.606s, episode steps: 1834, steps per second:  30, episode reward: 35.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.006917, mae: 0.070677, mean_q: 0.080730, mean_eps: 0.083934\n",
            " 242529/250000: episode: 339, duration: 18.119s, episode steps: 541, steps per second:  30, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.006426, mae: 0.071410, mean_q: 0.080905, mean_eps: 0.079420\n",
            " 243151/250000: episode: 340, duration: 21.000s, episode steps: 622, steps per second:  30, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.937 [0.000, 5.000],  loss: 0.006890, mae: 0.072485, mean_q: 0.083060, mean_eps: 0.077208\n",
            " 243541/250000: episode: 341, duration: 13.126s, episode steps: 390, steps per second:  30, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.526 [0.000, 5.000],  loss: 0.005793, mae: 0.070427, mean_q: 0.083014, mean_eps: 0.075285\n",
            " 244170/250000: episode: 342, duration: 21.411s, episode steps: 629, steps per second:  29, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.006278, mae: 0.070668, mean_q: 0.081890, mean_eps: 0.073347\n",
            " 245376/250000: episode: 343, duration: 41.080s, episode steps: 1206, steps per second:  29, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.006238, mae: 0.071144, mean_q: 0.080497, mean_eps: 0.069866\n",
            " 246561/250000: episode: 344, duration: 39.838s, episode steps: 1185, steps per second:  30, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.006977, mae: 0.070807, mean_q: 0.080432, mean_eps: 0.065322\n",
            " 247249/250000: episode: 345, duration: 23.205s, episode steps: 688, steps per second:  30, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 3.036 [0.000, 5.000],  loss: 0.006794, mae: 0.070522, mean_q: 0.079544, mean_eps: 0.061757\n",
            " 248100/250000: episode: 346, duration: 28.755s, episode steps: 851, steps per second:  30, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.846 [0.000, 5.000],  loss: 0.006849, mae: 0.070538, mean_q: 0.081156, mean_eps: 0.058839\n",
            " 249325/250000: episode: 347, duration: 41.178s, episode steps: 1225, steps per second:  30, episode reward: 20.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.277 [0.000, 5.000],  loss: 0.006787, mae: 0.070448, mean_q: 0.079767, mean_eps: 0.054894\n",
            " 249912/250000: episode: 348, duration: 19.721s, episode steps: 587, steps per second:  30, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.006845, mae: 0.071331, mean_q: 0.081639, mean_eps: 0.051452\n",
            "done, took 6849.220 seconds\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 3.000, steps: 490\n",
            "Episode 2: reward: 4.000, steps: 509\n",
            "Episode 3: reward: 9.000, steps: 764\n",
            "Episode 4: reward: 9.000, steps: 628\n",
            "Episode 5: reward: 8.000, steps: 522\n",
            "Episode 6: reward: 1.000, steps: 438\n",
            "Episode 7: reward: 8.000, steps: 613\n",
            "Episode 8: reward: 4.000, steps: 417\n",
            "Episode 9: reward: 6.000, steps: 585\n",
            "Episode 10: reward: 7.000, steps: 528\n",
            "Episode 11: reward: 4.000, steps: 361\n",
            "Episode 12: reward: 4.000, steps: 395\n",
            "Episode 13: reward: 5.000, steps: 384\n",
            "Episode 14: reward: 13.000, steps: 956\n",
            "Episode 15: reward: 1.000, steps: 364\n",
            "Episode 16: reward: 2.000, steps: 528\n",
            "Episode 17: reward: 10.000, steps: 604\n",
            "Episode 18: reward: 2.000, steps: 498\n",
            "Episode 19: reward: 4.000, steps: 377\n",
            "Episode 20: reward: 7.000, steps: 528\n",
            "DUELING --> Reward promedio: 5.55\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Comparación de agentes: DQN baseline, Boltzmann, Double DQN, Dueling DQN\n",
        "\n",
        "import numpy as np\n",
        "import gym\n",
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Lambda, Add, Permute\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy, BoltzmannQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# === Constantes ===\n",
        "ENV_NAME = 'SpaceInvaders-v0'\n",
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "\n",
        "dqn_variants = {\n",
        "    'baseline': {'double_dqn': False, 'dueling': False, 'policy': EpsGreedyQPolicy()},\n",
        "    'boltzmann': {'double_dqn': False, 'dueling': False, 'policy': BoltzmannQPolicy()},\n",
        "    'double': {'double_dqn': True, 'dueling': False, 'policy': EpsGreedyQPolicy()},\n",
        "    'dueling': {'double_dqn': True, 'dueling': True, 'policy': EpsGreedyQPolicy()}\n",
        "}\n",
        "\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        img = Image.fromarray(observation).resize(INPUT_SHAPE).convert('L')\n",
        "        return np.array(img).astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        return batch.astype('float32') / 255.\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n",
        "\n",
        "def build_model(nb_actions, input_shape, dueling=False):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Permute((2, 3, 1))(inputs)\n",
        "    x = Conv2D(32, 8, strides=4, activation='relu')(x)\n",
        "    x = Conv2D(64, 4, strides=2, activation='relu')(x)\n",
        "    x = Conv2D(64, 3, strides=1, activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    if dueling:\n",
        "        value = Dense(512, activation='relu')(x)\n",
        "        value = Dense(1)(value)\n",
        "\n",
        "        advantage = Dense(512, activation='relu')(x)\n",
        "        advantage = Dense(nb_actions)(advantage)\n",
        "\n",
        "        advantage_mean = Lambda(lambda a: a - K.mean(a, axis=1, keepdims=True))(advantage)\n",
        "        q_values = Add()([value, advantage_mean])\n",
        "    else:\n",
        "        q_values = Dense(512, activation='relu')(x)\n",
        "        q_values = Dense(nb_actions)(q_values)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=q_values)\n",
        "\n",
        "def run_agent(name, config):\n",
        "    env = gym.make(ENV_NAME)\n",
        "    np.random.seed(123)\n",
        "    env.seed(123)\n",
        "    nb_actions = env.action_space.n\n",
        "\n",
        "    model = build_model(nb_actions, input_shape, dueling=config['dueling'])\n",
        "    memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "\n",
        "    if isinstance(config['policy'], EpsGreedyQPolicy):\n",
        "        policy = LinearAnnealedPolicy(config['policy'], attr='eps', value_max=1.0, value_min=0.05,\n",
        "                                       value_test=0.01, nb_steps=250000)\n",
        "    else:\n",
        "        policy = config['policy']\n",
        "\n",
        "    agent = DQNAgent(model=model, nb_actions=nb_actions, memory=memory,\n",
        "                     processor=AtariProcessor(), nb_steps_warmup=50000,\n",
        "                     enable_double_dqn=config['double_dqn'],\n",
        "                     target_model_update=50000, policy=policy, train_interval=4, gamma=0.995)\n",
        "\n",
        "    agent.compile(Adam(learning_rate=1e-4), metrics=['mae'])\n",
        "\n",
        "    # Callbacks y logs\n",
        "    weights_file = f'{name}_weights.h5f'\n",
        "    log_file = f'{name}_log.json'\n",
        "    callbacks = [\n",
        "        ModelIntervalCheckpoint(f'{name}_weights_{{step}}.h5f', interval=100000),\n",
        "        FileLogger(log_file, interval=100)\n",
        "    ]\n",
        "\n",
        "    agent.fit(env, nb_steps=250000, visualize=False, verbose=2, callbacks=callbacks)\n",
        "\n",
        "    agent.save_weights(weights_file, overwrite=True)\n",
        "    history = agent.test(env, nb_episodes=20, visualize=False)\n",
        "    rewards = history.history['episode_reward']\n",
        "    print(f\"{name.upper()} --> Reward promedio: {np.mean(rewards):.2f}\")\n",
        "\n",
        "    return log_file\n",
        "\n",
        "# Ejecutar todos los agentes\n",
        "log_files = {}\n",
        "for name, config in dqn_variants.items():\n",
        "    log_files[name] = run_agent(name, config)\n",
        "\n",
        "# Graficar resultados\n",
        "plt.figure(figsize=(12, 6))\n",
        "for name, log_file in log_files.items():\n",
        "    with open(log_file) as f:\n",
        "        log = json.load(f)\n",
        "        rewards = log['episode_reward']\n",
        "        episodes = list(range(1, len(rewards) + 1))\n",
        "        ma = np.convolve(rewards, np.ones(10)/10, mode='valid')\n",
        "        plt.plot(episodes[:len(ma)], ma, label=name)\n",
        "\n",
        "plt.title(\"Comparación de agents DQN\")\n",
        "plt.xlabel(\"Episodio\")\n",
        "plt.ylabel(\"Reward (media móvil)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1FtbEi88tp4",
        "outputId": "9845918b-fb74-482f-cf3d-a3fe039c46d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting gymnasium<1.2.0,>=0.29.1 (from stable-baselines3[extra])\n",
            "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.23.5)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.12.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.11.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.73.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.8.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.45.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (2.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->stable-baselines3[extra]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->stable-baselines3[extra]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->stable-baselines3[extra]) (2025.7.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.3.1)\n",
            "Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.0\n",
            "    Uninstalling gymnasium-1.2.0:\n",
            "      Successfully uninstalled gymnasium-1.2.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gymnasium-1.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.6.0\n",
            "Collecting sb3-contrib\n",
            "  Downloading sb3_contrib-2.6.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: stable_baselines3<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from sb3-contrib) (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.23.5)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.6.0->sb3-contrib) (3.0.2)\n",
            "Downloading sb3_contrib-2.6.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m682.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sb3-contrib\n",
            "Successfully installed sb3-contrib-2.6.0\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.11/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (1.15.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (1.23.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (1.6.0)\n",
            "Collecting atari-py~=0.2.0 (from gym[accept-rom-license,atari])\n",
            "  Downloading atari-py-0.2.9.tar.gz (540 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.6/540.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (11.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from gym[accept-rom-license,atari]) (4.11.0.86)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from atari-py~=0.2.0->gym[accept-rom-license,atari]) (1.17.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[accept-rom-license,atari]) (1.0.0)\n",
            "Building wheels for collected packages: atari-py\n",
            "  Building wheel for atari-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atari-py: filename=atari_py-0.2.9-cp311-cp311-linux_x86_64.whl size=2871718 sha256=3bb14d4fc4dad9cfa70282019ac1b4a1b0c40f5409c7699fcb9fff9a7736de7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/bb/c9/355a2560e9a75e6800cd54c37a19ca22badc1cf6a8b4a34c1b\n",
            "Successfully built atari-py\n",
            "Installing collected packages: atari-py\n",
            "  Attempting uninstall: atari-py\n",
            "    Found existing installation: atari-py 1.2.2\n",
            "    Uninstalling atari-py-1.2.2:\n",
            "      Successfully uninstalled atari-py-1.2.2\n",
            "Successfully installed atari-py-0.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3[extra]\n",
        "!pip install sb3-contrib\n",
        "!pip install gym[atari,accept-rom-license]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}